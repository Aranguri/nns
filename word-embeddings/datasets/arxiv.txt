### abstract ###
Point clouds are sets of points in two or three dimensions
Most kernel methods for learning on sets of points have not yet dealt with the specific geometrical invariances and practical constraints associated with point clouds in computer vision and graphics
In this paper, we present extensions of graph kernels for point clouds, which allow to use kernel methods for such objects as shapes, line drawings, or any three-dimensional point clouds
In order to design rich and numerically efficient kernels with as few free parameters as possible, we use kernels between covariance matrices and their factorizations on graphical models
We derive polynomial time dynamic programming recursions and  present applications to recognition of handwritten digits and Chinese characters from few training examples
### introduction ###
In recent years, kernels for structured data have been designed in many domains, such as bioinformatics~ CITATION , speech processing~ CITATION , text processing~ CITATION  and computer vision~ CITATION
They provide an elegant way of including known  a priori  information, by using directly the natural topological structure of objects
Using a priori knowledge through structured kernels have proved beneficial because it allows to reduce the number of training examples, and to re-use existing data representations that are already well developed by experts of those domains
In this paper, we propose a kernel between point clouds, with applications to classification of line drawings (such as handwritten digits~ CITATION  or Chinese characters~ CITATION ) or shapes~ CITATION
The natural geometrical structure of point clouds is hard to represent in a few real-valued features~ CITATION , in particular because of (a)  the required local or global invariances by rotation, scaling, and/or translation, (b) the lack of pre-established registrations of the point clouds (i e , points from one cloud are not matched to points from another cloud), and (c) the noise and occlusion that impose that only portions of two point clouds ought to be compared
Following one of the leading principles for designing kernels between structured data, we propose to look at all possible partial matches between two point clouds~ CITATION
More precisely, we assume that each point cloud has a graph structure (most often a neighborhood graph), and we consider recently introduced  graph kernels ~ CITATION
Intuitively, these kernels consider all possible subgraphs and compare and count the matching subgraphs
However, the set of subgraphs (or even the set of paths) has exponential size and cannot be efficiently described recursively; so larger sets of substructures are commonly used, eg , walks and tree-walks
As shown in \mysec{graphkernels}, by choosing appropriate substructures and fully factorized local kernels, efficient dynamic programming implementations allow to sum over an exponential number of substructures in polynomial time
The kernel thus provides an efficient and elegant way of considering very large feature spaces (see, eg ,~ CITATION )
However, in the context of computer vision, substructures correspond to matched sets of points, and dealing with local invariances imposes to use a local kernel that cannot be readily expressed as a product of separate terms for each pair of points, and the usual dynamic programming approaches cannot then be applied
The main contribution of this paper is to design a local kernel that is not fully factorized but can be instead factorized according to the graph underlying the substructure
This is naturally done through graphical models and the design of positive kernels for covariance matrices that factorize on graphical models (\mysec{GM})
With this novel local kernel, we derive new polynomial time dynamic programming recursions in \mysec{recursions}
In \mysec{simulations}, we present simulations on handwritten character recognition
### abstract ###
In this paper, we propose a spreading activation approach for collaborative filtering (SA-CF)
By using the opinion spreading process, the similarity between any users can be obtained
The algorithm has remarkably higher accuracy than the standard collaborative filtering (CF) using Pearson correlation
Furthermore, we introduce a free parameter  SYMBOL  to regulate the contributions of objects to user-user correlations
The numerical results indicate that decreasing the influence of popular objects can further improve the algorithmic accuracy and personality
We argue that a better algorithm should simultaneously require less computation and generate higher accuracy
Accordingly, we further propose an algorithm involving only the top- SYMBOL  similar neighbors for each target user, which has both less computational complexity and higher algorithmic accuracy \keywords{Recommendation systems; Bipartite network; Collaborative filtering }
### introduction ###
With the advent of the Internet, the exponential growth of the World-Wide-Web and routers confront people with an information overload  CITATION
We are facing too much data to be able to effectively filter out the pieces of information that are most appropriate for us
A promising way is to provide personal recommendations to filter out the information
Recommendation systems use the opinions of users to help them more effectively identify content of interest from a potentially overwhelming set of choices  CITATION
Motivated by the practical significance to the e-commerce and society, various kinds of algorithms have been proposed, such as correlation-based methods  CITATION , content-based methods  CITATION , the spectral analysis  CITATION , principle component analysis  CITATION , network-based methods  CITATION , and so on
For a review of current progress, see Ref
CITATION  and the references therein
One of the most successful technologies for recommendation systems, called  collaborative filtering  (CF), has been developed and extensively investigated over the past decade  CITATION
When predicting the potential interests of a given user, such approach first identifies a set of similar users from the past records and then makes a prediction based on the weighted combination of those similar users' opinions
Despite its wide applications, collaborative filtering suffers from several major limitations including system scalability and accuracy  CITATION
Recently, some physical dynamics, including mass diffusion  CITATION , heat conduction  CITATION  and trust-based model  CITATION , have found their applications in personal recommendations
These physical approaches have been demonstrated to be of both high accuracy and low computational complexity  CITATION
However, the algorithmic accuracy and computational complexity may be very sensitive to the statistics of data sets
For example, the algorithm presented in Ref
CITATION  runs much faster than standard CF if the number of users is much larger than that of objects, while when the number of objects is huge, the advantage of this algorithm vanishes because its complexity is mainly determined by the number of objects (see Ref
CITATION  for details)
In order to increase the system scalability and accuracy of standard CF, we introduce a network-based recommendation algorithm with spreading activation, namely SA-CF
In addition, two free parameters,  SYMBOL  and  SYMBOL  are presented to increase the accuracy and personality
### abstract ###
In this contribution, we propose a generic online (also sometimes called adaptive or recursive) version of the Expectation-Maximisation (EM) algorithm applicable to latent variable models of independent observations
Compared to the algorithm of  CITATION , this approach is more directly connected to the usual EM algorithm and does not rely on integration with respect to the complete data distribution
The resulting algorithm is usually simpler and is shown to achieve convergence to the stationary points of the Kullback-Leibler divergence between the marginal distribution of the observation and the model distribution at the optimal rate, \ie, that of the maximum likelihood estimator
In addition, the proposed approach is also suitable for conditional (or regression) models, as illustrated in the case of the mixture of linear regressions model {Keywords:} Latent data models, Expectation-Maximisation, adaptive algorithms, online estimation, stochastic approximation, Polyak-Ruppert averaging, mixture of regressions
### introduction ###
The EM (Expectation-Maximisation) algorithm  CITATION  is a popular tool for maximum-likelihood (or maximum a posteriori) estimation
The common strand to problems where this approach is applicable is a notion of  incomplete data , which includes the conventional sense of missing data but is much broader than that
The EM algorithm demonstrates its strength in situations where some hypothetical experiments yields  complete  data that are related to the parameters more conveniently than the measurements are
Problems where the EM algorithm has proven to be useful include, among many others, mixture of densities  CITATION , censored data models  CITATION , etc
The EM algorithm has several appealing properties
Because it relies on complete data computations, it is generally simple to implement: at each iteration,  (i)  the so-called  E-step  only involves taking expectation over the conditional distribution of the latent data given the observations and  (ii)  the  M-step  is analogous to complete data weighted maximum-likelihood estimation
Moreover,  (iii)  the EM algorithm naturally is an ascent algorithm, in the sense that it increases the (observed) likelihood at each iteration
Finally under some mild additional conditions,  (iv)  the EM algorithm may be shown to converge to a  stationary point  (\ie, a point where the gradient vanishes) of the log-likelihood  CITATION
Note that convergence to the maximum likelihood estimator cannot in general be guaranteed due to possible presence of multiple stationary points
When processing large data sets or data streams  however, the EM algorithm becomes impractical due to the requirement that the whole data be available at each iteration of the algorithm
For this reason, there has been a strong interest for online variants of the EM which make it possible to estimate the parameters of a latent data model without storing the data
In this work, we consider online algorithms for latent data models with independent observations
The dominant approach (see also Section~ below) to online EM-like estimation follows the method proposed by  CITATION  which consists in using a  stochastic approximation algorithm, where the parameters are updated after each new observation using the gradient of the incomplete data likelihood weighted by the complete data Fisher information matrix
This approach has been used, with some variations, in many different applications (see, \eg,  CITATION ); a proof of convergence was given by  CITATION
In this contribution, we propose a new online EM algorithm that sticks more closely to the principles of the original (batch-mode) EM algorithm
In particular, each iteration of the proposed algorithm is decomposed into two steps, where the first one is a stochastic approximation version of the E-step aimed at incorporating the information brought by the newly available observation, and, the second step consists in the maximisation program that appears in the M-step of the traditional EM algorithm
In addition, the proposed algorithm does not rely on the complete data information matrix, which has two important consequences: firstly, from a practical point of view, the evaluation and inversion of the information matrix is no longer required, secondly, the convergence of the procedure does not rely on the implicit assumption that the model is  well-specified , that is, that the data under consideration is actually generated by the model, for some unknown value of the parameter
As a consequence, and in contrast to previous work, we provide an analysis of the proposed algorithm also for the case where the observations are not assumed to follow the fitted statistical model
This consideration is particularly relevant in the case of %regression, or conditional missing data models, a simple case of which is used as an illustration of the proposed online EM algorithm
Finally, it is shown that, with the additional use of Polyak-Ruppert averaging, the proposed approach converges to the stationary points of the limiting normalised log-likelihood criterion (\ie, the Kullback-Leibler divergence between the marginal density of the observations and the model pdf) at a rate which is optimal
The paper is organised as follows: In Section~, we review the basics of the EM and associated algorithms and introduce the proposed approach
The connections with other existing methods are discussed at the end of Section~ and a simple example of application is described in Section~
Convergence results are stated in Section~, first in term of consistency (Section~) and then of convergence rate (Section~), with the corresponding proofs given in Appendix~
Finally in Section~, the performance of this approach is illustrated in the context of mixture of linear regressions
### abstract ###
It is hard to exaggerate the role of economic aggregators --- functions that summarize numerous and / or heterogeneous data --- in economic models  since the early XX SYMBOL  century
In many cases, as witnessed by the pioneering works of Cobb and Douglas, these functions were information quantities tailored to economic theories, ie they were built to fit economic phenomena
In this paper, we look at these functions from the complementary side: information
We use a recent toolbox built on top of a vast class of distortions coined by Bregman, whose application field rivals metrics' in various subfields of mathematics
This toolbox makes it possible to find  the quality of an aggregator (for consumptions, prices, labor, capital, wages, etc ), from the standpoint  of the information it carries
We prove a rather striking result
From the informational standpoint, well-known economic aggregators do belong to the  optimal  set
As common economic assumptions enter the analysis, this large set shrinks, and it essentially ends up  exactly fitting  either CES, or Cobb-Douglas, or both
To summarize, in the relevant economic contexts, one could not have crafted better some aggregator from the information standpoint
We also discuss global economic behaviors of optimal information aggregators in general, and present a brief panorama of  the links between economic and information aggregators \\  Keywords  : Economic Aggregators, CES, Cobb-Douglas, Bregman divergences
### introduction ###
Since the end of the XIX SYMBOL  century and the birth of the ``neo-classical'' school,  mathematics have played a growing role in economics
With the works of L\'eon Walras,  the question of aggregation of the behavior of many individuals has risen and become  central in the economic theory
In order to represent as well as possible the evolution  of these aggregate variables, some mathematical functions have been proposed and become  very famous in the economic literature
One of the most famous neo-classical function is the Cobb-Douglas  CITATION
This  function is of particular interest, since it allows for perfect substitutability between the  different inputs it depends on
Another well-known ``linear'' function was later formulated  by Leontief  CITATION , in which inputs are conversely complementary
The choice of such a function  to describe the production process has very strong implications at the macroeconomic level, as  illustrated by many results found by Keynesians economics in the literature on growth theory
But beyond these different aggregate functions, one of the most recently built and well-known one is  the constant elasticity of substitution (CES) function elaborated by Arrow et al CITATION
Indeed, in the Cobb-Douglas production function, the elasticity of substitution of capital for  labor is fixed to unity
This implies that a one percent increase in the capital stock implies an  equal one percent fall in labor inputs in order to maintain a constant production level, given the  structure of relative prices
On the contrary, the CES function allows this elasticity to lie between  zero and infinity, but to stay fixed at that number along and across the isoquants, whatever the  quantities of inputs that are used in the production process
The main advantage exhibited by the  CES function is that it encompasses the Cobb-Douglas, the Leontief and the Linear production  functions, which are in fact limit and thus particular cases of it
Nevertheless, one of the  reasons economists have kept on using simpler functions such as the Cobb-Douglas one is the  heavy calculus to which the CES function often leads, especially at the point where models have to be closed
In a seminal work, Douglas in  CITATION  highlights the importance of the progresses in the field of statistical  information in the genesis of his essay
Pioneering works of Cobb and Douglas  CITATION , and Arrow  et al CITATION , underline the inductive nature of the inception of their respective functions, as the purpose was to fit as best as possible information quantities (aggregators) to observed economic phenomena
In this paper, we take a deductive route paved with a rigorous information material, to derive these fundamental quantities based on two assumptions:   an aggregator should always be as informative as possible with respect to the data it summarizes (prices,  consumptions, wages, capital, labor, etc );  an aggregator might be require to satisfy standard economic assumptions, relying on aggregator dualities (prices / consumptions, wages / labor, etc ), elasticities, marginal rates of substitutions, returns to scale, etc
The starting point of our work is a class of distortions coined in the sixties by Bregman  CITATION , in the context of convex programming
Though they were born four decades ago, it was only much later that  these distortions literally spread out to other fields, including statistics, signal processing and  classification  CITATION , fields where they had to become undeniably central
It was even later  that was discovered their broad applicability, with an  axiomatization that makes it possible to relate them to metrics and their spawns  CITATION
Very roughly,  Bregman divergences  are non-negative functions that meet the same identity of indiscernibles condition as metrics, and rely on a third assumption about the existence of a particular aggregator which minimizes the total distortion to a set
This last condition, which can be rephrased as a maximum likelihood condition, makes this aggregator the  most informative   quantity about the data, and we call it a  Low Distortion Aggregator  (LDA)
In this paper, our contribution is threefold
First, we make a clear partition of economic aggregators with respect to information, as we show that some  are  LDAs (CES, Cobb-Douglas), some are limit cases of LDAs (Leontief), and some are neither (Mitscherlich-Spillman-von Th{\"u}nen)
Without more assumptions, the set of all LDAs is huge, yet we show that global trends of economic relevance can be easily shown for all, such as on marginal rates of substitution, and the set can be quite  easily drilled down for aggregators with general behaviors, such as concavity or convexity
This, in fact, is our last contribution
Our main contribution is to show that, when we plug in various standard economic assumptions (see above), the set of all LDAs reduces to a particular subset which  precisely  matches CES, Cobb-Douglas, or both sets
This novel advocacy for the use of these popular aggregators brings a very strong information-theoretic rationale to their ``economic'' existence
The remaining of the paper is structured as follows
Section 2 presents LDAs and their main properties
In Section 3, we relate common economic aggregators to LDAs
Section 4 discusses additional properties of LDAs
A last section concludes the paper, with avenues for future research
In order not to laden the paper's body, all proofs have been postponed to an appendix
### abstract ###
In this paper we propose a novel algorithm, factored value iteration (FVI), for the approximate solution of factored Markov decision processes (fMDPs)
The traditional approximate value iteration algorithm is modified in two ways
For one, the least-squares projection operator is modified so that it does not increase max-norm, and thus preserves convergence
The other modification is that we uniformly sample polynomially many samples from the (exponentially large) state space
This way, the complexity of our algorithm becomes polynomial in the size of the fMDP description length
We prove that the algorithm is convergent
We also derive an upper bound on the difference between our approximate solution and the optimal one, and also on the error introduced by sampling
We analyze various projection operators with respect to their computation complexity and their convergence when combined with approximate value iteration \keywords{factored Markov decision process, value iteration, reinforcement learning}
### introduction ###
Markov decision processes (MDPs) are extremely useful for formalizing and solving sequential decision problems, with a wide repertoire of algorithms to choose from  CITATION
Unfortunately, MDPs are subject to the `curse of dimensionality'  CITATION : for a problem with  SYMBOL  state variables, the size of the MDP grows exponentially with  SYMBOL , even though many practical problems have polynomial-size descriptions
Factored MDPs (fMDPs) may rescue us from this explosion, because they offer a more compact representation  CITATION
In the fMDP framework, one assumes that dependencies can be factored to several easy-to-handle components
For MDPs with known parameters, there are three basic solution methods (and, naturally, countless variants of them): value iteration, policy iteration and linear programming (see the books of Sutton \& Barto  CITATION  or Bertsekas \& Tsitsiklis  CITATION  for an excellent overview)
Out of these methods, linear programming is generally considered less effective than the others
So, it comes as a surprise that all effective fMDPs algorithms, to our best knowledge, use linear programming in one way or another
Furthermore, the classic value iteration algorithm is known to be divergent when function approximation is used  CITATION , which includes the case of fMDPs, too
In this paper we propose a variant of the approximate value iteration algorithm for solving fMDPs
The algorithm is a direct extension of the traditional value iteration algorithm
Furthermore, it avoids computationally expensive manipulations like linear programming or the construction of decision trees
We prove that the algorithm always converges to a fixed point, and that it requires polynomial time to reach a fixed accuracy
A bound to the distance from the optimal solution is also given
In Section  we review the basic concepts of Markov decision processes, including the classical value iteration algorithm and its combination with linear function approximation
We also give a sufficient condition for the convergence of approximate value iteration, and list several examples of interest
In Section  we extend the results of the previous section to fMDPs and review related works in Section~
Conclusions are drawn in Section
### abstract ###
We prove that the optimal assignment kernel, proposed recently as an attempt to embed labeled graphs and more generally tuples of basic data to a Hilbert space, is in fact not always positive definite
### introduction ###
Let  SYMBOL  be a set, and  SYMBOL  a symmetric function that satisfies, for any  SYMBOL  and any  SYMBOL  and  SYMBOL :  SYMBOL  SYMBOL SYMBOL SYMBOL k SYMBOL SYMBOL SYMBOL \inpH{\cdot,\cdot}{\Hcal} SYMBOL \Phi:\Xcal\rightarrowSYMBOL x,x'\inSYMBOL SYMBOL SYMBOL k$ through (), because they only access data through inner products, hence through the kernel
This ``kernel trick'' allows, for example, to perform supervised classification or regression on strings or graphs with state-of-the-art statistical methods as soon as a positive definite kernel for strings or graphs is defined
Unsurprisingly, this has triggered a lot of activity focused on the design of specific positive definite kernels for specific data, such as strings and graphs for applications in bioinformatics in natural language processing  CITATION
Motivated by applications in computational chemistry,  CITATION  proposed recently a kernel for labeled graphs, and more generally for structured data that can be decomposed into subparts
The kernel, called  optimal assignment kernel , measures the similarity between two data points by performing an optimal matching between the subparts of both points
It translates a natural notion of similarity between graphs, and can be efficiently computed with the Hungarian algorithm
However, we show below that it is in general not positive definite, which suggests that special care may be needed before using it with kernel methods
It should be pointed out that not being positive definite is not necessarily a big issue for the use of this kernel in practice
First, it may in fact be positive definite when restricted to a particular set of data used in a practical experiment
Second, other non positive definite kernels, such as the sigmoid kernel, have been shown to be very useful and efficient in combination with kernel methods
Third, practitioners of kernel methods have developed a variety of strategies to limit the possible dysfunction of kernel methods when non positive definite kernels are used, such as projecting the Gram matrix of pairwise kernel values on the set of positive semidefinite matrices before processing it
The good results reported on several chemoinformatics benchmark in  CITATION  indeed confirm the usefulness of the method
Hence our message in this note is certainly not to criticize the use of the optimal assignment kernel in the context of kernel methods
Instead we wish to warn that in some cases, negative eigenvalues may appear in the Gram matrix and specific care may be needed, and simultaneously to contribute to the limitation of error propagation in the scientific litterature
### abstract ###
Kolmogorov argued that the concept of information  exists also in problems with no underlying stochastic  model (as Shannon's information representation) for instance,  the information contained in an algorithm or in the genome
He introduced a combinatorial notion of entropy  and information  SYMBOL   conveyed by a binary string   SYMBOL  about the unknown value of a variable  SYMBOL
The current paper poses the following questions: what is the relationship between the information conveyed by   SYMBOL  about  SYMBOL  to  the  description complexity of   SYMBOL
is there a notion of cost of information
are there limits on how efficient   SYMBOL  conveys information
To answer these questions Kolmogorov's definition is extended and a new concept  termed  information width  which is similar to  SYMBOL -widths in approximation theory is introduced
Information of any input  source, eg , sample-based, general side-information or a hybrid of both can be evaluated by a single common formula
An application to the space of binary functions is considered
### introduction ###
Kolmogorov  CITATION  sought for a measure of information of  `finite objects'
He considered three approaches, the so-called {combinatorial}, {probabilistic} and {algorithmic}
The probabilistic approach corresponds to the well-established definition of the Shannon entropy which applies to  stochastic settings where an `object' is represented by a random variable
In this setting,  the entropy of an object and the  information conveyed by one object about another  are well defined
Here it is necessary to view an object (or a finite binary string) as a realization of a stochastic process
While this has often been used, for instance, to measure the information of  English texts  CITATION  by assuming some finite-order Markov process, it is not obvious that such modeling of finite objects provides a natural and a universal representation of information as  Kolmogorov states in  CITATION :  What real meaning is there, for example, in asking how much information is contained in (the book) "War and Peace"
Is it reasonable to


postulate some probability distribution for this set
Or, on the other hand, must we assume that the individual scenes in this book form a random sequence with stochastic relations that damp out quite rapidly over a distance of several pages
These questions  led Kolmogorov to  introduce an alternate  non-probabilistic and algorithmic notion  of the  information contained in a finite binary string
He defined  it as the length of the minimal-size program that can compute the string
This has been later developed into  the  so-called   Kolmogorov Complexity  field    CITATION
In the combinatorial approach,  Kolmogorov investigated another non stochastic measure of information  for an object  SYMBOL
Here  SYMBOL  is taken to be any element in  a finite space  SYMBOL  of objects
In  CITATION  he defines the `entropy' of    SYMBOL   as  SYMBOL  where  SYMBOL  denotes the cardinality of  SYMBOL  and all logarithms henceforth are taken with respect to  SYMBOL
As he writes, if the value  of   SYMBOL  is known to be  SYMBOL  then this much entropy  is `eliminated' by providing  SYMBOL  bits of `information'
Let  SYMBOL  be a general finite domain and consider a set   AR that consists of all `allowed' values of pairs  SYMBOL
The entropy of  SYMBOL  is defined as   SYMBOL  where \( \Pi_\bY(A)  \{y\bY: (x,y)A \text{ for some } x\bX\} \) denotes the projection of   SYMBOL  on  SYMBOL
Consider the restriction of  SYMBOL  on  SYMBOL  based on  SYMBOL  which is defined as  Y_x =\{y\bY: (x,y) A\}, \; x\in\Pi_\bX(A) then the conditional combinatorial  entropy of  SYMBOL  given  SYMBOL  is defined as  H(\bY|x) = |Y_x|
Kolmogorov  defines  the  information conveyed by   SYMBOL  about   SYMBOL  by the quantity   I(x:\bY) = H(\bY) - H(\bY|x)
Alternatively, we may view  SYMBOL  as the information that a set  SYMBOL  conveys about another set  SYMBOL  satisfying  SYMBOL
In this case we  let the domain be  SYMBOL ,  SYMBOL   is the set of permissible pairs  SYMBOL  and  the information is defined as  I(Y_x: \bY) = \log|\Pi_\bY(A)|^2 - \log(|Y_x| |\Pi_\bY(A)|)
We will refer to this representation as Kolmogorov's  information between  sets
Clearly,  SYMBOL
In many applications,  knowing an input  SYMBOL   only conveys partial information about an unknown value  SYMBOL
For instance, in  problems  which involve  the analysis of algorithms on discrete classes of structures,  such as sets of binary vectors or functions on a finite domain, an algorithmic search is made for some optimal element in this set based only on partial information
One such paradigm is the area of  statistical pattern recognition  CITATION   where an unknown target, i e , a pattern classifier, is seeked  based on the information contained in a finite sample and some side-information
This information is implicit in the particular set of classifiers that form  the possible hypotheses
For example, let   SYMBOL  be a positive integer and   consider the domain  SYMBOL
Let  SYMBOL  be the set of all binary functions  SYMBOL
The power set  SYMBOL  represents  the family of all  sets  SYMBOL
Repeating this, we have   SYMBOL   as the collection of all properties of sets  SYMBOL , i e , a  property  is a set whose elements are  subsets  SYMBOL  of  SYMBOL
We  denote by  SYMBOL  a property of a set  SYMBOL  and write  SYMBOL
Suppose that we seek to know  an unknown target function  SYMBOL
Any  partial  information about    SYMBOL  which may be expressed by  SYMBOL  can effectively reduce the search space
It has been a long-standing problem  to try to quantify  the value of general side-information for learning (see  CITATION  and references therein)
We assert  that Kolmogorov's combinatorial framework may serve as a basis
We let   SYMBOL  index possible properties  SYMBOL   of  subsets  SYMBOL  and the  object  SYMBOL  represent the unknown  target  SYMBOL   which may be any element of  SYMBOL
Side information is then represented by knowing certain properties of sets that contain the  target
The input  SYMBOL  conveys that  SYMBOL  is in some subset  SYMBOL   that has a certain property  SYMBOL
In principle, Kolmogorov's quantity  SYMBOL   should  serve as the value of information in  SYMBOL  about the unknown value of  SYMBOL
However,  its current form ()   is not general enough since it requires that the target  SYMBOL  be restricted to a fixed set  SYMBOL  on knowledge of   SYMBOL
To see this, suppose  SYMBOL  is in a set that satisfies property  SYMBOL
Consider the collection  SYMBOL  of all subsets  SYMBOL  that have this property
Clearly,  SYMBOL  hence we may first consider   SYMBOL  but some useful information  implicit in this collection is ignored as we now show: consider two properties  SYMBOL  and  SYMBOL   with corresponding index sets  SYMBOL  and  SYMBOL  such that  SYMBOL
Suppose that most of the sets  SYMBOL ,  SYMBOL  are small while the sets  SYMBOL ,  SYMBOL  are large
Clearly, property  SYMBOL  is more informative than  SYMBOL  since starting with  knowledge that   SYMBOL  is in  a set that satisfies it should take (on average)  less additional information (once the particular set  SYMBOL   becomes known) in order to completely specify  SYMBOL
If, as above, we let  SYMBOL  and  SYMBOL  then we have   SYMBOL  which wrongly implies that both properties are equally informative
Knowing   SYMBOL  provides implicit information associated with  the collection of possible sets  SYMBOL ,   SYMBOL
This implicit structural information  cannot be represented in  ()
### abstract ###
0 3cm Consider a class  SYMBOL  of  binary functions  SYMBOL   on a finite interval  SYMBOL
Define the  sample width  of  SYMBOL   on a finite subset (a sample)  SYMBOL  as \( \w_S(h) \min_{xS} |\w_h(x)| \) where  SYMBOL
Let   SYMBOL  be the space of all samples in  SYMBOL  of cardinality  SYMBOL   and consider  sets  of wide samples, ie ,  hypersets  which are defined as \( A_{\beta, h} = \{S\mathbb{S}_\ell: \w_{S}(h) \beta\} \) Through an application of the Sauer-Shelah result on the density of sets an upper estimate is obtained on the growth function (or trace) of  the class   SYMBOL ,  SYMBOL , ie , on the number of possible dichotomies obtained by intersecting all hypersets with a fixed collection of samples  SYMBOL  of  cardinality  SYMBOL
The estimate is  SYMBOL
### introduction ###
For any logical expression  SYMBOL   denote by  SYMBOL  the indicator function which takes the value  SYMBOL  or  SYMBOL  whenever  the statement  SYMBOL  is true or false, respectively
Let  SYMBOL  be any fixed positive integer and define  the space  SYMBOL   of all samples  SYMBOL  of size  SYMBOL
On  SYMBOL   consider  sets  of wide samples, i e ,  SYMBOL  We refer to such sets as  hypersets
It will be convenient to associate with these sets the indicator functions on  SYMBOL  which are denoted as  SYMBOL  These are referred to as  hyperconcepts  and we may write   SYMBOL  for brevity
For any fixed width parameter  SYMBOL   define the  hyperclass   SYMBOL } In words,  SYMBOL  consists of all  sets of subsets  SYMBOL  of cardinality  SYMBOL   on which the corresponding binary functions  SYMBOL  are wide by at least  SYMBOL
The aim of the paper is to compute the complexity of the hyperclass  SYMBOL  that corresponds to the class  SYMBOL
Since the domain  SYMBOL  is infinite then so is  SYMBOL  hence one cannot simply measure its cardinality
Instead  we  apply a standard combinatorial measure of the complexity of a family of sets as follows: suppose  SYMBOL  is  a general domain and  SYMBOL  is  an infinite  class of subsets of  SYMBOL
For  any subset  SYMBOL  let  \Gamma_\mG(S) |\mG_{|S}| where  SYMBOL
The   growth function   (see for instance  CITATION )  is defined as  SYMBOL  It measures the rate in which the number of dichotomies obtained by intersecting subsets  SYMBOL  of  SYMBOL  with a finite set  SYMBOL   increases as a function of the cardinality  SYMBOL  of  SYMBOL  in the maximal case (it is  also called the trace of  SYMBOL  in  CITATION )
Since we are interested in hypersets as opposed to simple sets  SYMBOL  (as above) then we consider the trace on a finite  collection  SYMBOL  of samples (instead of a finite sample  SYMBOL  as above)
It will be convenient to define  the cardinality of such a collection as the cardinality of the union of its component sets, i e , for any given finite collection  SYMBOL  let  |\zeta| = \left|\bigcup_{S: S\in\zeta} S\right| and we use   SYMBOL  to denote   a possible value of  SYMBOL
As a measure of complexity of   SYMBOL  we  compute the growth as a function of  SYMBOL , i e SYMBOL
### abstract ###
We study the problem of partitioning a small sample of  SYMBOL  individuals  from a mixture of  SYMBOL  product distributions over a Boolean cube  SYMBOL   according to their distributions
Each distribution is described by a  vector of allele frequencies in  SYMBOL
Given two distributions, we use  SYMBOL  to denote the average  SYMBOL   distance in frequencies across  SYMBOL  dimensions,  which measures the statistical divergence  between them
We study the case assuming that bits are independently distributed  across  SYMBOL  dimensions
This work demonstrates that, for a balanced input instance for  SYMBOL , a certain graph-based optimization function returns the correct partition with  high probability, where a weighted graph  SYMBOL  is formed over  SYMBOL  individuals,  whose pairwise hamming distances between their corresponding bit vectors define the edge weights, so long as  SYMBOL  and   SYMBOL
The function computes a maximum-weight balanced cut of  SYMBOL ,  where the weight of a cut is the sum of the weights across all edges in the cut
This result demonstrates a nice property in the high-dimensional feature space: one can trade off the number of features that are required with the size  of the sample to accomplish certain tasks like clustering
### introduction ###
We explore a type of classification problem that arises in the context of computational biology
The problem is that we are given a small sample of size  SYMBOL , eg , DNA of  SYMBOL  individuals, each described by the values  of  SYMBOL   features  or  markers , eg , SNPs (Single Nucleotide Polymorphisms),  where  SYMBOL
Features have slightly different frequencies depending on which population the  individual belongs to, and are assumed to be independent of each other
Given the population of origin of an individual, the genotype (represented as a bit vector in this paper) can be reasonably assumed to be generated by drawing  alleles independently from the appropriate distribution
The objective we consider is to minimize the number of features  SYMBOL , and thus total data size  SYMBOL , to correctly  classify the individuals in the sample according to their population of origin,  given any  SYMBOL
We describe  SYMBOL  and  SYMBOL  as a function of the ``average quality''   SYMBOL  of the features
Throughout the paper, we use  SYMBOL  and  SYMBOL  as  shorthands for  SYMBOL  and  SYMBOL  respectively
We first describe a general mixture model that we use in this paper
The same model was previously used  in~ CITATION  and ~ CITATION  {Statistical Model:} We have   SYMBOL  probability spaces  SYMBOL  over the set  SYMBOL
Further, the components ( features ) of  SYMBOL  are independent and  SYMBOL   ( SYMBOL ,  SYMBOL )
Hence, the probability spaces  SYMBOL  comprise the distribution of the features for each of the  SYMBOL  populations
Moreover, the input of the algorithm consists of  a collection ( mixture ) of  SYMBOL  unlabeled samples,  SYMBOL  points  from  SYMBOL , and the algorithm is to determine for each data point from which of  SYMBOL  it was chosen
In general we do  not  assume that  SYMBOL  are revealed to the algorithm; but we do require some bounds on their relative sizes
An important parameter of the probability ensemble  SYMBOL  is the  measure of divergence   between any two distributions
Note that  SYMBOL  provides a lower bound on the Euclidean distance  between the means of any two distributions and represents their separation
Further, let  SYMBOL  (so if the populations were balanced we would have  SYMBOL  of each type)
This paper proves the following theorem which gives a sufficient condition for a  balanced ( SYMBOL ) input instance when  SYMBOL
Variants of the above theorem, based on a model that allows two random draws at each dimension for all points, are given in~ CITATION  and ~ CITATION
The cleverness there is the construction of a diploid score at each dimension,  given any  pair of individuals , under the assumption that two random bits can be  drawn from the same distribution at each dimension
In expectation, diploid scores are higher among pairs from different groups  than for pairs in the same group across all  SYMBOL  dimensions
In addition,~ CITATION  shows that when  SYMBOL ,  given two bits from each dimension, one can always classify for any size of  SYMBOL ,  for unbalanced cases with any number of mixtures, using essentially connected  component based algorithms, given the weighted graph as in described in  Theorem~
The key contribution of this paper is to show new ideas that we use to  accomplish the goal of clustering with the same amount of features,  while requiring only one random bit at each dimension
While some ideas and proofs for Theorem~  in Section~ have appeared in~ CITATION , modifications for  handling a single bit at each dimension are ubiquitous throughout the proof
Hence we contain the complete proof in this paper nonetheless to give a  complete exposition
Finding a max-cut is computationally intractable;  a hill-climbing algorithm was given in~ CITATION  to partition a balanced  mixture, with a stronger requirement on  SYMBOL , given any  SYMBOL ,  as the middle green curve in Figure~ shows
Two simpler algorithms using spectral techniques were constructed  in~ CITATION , attempting to reproduce conditions above
Both spectral algorithms in~ CITATION  achieve the bound established by Theorem~ without requiring the input instances being balanced, and work for cases when  SYMBOL  is a constant; However, they require  SYMBOL , even when  SYMBOL  and the input instance  is balanced, as the vertical line in Figure~ shows
Note that when  SYMBOL , i e , when we have enough sample from  each distribution,  SYMBOL  becomes the only requirement  in Theorem~
Exploring the tradeoffs between  SYMBOL  and  SYMBOL , when  SYMBOL  is small, as in  Theorem~ in algorithmic design is both of  theoretical interests and practical value }                                                                                                                                                                                                                                                                                                                                                                                                                                           long-lemma
### abstract ###
We address the problem of reinforcement learning in which observations may exhibit an arbitrary form of stochastic dependence on past observations and actions
The task for an agent is to attain the  best possible asymptotic reward where the true generating environment is unknown but belongs to a known countable family of environments
We find some sufficient conditions on the class of  environments under which an agent exists which attains the best asymptotic reward for any environment in the class
We analyze how tight these conditions are and how they relate to different probabilistic assumptions known in reinforcement learning and related fields, such as Markov Decision Processes and mixing conditions
### introduction ###
Many real-world ``learning'' problems (like learning to drive a car or playing a game) can be modelled as an agent  SYMBOL  that interacts with an environment  SYMBOL  and is (occasionally) rewarded for its behavior
We are interested in agents which perform well in the sense of having high long-term reward, also called the value  SYMBOL  of agent  SYMBOL  in environment  SYMBOL
If  SYMBOL  is known, it is a pure (non-learning) computational problem to determine the optimal agent  SYMBOL
It is far less clear what an ``optimal'' agent means, if  SYMBOL  is unknown
A reasonable objective is to have a single policy  SYMBOL  with high value simultaneously in many environments
We will formalize and call this criterion  self-optimizing  later
Reinforcement learning, sequential decision theory,  adaptive control theory, and active expert advice, are theories dealing with this problem
They overlap but have different core focus: Reinforcement learning algorithms  CITATION  are developed to learn  SYMBOL  or directly its value
Temporal difference learning is computationally very efficient, but has slow asymptotic guarantees (only) in (effectively) small observable MDPs
Others have faster guarantee in finite state MDPs  CITATION
There are algorithms   CITATION   which are optimal for any finite connected POMDP, and this is apparently the largest class of environments considered
In sequential decision theory, a Bayes-optimal agent  SYMBOL  that maximizes  SYMBOL  is considered, where  SYMBOL  is a mixture of environments  SYMBOL  and  SYMBOL  is a class of environments that contains the true environment  SYMBOL   CITATION
Policy  SYMBOL  is self-optimizing in an arbitrary class  SYMBOL , provided  SYMBOL  allows for self-optimizingness  CITATION
Adaptive control theory  CITATION  considers very simple (from an AI perspective) or special systems (e g \ linear with quadratic loss function), which sometimes allow computationally and data efficient solutions
Action with expert advice  CITATION  constructs an agent (called master) that performs nearly as well as the best agent (best expert in hindsight) from some class of experts, in  any  environment  SYMBOL
The important special case of passive sequence prediction in arbitrary unknown environments, where the actions=predictions do not affect the environment is comparably easy  CITATION
The difficulty in active learning problems can be identified (at least, for countable classes) with  traps  in the environments
Initially the agent does not know  SYMBOL , so has asymptotically to be forgiven in taking initial ``wrong'' actions
A well-studied such class are ergodic MDPs which guarantee that, from any action history, every state can be (re)visited  CITATION
The aim of this paper is to characterize as general as possible classes  SYMBOL  in which self-optimizing behaviour is possible, more general than POMDPs
To do this we need to characterize classes of environments that forgive
For instance, exact state recovery is unnecessarily strong; it is sufficient being able to recover high rewards, from whatever states
Further, in many real world problems there is no information available about the ``states'' of the environment (e g \ in POMDPs) or the environment may exhibit long history dependencies
Rather than trying to model an environment (e g by MDP) we try to identify the conditions sufficient for learning
Towards this aim, we propose to consider only environments in which, after any arbitrary finite sequence of actions, the best value is still achievable
The performance criterion here is asymptotic average reward
Thus we consider such environments for which there exists a policy whose asymptotic average reward exists and upper-bounds asymptotic average reward of any other policy
Moreover, the same property should hold after any finite sequence of actions has been taken (no traps)
Yet this property in itself is not sufficient for identifying optimal behavior
We require further that, from any sequence of  SYMBOL  actions, it is possible to return to the optimal level of reward in  SYMBOL  steps (The above conditions will be formulated in a probabilistic form ) Environments which possess this property are called  (strongly) value-stable
We show that for any countable class of value-stable environments there exists a policy which achieves best possible value in any of the environments from the class (i e is  self-optimizing  for this class)
We also show that strong value-stability is in a certain sense necessary
We also consider examples of environments which possess strong value-stability
In particular, any ergodic MDP can be easily shown to have this property
A  mixing-type condition which implies value-stability is also demonstrated
Finally, we provide a construction allowing to build  examples of  value-stable environments which are not isomorphic to a finite POMDP, thus demonstrating that the class of value-stable environments is quite general
It is important in our argument that the class of environments for which we seek a self-optimizing policy is countable, although the class of all value-stable environments is uncountable
To find a set of  conditions necessary and sufficient for learning which do not rely on countability of the class is yet an open problem
However, from a computational perspective countable classes are sufficiently large (e g \ the class of all computable probability measures is countable)
The paper is organized as follows
Section~ introduces necessary notation of the agent framework
In Section~ we define and explain the notion of value-stability, which is central in the paper
Section~ presents the theorem about self-optimizing policies for classes of value-stable environments, and illustrates the  applicability of the theorem by providing examples of strongly value-stable environments
In Section~ we discuss necessity of the conditions of the main theorem
Section~ provides some discussion of the results and an outlook to future research
The formal proof of the main theorem is given in the appendix, while Section~ contains only intuitive explanations
### abstract ###
We propose a novel model for nonlinear dimension reduction motivated by the probabilistic formulation of principal component analysis
Nonlinearity is achieved by specifying different transformation matrices at different locations of the latent space and smoothing the transformation using a Markov random field type prior
The computation is made feasible by the recent advances in sampling from von Mises-Fisher distributions
### introduction ###
\PARstart{P}{rincipal} component analysis (PCA) is an old statistical technique for unsupervised dimension reduction
It is often used for exploratory data analysis with the objective of understanding the structure of the data
PCA aims to represent the high dimensional data points with low-dimensional representers commonly called latent variables, which can be used for visualization, data compression etc
Sometimes PCA is also used as a preprocessing step before regression  CITATION  or clustering  CITATION
In these context, however, PCA typically does not have satisfying performance due to the ignorance of subsequent analysis
We denote the original high dimensional data by  SYMBOL , where  SYMBOL
Note that the superscript  SYMBOL  is used to denote transposition so that  SYMBOL  is a column vector
We assume the data are already centered so that  SYMBOL
One common definition of PCA is that of taking a linear combination of the components of  SYMBOL :  SYMBOL  where  SYMBOL  is the weighting coefficient of the  SYMBOL -th covariate
This can be written as   SYMBOL } where  SYMBOL
We take  SYMBOL  so that () represents a projection onto the linear subspace spanned by  SYMBOL
Given  SYMBOL  and  SYMBOL , the optimal linear reconstruction of  SYMBOL  is given by  SYMBOL
We want  SYMBOL  to be a good representation of the original  SYMBOL
Thus we aim to minimize  SYMBOL
It can be shown that the minimizing  SYMBOL  is the eigenvector of  SYMBOL  associated with its largest eigenvalue, called the first principal component and denoted by  SYMBOL
Similarly, we can define  SYMBOL  principal components  SYMBOL  as the minimizer with respect to  SYMBOL  of the total squared reconstruction error  SYMBOL , where  SYMBOL ,  SYMBOL , and  SYMBOL  is the projection of  SYMBOL  onto the subspace spanned by the columns of  SYMBOL , the principal components
PCA is a linear procedure since the reconstruction is based on a linear combination of the principal components
Several nonlinear extensions have been proposed
The most famous one in the statistical literature is the principal curves proposed in  CITATION
The principal curve is defined as the curve such that each point on the curve is the center of all the data points whose projection onto the curve is that point
Thus visually the principal curve is defined as the curve that passes through the ``middle" of the data points
Although conceptually appealing, the computational constraint makes it difficult to extend this approach to higher dimensions
Other approaches including neural networks  CITATION , kernel embedding  CITATION , and generative topographic mapping  CITATION  have been proposed
The absence of probabilistic models in traditional PCA motivated the probabilistic PCA (PPCA) approach adopted by  CITATION
The advantage of probabilistic modeling is multifold, including providing a mechanism for density modeling, determination of degree of novelty of a new data point, and naturally incorporating incomplete observations
In  CITATION , the generative model is defined through the observation equation:  SYMBOL } which stated the linear relationship between the latent variable and the data points,  SYMBOL  is a  SYMBOL  matrix that is not constrained to have orthogonal columns a priori, and  SYMBOL  are  iid 
noises with  SYMBOL
Note we assume that the data is already centered, otherwise the observation model should be changed to  SYMBOL  with shift parameter  SYMBOL
In PPCA, we put a zero mean, unit covariance Gaussian prior on  SYMBOL , and the likelihood is maximized over  SYMBOL  after marginalizing over  SYMBOL :  SYMBOL   It is shown that when the noise level  SYMBOL  goes to zero, the maximum likelihood estimator for  SYMBOL  will converge to   SYMBOL } where the matrix  SYMBOL  and  SYMBOL  comes from singular value decomposition of  SYMBOL
Thus PPCA is a natural extension of the traditional PCA
CITATION  extends PPCA to mixture PPCA which can be used to model nonlinear structure in the data
In PPCA, after marginalizing over  SYMBOL , the distribution of  SYMBOL  becomes  SYMBOL  if the data are not centered
The mixture PPCA models the marginal distribution of  SYMBOL  as   SYMBOL  a mixture with  SYMBOL  components, and for each component, the observation model is  SYMBOL  if the  SYMBOL -th observation comes from the  SYMBOL -th mixture component
Thus in mixture PPCA, each mixture component is defined by a different linear transformation, while clustering is defined on the original  SYMBOL dimensional space
Marginalization over  SYMBOL  is still the same using unit covariance Gaussian distribution
The maximization over  SYMBOL  and  SYMBOL  can be performed using EM algorithm taking the mixture indicators as the missing data
The experiments in  CITATION  showed that this model has a wide applicability
We also note that when using  SYMBOL  to reconstruct the data point  SYMBOL , we must also store the mixture component which is responsible for generating  SYMBOL , or, more preferably, the posterior responsibility of each mixture for the  SYMBOL th observation
This piece of information cannot be recovered from the latent variable  SYMBOL  alone
Another approach of probabilistic nonlinear PCA based on Gaussian processes has been proposed in  CITATION
It starts from the same observation model (), but instead of marginalizing over  SYMBOL , it marginalizes over  SYMBOL  by putting independent spherical Gaussian prior on the  SYMBOL  columns of  SYMBOL , resulting in the marginal distribution of  SYMBOL , where  SYMBOL  is the  SYMBOL -th column of  SYMBOL  and  SYMBOL  is the  SYMBOL  matrix of latent variables
The author noticed that one can replace  SYMBOL  with another kernel matrix to achieve nonlinearity
Conceptually, this can be regarded as multivariate nonparametric regression problem  SYMBOL  with  SYMBOL  unknown, and need to be found by optimization of the likelihood
The computational complexity of Gaussian process approach is cubic in the number of data points  SYMBOL , although approximation algorithm can be designed to reduce the complexity
In this contribution, we propose a novel Bayesian approach to nonlinear PCA which puts priors on both  SYMBOL  and  SYMBOL
The model is based on an observation model similar to (), but with two differences
First, the linear transformation is defined through the orthonormal matrix  SYMBOL  instead of  SYMBOL  which roughly corresponds to  SYMBOL  in PPCA
Second, the linear transformation  SYMBOL  in our model is dependent on the corresponding latent variable
The linear transformations in different parts of the latent space are related by putting a Markov random field prior over the space of orthonormal matrices which makes the model identifiable
The model is estimated by Gibbs sampling which explores the posterior distribution of both the latent space and the transformation space
The computational burden for each iteration of Gibbs sampling is square in the number of data points
The rest of the paper is organized as follows: In the next section, we present the Baysian model and discuss the Gibbs sampling estimation procedure
Since we think the readers might not be familiar with the von Mises-Fisher distribution, some background material is also provided
Some experiments are carried out in section 3 using both simulated manifold data and the handwritten digits data
We conclude in section 4 with some thoughts on possible extensions of the model
### abstract ###
We present a general approach for collaborative filtering (CF) using spectral regularization to learn linear operators from ``users'' to a set of possibly desired ``objects''
Recent low-rank type matrix completion approaches to CF are shown to be special cases
However, unlike existing regularization based CF methods, our approach can be used to also incorporate information such as attributes of the users or the objects---a limitation of existing regularization based CF methods
We provide novel representer theorems that we use to develop new estimation methods
We then provide learning algorithms based on low-rank decompositions, and test them on a standard CF dataset
The experiments indicate the advantages of generalizing the existing regularization based CF methods to incorporate related information about users and objects
Finally, we show that certain multi-task learning methods can be also seen as special cases of our proposed approach
### introduction ###
Collaborative filtering (CF) refers to the task of predicting preferences of a given ``user'' for some ``objects'' (e g , books, music, products, people, etc ) based on his/her previously revealed preferences---typically in the form of purchases or ratings---as well as the revealed preferences of other users
In a book recommender system, for example, one would like to suggest new books to someone based on what she and other users have recently purchased or rated
The ultimate goal of CF is to infer the preferences of users in order to offer them new objects
A number of CF methods have been developed in the past  CITATION
Recently there has been interest in CF using regularization based methods  CITATION
This work adds to that literature by developing a novel general approach to developing regularization based CF methods
Recent regularization based CF methods assume that the only data available are the revealed preferences, where no other information such as background information on the objects or users is given
In this case, one may formulate the problem as that of inferring the contents of a partially observed  preference matrix : each row represents a user, each column represents an object (e g , books or movies), and entries in the matrix represent a given user's rating of a given object
When the only information available is a set of observed user/object ratings, the unknown entries in the matrix must be inferred from the known ones -- of which there are typically very few relative to the size of the matrix
To make useful predictions within this setting, regularization based CF methods make certain assumptions about the  relatedness  of the objects and users
The most common assumption is that preferences can be decomposed into a small number of factors, both for users and objects, resulting in the search for a low-rank matrix which approximates the partially observed matrix of preferences  CITATION
The rank constraint can be interpreted as a regularization on the hypothesis space
Since the rank constraint gives rise to a non-convex set of matrices, the associated optimization problem will be a difficult non-convex problem for which only heuristic algorithms exist  CITATION
An alternative formulation, proposed by~ CITATION , suggests penalizing the predicted matrix by its  trace norm , i e , the sum of its singular values
An added benefit of the trace norm regularization is that, with a sufficiently large regularization parameter, the final solution will be low-rank~ CITATION
However, a key limitation of current regularization based CF methods is that they do not take advantage of information, such as attributes of users (e g , gender, age) or objects (e g , book's author, genre), which is often available
Intuitively, such information might be useful to guide the inference of preferences, in particular for users and objects with very few known ratings
For example, at the extreme, users and objects with no prior ratings can not be considered in the standard CF formulation, while their attributes alone could provide some basic preference inference
The main contribution of this paper is to develop a general framework and specific algorithms also based on novel representer theorems for the more general CF setting where other information, such as attributes for users and/or objects, may be available
More precisely we show that CF, while typically seen as a problem of matrix completion, can be thought of more generally as estimating a linear operator from the space of users to the space of objects
Equivalently, this can be viewed as learning a bilinear form between users and objects
We then develop  spectral regularization  based methods to learn such linear operators
When dealing with operators, rather than matrices, one may also work with infinite dimension, allowing one to consider arbitrary feature space, possibly induced by some kernel function
Among key theoretical contributions of this paper are new representer theorems, allowing us to develop new general methods that learn finitely many parameters even when working in infinite dimensional  user/object feature space
These representer theorems generalize the classical representer theorem for minimization of an empirical loss penalized by the norm in a Reproducing Kernel Hilbert Space (RKHS) to more general penalty functions and function classes
We also show that, with the appropriate choice of kernels for both users and objects, we may consider a number of existing machine learning methods as special cases of our general framework
In particular, we show that several CF methods such as rank constrained optimization, trace-norm regularization, and those based on Frobenius norm regularization, can all be cast as special cases of spectral regularization on operator spaces
Moreover, particular choices of kernels lead to specific sub-cases such as regular matrix completion and multitask learning
In the specific application of collaborative filtering with the presence of attributes, we show that our generalization of these sub-cases leads to better predictive performance
The outline of the paper is as follows
In Section~, we review the notion of a compact operator on Hilbert Space, and we show how to cast the collaborative filtering problem within this framework
We then introduce spectral regularization and discuss how rank constraint, trace norm regularization, and Frobenius norm regularization are all special cases of spectral regularization
In Section~, we show how our general framework encompasses many existing methods by proper choices of the loss function, the kernels, and the spectral regularizer
In Section~, we provide three representer theorems for operator estimation with spectral regularization which allow for efficient learning algorithms
Finally in Section~ we present a number of algorithms and describe several techniques to improve efficiency
We test these algorithms in Section~ on synthetic examples and a widely used movie database
### abstract ###
We show how models for prediction with expert advice can be defined concisely and clearly using hidden Markov models (HMMs); standard HMM algorithms can then be used to efficiently calculate, among other things, how the expert predictions should be weighted according to the model
We cast many existing models as HMMs and recover the best known running times in each case
We also describe two new models: the switch distribution, which was recently developed to improve Bayesian/Minimum Description Length model selection, and a new generalisation of the fixed share algorithm based on run-length coding
We give loss bounds for all models and shed new light on their relationships
### introduction ###
We cannot predict exactly how complicated processes such as the weather, the stock market, social interactions and so on, will develop into the future
Nevertheless, people do make weather forecasts and buy shares all the time
Such predictions can be based on formal models, or on human expertise or intuition
An investment company may even want to choose between portfolios on the basis of a combination of these kinds of predictors
In such scenarios, predictors typically cannot be considered ``true''
Thus, we may well end up in a position where we have a whole collection of prediction strategies, or  experts , each of whom has  some  insight into  some  aspects of the process of interest
We address the question how a given set of experts can be combined into a single predictive strategy that is as good as, or if possible even better than, the best individual expert
The setup is as follows
Let  SYMBOL  be a finite set of experts
Each expert  SYMBOL  issues a distribution  SYMBOL  on the next outcome  SYMBOL  given the previous observations  SYMBOL
Here, each outcome  SYMBOL  is an element of some countable space  SYMBOL , and random variables are written in bold face
The probability that an expert assigns to a sequence of outcomes is given by the chain rule:  SYMBOL
A standard Bayesian approach to combine the expert predictions is to define a prior  SYMBOL  on the experts  SYMBOL  which induces a joint distribution with mass function  SYMBOL
Inference is then based on this joint distribution
We can compute, for example: (a) the  marginal probability  of the data  SYMBOL , (b) the  predictive distribution  on the next outcome  SYMBOL , which defines a prediction strategy that combines those of the individual experts, or (c) the  posterior distribution  on the experts  SYMBOL , which tells us how the experts' predictions should be weighted
This simple probabilistic approach has the advantage that it is computationally easy: predicting   SYMBOL  outcomes using  SYMBOL  experts requires only  SYMBOL  time
Additionally, this Bayesian strategy guarantees that the overall probability of the data is only a factor  SYMBOL  smaller than the probability of the data according to the best available expert  SYMBOL
On the flip side, with this strategy we never do any  better  than  SYMBOL  either: we have  SYMBOL , which means that potentially valuable insights from the other experts are not used to our advantage
More sophisticated combinations of prediction strategies can be found in the literature under various headings, including (Bayesian) statistics, source coding and universal prediction
In the latter the experts' predictions are not necessarily probabilistic, and scored using an arbitrary loss function
In this paper we consider only logarithmic loss, although our results can undoubtedly be generalised to the framework described in, eg \  CITATION
We introduce HMMs as an intuitive graphical language that allows unified description of existing and new models
Additionally, the running time for evaluation of such models can be read off directly from the size of their representation
### abstract ###
Counting  is a fundamental operation
For example,  counting the  SYMBOL th frequency moment,   SYMBOL , of a streaming signal  SYMBOL  (where  SYMBOL  denotes time), has been an active area of research, in theoretical computer science, databases, and data mining
When  SYMBOL , the task (i e , counting the sum) can be accomplished using a  counter
When  SYMBOL , however, it becomes non-trivial to design a small space (i e , low memory) counting system
Compressed Counting (CC)  is proposed for efficiently  computing the  SYMBOL th frequency moment of a data stream   SYMBOL , where  SYMBOL
CC is applicable if the streaming data follow the  Turnstile  model, with the restriction that at the time  SYMBOL  for the evaluation,  SYMBOL , which includes the  strict Turnstile  model as a special case
For  data streams  in practice, this restriction is  minor
The underlying technique is   skewed stable random projections , which  captures the intuition that, when  SYMBOL  a simple counter suffices, and when  SYMBOL  with small  SYMBOL , the sample complexity  should be low (continuously as a function of  SYMBOL )
We show the sample complexity (number of projections) {SYMBOL }, where {SYMBOL } as  {SYMBOL }
In other words, for small  SYMBOL ,  SYMBOL  instead of  SYMBOL
The case  SYMBOL  is practically very important
It is now well-understood that one can obtain good approximations to the entropies of data streams using the  SYMBOL th moments with  SYMBOL  and very small  SYMBOL
For statistical inference using the  method of moments , it is sometimes reasonable use the  SYMBOL th moments with  SYMBOL  very close to 1
As another example,  SYMBOL  might be the ``decay rate'' or ``interest rate,'' which is usually small
Thus,  Compressed Counting  will be an ideal tool, for estimating the total value in the future, taking in account the effect of decaying or interest accruement
Finally, our another contribution is an algorithm for approximating the logarithmic norm, {SYMBOL }, and the logarithmic distance, {SYMBOL }
The logarithmic norm arises in  statistical estimations
The logarithmic distance is  useful in machine learning practice with heavy-tailed data
### introduction ###
This paper % } focuses on  counting , which is among the most fundamental operations in almost every field of science and engineering
Computing the sum {SYMBOL } is the simplest counting ( SYMBOL  denotes time)
Counting the {SYMBOL th moment  SYMBOL } is more general
When {SYMBOL ,  SYMBOL } counts the total number of non-zeros in  SYMBOL
When {SYMBOL ,  SYMBOL } counts the ``energy'' or  ``power'' of the signal  SYMBOL
If   SYMBOL  actually outputs the power of an underlying signal  SYMBOL , counting the sum {SYMBOL } is equivalent to computing {SYMBOL }
Here,  SYMBOL  denotes a time-varying signal, for example,   data streams  CITATION
In the literature, the  SYMBOL th frequency moment of a data stream  SYMBOL  is defined as {}  Counting  SYMBOL  for massive data streams is practically important, among many  challenging issues in data stream computations
In fact, the general theme of ``scaling up for high dimensional data and high speed data streams'' is among the  ``ten challenging problems in data mining research
''%}  Because the elements,  SYMBOL , are time-varying,  a na\'ive counting mechanism requires a system of  SYMBOL  counters to compute  SYMBOL  exactly
This is not always realistic when  SYMBOL  is large and we only need an approximate answer
For example,  SYMBOL  may be   SYMBOL  if  SYMBOL  records the arrivals of IP addresses
Or,  SYMBOL  can be the total number of checking/savings accounts
Compressed Counting (CC)  is a new scheme for approximating the  SYMBOL th frequency moments of data streams (where  SYMBOL ) using low memory
The underlying technique is based on what we call  skewed stable random projections
### abstract ###
We consider the framework of stochastic multi-armed bandit problems and study the possibilities and limitations of forecasters that perform an on-line exploration of the arms
These forecasters are assessed in terms of their simple regret, a regret notion that captures the fact that exploration is only constrained by the number of available rounds (not necessarily known in advance), in contrast to the case when the cumulative regret is considered and when exploitation needs to be performed at the same time
We believe that this performance criterion is suited to situations when the cost of pulling an arm is expressed in terms of resources rather than rewards
We discuss the links between the simple and the cumulative regret
One of the main results in the case of a finite number of arms is a general lower bound on the simple regret of a forecaster in terms of its cumulative regret: the smaller the latter, the larger the former
Keeping this result in mind, we then exhibit upper bounds on the simple regret of some forecasters
The paper ends with a study devoted to continuous-armed bandit problems; we show that the simple regret can be minimized with respect to a family of probability distributions if and only if the cumulative regret can be minimized for it
Based on this equivalence, we are able to prove that the separable metric spaces are exactly the metric spaces on which these regrets can be minimized with respect to the family of all probability distributions with continuous mean-payoff functions
### introduction ###
Learning processes usually face an exploration versus exploitation dilemma, since they have to get information on the environment (exploration) to be able to take good actions (exploitation)
A key example is the multi-armed bandit problem  CITATION , a sequential decision problem where, at each stage, the forecaster has to pull one out of  SYMBOL  given stochastic arms and gets a reward drawn at random according to the distribution of the chosen arm
The usual assessment criterion of a forecaster is given by its cumulative regret, the sum of differences between the expected reward of the best arm and the obtained rewards
Typical good forecasters, like UCB  CITATION , trade off between exploration and exploitation
Our setting is as follows
The forecaster may sample the arms a given number of times  SYMBOL  (not necessarily known in advance) and is then asked to output a recommended arm
He is evaluated by his simple regret, that is, the difference between the average payoff of the best arm and the average payoff obtained by his recommendation
The distinguishing feature from the classical multi-armed bandit problem is that the exploration phase and the evaluation phase are separated
We now illustrate why this is a natural framework for numerous applications
Historically, the first occurrence of multi-armed bandit problems was given by medical trials
In the case of a severe disease, ill patients only are included in the trial and the cost of picking the wrong treatment is high (the associated reward would equal a large negative value)
It is important to minimize the cumulative regret, since the test and cure phases coincide
However, for cosmetic products, there exists a test phase separated from the commercialization phase, and one aims at minimizing the regret of the commercialized product rather than the cumulative regret in the test phase, which is irrelevant (Here, several formul{\ae} for a cream are considered and some quantitative measurement, like skin moisturization, is performed )  \medskip The pure exploration problem addresses the design of strategies making the best possible use of available numerical resources (e g , as {cpu} time) in order to optimize the performance of some decision-making task
That is, it occurs in situations with a preliminary exploration phase in which costs are not measured in terms of rewards but rather in terms of resources, that come in limited budget
A motivating example concerns recent works on computer-go (e g , the MoGo program  CITATION )
A given time, i e , a given amount of {cpu} times is given to the player to explore the possible outcome of sequences of plays and output a final decision
An efficient exploration of the search space is obtained by considering a hierarchy of forecasters minimizing some cumulative regret~-- see, for instance, the {uct} strategy  CITATION  and the {bast} strategy  CITATION
However, the cumulative regret does not seem to be the right way to base the strategies on, since the simulation costs are the same for exploring all options, bad and good ones
This observation was actually the starting point of the notion of simple regret and of this work
A final related example is the maximization of some function  SYMBOL , observed with noise, see, eg ,  CITATION
Whenever evaluating  SYMBOL  at a point is costly (e g , in terms of numerical or financial costs), the issue is to choose as adequately as possible where to query the value of this function in order to have a good approximation to the maximum
The pure exploration problem considered here addresses exactly the design of adaptive exploration strategies making the best use of available resources in order to make the most precise prediction once all resources are consumed
As a remark, it also turns out that in all examples considered above, we may impose the further restriction that the forecaster ignores ahead of time the amount of available resources (time, budget, or the number of patients to be included)~-- that is, we seek for anytime performance \medskip The problem of pure exploration presented above was referred to as ``budgeted multi-armed bandit problem'' in the open problem  CITATION  (where, however, another notion of regret than simple regret is considered)
The pure exploration problem was solved in a minmax sense for the case of two arms only and rewards given by probability distributions over  SYMBOL  in  CITATION
A related setting is considered in  CITATION  and  CITATION , where forecasters perform exploration during a random number of rounds  SYMBOL  and aim at identifying an  SYMBOL --best arm
These articles study the possibilities and limitations of policies achieving this goal with overwhelming  SYMBOL  probability and indicate in particular upper and lower bounds on (the expectation of)  SYMBOL
Another related problem is the identification of the best arm (with high probability)
However, this binary assessment criterion (the forecaster is either right or wrong in recommending an arm) does not capture the possible closeness in performance of the recommended arm compared to the optimal one, which the simple regret does
Moreover unlike the latter, this criterion is not suited for a distribution-free analysis
### abstract ###
Learning problems form an important category of computational tasks that generalizes many of the computations researchers apply to large real-life data sets
We ask: what concept classes can be learned privately, namely, by an algorithm whose output does not depend too heavily on any one input or specific training example
More precisely, we investigate  learning algorithms that satisfy  differential privacy , a notion that provides strong confidentiality guarantees in contexts where aggregate information is released about a database containing sensitive information about individuals \ifnum\full=0 We present several basic results that demonstrate general feasibility of private learning and relate several models previously studied separately in the contexts of privacy and standard learning
Our goal is a broad understanding of the resources required for private learning in terms of samples, computation time, and interaction
We demonstrate that, ignoring computational constraints, it is possible to privately agnostically learn any concept class using a sample size approximately logarithmic in the cardinality of the concept class
Therefore, almost anything learnable is learnable privately: specifically, if a concept class is learnable by a (non-private) algorithm with polynomial sample complexity and output size, then it can be learned privately using a polynomial number of samples
We also present a computationally efficient private PAC learner for the class of  parity  functions
This result dispels the similarity between learning with noise and private learning (both must be robust to small changes in inputs), since parity is thought to be very hard to learn given random classification noise
Local  (or  randomized response ) algorithms are a practical class of private algorithms that have received extensive investigation
We provide a precise characterization of local private learning algorithms
We show that a concept class is learnable by a local algorithm if and only if it is learnable in the  statistical query  (SQ) model
Therefore, for local private learning algorithms, the similarity to learning with noise is stronger: local learning is equivalent to SQ learning, and SQ algorithms include most known noise-tolerant learning algorithms
Finally, we present a separation between the power of  interactive  and  noninteractive  local learning algorithms
Because of the equivalence to SQ learning, this result also separates  adaptive  and  nonadaptive  SQ learning
### introduction ###
The data privacy problem in modern databases is similar to that faced by  statistical agencies and medical researchers: to learn and publish global analyses of a population while maintaining the confidentiality of the participants in a survey
There is a vast body of work on this problem in statistics and computer science
However, until recently, most schemes proposed in the literature lacked rigorous analysis of privacy and utility
A recent line of work% \ifnum\full=1 ~ CITATION  , initiated by Dinur and Nissim~ CITATION  and called  private data analysis , seeks to place data privacy on firmer theoretical foundations and has been  successful at formulating a strong, yet attainable privacy definition
The notion of  differential privacy ~ CITATION  that emerged from this line of work provides rigorous guarantees even in the presence of a malicious adversary with access to  arbitrary auxiliary information
It requires that whether an individual supplies her actual or fake information has almost no effect on the outcome of the analysis
Given this definition, it is natural to ask: what computational tasks can be performed while maintaining privacy
Research on data privacy, to the extent that it formalizes precise goals,  has mostly focused on  function evaluation  (``what is the value of  SYMBOL
''), namely, how much privacy is possible if one wishes to release (an approximation to) a particular function  SYMBOL , evaluated on the database  SYMBOL  (A notable exception is the recent work of McSherry and Talwar, using differential privacy in the design of auction mechanisms~ CITATION )
Our goal is to expand the utility of private protocols by examining which other computational tasks can be performed in a privacy-preserving manner \paragraph{Private Learning } \ifnum\full=1 Learning problems form an important category of computational tasks that generalizes many of the computations researchers apply to large real-life data sets
In this work, we ask what can be learned  privately , namely, by an algorithm whose output does not depend too heavily on any one input or specific training example
Our goal is a broad understanding of the resources required for private learning in terms of samples, computation time, and interaction
We examine two basic notions from \ifnum\full=1 computational learning theory: learning: Valiant's probabilistically approximately correct (PAC) learning~ CITATION  model and Kearns' statistical query (SQ) model~ CITATION
Informally, a concept is a function from examples to labels, and a class of concepts is learnable if for any distribution  SYMBOL  on examples, one can, given limited access to examples sampled from  SYMBOL  labeled according to some target concept  SYMBOL , find a small circuit (hypothesis) which predicts  SYMBOL 's labels with high probability over future examples taken from the same distribution
In the PAC model, a learning algorithm can access a polynomial number of labeled examples
In the SQ model, instead of accessing examples directly, the learner can specify some properties (i e , predicates) on the examples, for which he is given an estimate, up to an additive polynomially small error, of the probability that a random example chosen from  SYMBOL  satisfies the property
PAC learning is strictly stronger than the SQ learning ~ CITATION
We model a statistical database as a vector  SYMBOL , where each entry has been contributed by an individual
When analyzing how well a private algorithm learns a concept class, we assume that entries  SYMBOL  of the database are random examples generated  iid  \ from the underlying distribution  SYMBOL  and labeled by a target concept  SYMBOL
This is exactly how (not necessarily private) learners are analyzed
For instance, an example might consist of an individual's gender, age, and blood pressure history, and the label, whether this individual has had a heart attack
The algorithm has to learn to predict whether an individual has had a heart attack, based on gender, age, and blood pressure history, generated according to  SYMBOL
We require a private algorithm to keep entire examples (not only the labels) confidential
In the scenario above, it translates to not revealing each participant's gender, age, blood pressure history, and heart attack incidence
More precisely, the output of a private learner should not be significantly affected if a particular example  SYMBOL  is replaced with arbitrary  SYMBOL , for all  SYMBOL  and  SYMBOL
In contrast to correctness or utility, which is analyzed with respect to distribution  SYMBOL , differential privacy is a worst-case notion
Hence, when we analyze the privacy of our learners we do not make any assumptions on the underlying distribution
Such assumptions are fragile and, in particular, would fall apart in the presence of auxiliary knowledge \ifnum\full=1 (also called background knowledge or side information) that the adversary might have: conditioned on the adversary's auxiliary knowledge, the distribution over examples might look very different from  SYMBOL
%shiva-explain this point in the full version
### abstract ###
We consider regularized support vector machines (SVMs) and show that they are precisely equivalent to a new robust optimization formulation
We show that this equivalence of robust optimization and regularization has implications for both algorithms, and analysis
In terms of algorithms, the equivalence  suggests more general SVM-like algorithms for classification that explicitly build in protection to noise, and at the same time control overfitting
On the analysis front, the equivalence of robustness and regularization,  provides a robust optimization interpretation for the success of regularized SVMs
We use the this new robustness interpretation of SVMs to give a new proof of consistency of (kernelized) SVMs, thus establishing robustness as the  reason  regularized SVMs generalize well
### introduction ###
Support Vector Machines (SVMs for short) originated in  CITATION  and can be traced back to as early as  CITATION  and  CITATION
They continue to be one of the most successful algorithms for classification
SVMs address the classification problem by finding the hyperplane in the feature space that achieves maximum sample margin when the training samples are separable, which leads to minimizing the norm of the classifier
When the samples are not separable, a penalty term that approximates the total training error is considered  CITATION
It is well known that minimizing the training error itself can lead to poor classification performance for new unlabeled data; that is, such an approach may have poor generalization error because of, essentially, overfitting  CITATION
A variety of modifications have been proposed to combat this problem, one of the most popular methods being that of minimizing a combination of the training-error and a regularization term
The latter is typically chosen as a norm of the classifier
The resulting regularized classifier  performs better on new data
This phenomenon is often interpreted from a statistical learning theory view: the regularization term restricts the complexity of the classifier, hence the deviation of the testing error and the training error is controlled  CITATION
In this paper we consider a different setup,  assuming that the training data are generated by the true underlying distribution, but some non- iid  (potentially adversarial) disturbance is then added to the samples we observe
We follow a robust optimization  CITATION  approach, i e , minimizing the worst possible empirical error under such disturbances
The use of robust optimization in classification is not new  CITATION
Robust classification models studied in the past have considered only box-type uncertainty sets, which allow the possibility that the data have all been skewed in some non-neutral manner by a correlated disturbance
This has made it difficult to obtain non-conservative generalization bounds
Moreover, there has not been an explicit connection to the regularized classifier, although at a high-level it is known that regularization and robust optimization are related  CITATION
The main contribution in this paper is solving the robust classification problem for a class of non-box-typed uncertainty sets, and providing a linkage between robust classification and the standard regularization scheme of SVMs
In particular, our contributions include the following:   We solve the robust SVM formulation for a class of non-box-type uncertainty sets
This permits finer control of the adversarial disturbance, restricting it to satisfy aggregate constraints across data points, therefore reducing the possibility of highly correlated disturbance
We show that the standard regularized SVM classifier is a special case of our robust classification, thus explicitly relating robustness and regularization
This provides an alternative explanation to the success of regularization, and also suggests new physically motivated ways to construct regularization terms
We relate our robust formulation to several probabilistic formulations
We consider a chance-constrained  classifier (i e , a classifier with probabilistic constraints on misclassification) and show that our robust formulation can approximate it far less conservatively than previous robust formulations could possibly do
We also consider a Bayesian setup, and show that this can be used to provide a principled means of selecting the regularization coefficient without cross-validation
We show that the robustness perspective, stemming from a non- iid 
analysis, can be useful in the standard learning ( iid  ) setup, by using it  to  prove consistency for standard SVM classification,  without using VC-dimension or stability arguments
This result implies that generalization ability is a direct result of robustness to local disturbances; it therefore suggests a new justification for good performance, and consequently allows us to construct learning algorithms that generalize well by robustifying non-consistent algorithms \subsubsection*{Robustness and Regularization} We comment here on the explicit equivalence of robustness and regularization
We briefly explain how this observation is different from previous work and why it is interesting
Certain equivalence relationships between robustness and regularization have been established for problems other than classification  CITATION , but their results do not directly apply to the classification problem
Indeed, research on classifier regularization mainly discusses its effect on bounding the complexity of the function class  CITATION
Meanwhile, research on robust classification has not attempted to relate robustness and regularization  CITATION , in part due to the robustness formulations used in those papers
In fact, they all consider robustified versions of  regularized  classifications
CITATION  considers a robust formulation for box-type uncertainty, and relates this robust formulation with regularized SVM
However, this formulation involves a non-standard loss function that does not bound the  SYMBOL  loss, and hence its physical interpretation is not clear
The connection of robustness and regularization in the SVM context is important for the following reasons
First, it gives an alternative and potentially powerful explanation of the generalization ability of the regularization term
In the classical machine learning literature, the regularization term bounds the complexity of the class of classifiers
The robust view of regularization regards the testing samples as a perturbed copy of the training samples
We show that when the total perturbation is given or bounded, the regularization term bounds the gap between the classification errors of the SVM on these two sets of samples
In contrast to the standard PAC approach, this bound depends neither on how rich the class of candidate classifiers is, nor on an assumption that all samples are picked in an  iid 
manner
In addition, this suggests novel approaches to designing good classification algorithms, in particular, designing the regularization term
In the PAC structural-risk minimization approach, regularization is chosen to minimize a bound on the generalization error based on the training error and a complexity term
This complexity term typically leads to overly emphasizing the regularizer, and indeed this approach is known to often be too pessimistic~ CITATION  for problems with more structure
The robust approach offers another avenue
Since both noise and robustness are physical processes, a close investigation of the application and noise characteristics at hand, can provide insights into how to properly robustify, and therefore regularize the classifier
For example, it is known that normalizing the samples so that the variance among all features is roughly the same (a process commonly used to eliminate the scaling freedom of individual features) often leads to good generalization performance
From the robustness perspective, this simply says that the noise is anisotropic (ellipsoidal) rather than spherical, and hence an appropriate robustification must be designed to fit this anisotropy
We also show that using the robust optimization viewpoint, we obtain some probabilistic results outside the PAC setup
In Section~ we bound the probability that a noisy training sample is correctly labeled
Such a bound considers the behavior of  corrupted  samples and is hence different from the known PAC bounds
This is helpful when the training samples and the testing samples are drawn from different distributions, or some adversary manipulates the samples to prevent them from being correctly labeled (e g , spam senders change their patterns from time to time to avoid being labeled and filtered)
Finally, this connection of robustification and regularization also provides us with new proof techniques as well (see Section~)
We need to point out that there are several different definitions of robustness in literature
In this paper, as well as the aforementioned robust classification papers, robustness is mainly understood from a Robust Optimization perspective, where a min-max optimization is performed over all possible disturbances
An alternative interpretation of robustness stems from the rich literature on Robust Statistics  CITATION , which studies how an estimator or algorithm behaves under a small perturbation of the statistics model
For example, the Influence Function approach, proposed in  CITATION  and  CITATION , measures the impact  of an infinitesimal amount of contamination of the original distribution on the quantity of interest
Based on this notion of robustness,  CITATION  showed that many kernel classification algorithms, including SVM, are robust in the sense of having a finite Influence Function
A similar result for regression algorithms is shown in  CITATION  for smooth loss functions, and in  CITATION  for non-smooth loss functions where a relaxed version of the Influence Function is applied
In the machine learning literature, another widely used notion closely related to robustness is the  stability , where an algorithm is required to be robust (in the sense that the output function does not change significantly) under a specific perturbation: deleting one sample from the training set
It is now well known that a stable algorithm such as SVM has desirable generalization properties, and is statistically consistent under mild technical conditions; see for example  CITATION  for details
One main difference between Robust Optimization and other robustness notions is that the former is constructive rather than analytical
That is, in contrast to robust statistics or the stability approach that measures the robustness of a  given  algorithm, Robust Optimization can  robustify  an algorithm: it converts a given algorithm to a robust one
For example, as we show in this paper, the RO version of a naive empirical-error minimization is the well known SVM
As a constructive process, the RO approach also leads to additional flexibility in algorithm design, especially when the nature of the perturbation is known or can be well estimated {Structure of the Paper:} This paper is organized as follows
In Section~ we  investigate the correlated disturbance case, and  show the equivalence between the robust classification and the regularization process
We develop the connections to probabilistic formulations in Section~, and prove a consistency result based on robustness analysis in Section~
The kernelized version is investigated in Section~
Some concluding remarks are given in Section~ {Notation:} Capital letters are used to denote matrices, and boldface letters are used to denote column vectors
For a given norm  SYMBOL , we use  SYMBOL  to denote its dual norm, i e ,  SYMBOL
For a vector  SYMBOL  and a positive semi-definite matrix  SYMBOL  of the same dimension,  SYMBOL  denotes  SYMBOL
We use  SYMBOL  to denote disturbance affecting the samples
We use superscript  SYMBOL  to denote the true value for an uncertain variable, so that  SYMBOL  is the true (but unknown) noise of the  SYMBOL  sample
The set of non-negative scalars is denoted by  SYMBOL
The set of integers from  SYMBOL  to  SYMBOL  is denoted by  SYMBOL
### abstract ###
We propose a method for support vector machine classification using indefinite kernels
Instead of directly minimizing or stabilizing a nonconvex loss function, our algorithm simultaneously computes support vectors and a proxy kernel matrix used in forming the loss
This can be interpreted as a penalized kernel learning problem where indefinite kernel matrices are treated as noisy observations of a true Mercer kernel
Our formulation keeps the problem convex and relatively large problems can be solved efficiently using the projected gradient or analytic center cutting plane methods
We compare the performance of our technique with other methods on several standard data sets
### introduction ###
Support vector machines (SVM) have become a central tool for solving binary classification problems
A critical step in support vector machine classification is choosing a suitable kernel matrix, which measures similarity between data points and must be positive semidefinite because it is formed as the Gram matrix of data points in a reproducing kernel Hilbert space
This positive semidefinite condition on kernel matrices is also known as Mercer's condition in the machine learning literature
The classification problem then becomes a linearly constrained quadratic program
Here, we present an algorithm for SVM classification using indefinite kernels}, i e kernel matrices formed using similarity measures which are not positive semidefinite
Our interest in indefinite kernels is motivated by several observations
First, certain similarity measures take advantage of application-specific structure in the data and often display excellent empirical classification performance
Unlike popular kernels used in support vector machine classification, these similarity matrices are often indefinite, so do not necessarily correspond to a reproducing kernel Hilbert space (See  CITATION  for a discussion )  In particular, an application of classification with indefinite kernels to image classification using Earth Mover's Distance was discussed in  CITATION
Similarity measures for protein sequences such as the Smith-Waterman and BLAST scores are indefinite yet have provided hints for constructing useful positive semidefinite kernels such as those decribed in  CITATION  or have been transformed into positive semidefinite kernels with good empirical performance (see  CITATION , for example)
Tangent distance similarity measures, as described in  CITATION  or  CITATION , are invariant to various simple image transformations and have also shown excellent performance in optical character recognition
Finally, it is sometimes impossible to prove that some kernels satisfy Mercer's condition or the numerical complexity of evaluating the exact positive kernel is too high and a proxy (and not necessarily positive semidefinite) kernel has to be used instead (see  CITATION , for example)
In both cases, our method allows us to bypass these limitations
Our objective here is to derive efficient algorithms to directly use these indefinite similarity measures for classification
Our work closely follows, in spirit, recent results on kernel learning (see  CITATION  or  CITATION ), where the kernel matrix is learned as a linear combination of given kernels, and the result is explicitly constrained to be positive semidefinite
While this problem is numerically challenging,  CITATION   adapted the SMO algorithm to solve the case where the kernel is written as a positively weighted combination of other kernels
In our setting here, we never  numerically  optimize the kernel matrix because this part of the problem can be solved explicitly, which means that the complexity of our method is substantially lower than that of classical kernel learning algorithms and closer in practice to the algorithm used in  CITATION , who formulate the multiple kernel learning problem of  CITATION  as a semi-infinite linear program and solve it with a column generation technique similar to the analytic center cutting plane method we use here
### abstract ###
We consider the least-square linear regression problem with regularization by the  SYMBOL -norm, a problem usually referred to as the Lasso
In this paper, we present a detailed asymptotic analysis of model consistency of the Lasso
For various decays of the regularization parameter, we compute asymptotic equivalents of the probability of correct model selection (i e , variable selection)
For a specific rate decay, we show that the Lasso selects all the variables that should enter the model with probability tending to one exponentially fast, while it selects all other variables with strictly positive probability
We show that this property implies that if we run the Lasso for several bootstrapped replications of a given sample, then intersecting the supports of the Lasso bootstrap estimates leads to consistent model selection
This novel variable selection algorithm, referred to as the Bolasso, is compared favorably to other linear regression methods on synthetic data and datasets from the UCI machine learning repository
### introduction ###
Regularization by the  SYMBOL -norm has attracted a lot of interest in recent years in machine learning, statistics and signal processing
In the context of least-square linear regression, the problem is usually referred to as the  Lasso ~ CITATION
Much of the early effort has been dedicated to algorithms to solve the optimization problem efficiently
In particular, the  Lars  algorithm of~\singleemcite{lars} allows to find the entire regularization path (i e , the set of solutions for all values of the regularization parameters) at the cost of a single matrix inversion
Moreover, a well-known justification of the  regularization by the  SYMBOL -norm is that it leads to  sparse  solutions, i e , loading vectors with many zeros, and thus performs model selection
Recent works  CITATION  have looked precisely at the model consistency of the Lasso, i e , if we know that the data were generated from a sparse loading vector, does the Lasso actually recover it when the number of observed data points grows
In the case of a fixed number of covariates, the Lasso does recover the sparsity pattern if and only if a certain simple condition on the generating covariance matrices is verified~ CITATION
In particular, in low correlation settings, the Lasso is indeed consistent
However, in presence of strong correlations, the Lasso cannot be consistent, shedding light on potential problems of such procedures for variable selection
Adaptive versions where data-dependent weights are added to the  SYMBOL -norm  then allow to keep the consistency in all situations~ CITATION
In this paper, we first derive a detailed asymptotic analysis of sparsity pattern selection of the Lasso estimation procedure, that extends previous analysis~ CITATION , by focusing on a specific decay of the regularization parameter
We show that when the decay is proportional to  SYMBOL , where  SYMBOL  is the number of observations, then the Lasso will select all the variables that should enter the model (the  relevant  variables) with probability tending to one exponentially fast with~ SYMBOL , while it selects all other variables (the  irrelevant  variables) with strictly positive probability
If several datasets generated from the same distribution were available, then the latter property  would suggest to consider the intersection of the supports of the Lasso estimates for each dataset: all relevant variables would always be selected for all datasets, while irrelevant variables would enter the models randomly, and intersecting the supports from sufficiently many different datasets would simply eliminate them
However, in practice, only one dataset is given; but resampling methods such as the  bootstrap  are exactly dedicated to mimic the availability of several datasets by resampling from the same unique dataset~ CITATION
In this paper, we show that when using the bootstrap and intersecting the supports, we actually get a consistent model estimate, without the consistency condition required by the regular Lasso
We refer to this new procedure as the  Bolasso  ( bo otstrap-enhanced  l east  a b s olute  s hrinkage  o perator)
Finally, our Bolasso framework could be seen as a voting scheme applied to the supports of the bootstrap Lasso estimates; however, our procedure may rather be considered as a consensus combination scheme, as we keep the (largest) subset of variables on which  all  regressors agree in terms of variable selection, which is in our case provably consistent and also allows to get rid of a potential additional hyperparameter
The paper is organized as follows: in \mysec{analysis}, we present the asymptotic analysis of model selection for the Lasso; in \mysec{bootstrap}, we describe the Bolasso algorithm as well as its proof of model consistency, while in \mysec{simulations}, we illustrate our results on synthetic data, where the true sparse generating model is known, and data from the UCI machine learning repository
Sketches of proofs can be found in Appendix~A \paragraph{Notations} For a vector  SYMBOL , we let denote  SYMBOL  the  SYMBOL -norm,  SYMBOL  the  SYMBOL -norm and  SYMBOL  the  SYMBOL -norm
For    SYMBOL ,  SYMBOL  denotes the sign of  SYMBOL , defined as  SYMBOL  if  SYMBOL ,  SYMBOL  if  SYMBOL , and  SYMBOL  if  SYMBOL
For a vector  SYMBOL ,  SYMBOL  denotes the the vector of signs of elements of  SYMBOL
Moreover, given a vector  SYMBOL  and a subset  SYMBOL  of  SYMBOL ,  SYMBOL  denotes the vector in  SYMBOL  of elements of  SYMBOL  indexed by  SYMBOL
Similarly, for a matrix  SYMBOL ,  SYMBOL  denotes the submatrix of   SYMBOL  composed of elements of  SYMBOL  whose rows are in  SYMBOL  and columns are in  SYMBOL
### abstract ###
This paper focuses on the problem of kernelizing an existing supervised Mahalanobis distance learner
The following features are included in the paper
Firstly, three popular learners, namely, ``neighborhood component analysis'', ``large margin nearest neighbors'' and ``discriminant neighborhood embedding'', which do not have kernel versions are kernelized in order to improve their classification performances
Secondly, an alternative kernelization framework called ``KPCA trick'' is presented
Implementing a learner in the new framework gains several advantages over the standard framework, eg no mathematical formulas and no reprogramming are required for a kernel implementation, the framework avoids troublesome problems such as singularity, etc
Thirdly, while the truths of representer theorems are just assumptions in previous papers related to ours, here, representer theorems are formally proven
The proofs validate both the kernel trick and the KPCA trick in the context of Mahalanobis distance learning
Fourthly, unlike previous works which always apply brute force methods to select a kernel, we investigate two approaches which can be efficiently adopted to construct an appropriate kernel for a given dataset
Finally, numerical results on various real-world datasets are presented
### introduction ###
Recently, many Mahalanobis distance learners are invented \shortcite{Chen:CVPR05,Goldberger:NIPS05,Weinberger:NIPS06,Yang:AAAI06,Sugiyama:ICML06,Yan:PAMI07,Wei:ICML07,Torresani:NIPS07,Xing:NIPS03}
These recently proposed learners are carefully designed so that they can handle a class of problems where data of one class form multi-modality where classical learners such as principal component analysis (PCA) and Fisher discriminant analysis (FDA) cannot handle
Therefore, promisingly, the new learners usually outperform the classical learners on experiments reported in recent papers
Nevertheless, since learning a Mahalanobis distance is equivalent to learning a linear map, the inability to learn a non-linear transformation is one important limitation of all Mahalanobis distance learners
As the research in Mahalanobis distance learning has just recently begun, several issues are left open such as (1) some efficient learners do not have non-linear extensions, (2) the  kernel trick   CITATION , a standard non-linearization method, is not fully automatic in the sense that new mathematical formulas have to be derived and new programming codes have to be implemented; this is not convenient to non-experts, (3) existing algorithms ``assume'' the truth of the  representer theorem  \shortcite[Chapter 4]{Scholkopf:BOOK01}; however, to our knowledge, there is no formal proof of the theorem in the context of Mahalanobis distance learning, and (4) the problem of how to select an efficient kernel function has been left untouched in previous works; currently, the best kernel is achieved via a brute-force method such as cross validation
In this paper, we highlight the following key contributions:   SYMBOL  Three popular learners recently proposed in the literatures, namely,  neighborhood component analysis  (NCA) \shortcite{Goldberger:NIPS05},  large margin nearest neighbors  (LMNN) \shortcite{Weinberger:NIPS06} and  discriminant neighborhood embedding  (DNE) \shortcite{Wei:ICML07} are kernelized in order to improve their classification performances with respect to the kNN algorithm
SYMBOL  A  KPCA trick  framework is presented as an alternative choice to the kernel-trick framework
In contrast to the kernel trick, the KPCA trick does not require users to derive new mathematical formulas
Also, whenever an implementation of an original learner is available, users are not required to re-implement the kernel version of the original learner
Moreover, the new framework avoids problems such as singularity in eigen-decomposition and provides a convenient way to speed up a learner
SYMBOL  Two representer theorems in the context of Mahalanobis distance learning are proven
Our theorems justify both the kernel-trick and the KPCA-trick frameworks
Moreover, the theorems validate kernelized algorithms learning a Mahalanobis distance in any separable Hilbert space and also cover kernelized algorithms performing dimensionality reduction
SYMBOL  The problem of efficient kernel selection is dealt with
Firstly, we investigate the  kernel alignment  method proposed in previous works \shortcite{Lanckriet:JMLR04,Zhu:NIPS05} to see whether it is appropriate for a kernelized Mahalanobis distance learner or not
Secondly, we investigate a simple method which constructs an unweighted combination of base kernels
A theoretical result is provided to support this simple approach
Kernel constructions based on our two approaches require much shorter running time when comparing to the standard cross validation approach
SYMBOL  As kNN is already a non-linear classifier, there are some doubts about the usefulness of kernelizing Mahalanobis distance learners \shortcite[pp 8]{Weinberger:NIPS06}
We provide an explanation and conduct extensive experiments on real-world datasets to prove the usefulness of the kernelization
### abstract ###
While in general trading off exploration and exploitation in reinforcement learning is hard, under some formulations relatively simple solutions exist
Optimal decision thresholds for the multi-armed bandit problem, one for the infinite horizon discounted reward case and one for the finite horizon undiscounted reward case are derived, which make the link between the reward horizon, uncertainty and the need for exploration explicit
From this result follow two practical approximate algorithms, which are illustrated experimentally
### introduction ###
In reinforcement learning, the dilemma between selecting actions to maximise the expected return according to the current world model and to improve the world model such as to  potentially  be able to achieve a higher expected return is referred to as the  exploration-exploitation trade-off
This has been the subject of much interest before, one of the earliest developments being the theory of sequential sampling in statistics, as developed by  CITATION
This dealt mostly with making sequential decisions for accepting one among a set of particular hypothesis, with a view towards applying it to jointly decide the termination of an experiment and the acceptance of a hypothesis
A more general overview of sequential decision problems from a Bayesian viewpoint is offered in  CITATION
The optimal, but intractable, Bayesian solution for bandit problems was given in~ CITATION , while recently tight bounds on the sample complexity of exploration have been found  CITATION
An approximation to the full Bayesian case for the general reinforcement learning problem is given in  CITATION , while an alternative technique based on eliminating actions which are confidently estimated as low-value is given in  CITATION
The following section formulates the intuitive concept of trading exploration and exploitation as a natural consequence of the  definition  of the problem of reinforcement learning
After the problem definitions which correspond to either extreme are identified, Sec
derives a threshold for switching from exploratory to greedy behaviour in bandit problems
This threshold is found to depend on the effective reward horizon of the optimal policy and on our current belief distribution of the expected rewards of each action
A sketch of the extension to MDPs is presented in Sec ~
Section~ uses an upper bound on the value of exploration to derive practical algorithms, which are then illustrated experimentally in Sec

We conclude with a discussion on the relations with other methods
### abstract ###
We present an extension of Principal Component Analysis (PCA) and a new algorithm for clustering points in  SYMBOL  based on it
The key property of the algorithm is that it is affine-invariant
When the input is a sample from a mixture of two arbitrary Gaussians, the algorithm correctly classifies the sample assuming only that the two components are separable by a hyperplane, ie , there exists a halfspace that contains most of one Gaussian and almost none of the other in probability mass
This is nearly the best possible, improving known results substantially  CITATION
For  SYMBOL  components, the algorithm requires only that there be some  SYMBOL -dimensional subspace in which the  overlap  in every direction is small
Here we define overlap to be the ratio of the following two quantities: 1) the average squared distance between a point and the mean of its component, and 2) the average squared distance between a point and the mean of the mixture
The main result may also be stated in the language of linear discriminant analysis: if the standard Fisher discriminant  CITATION  is small enough, labels are not needed to estimate the optimal subspace for projection
Our main tools are isotropic transformation, spectral projection and a simple reweighting technique
We call this combination  isotropic PCA
### introduction ###
We present an extension to Principal Component Analysis (PCA), which is able to go beyond standard PCA in identifying ``important'' directions
When the covariance matrix of the input (distribution or point set in  SYMBOL ) is a multiple of the identity, then PCA reveals no information; the second moment along any direction is the same
Such inputs are called isotropic
Our extension, which we call  isotropic PCA , can reveal interesting information in such settings
We use this technique to give an affine-invariant clustering algorithm for points in  SYMBOL
When applied to the problem of unraveling mixtures of arbitrary Gaussians from unlabeled samples, the algorithm yields substantial improvements of known results
To illustrate the technique, consider the uniform distribution on the set  SYMBOL , which is isotropic
Suppose this distribution is rotated in an unknown way and that we would like to recover the original  SYMBOL  and  SYMBOL  axes
For each point in a sample, we may project it to the unit circle and compute the covariance matrix of the resulting point set
The  SYMBOL  direction will correspond to the greater eigenvector, the  SYMBOL  direction to the other
See Figure  for an illustration
Instead of projection onto the unit circle, this process may also be thought of as importance weighting, a technique which allows one to simulate one distribution with another
In this case, we are simulating a distribution over the set  SYMBOL , where the density function is proportional to  SYMBOL , so that points near  SYMBOL  or  SYMBOL  are more probable }  In this paper, we describe how to apply this method to mixtures of arbitrary Gaussians in  SYMBOL  in order to find a set of directions along which the Gaussians are well-separated
These directions span the Fisher subspace of the mixture, a classical concept in Pattern Recognition
Once these directions are identified, points can be classified according to which component of the distribution generated them, and hence all parameters of the mixture can be learned
What separates this paper from previous work on learning mixtures is that our algorithm is affine-invariant
Indeed, for every mixture distribution that can be learned using a previously known algorithm, there is a linear transformation of bounded condition number that causes the algorithm to fail
For  SYMBOL  components our algorithm has nearly the best possible guarantees (and subsumes all previous results) for clustering Gaussian mixtures
For  SYMBOL , it requires that there be a  SYMBOL -dimensional subspace where the  overlap  of the components is small in every direction (See section )
This condition can be stated in terms of the Fisher discriminant, a quantity commonly used in the field of Pattern Recognition with labeled data
Because our algorithm is affine invariant, it makes it possible to unravel a much larger set of Gaussian mixtures than had been possible previously
The first step of our algorithm is to place the mixture in isotropic position (see Section ) via an affine transformation
This has the effect of making the  SYMBOL -dimensional Fisher subspace, i e , the one that minimizes the Fisher discriminant, the same as the subspace spanned by the means of the components (they only coincide in general in isotropic position), for  any  mixture
The rest of the algorithm identifies directions close to this subspace and uses them to cluster, without access to labels
Intuitively this is hard since after isotropy, standard PCA reveals no additional information
Before presenting the ideas and guarantees in more detail, we describe relevant related work
### abstract ###
This article considers constrained  SYMBOL  minimization methods for the recovery of high dimensional sparse signals in three settings: noiseless, bounded error and Gaussian noise
A unified and elementary treatment is given in these noise settings for two  SYMBOL  minimization methods: the Dantzig selector and  SYMBOL  minimization with an  SYMBOL  constraint
The results of this paper improve the existing results in the literature by weakening the conditions and tightening the error bounds
The improvement on the conditions shows that signals with larger support can be recovered accurately
This paper also establishes connections between restricted isometry property and the mutual incoherence property
Some results of Candes, Romberg and Tao (2006) and Donoho, Elad, and Temlyakov (2006) are extended
### introduction ###
The problem of recovering a high-dimensional sparse signal based on a small number of measurements, possibly corrupted by noise, has attracted much recent attention
This problem arises in many different settings, including model selection in linear regression, constructive approximation,  inverse problems, and compressive sensing
Suppose we have  SYMBOL  observations of the form  y = F+ z where the matrix  SYMBOL  with  SYMBOL  is given and  SYMBOL  is a vector of measurement errors
The goal is to reconstruct the unknown vector  SYMBOL
Depending on settings, the error vector  SYMBOL  can either be zero (in the noiseless case), bounded, or Gaussian where  SYMBOL
It is now well understood that  SYMBOL  minimization provides an effective way for reconstructing a sparse signal in all three settings
A special case of particular interest is when no noise is present in () and  SYMBOL
This is an underdetermined system of linear equations with more variables than the number of equations
It is clear that the problem is ill-posed and there are generally infinite many solutions
However, in many applications the vector  SYMBOL  is known to be sparse or nearly sparse in the sense that it contains only a small number of nonzero entries
This sparsity assumption fundamentally changes the problem, making unique solution possible
Indeed in many cases the unique sparse solution can be found exactly through  SYMBOL  minimization: (P) \min\|\|_1 \mbox{subject to} F= y
This  SYMBOL  minimization problem has been studied, for example, in Fuchs  CITATION , Candes and Tao  CITATION  and Donoho  CITATION
Understanding the noiseless case is not only of significant interest on its own right, it also provides deep insight into the problem of reconstructing sparse signals in the noisy case
See, for example, Candes and Tao  CITATION  and Donoho  CITATION
When  noise is present, there are two well known  SYMBOL  minimization methods
One is  SYMBOL  minimization under the  SYMBOL  constraint on the residuals: (P_1) \min\|\|_1 \mbox{subject to} \|y-F\gamma\|_2\epsilon
Writing in terms of the Lagrangian function of ( SYMBOL ), this is closely related to finding the solution to the  SYMBOL  regularized least squares:  \min_\left\{\|y-F\gamma\|_2^2 + \rho\|\|_1\right\}
The latter is often called the Lasso in the statistics literature (Tibshirani  CITATION )
Tropp  CITATION  gave a detailed treatment of the  SYMBOL  regularized least squares problem
Another method, called the Dantzig selector, is recently proposed by Candes and Tao  CITATION
The Dantzig selector solves the sparse recovery problem through  SYMBOL -minimization with a constraint on the correlation between the residuals and the column vectors of  SYMBOL :  SYMBOL } Candes and Tao  CITATION  showed that the Dantzig selector can be computed by solving a linear program and it mimics the performance of an oracle procedure up to a logarithmic factor  SYMBOL
It is clear that regularity conditions are needed in order for these problems to be well behaved
Over the last few years, many interesting results for recovering sparse signals have been obtained in the framework of the  Restricted Isometry Property  (RIP)
In their seminal work  CITATION , Candes and Tao considered sparse recovery problems in the RIP framework
They provided beautiful solutions to the problem under some conditions on the restricted isometry constant  and restricted orthogonality constant (defined in Section )
Several different conditions have been imposed in various settings
In this paper, we consider  SYMBOL  minimization methods for the sparse recovery problem in three cases: noiseless, bounded error and Gaussian noise
Both the Dantzig selector (DS) and  SYMBOL  minimization under the  SYMBOL  constraint  SYMBOL  are considered
We give a unified and elementary treatment for the two methods under the three noise settings
Our results improve on the existing results in  CITATION  by weakening the conditions and tightening the error bounds
In all cases we solve the problems under the weaker condition  SYMBOL  where  SYMBOL  is the sparsity index and  SYMBOL  and  SYMBOL  are respectively the restricted isometry constant and restricted orthogonality constant defined in Section
The improvement on the condition shows that signals with larger support can be recovered
Although our main interest is on recovering sparse signals, we state the results in the general setting of reconstructing an arbitrary signal
Another widely used condition for sparse recovery is the so called  Mutual Incoherence  Property  (MIP) which requires the pairwise correlations among the column vectors of  SYMBOL  to be small
See  CITATION
We establish connections between the concepts of RIP and MIP
As an application, we present an improvement to a recent result of Donoho, Elad, and Temlyakov   CITATION
The paper is organized as follows
In Section , after basic notation and definitions are reviewed, two elementary inequalities, which allow us to make finer analysis of the sparse recovery problem, are introduced
We begin the analysis of  SYMBOL  minimization methods for sparse recovery by considering the exact recovery in the noiseless case in Section
Our result improves the main result in Candes and Tao  CITATION  by using weaker conditions and providing tighter error bounds
The analysis of the noiseless case provides insight to the case when the observations are contaminated by noise
We then consider the case of bounded error in Section
The connections between the RIP and MIP are also explored
The case of Gaussian noise is treated in Section
The Appendix contains the proofs of some technical results
### abstract ###
Several researchers have recently investigated the connection between reinforcement learning and classification
We are motivated by proposals of approximate policy iteration schemes without value functions, which focus on policy representation using classifiers and address policy learning as a supervised learning problem
This paper proposes variants of an improved policy iteration scheme which addresses the core sampling problem in evaluating a policy through simulation as a multi-armed bandit machine
The resulting algorithm offers comparable performance to the previous algorithm achieved, however, with significantly less computational effort
An order of magnitude improvement is demonstrated experimentally in two standard reinforcement learning domains: inverted pendulum and mountain-car
### introduction ###
Supervised and reinforcement learning are two well-known learning paradigms, which have been researched mostly independently
Recent studies have investigated the use of supervised learning methods for reinforcement learning, either for value function~\mycite{lagoudakis2003lsp,riedmiller2005nfq} or policy representation~\mycite{lagoudakisICML03,fern2004api,langfordICML05}
Initial results have shown that policies can be approximately represented using either multi-class classifiers or combinations of binary classifiers~\mycite{rexakis+lagoudakis:ewrl2008} and, therefore, it is possible to incorporate classification algorithms within the inner loops of several reinforcement learning algorithms~\mycite{lagoudakisICML03,fern2004api}
This viewpoint allows the quantification of the performance of reinforcement learning algorithms in terms of the performance of classification algorithms~\mycite{langfordICML05}
While a variety of promising combinations become possible through this synergy, heretofore there have been limited practical and widely-applicable algorithms
Our work builds on the work of Lagoudakis and Parr~\mycite{lagoudakisICML03} who suggested an approximate policy iteration algorithm for learning a good policy represented as a classifier, avoiding representations of any kind of value function
At each iteration, a new policy/classifier is produced using training data obtained through extensive simulation (rollouts) of the previous policy on a generative model of the process
These rollouts aim at identifying better action choices over a subset of states in order to form a set of data for training the classifier representing the improved policy
A similar algorithm was proposed by Fern et al ~\mycite{fern2004api} at around the same time
The key differences between the two algorithms are related to the types of learning problems they are suitable for, the choice of the underlying classifier type, and the exact form of classifier training
Nevertheless, the main ideas of producing training data using rollouts and iterating over policies remain the same
Even though both of these studies look carefully into the distribution of training states over the state space, their major limitation remains the large amount of sampling employed at each training state
It is hinted~\mycite{lagoudakisPhD03}, however, that great improvement could be achieved with sophisticated management of rollout sampling
Our paper suggests managing the rollout sampling procedure within the above algorithm with the goal of obtaining comparable training sets (and therefore policies of similar quality), but with significantly less effort in terms of number of rollouts and computation effort
This is done by viewing the setting as akin to a bandit problem over the rollout states (states sampled using rollouts)
Well-known algorithms for bandit problems, such as Upper Confidence Bounds~\mycite{auerMLJ02} and Successive Elimination~\mycite{evendarJMLR06}, allow optimal allocation of resources (rollouts) to trials (states)
Our contribution is two-fold: (a) we suitably adapt bandit techniques for rollout management, and (b) we suggest an improved statistical test for identifying early with high confidence states with dominating actions
In return, we obtain up to an order of magnitude improvement over the original algorithm in terms of the effort needed to collect the training data for each classifier
This makes the resulting algorithm attractive to practitioners who need to address large real-world problems
The remainder of the paper is organized as follows
Section~ provides the necessary background and Section~ reviews the original algorithm we are based on
Subsequently, our approach is presented in detail in Section~
Finally, Section~ includes experimental results obtained from well-known learning domains
### abstract ###
We prove existence and uniqueness of the minimizer for the average geodesic distance to the points of a geodesically convex set on the sphere
This implies a corresponding existence and uniqueness result for an optimal algorithm for halfspace learning, when data and target functions are drawn from the uniform distribution
### introduction ###
Let  SYMBOL  be the unit sphere in  SYMBOL  with normalized uniform measure  SYMBOL  and geodesic metric  SYMBOL , and let  SYMBOL  be a proper convex cone with nonempty interior in  SYMBOL
We will show that the function  SYMBOL  defined by%  SYMBOL % attains its global minimum at a unique point on  SYMBOL
While existence of the minimum is straightforward, uniqueness seems surprisingly difficult to prove
A similar problem has been considered in  CITATION  and  CITATION
In these works the intention is to define a centroid, so integration is replaced by finite summation and  SYMBOL  replaced by  SYMBOL
Since the problem is rather obvious, it appears likely that a proof of the above result exists somewhere in the literature and we just haven't been able to find it
### abstract ###
% %AG_18/04/08 Update to abstract We propose a framework for analyzing and comparing distributions, allowing us to design statistical tests to determine if two samples are drawn from different distributions
Our test statistic is the largest difference in expectations over functions in the unit ball of a reproducing kernel Hilbert space (RKHS)
We present two tests based on large deviation bounds for the test statistic, while a third is based on the asymptotic distribution of this statistic
The test statistic can be computed in quadratic time, although efficient linear time approximations are available
Several classical metrics on distributions are recovered when the function space used to compute the difference in expectations is allowed to be more general (eg ~a Banach space)
We apply our two-sample tests  to a variety of problems, including attribute matching for databases using the Hungarian marriage method, where they perform strongly
Excellent performance is also obtained when comparing distributions over graphs, for which these are the first such tests
### introduction ###
We address the problem of comparing samples from two probability distributions, by proposing  statistical tests of the hypothesis that these distributions are different (this is  called  the two-sample or homogeneity problem)
Such tests have application in a variety of areas
In bioinformatics, it is of interest to compare microarray data from identical tissue types as measured by different laboratories, to detect whether the data may be analysed jointly, or whether differences in experimental procedure have caused systematic differences in the data distributions
Equally of interest are comparisons between microarray data from different tissue types, either to determine whether two subtypes of cancer may be treated as statistically indistinguishable from a diagnosis perspective, or to detect differences in healthy and cancerous tissue
In database attribute matching, it is desirable to merge databases containing multiple fields, where it is not known in advance which fields correspond: the fields are matched by maximising the similarity in the distributions of their entries
We test whether distributions  SYMBOL  and  SYMBOL  are different on the basis of samples drawn from each of them, by finding a well behaved (e g \ smooth) function which is large on the points drawn from  SYMBOL , and small (as negative as possible) on the points from  SYMBOL
We use as our test statistic the difference between the mean function values on the two samples; when this is large, the samples are likely from different distributions
We call this statistic the Maximum Mean Discrepancy (MMD)
Clearly the quality of the MMD as a statistic  depends on the class  SYMBOL  of smooth functions that define it
On one hand,  SYMBOL  must be ``rich enough'' so that the population MMD vanishes if and only if  SYMBOL
On the other hand, for the test to be consistent,  SYMBOL  needs to be ``restrictive'' enough for the empirical estimate of MMD to converge quickly to its expectation as the sample size increases
We shall use the unit balls in universal reproducing kernel Hilbert spaces  CITATION  as our function classes, since these will be shown to satisfy both of the foregoing properties (we also review classical metrics on distributions, namely the Kolmogorov-Smirnov and Earth-Mover's distances, which are based on different function classes)
On a more practical note, the MMD has a reasonable computational cost, when compared with other two-sample tests: given  SYMBOL  points sampled from  SYMBOL  and  SYMBOL  from  SYMBOL , the cost is  SYMBOL  time
We also propose a less statistically efficient algorithm  with a computational cost of  SYMBOL , which can yield superior performance at a given computational cost by looking at a larger volume of data
We define three non-parametric statistical tests based on the MMD
The first two, which use distribution-independent uniform convergence bounds, provide finite sample guarantees of test performance, at the expense of being conservative in detecting differences between  SYMBOL  and  SYMBOL
The third test is based on the asymptotic distribution of the MMD, and is in practice more sensitive to differences in distribution at small sample sizes
The present work synthesizes and expands on  results of  CITATION ,  CITATION , and  CITATION  who in turn build on the earlier work of  CITATION
Note that the latter addresses only the third kind of test, and that the  approach of  CITATION  employs a more accurate approximation to the asymptotic distribution of the test statistic
We begin our presentation in Section  with a formal definition of the MMD, and a  proof that the population MMD is zero if and only if  SYMBOL  when  SYMBOL  is the unit ball of a universal RKHS
We also review alternative function classes for which the MMD defines a metric on probability distributions
In Section , we give an overview of hypothesis testing as it applies to the two-sample problem, and review other approaches to this problem
We present our first two hypothesis tests in Section ,  based on two different bounds on the deviation between the population and empirical  SYMBOL
We take a different approach in Section , where we use the asymptotic distribution of the empirical  SYMBOL  estimate as the basis for a third test
When large volumes of data are available, the cost of computing the MMD (quadratic in the sample size) may  be excessive: we therefore propose in Section  a modified version of the MMD statistic that has a linear cost in the number of samples, and an associated asymptotic test
In Section , we provide an overview of methods related to the MMD in the statistics and machine learning literature
Finally, in Section , we demonstrate the performance of MMD-based two-sample tests on problems from neuroscience, bioinformatics, and attribute matching using the Hungarian marriage method
Our approach performs well on high dimensional data with low sample size; in addition, we are able to successfully distinguish distributions on graph data,  for which ours is the first proposed test
### abstract ###
We identify the classical Perceptron algorithm with margin as a member of a broader family of large margin classifiers  which we collectively call the Margitron
The Margitron, (despite its) sharing the same update rule with the Perceptron, is shown  in an incremental setting to converge in a finite number of updates to solutions possessing any desirable fraction of the maximum margin
Experiments comparing the Margitron with decomposition SVMs on tasks involving linear kernels and 2-norm soft margin are also reported
### introduction ###
It is widely accepted that the larger the margin of the solution hyperplane the greater is the generalisation ability of the learning machine  CITATION
The simplest online learning algorithm for binary linear classification, the Perceptron  CITATION , does not aim at any margin
The problem, instead, of finding the optimal margin hyperplane lies at the core of Support Vector Machines (SVMs)  CITATION
Their efficient implementation, however, is somewhat hindered by the fact that they require solving a quadratic programming problem
The complications encountered in implementing SVMs has respurred the interest in alternative large margin classifiers many of which are based on the Perceptron algorithm
The oldest such algorithm which appeared long before the advent of SVMs is the standard Perceptron with margin  CITATION , a straightforward extension of the Perceptron, which, however, in an incremental setting is known to be able to guarantee achieving only up to  SYMBOL  of the maximum margin that the dataset possesses  CITATION
Subsequently, various algorithms succeeded in achieving larger fractions of the maximum margin by employing modified perceptron-like update rules
Such algorithms include ROMMA  CITATION , ALMA  CITATION , CRAMMA  CITATION  and MICRA  CITATION
A somewhat different approach from the hard margin one adopted by most of the algorithms above was also developed which focuses on the minimisation of the 1-norm soft margin loss through stochastic gradient descent
There is a connection, however, between such algorithms and the Perceptron since their unregularised form with constant learning rate is identical to the Perceptron with margin
Notable representatives of this approach are the pioneer NORMA  CITATION  and the very recent Pegasos  CITATION
A question that arises naturally and which we attempt to answer in the present work is whether it is possible to achieve a guaranteed fraction of the maximum margin larger than  SYMBOL  while retaining the original perceptron update rule
To this end we construct a whole new family of algorithms at least one member of which has guaranteed convergence in a finite number of steps to a solution hyperplane possessing any desirable fraction of the unknown maximum margin
This family of algorithms in which the classical Perceptron with margin is naturally embedded will be termed the Margitron
Hopefully, the algorithms belonging to the margitron family by virtue of being generalisations of the very successful Perceptron will have a respectable performance in various classification tasks
Section 2 contains some preliminaries and the description of the Margitron algorithm
Section 3 is devoted to a theoretical analysis
Section 4 contains our experimental results while Section 5 our conclusions
### abstract ###
This paper presents a theoretical analysis of sample selection bias correction
The sample bias correction technique commonly used in machine learning consists of reweighting the cost of an error on each training point of a biased sample to more closely reflect the unbiased distribution
This relies on weights derived by various estimation techniques based on finite samples
We analyze the effect of an error in that estimation on the accuracy of the hypothesis returned by the learning algorithm for two estimation techniques: a cluster-based estimation technique and kernel mean matching
We also report the results of sample bias correction experiments with several data sets using these techniques
Our analysis is based on the novel concept of  distributional stability  which generalizes the existing concept of point-based stability
Much of our work and proof techniques can be used to analyze other importance weighting techniques and their effect on accuracy when using a distributionally stable algorithm
### introduction ###
In the standard formulation of machine learning problems, the learning algorithm receives training and test samples drawn according to the same distribution
However, this assumption often does not hold in practice
The training sample available is  biased  in some way, which may be due to a variety of practical reasons such as the cost of data labeling or acquisition
The problem occurs in many areas such as astronomy,  econometrics, and species habitat modeling
In a common instance of this problem, points are drawn according to the test distribution but not all of them are made available to the learner
This is called the  sample selection bias problem
Remarkably, it is often possible to correct this bias by using large amounts of unlabeled data
The problem of sample selection bias correction for linear regression has been extensively studied in econometrics and statistics  CITATION  with the pioneering work of \emcite{heckman}
Several recent machine learning publications  CITATION  have also dealt with this problem
The main correction technique used in all of these publications consists of reweighting the cost of training point errors to more closely reflect that of the test distribution
This is in fact a technique commonly used in statistics and machine learning for a variety of problems of this type  CITATION
With the exact weights, this reweighting could optimally correct the bias, but, in practice, the weights are based on an estimate of the sampling probability from finite data sets
Thus, it is important to determine to what extent the error in this estimation can affect the accuracy of the hypothesis returned by the learning algorithm
To our knowledge, this problem has not been analyzed in a general manner
This paper gives a theoretical analysis of sample selection bias correction
Our analysis is based on the novel concept of  distributional stability  which generalizes the point-based stability introduced and analyzed by previous authors  CITATION
We show that large families of learning algorithms, including all kernel-based regularization algorithms such as Support Vector Regression (SVR)  CITATION  or kernel ridge regression  CITATION  are distributionally stable and we give the expression of their stability coefficient for both the  SYMBOL  and  SYMBOL  distance
We then analyze two commonly used sample bias correction techniques: a cluster-based estimation technique and kernel mean matching (KMM)  CITATION
For each of these techniques, we derive bounds on the difference of the error rate of the hypothesis returned by a distributionally stable algorithm when using that estimation technique versus using perfect reweighting
We briefly discuss and compare these bounds and also report the results of experiments with both estimation techniques for several publicly available machine learning data sets
Much of our work and proof techniques can be used to analyze other importance weighting techniques and their effect on accuracy when used in combination with a distributionally stable algorithm
The remaining sections of this paper are organized as follows
Section~ describes in detail the sample selection bias correction technique
Section~ introduces the concept of distributional stability and proves the distributional stability of kernel-based regularization algorithms
Section~ analyzes the effect of estimation error using distributionally stable algorithms for both the cluster-based and the KMM estimation techniques
Section~ reports the results of experiments with several data sets comparing these estimation techniques
### abstract ###
We define a novel, basic, unsupervised learning problem - learning the lowest density homogeneous hyperplane separator of an unknown probability distribution
This task is relevant to several problems in machine learning, such as semi-supervised learning and clustering stability
We investigate the question of existence of a universally consistent algorithm for this problem
We propose two natural learning paradigms and prove that, on input unlabeled random samples generated by any member of a rich family of distributions, they are guaranteed to converge to the optimal separator for that distribution
We complement this result by showing that no learning algorithm for our task can achieve uniform learning rates (that are independent of the data generating distribution)
### introduction ###
While the theory of machine learning has achieved extensive understanding of many aspects of supervised learning, our theoretical understanding of unsupervised learning leaves a lot to be desired
In spite of the obvious practical importance of various unsupervised learning tasks, the state of our current knowledge does not provide anything that comes close to the rigorous mathematical performance guarantees that classification prediction theory enjoys
In this paper we make a small step in that direction by analyzing one specific unsupervised learning task -- the detection of low-density linear separators for data distributions over Euclidean spaces
We consider the following task:  for an unknown data distribution over  SYMBOL , find the homogeneous hyperplane of lowest density that cuts through that distribution
We assume that the underlying data distribution has a continuous density function and that the data available to the learner are finite  iid 
samples of that distribution
Our model can be viewed as a restricted instance of the fundamental issue of inferring information about a probability distribution from the random samples it generates
Tasks of that nature range from the ambitious problem of density estimation  CITATION , through estimation of level sets  CITATION ,  CITATION ,  CITATION , densest region detection  CITATION , and, of course, clustering
All of these tasks are notoriously difficult with respect to both the sample complexity and the computational complexity aspects (unless one presumes strong restrictions about the nature of the underlying data distribution)
Our task seems more modest than these
Although we are not aware of any previous work on this problem (from the point of view of statistical machine learning, at least), we believe that it is a rather basic problem that is relevant to various practical learning scenarios
One important domain to which the detection of low-density linear data separators is relevant is semi-supervised learning  CITATION
Semi-supervised learning is motivated by the fact that in many real world classification problems, unlabeled samples are much cheaper and easier to obtain than labeled examples
Consequently, there is great incentive to develop tools by which such unlabeled samples can be utilized to improve the quality of sample based classifiers
Naturally, the utility of unlabeled data to classification depends on assuming some relationship between the unlabeled data distribution and the class membership of data points (see  CITATION  for a rigorous discussion of this point)
A common postulate of that type is that the boundary between data classes passes through low-density regions of the data distribution
The Transductive Support Vector Machines paradigm (TSVM)~ CITATION  is an example of an algorithm that implicitly uses such a low density boundary assumption
Roughly speaking, TSVM searches for a hyperplane that has small error on the labeled data and at the same time has wide margin with respect to the unlabeled data sample
Another area in which low-density boundaries play a significant role is the analysis of clustering stability
Recent work on the analysis of clustering stability found close relationship between the stability of a clustering and the data density along the cluster boundaries -- roughly speaking, the lower these densities the more stable the clustering ( CITATION ,  CITATION )
A low-density-cut algorithm for a family  SYMBOL  of probability distributions takes as an input a finite sample generated by some distribution  SYMBOL  and has to output a hyperplane through the origin with low density w r t
SYMBOL
In particular, we consider the family of all distributions over  SYMBOL  that have continuous density functions
We investigate two notions of success for low-density-cut algorithms -- uniform convergence (over a family of probability distributions) and consistency
For uniform convergence we prove a general negative result, showing that no algorithm can guarantee any fixed convergence rates (in terms of sample sizes)
This negative result holds even in the simplest case where the data domain is the one-dimensional unit interval
For consistency (e g , allowing the learning/convergence rates to depend on the data-generating distribution), we prove the success of two natural algorithmic paradigms;  Soft-Margin  algorithms that choose a margin parameter (depending on the sample size) and output the separator with lowest empirical weight in the margins around it, and  Hard-Margin  algorithms that choose the separator with widest sample-free margins
The paper is organized as follows: Section  provides the formal definition of our learning task as well as the success criteria that we investigate
In Section  we present two natural learning paradigms for the problem over the real line and prove their universal consistency over a rich class of probability distributions
Section  extends these results to show the learnability of lowest-density homogeneous linear cuts for probability distributions over  SYMBOL  for arbitrary dimension,  SYMBOL
In Section  we show that the previous universal consistency results cannot be improved to obtain  uniform  learning rates (by any finite-sample based algorithm)
We conclude the paper with a discussion of directions for further research
### abstract ###
We describe a novel approach to statistical learning from particles tracked while moving in a random environment
The problem consists in inferring properties of the environment from recorded snapshots
We consider here the case of a fluid seeded with identical passive particles that diffuse and are advected by a flow
Our approach rests on efficient algorithms to estimate the weighted number of possible matchings among particles in two consecutive snapshots, the partition function of the underlying graphical model
The partition function is then maximized over the model parameters, namely diffusivity and velocity gradient
A Belief Propagation (BP) scheme is the backbone of our algorithm, providing accurate results for the flow parameters we want to learn
The BP estimate is additionally improved by incorporating Loop Series (LS) contributions
For the weighted matching problem, LS is compactly expressed as a Cauchy integral, accurately estimated by a saddle point approximation
Numerical experiments show that the quality of our improved BP algorithm is comparable to the one of a fully polynomial randomized approximation scheme, based on the Markov Chain Monte Carlo (MCMC) method, while the BP-based scheme is substantially faster than the MCMC scheme
### introduction ###
Graphical model approaches to statistical learning and inference are widespread in many fields of science, ranging from machine learning to bioinformatics, statistical physics and error-correction
Such applications often require evaluation of a weighted sum over an exponentially large number of configurations --- a formidable  SYMBOL -hard problem in the majority of cases
In this paper we focus on one such difficult problem, which occurs when tracking identical particles moving in a random environment
As long as particles are sufficiently dilute, their tracking in two consecutive frames is rather straightforward
When the density of particles and/or the acquisition time increase, many possible sets of trajectories become statistically compatible with the acquired data and multiple matchings of the particles in two consecutive snapshots are likely
Despite of these uncertainties, one expects that reliable estimates of the properties of the environment should still be possible if the number  SYMBOL  of tracked particles is sufficiently large
This is the problem that we want to address here
The nature of the moving particles and their environment are not subject to particular restrictions, eg they might move actively, such as living organisms, or passively
Here, we shall consider the case of a fluid seeded with passive particles, a problem arising in the context of fluid mechanics experiments
Given a statistical model of the fluid flow with unknown parameters, along with the positions of  SYMBOL  indistinguishable particles in two subsequent snapshots, one aims at predicting the most probable values of the model parameters
This task is formally stated in Section~ as searching for the maximum of a weighted sum over all possible matchings between particles in the two snapshots
The problem turns out to be equivalent to computing the permanent of a non-negative matrix, known to be a  SYMBOL -complete problem~ CITATION
The main contribution of this paper is  an efficient and accurate algorithm of Belief   Propagation (BP) type for calculating the permanent  for the class of weight matrices arising from the particle tracking problem
The BP algorithm seeks a minimum of the Bethe Free Energy~ CITATION  for a suitable graphical model
The graphical model is a fully connected bipartite graph: nodes are associated with the measured particles, edges are weighted according to the model of the flow transporting the particles and constraints enforce the condition that exactly one edge per node is active
It is known that BP gives the exact result for the maximum likelihood version of the problem (finding a maximum weight matching) in spite of multiple loops characterizing the graphical model~ CITATION
The BP algorithm for the matching problem is derived and discussed in Section~
BP equations could be understood as a re-parametrization, or gauge transformation, of factor functions in the graphical model~ CITATION
Furthermore, BP solutions also provide an explicit representation of the exact partition function in terms of the so-called Loop Series~ CITATION
Our main technical result is  the derivation of a compact expression and efficient approximation for the Loop Series in the problem of weighted particle matching
This is done in Section~, where the Loop Series is expressed in terms of an  SYMBOL -th order mixed derivative of an explicit functional, reduced to  SYMBOL -dimensional Cauchy integral and finally estimated by a saddle-point approximation
Section~ describes empirical results demonstrating the performance of bare BP and the saddle-point improved BP in comparison with a (simplified) fully polynomial randomized approximation scheme for computing the permanent~ CITATION
Our improved BP achieves comparable accuracy, with significant gains in terms of speed
As the number of particles tracked in experiments is typically large (order tens of thousands) we argue that our approach is both useful and promising for applications
                                                                                                                                                                                                                                                                                                                                                                                                                                                                        loops
### abstract ###
As a fundamental problem in pattern recognition, graph matching has applications in a variety of fields, from computer vision to computational biology
In graph matching, patterns are modeled as graphs and pattern recognition amounts to finding a correspondence between the nodes of different graphs
Many formulations of this problem can be cast in general as a quadratic assignment problem, where a linear term in the objective function encodes node compatibility and a quadratic term encodes edge compatibility
The main research focus in this theme is about designing efficient algorithms for approximately solving the quadratic assignment problem, since it is NP-hard
In this paper we turn our attention to a different question: how to  estimate  compatibility functions such that the solution of the resulting graph matching problem best matches the expected solution that a human would manually provide
We present a method for  learning graph matching : the training examples are pairs of graphs and the `labels' are matches between them
Our experimental results reveal that learning can substantially improve the performance of standard graph matching algorithms
In particular, we find that simple linear assignment with such a learning scheme outperforms Graduated Assignment with bistochastic normalisation, a state-of-the-art quadratic assignment relaxation algorithm
### introduction ###
Graphs are commonly used as abstract representations for complex structures, including DNA sequences, documents, text, and images
In particular they are extensively used in the field of computer vision, where many problems can be formulated as an attributed graph matching problem
Here the nodes of the graphs correspond to local features of the image and edges correspond to relational aspects between features (both nodes and edges can be attributed, i e ~they can encode feature vectors)
Graph matching then consists of finding a correspondence between nodes of the two graphs such that they 'look most similar' when the vertices are labeled according to such a correspondence
Typically, the problem is mathematically formulated as a quadratic assignment problem, which consists of finding the assignment that maximizes an objective function encoding local compatibilities (a linear term) and structural compatibilities (a quadratic term)
The main body of research in graph matching has then been focused on devising more accurate and/or faster algorithms to solve the problem approximately (since it is NP-hard); the compatibility functions used in graph matching are typically handcrafted
An interesting question arises in this context: If we are given two attributed graphs to match,  SYMBOL  and  SYMBOL , should the optimal match be uniquely determined
For example, assume first that  SYMBOL  and  SYMBOL  come from two images acquired by a surveillance camera in an airport's lounge; now, assume the same  SYMBOL  and  SYMBOL  instead come from two images in a photographer's image database; should the optimal match be the same in both situations
If the algorithm takes into account exclusively the graphs to be matched, the optimal solutions will be the same since the graph pair is the same in both cases
This is the standard way graph matching is approached today
In this paper we address what we believe to be a limitation of this approach
We argue that if we know the `conditions' under which a pair of graphs has been extracted, then we should take into account  how graphs arising in those conditions are typically matched
However, we do not take the information on the conditions explicitly into account, since this would obviously be impractical
Instead, we approach the problem purely from a statistical inference perspective
First, we extract graphs from a number of images acquired under the same conditions as those for which we want to solve, whatever the word `conditions' means (e g ~from the surveillance camera or the photographer's database)
We then  manually  provide what we understand to be the optimal matches between the resulting graphs
This information is then used in a  learning  algorithm which learns a map from the space of pairs of graphs to the space of matches
In terms of the quadratic assignment problem, this learning algorithm amounts to (in loose language) adjusting the node and edge compatibility functions such that the expected optimal match in a test pair of graphs agrees with the expected match they would have had, had they been in the training set
In this formulation, the learning problem consists of a convex, quadratic program which is readily solvable by means of a column generation procedure
We provide experimental evidence that applying learning to standard graph matching algorithms significantly improves their performance
In fact, we show that learning improves upon non-learning results so dramatically that linear assignment  with learning  outperforms Graduated Assignment with bistochastic normalisation, a state-of-the-art quadratic assignment relaxation algorithm
Also, by introducing learning in Graduated Assignment itself, we obtain results that improve both in accuracy and speed over the best existing quadratic assignment relaxations
A preliminary version of this paper appeared in  CITATION
### abstract ###
We present a novel approach to semi-supervised learning  which is based on statistical physics
Most of the former work in the field of semi-supervised learning classifies the points by minimizing a certain energy function, which corresponds to a minimal k-way cut solution
In contrast to these methods, we estimate the  distribution  of classifications, instead of the sole minimal k-way cut, which yields more accurate and robust results
Our approach may be applied to all energy functions used for semi-supervised learning
The method is based on sampling using a Multicanonical Markov chain Monte-Carlo algorithm, and has a straightforward probabilistic interpretation, which allows for soft assignments of points to classes, and also to cope with yet unseen class types
The  suggested approach is  demonstrated on a toy data set and on two real-life data sets of  gene expression
### introduction ###
Situations in which  many unlabelled points are available  and  only few labelled points are provided call for semi-supervised learning methods
The goal of semi-supervised learning is to classify the unlabelled points, on the basis of their distribution and the provided labelled points
Such problems occur in many fields, in which obtaining data is cheap but labelling is expensive
In such scenarios supervised methods are impractical, but the presence of the few labelled points can significantly improve the performance of unsupervised methods
The basic assumption of unsupervised learning, i e clustering, is that points which belong to the same cluster actually originate from the same class
Clustering methods which are based on estimating the density of data points define a cluster as a `mode' in the distribution, i e a relatively dense region surrounded by  relatively lower density
Hence each mode is assumed to originate from a single class, although a certain class may be dispersed over several modes
In case the modes are well separated  they can be easily identified by unsupervised techniques, and there is no need for semi-supervised methods
However, consider the case of two close  modes which belong to two different classes, but the  density of points between them  is not significantly lower than the density within each mode
In this case density based unsupervised methods may encounter difficulties in distinguishing between  the modes (classes), while semi-supervised methods can be of help
Even if a few points are labelled in each class, semi-supervised algorithms, which cannot cluster together points of different labels, are  forced  to place a border between the modes
Most probably the border will pass in between the modes, where  the density of points is lower
Hence, the forced border `amplifies' the otherwise less noticed differences between the modes
For example, consider the image in Fig ~a
Each pixel corresponds to a data point and the similarity score between adjacent pixels is of value unity
The green and red pixels are labelled while the rest of the blue pixels are unlabelled
The desired classification into red and green classes appears in Fig ~b
It is unlikely that any unsupervised method would partition the data correctly (see eg Fig ~c) since the two classes   form  one uniform cluster
However, using a few labelled points semi-supervised methods which must place a border between the red and green classes may become useful
In recent years various types of semi-supervised learning algorithms have been proposed, however almost all of these methods share a common basic approach
They define a certain cost function, i e energy , over the possible classifications, try to minimize this energy, and output the minimal energy classification as their solution
Different methods vary by the specific energy function and by their minimization procedures; for example the work on graph cuts~ CITATION , minimizes the cost of a cut in the graph, while others  choose to  minimize the normalized cut cost~ CITATION , or a quadratic cost~ CITATION
As stated recently by~ CITATION , searching for a minimal energy has a  basic disadvantage, common to all former methods: it ignores the robustness of the found solution
Blum et al mention the case of  several minima with equal energy, where  one arbitrarily chooses one solution, instead of considering them all
Put differently, imagine the energy landscape in the space of  solutions; it may contain many equal energy minima as considered Blum et al , but also other phenomena may harm the robustness of the global minimum as an optimal  solution
First,  it may happen that the difference in energy between the global minimum, and close by solutions is minuscule, thus picking the minimum as the sole solution may be incorrect or arbitrary
Secondly, in many  cases there are too few data points (both labelled and unlabelled) which may cause the empirical density to locally deviate from the true density
Such fluctuations in the density may drive the minimal energy solution far from the correct one
For example, due to fluctuations a low density ``crack" may be formed inside a high density region, which may erroneously split  a single  cluster in two
Another type of fluctuation may generate  a ``filament" of high density points in  a low density region, which may unite two clusters of different classes
In both cases, the minimal energy solution is erroneously `guided' by the fluctuations, and fails to find the correct classification
An example of the latter case appears in Fig ~a;   the classifications provided by three semi-supervised methods appear in Fig ~d--f, fail to recover the desired classification, due to a `filament' which connects the  classes *}  Searching for  the minimal energy solution is equivalent to seeking the most probable joint classification (MAP)
A possible remedy to the difficulties in this approach may then be to consider the probability distribution of all possible classifications
Blum et al provided a first step in this direction using a randomized min-cut  algorithm
In this work we provide a different solution  based on   statistical physics
Basically each solution in our method  is weighed by its energy  SYMBOL , also known as the Boltzmann weight, and its probability is given by:  SYMBOL } where the ``temperature''  SYMBOL  serves as a free parameter, and the energy  SYMBOL  takes into account both  unlabelled and labelled points
Classification is then performed by marginalizing (), thus estimating the probability that a point  SYMBOL  belongs to a class  SYMBOL
This formalism is often referred to  as a Markov random field (MRF), which has been applied in numerous works, including in the context of semi-supervised learning by~ CITATION
However,  they seek  the MAP solution (which corresponds to  SYMBOL ), while we estimate the distribution itself (at  SYMBOL )
Using the framework of statistical physics has several advantages in the context of semi-supervised learning: First, classification  has a simple probabilistic interpretation
It yields a fuzzy assignment of points to class types, which may also  serve as a confidence level in the classification
Secondly, since exactly estimating the marginal probabilities is, in most cases,  intractable, statistical physics has developed elegant Markov chain Monte-Carlo (MCMC) methods which are suitable for estimating semi-supervised systems
Due to the inherent complexity of semi-supervised problems, `standard' MCMC methods, such as the Metropolis~ CITATION  and Swendsen-Wang~ CITATION  methods  provide poor results, and one needs to apply more sophisticated algorithms, as discussed in section~
Thirdly, using statistical physics allows us to gain an intuition  regarding  the nature of a semi-supervised problem, i e , it allows for a detailed analysis of the effect of adding labelled points to an unlabelled data set
In addition, our method also has two practical advantages: (i) while most semi-supervised learning methods consider only the case of two class types, our method is naturally extended  to  the multi-class scenario (ii) Another unique feature of our method is its ability to suggest the existence of a new class type, which did  not appear in the labelled set
Our main objective in this paper is to present a framework, which can later be applied in  different directions
For example, the energy function in () can be any of the functions used in other semi-supervised  methods
In this paper we chose to use the min-cut cost function
We do not claim that using this cost function is optimal, and indeed we observed that it is suboptimal in some cases
However, we aim to convince the reader that applying our method, to any energy function, would always yield equal or better results than merely minimizing the same energy function
Our work is closely related to the typical cut criterion for unsupervised learning, first introduced by~ CITATION  in the framework of statistical physics and later in a graph theoretic context   by~ CITATION
The method introduced in this work can be viewed as  an extension of these clustering algorithms to the semi-supervised case
The paper is organized as follows: Section~ presents the model, and Section~ discusses the issue of estimating  marginal probabilities
Section~ presents the qualitative effect of adding labelled points
Our semi-supervised algorithm is outlined in Section~
Section~ demonstrates the performance of our algorithm on a toy data set  and on two real-life examples  of  gene expression data
### abstract ###
Statistical learning theory chiefly studies restricted hypothesis classes,  particularly those with finite Vapnik-Chervonenkis (VC) dimension
The fundamental quantity of interest is the sample complexity: the number of samples required to learn to a specified level of accuracy
Here we consider learning over the set of all computable labeling functions
Since the VC-dimension is infinite and a priori (uniform) bounds on the number of samples are impossible, we let the learning algorithm decide when it has seen sufficient samples to have learned
We first show that learning in this setting is indeed possible, and develop a learning algorithm
We then show, however, that bounding sample complexity independently of the distribution is impossible
Notably, this impossibility is entirely due to the requirement that the learning algorithm be computable,  and not due to the statistical nature of the problem
### introduction ###
Suppose we are trying to learn a difficult classification problem: for example determining whether the given image contains a human face,  or whether the MRI image shows a malignant tumor, etc
We may first try to train a simple model such as a small neural network
If that fails, we may move on to other, potentially more complex, methods of classification such as support vector machines with different kernels,  techniques to apply certain transformations to the data first, etc
Conventional statistical learning theory attempts to bound the number of samples needed to learn to a specified level of accuracy for each of the above models (e g \ neural networks, support vector machines)
Specifically, it is enough to bound the VC-dimension of the learning model to determine the number of samples to use~ CITATION
However, if we allow ourselves to change the model, then the VC-dimension of the overall learning algorithm is not finite, and much of statistical learning theory does not directly apply
Accepting that much of the time the complexity of the model cannot be a priori bounded,  Structural Risk Minimization~ CITATION  explicitly considers a hierarchy of increasingly complex models
An alternative approach, and one we follow in this paper, is simply to consider a single learning model that includes all possible classification methods
We consider the unrestricted learning model consisting of all computable classifiers
Since the VC-dimension is clearly infinite,  there are no uniform bounds (independent of the distribution and the target concept) on the number of samples needed to learn accurately~ CITATION
Yet we still want to guarantee a desired level of accuracy
Rather than deciding on the number of samples a priori,  it is natural to allow the learning algorithm to decide when it has seen sufficiently many labeled samples based on the training samples seen up to now and their labels
Since the above learning model includes any practical classification scheme, we term it universal (PAC-) learning
We first show that there is a computable learning algorithm in our universal setting
Then, in order to obtain bounds on the number of training samples that would be needed, we consider measuring sample complexity of the learning algorithm as a function of the unknown correct labeling function (i e \ target concept)
Although the correct labeling is unknown, this sample complexity measure could be used to compare learning algorithms speculatively: ``if the target labeling were such and such, learning algorithm  SYMBOL  requires fewer samples than learning algorithm  SYMBOL "
By asking what is the largest sample size needed assuming the target labeling function is in a certain class, we could compare the sample complexity of the universal learner to a learner over the restricted class (e g \ with finite VC-dimension)
However, we prove that it is impossible to bound the sample complexity of any  computable  universal learning algorithm, even as a function of the target concept
Depending on the distribution, any such bound will be exceeded with arbitrarily high probability
The impossibility of a distribution-independent bound is entirely due to the computability requirement
Indeed we show there is an uncomputable learning procedure for which we bound the number of samples queried as a function of the unknown target concept, independently of the distribution
Our results imply that computable learning algorithms in the universal setting must ``waste samples" in the sense of requiring more samples than is necessary for statistical reasons alone
### abstract ###
The remarkable results of Foster and Vohra was a starting point for a series of papers which show that any sequence of outcomes can be learned (with no prior knowledge) using some universal randomized forecasting algorithm and forecast-dependent checking rules
We show that for the class of all computationally efficient outcome-forecast-based checking rules, this property is violated
Moreover, we present a probabilistic algorithm generating with probability close to one a sequence with a subsequence which simultaneously miscalibrates all partially weakly computable randomized forecasting algorithms
According to the Dawid's prequential framework we consider partial recursive randomized algorithms
### introduction ###
Let a binary sequence  SYMBOL  of outcomes is observed by a forecaster whose task is to give a probability  SYMBOL  of a future event  SYMBOL
The evaluation of probability forecasts is based on a method called  calibration : informally, following Dawid~ CITATION  forecaster is said to be well-calibrated if for any  SYMBOL  the event  SYMBOL  holds in  SYMBOL  of moments of time as he choose  SYMBOL  (see also~ CITATION )
Let us give some notations
Let  SYMBOL  be the set of all infinite binary sequences,  SYMBOL  be the set of all finite binary sequences and  SYMBOL  be the empty sequence
For any finite or an infinite sequence  SYMBOL , we write  SYMBOL  (we put  SYMBOL )
Also,  SYMBOL  denotes the length of the sequence  SYMBOL
If  SYMBOL  is a finite sequence and  SYMBOL  is a finite or infinite sequence then  SYMBOL  denotes the concatenation of these sequences,  SYMBOL  means that  SYMBOL  for some  SYMBOL
In the measure-theoretic framework we expect that the forecaster has a method for assigning probabilities  SYMBOL  of a future event  SYMBOL  for all possible finite sequences  SYMBOL
In other words, all conditional probabilities  SYMBOL  SYMBOL SYMBOL \omega_1,\omega_2,,\omega_{n-1} SYMBOL p_n SYMBOL SYMBOL p_n SYMBOL f:\Xi[0,1] SYMBOL f SYMBOL \omega_1,,\omega_{n-1},SYMBOL f SYMBOL \omega=\omega_1\omega_2SYMBOL p_i=f(\omega_1\dots\omega_{i-1}) SYMBOL i=1,2,SYMBOL f(\alpha;x) SYMBOL \Omega_x SYMBOL Pr_x SYMBOL x\inSYMBOL SYMBOL SYMBOL Pr_{\omega^{i-1}} SYMBOL Pr SYMBOL \Omega_{\omega^{i-1}} SYMBOL i=1,2,SYMBOL \Delta>0 SYMBOL f SYMBOL \omega=\omega_1\omega_2SYMBOL Pr SYMBOL n\toSYMBOL p_i=f(\omega^{n-1}) SYMBOL I(p) SYMBOL [0,1] SYMBOL c(\omega^{i-1},p)=\delta(\omega^{i-1})I(p) SYMBOL \delta:\Xi\to\{0,1\} SYMBOL I(p) SYMBOL [0,1] SYMBOL p_i=f(\alpha;\omega^{i-1},p^{i-1}) SYMBOL p^{i-1}=p_1,,p_{i-1} SYMBOL k=1,2,SYMBOL \{\delta_k\} SYMBOL \{I_k\} SYMBOL [0,1] SYMBOL \{\delta_k I_k\} SYMBOL k=1,2,SYMBOL \Delta>0 SYMBOL \omega=\omega_1\omega_2SYMBOL n\toSYMBOL p_i=f(\omega^{n-1},p^{i-1}) SYMBOL I(p_i) SYMBOL \delta_k(\omega^{i-1})I_k(p_i) SYMBOL k=1,2,SYMBOL \{\delta_k\} SYMBOL p_i=f(\alpha;\omega^{i-1}) SYMBOL SYMBOL p_i=f(\alpha;\omega^{i-1}) SYMBOL SYMBOL SYMBOL I SYMBOL f$
### abstract ###
The games of prediction with expert advice are considered in this paper
We present some modification of Kalai and Vempala algorithm of following the perturbed leader for the case of unrestrictedly large one-step gains
We show that in general case the cumulative gain of any probabilistic prediction algorithm can be much worse than the gain of some expert of the pool
Nevertheless, we give the lower bound for this cumulative gain in general case and construct a universal algorithm which has the optimal performance; we also prove that in case when one-step gains of experts of the pool have ``limited deviations'' the performance of our algorithm is close to the performance of the best expert
### introduction ###
Experts algorithms are used for online prediction or repeated decision making or repeated game playing
Any such algorithm is based on a ``pool of experts''
At any step  SYMBOL , each expert gives its recommendation
From this, a ``master decision'' is performed
After that, losses (or rewards)  SYMBOL  are assigned to each expert  SYMBOL  by the environment (or adversary)
The master algorithm also receives some loss or reward depending on the master decision
The goal of the master algorithm is to perform almost as well as the best expert in hindsight in the long run
Prediction with Expert Advice considered in this paper proceeds as follows
We are asked to perform sequential actions at times  SYMBOL
At each time step  SYMBOL , we observe results of actions of experts in the form of their gains and losses on steps  SYMBOL
After that, at the beginning of the step  SYMBOL   Learner  makes a decision to follow one of these experts, say Expert  SYMBOL
At the end of step  SYMBOL  Learner receives the same gain or loss as Expert  SYMBOL  at step  SYMBOL
We use notations and definitions from~ CITATION  and~ CITATION
Let  SYMBOL  be the cumulative loss of Expert  SYMBOL  at time  SYMBOL
Given  SYMBOL ,  SYMBOL , at time  SYMBOL , a natural idea to solve the expert problem is ``to follow the leader'', i e to select the expert  SYMBOL  which performed best in the past
The following simple example from Kalai and Vempala~ CITATION  shows that Learner can perform much worse than each expert: let the current losses of two experts on steps  SYMBOL  be  SYMBOL  and  SYMBOL
The ``Follow Leader'' algorithm always chooses the wrong prediction
The method of following the perturbed leader was discovered by Hannan~ CITATION
Kalai and Vempala~ CITATION  rediscovered this method and published a simple proof of the main result of Hannan
They called the algorithm of this type FPL (Following the Perturbed Leader)
Hutter and Poland~ CITATION  presented a further developments of the FPL algorithm for countable class of experts, arbitrary weights and adaptive learning rate
The FPL algorithm outputs prediction of an expert  SYMBOL  which minimizes  SYMBOL  SYMBOL \xi_t^i SYMBOL i=1,m SYMBOL t=1,2,SYMBOL p(t)=e^{-t} SYMBOL SYMBOL  SYMBOL  SYMBOL SYMBOL n SYMBOL i SYMBOL t SYMBOL 0s^i_t1 SYMBOL t SYMBOL B_t SYMBOL s_tB_t SYMBOL t SYMBOL s^i_t SYMBOL i SYMBOL 0s^i_t1$ seems to be too restrictive
In Appendix~ we consider some applications of results of Sections~- of this paper
We define two financial experts learning the fractional Brownian motion whose one-step gains at any step can not be restricted in advance
This application is at the bottom of our special interest in zero-sum games with unbounded gains in Section~
In this paper we present some modification of Kalai and Vempala algorithm for the case of unrestrictedly large one-step gains not bounded in advance
We show that in general case, the cumulative gain of any probabilistic prediction algorithm can be much worse than the gain of some expert of the pool
Nevertheless, we give the lower bound for cumulative gain of any probabilistic algorithm in general case and prove that our universal algorithm has optimal performance; we also prove that in case when one-step gains of experts of the pool have ``limited deviations'' (in particular, when they are bounded) the performance of our algorithm is close to the performance of the best expert
This result is some improvement of results mentioned above
### abstract ###
The method of  stable random projections  is a  tool for efficiently computing the  SYMBOL    distances using low memory, where  SYMBOL  is a tuning parameter
The method boils down to a statistical estimation task and various estimators have been proposed, based on the  geometric mean , the  harmonic mean , and the  fractional power  etc
This study proposes the optimal quantile  estimator, whose main operation is selecting , which is considerably less expensive than taking fractional power, the main operation in previous estimators
Our experiments report that the  optimal quantile  estimator is nearly one order of magnitude more computationally efficient than previous estimators
For  large-scale learning  tasks in which storing and computing pairwise distances is a serious bottleneck, this estimator should be desirable
In addition to its computational advantages, the  optimal quantile  estimator exhibits nice theoretical properties
It is more accurate than previous estimators when {SYMBOL }
We  derive its theoretical error bounds and  establish the explicit (i e , no hidden constants) sample complexity bound
### introduction ###
The method of  stable random projections  CITATION , as an efficient tool for computing pairwise distances in massive high-dimensional data,  provides a promising mechanism to tackle  some of the challenges in modern machine learning
In this paper, we provide an easy-to-implement algorithm for  stable random projections  which is both statistically accurate and computationally efficient
### abstract ###
Many applications in machine learning and data mining require computing  pairwise  SYMBOL  distances in a data matrix  SYMBOL
For massive high-dimensional data, computing all pairwise distances of  SYMBOL  can be infeasible
In fact, even  storing  SYMBOL  or all pairwise distances of  SYMBOL  in the memory may be also infeasible
For  SYMBOL , efficient small space algorithms exist, for example, based on the method of  stable random projections , which unfortunately is not directly applicable to  SYMBOL  This paper proposes a simple method for  SYMBOL ,  SYMBOL ,  SYMBOL ,


We first decompose the  SYMBOL  (where  SYMBOL  is even) distances into a sum of 2 marginal norms and  SYMBOL  ``inner products'' at different orders
Then we apply normal or sub-Gaussian random projections to approximate the resultant ``inner products,'' assuming that the marginal norms can be computed exactly by a linear scan
We propose two strategies for applying random projections
The basic projection strategy requires only one projection matrix but it is more difficult to analyze, while the alternative projection strategy requires  SYMBOL  projection matrices but its theoretical analysis  is much easier
In terms of the accuracy, at least for  SYMBOL , the basic strategy is always more accurate than the alternative strategy if the data are non-negative, which is common in reality
### introduction ###
This study proposes a simple method for efficiently computing the  SYMBOL  distances in a massive data matrix  SYMBOL  for  SYMBOL  (where  SYMBOL  is even), using  random projections  CITATION
While many previous work on random projections focused on approximating the  SYMBOL  distances (and inner products), the  method of  symmetric stable random projections  CITATION  is applicable to approximating the  SYMBOL  distances for all  SYMBOL
This work proposes using random projections for  SYMBOL , a least for some special cases
Machine learning algorithms often operate on the  SYMBOL  distances of  SYMBOL  instead of the original data
A straightforward application would be searching for the nearest neighbors using  SYMBOL  distance
The  SYMBOL  distance is also a basic loss functions for quality measure
The widely used ``kernel trick,'' (e g , for support vector machines (SVM)), is often constructed on top of the  SYMBOL   distances CITATION
Here we can treat  SYMBOL  as a  tuning  parameter
It is common to take  SYMBOL  ( Euclidian  distance), or  SYMBOL  ( infinity distance ),  SYMBOL  ( Manhattan  distance),  or  SYMBOL  ( Hamming  distance); but in principle any  SYMBOL  values are possible
In fact, if there is an efficient mechanism to compute the  SYMBOL  distances, then it becomes affordable to tune  learning algorithms for many values of  SYMBOL  for the best performance
In modern data mining and learning applications, the ubiquitous phenomenon of ``massive data'' imposes challenges
For example, pre-computing and storing all pairwise  SYMBOL  distances in  memory at the cost  SYMBOL  can be infeasible when  SYMBOL  (or even just  SYMBOL ) CITATION
For ultra high-dimensional data, even just storing the whole data matrix can be infeasible
In the meanwhile, modern  applications can routinely involve millions of observations; and developing scalable  learning and data mining algorithms has  been an active research direction
One commonly used strategy in current practice is   to compute the distances  on the fly  CITATION , in stead of storing all pairwise  SYMBOL  distances
Data reduction algorithms such as  sampling or sketching methods are also popular
While there have been extensive studies on approximating the  SYMBOL  distances for  SYMBOL ,  SYMBOL  can be useful too
For example, because the normal distribution is completely determined by its first two moments (mean and variance), we can identify the non-normal components of the data by analyzing  higher moments, in particular, the fourth moments (i e ,  kurtosis )
Thus, the fourth moments are critical, for example, in the field of  Independent Component Analysis (ICA)  CITATION
Therefore, it is viable to use the  SYMBOL  distance for  SYMBOL  when  lower order distances can not efficiently differentiate data
It is unfortunate that the family of  stable distributions  CITATION  is limited to  SYMBOL  and hence we can not directly using  stable distributions  for approximating the  SYMBOL  distances
In the theoretical CS community, there have been many studies on approximating the  SYMBOL  norms and distances CITATION , some of which also applicable to the  SYMBOL  distances (e g , comparing two long vectors)
Those papers proved that small space ( SYMBOL ) algorithms exist only for  SYMBOL
### abstract ###
We study the a priori semimeasure of sets of  SYMBOL -random  infinite sequences, where  SYMBOL  is a family of probability distributions depending on a real parameter  SYMBOL
In the case when for a computable probability distribution  SYMBOL  an effectively strictly consistent estimator exists, we show that the Levin's a priory semimeasure of the set of all  SYMBOL -random sequences is positive if and only if the parameter  SYMBOL  is a computable real number
For the Bernoulli family  SYMBOL , we show that the a priory semimeasure of the set  SYMBOL , where  SYMBOL  is the set of all  SYMBOL -random sequences and the union is taken over all non-random  SYMBOL , is positive
### introduction ###
We use algorithmic randomness theory to analyze ``the size'' of sets  of infinite sequences random with respect to parametric families of probability distributions
Let a parametric family of probability distributions  SYMBOL , where  SYMBOL  is a real number, be given such that an effectively strictly consistent estimator exists for this family
The Bernoulli family with a real parameter  SYMBOL  is an example of such family
Theorem~ shows that the Levin's a priory semimeasure of the set of all  SYMBOL -random sequences is positive if and only if the parameter value  SYMBOL  is a computable real number
We say that a property of infinite sequences has no ``empirical meaning'' if the Levin's a priory semimeasure of the set of all sequences possessing this property is  SYMBOL
In this respect, the model of the biased coin with ``a prespecified'' probability  SYMBOL  of head is meaningless when  SYMBOL  is a noncomputable real number; noncomputable parameters  SYMBOL  can have empirical meaning only in their totality, i e , as elements of some uncountable sets
For example,  SYMBOL -random sequences with noncomputable  SYMBOL  can be generated by a Bayesian mixture of these  SYMBOL  using a computable prior
In this case, evidently, the semicomputable semimeasure of the set of all sequences random with respect to this mixture is positive
We give in Appendix~ the simple proof of our previous result (formulated in Theorem~) which says that the Levin's a priory semimeasure of the set of all infinite binary sequences non-equivalent by Turing to Martin-L\"of random sequences is positive
In particular,  these sequences are non-random with respect to each computable probability  distribution
We use this result to prove Theorem~
This theorem  shows that a probabilistic machine can be constructed, which with probability close to  SYMBOL  outputs a random  SYMBOL -Bernoulli sequence such that the parameter  SYMBOL  is not random with respect to each computable probability distribution
This result can be interpreted such that the Bayesian statistical approach is insufficient to cover all possible ``meaningful'' cases for  SYMBOL -random sequences
### abstract ###
We propose a general method called truncated gradient to induce sparsity in the weights of online learning algorithms with convex loss functions
This method has several essential properties:   The degree of sparsity is continuous---a parameter controls the rate of sparsification from no sparsification to total sparsification
The approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular  SYMBOL -regularization method in the batch setting
We prove that small rates of sparsification result in only small additional regret with respect to typical online learning guarantees
The approach works well empirically
We apply the approach to several datasets and find that for datasets with large numbers of features, substantial sparsity is discoverable
### introduction ###
We are concerned with machine learning over large datasets
As an example, the largest dataset we use here has over  SYMBOL  sparse examples and  SYMBOL  features using about  SYMBOL  bytes
In this setting, many common approaches fail, simply because they cannot load the dataset into memory or they are not sufficiently efficient
There are roughly two approaches which can work:   Parallelize a batch learning algorithm over many machines ( eg ,  CITATION )
Stream the examples to an online learning algorithm ( eg ,  CITATION ,  CITATION ,  CITATION , and  CITATION )
This paper focuses on the second approach
Typical online learning algorithms have at least one weight for every feature, which is too much in some applications for a couple reasons:    Space constraints
If the state of the online learning algorithm overflows RAM it can not efficiently run
A similar problem occurs if the state overflows the L2 cache
Test time constraints on computation
Substantially reducing the number of features can yield substantial improvements in the computational time required to evaluate a new sample
This paper addresses the problem of inducing sparsity in learned weights while using an online learning algorithm
There are several ways to do this wrong for our problem
For example:    Simply adding  SYMBOL  regularization to the gradient of an online weight update doesn't work because gradients don't induce sparsity
The essential difficulty is that a gradient update has the form  SYMBOL  where  SYMBOL  and  SYMBOL  are two floats
Very few float pairs add to  SYMBOL  (or any other default value) so there is little reason to expect a gradient update to accidentally produce sparsity
Simply rounding weights to  SYMBOL  is problematic because a weight may be small due to being useless or small because it has been updated only once (either at the beginning of training or because the set of features appearing is also sparse)
Rounding techniques can also play havoc with standard online learning guarantees
Black-box wrapper approaches which eliminate features and test the impact of the elimination are not efficient enough
These approaches typically run an algorithm many times which is particularly undesirable with large datasets
### abstract ###
Algorithm selection is typically based on models of algorithm performance,  learned during a separate  offline  training sequence, which can be  prohibitively expensive
In recent work, we adopted an  online  approach, in which a performance model is iteratively updated and used to guide selection on a sequence of problem instances
The resulting  exploration-exploitation  trade-off was represented as a bandit problem with expert advice, using an  existing solver for this game, but this required the setting of an arbitrary  bound on algorithm runtimes, thus invalidating the optimal regret of the solver
In this paper, we propose a simpler framework for representing algorithm selection as a bandit problem, with partial information, and an  unknown  bound on losses
We adapt an existing solver to this game, proving a bound on its expected regret,  which holds also for the resulting algorithm selection technique
We present  preliminary experiments with a set of SAT solvers on a mixed SAT-UNSAT benchmark
### introduction ###
Decades of research in the fields of Machine Learning and Artificial Intelligence brought us a variety of alternative algorithms for solving many kinds of problems
Algorithms often display variability in performance quality, and computational cost, depending on the particular problem instance being solved: in other words, there is no single ``best'' algorithm
While a ``trial and error'' approach is still the most popular, attempts to automate algorithm selection are not new   CITATION , and have grown to form a consistent and dynamic field of research in the area of  Meta-Learning   CITATION
Many selection methods follow an  offline  learning scheme, in which the availability of a  large training set of performance data for the different algorithms is assumed
This data is used to learn a model that %can  maps ( problem ,  algorithm ) pairs to expected performance, or to some probability distribution on performance
The model is later used to select and run, for each new problem instance, only the algorithm that is expected to give the best results
While this approach might sound reasonable, it actually ignores the computational cost of the initial training phase: collecting a representative sample of performance data has to be done via   solving a set of training problem instances, and each instance is solved repeatedly, at least once for each of the available algorithms,  or more if the algorithms are randomized
Furthermore, these training instances are assumed to be representative of future ones, as the model is not updated after training
In other words, there is an obvious trade-off  between the  exploration  of algorithm performances on different problem instances, aimed at learning the model, and the  exploitation  of the best algorithm/problem combinations, based on the model's predictions
This trade-off is typically ignored  in offline algorithm selection, and the size of the training set  is chosen heuristically
In our previous work  CITATION , we have kept an  online  view of algorithm selection, in which the only input available to the meta-learner is a set of algorithms, of  unknown performance, and a sequence of problem instances that have to be solved
Rather than artificially subdividing the problem set into a training and a test set, we iteratively update the model  each time an instance is solved, and use it to guide algorithm selection on the next instance
Bandit problems  CITATION  offer a solid theoretical framework for dealing with the exploration-exploitation trade-off in an online setting
One important obstacle to the straightforward application of a bandit problem solver to algorithm selection is that most existing solvers assume a bound on losses to be available beforehand
In  CITATION  we dealt with this issue heuristically, fixing the bound in advance
In this paper, we introduce a modification of an existing bandit problem solver  CITATION , which allows it to deal with an unknown bound on losses, while retaining a bound on the expected regret
This allows us to propose a simpler version of  the algorithm selection framework \GambleTA, originally introduced in   CITATION
The result is a  parameterless online algorithm selection method,  the first, to our knowledge, with a provable upper bound on regret
The rest of the paper is organized as follows
Section  describes a tentative taxonomy of algorithm selection methods, along with a few examples from literature
Section  presents our framework for representing algorithm selection as a bandit problem, discussing the introduction of a higher level of selection among different algorithm selection techniques ( time allocators )
Section  introduces the modified bandit problem solver for unbounded loss games,  along with its bound on regret
Section  describes   experiments with SAT solvers
Section  concludes the paper
### abstract ###
Previous studies on multi-instance learning typically treated instances in the  bags  as  independently and identically distributed
The instances in a bag, however, are rarely independent in real tasks, and a better performance can be expected if the instances are treated in an non- iid 
way that exploits relations among instances
In this paper, we propose two simple yet effective methods
In the first method, we explicitly map every bag to an undirected graph and design a graph kernel for distinguishing the positive and negative bags
In the second method, we implicitly construct graphs by deriving affinity matrices and propose an efficient graph kernel considering the clique information
The effectiveness of the proposed methods are validated by experiments
### introduction ###
In multi-instance learning  CITATION , each training example is a  bag  of instances
A bag is positive if it contains at least one positive instance, and negative otherwise
Although the labels of the training bags are known, however, the labels of the instances in the bags are unknown
The goal is to construct a learner to classify unseen bags
Multi-instance learning has been found useful in diverse domains such as image categorization  CITATION , image retrieval  CITATION  , text categorization  CITATION , computer security  CITATION , face detection  CITATION , computer-aided medical diagnosis  CITATION , etc
A prominent advantage of multi-instance learning mainly lies in the fact that many real objects have inherent structures, and by adopting the multi-instance representation we are able to represent such objects more naturally and capture more information than simply using the flat single-instance representation
For example, suppose we can partition an image into several parts
In contrast to representing the whole image as a single-instance, if we represent each part as an instance, then the partition information is captured by the multi-instance representation; and if the partition is meaningful (e g , each part corresponds to a region of saliency), the additional information captured by the multi-instance representation may be helpful to make the learning task easier to deal with
It is obviously not a good idea to apply multi-instance learning techniques everywhere since if the single-instance representation is sufficient, using multi-instance representation just gilds the lily
Even on tasks where the objects have inherent structures, we should keep in mind that the power of multi-instance representation exists in its ability of capturing some structure information
However, as Zhou and Xu  CITATION  indicated, previous studies on multi-instance learning typically treated the instances in the bags as independently and identically distributed; this neglects the fact that the relations among the instances convey important structure information
Considering the above image task again, treating the different image parts as inter-correlated samples is evidently more meaningful than treating them as unrelated samples
Actually, the instances in a bag are rarely independent, and a better performance can be expected if the instances are treated in an non- iid 
way that exploits the relations among instances
In this paper, we propose two multi-instance learning methods which do not treat the instances as  iid 
samples
Our basic idea is to regard each bag as an entity to be processed as a whole, and regard instances as inter-correlated components of the entity
Experiments show that our proposed methods achieve performances highly competitive with state-of-the-art multi-instance learning methods
The rest of this paper is organized as follows
We briefly review related work in Section 2, propose the new methods in Section 3, report on our experiments in Section 4, conclude the paper finally in Section 5
### abstract ###
We study the problem of dynamic spectrum sensing and access in cognitive radio systems as a partially observed Markov decision process (POMDP)
A group of cognitive users cooperatively tries to exploit vacancies in primary (licensed) channels whose occupancies follow a Markovian evolution
We first consider the scenario where the cognitive users have perfect knowledge of the distribution of the signals they receive from the primary users
For this problem, we obtain a greedy channel selection and access policy that maximizes the instantaneous reward, while satisfying a constraint on the probability of interfering with licensed transmissions
We also derive an analytical universal upper bound on the performance of the optimal policy
Through simulation, we show that our scheme achieves good performance relative to the upper bound and improved performance relative to an existing scheme
We then consider the more practical scenario where the exact distribution of the signal from the primary is unknown
We assume a parametric model for the distribution and develop an algorithm that can learn the true distribution, still guaranteeing the constraint on the interference probability
We show that this algorithm outperforms the naive design that assumes a worst case value for the parameter
We also provide a proof for the convergence of the learning algorithm
### introduction ###
Cognitive radios that exploit vacancies in the licensed spectrum have been proposed as a solution to the ever-increasing demand for radio spectrum
The idea is to sense times when a specific licensed band is not used at a particular place and use this band for unlicensed transmissions without causing interference to the licensed user (referred to as the `primary')
An important part of designing such systems is to develop an efficient channel selection policy
The cognitive radio (also called the `secondary user') needs to adopt the best strategy for selecting channels for sensing and access
The sensing and access policies should jointly ensure that the probability of interfering with the primary's transmission meets a given constraint
In the first part of this paper, we consider the design of such a joint sensing and access policy, assuming a Markovian model for the primary spectrum usage on the channels being monitored
The secondary users use the observations made in each slot to track the probability of occupancy of the different channels
We obtain a suboptimal solution to the resultant POMDP problem
In the second part of the paper, we propose and study a more practical problem that arises when the secondary users are not aware of the exact distribution of the signals that they receive from the primary transmitters
We develop an algorithm that learns these unknown statistics and show that this scheme gives improved performance over the naive scheme that assumes a worst-case value for the unknown distribution
### abstract ###
We present a novel graphical framework for modeling non-negative sequential data with hierarchical structure
Our model corresponds to a network of coupled non-negative matrix factorization (NMF) modules, which we refer to as a positive factor network (PFN)
The data model is linear, subject to non-negativity constraints, so that observation data consisting of an additive combination of individually representable observations is also representable by the network
This is a desirable property for modeling problems in computational auditory scene analysis, since distinct sound sources in the environment are often well-modeled as combining additively in the corresponding magnitude spectrogram
We propose inference and learning algorithms that leverage existing NMF algorithms and that are straightforward to implement
We present a target tracking example and provide results for synthetic observation data which serve to illustrate the interesting properties of PFNs and motivate their potential usefulness in applications such as music transcription, source separation, and speech recognition
We show how a target process characterized by a hierarchical state transition model can be represented as a PFN
Our results illustrate that a PFN which is defined in terms of a single target observation can then be used to effectively track the states of multiple simultaneous targets
Our results show that the quality of the inferred target states degrades gradually as the observation noise is increased
We also present results for an example in which meaningful hierarchical features are extracted from a spectrogram
Such a hierarchical representation could be useful for music transcription and source separation applications
We also propose a network for language modeling
### introduction ###
We present a graphical hidden variable framework for modeling non-negative sequential data with hierarchical structure
Our framework is intended for applications where the observed data is non-negative and is well-modeled as a non-negative linear combination of underlying non-negative components
Provided that we are able to adequately model these underlying components individually, the full model will then be capable of representing any observed additive mixture of the components due to the linearity property
This leads to an economical modeling representation, since a compact parameterization can explain any number of components that combine additively
Thus, in our approach, we do not need to be concerned with explicitly modeling the maximum number of observed components nor their relative weights in the mixture signal
To motivate the approach, consider the problem of computational auditory scene analysis (CASA), which involves identifying auditory ``objects'' such as musical instrument sounds, human voice, various environmental noises, etc, from an audio recording
Speech recognition and music transcription are specific examples of CASA problems
When analyzing audio, it is common to first transform the audio signal into a time-frequency image, such as the spectrogram (i e , magnitude of the short-time Fourier transform (STFT))
We empirically observe that the spectrogram of a mixture of auditory sources is often well-modeled as a linear combination of the spectrograms of the individual audio sources, due to the sparseness of the time-frequency representation for typical audio sources
For example, consider a recording of musical piece performed by a band
We empirically observe that the spectrogram of the recording tends to be well-approximated as the sum of the spectrograms of the individual instrument notes played in isolation
If one could construct a model using our framework that is capable of representing any individual instrument note played in isolation, the model would then automatically be capable of representing observed data corresponding to arbitrary non-negative linear combinations of the individual notes
Likewise, if one could construct a model under our framework capable of representing a recording of a single human speaker (possibly including a language model), such a model would then be capable of representing an audio recording of multiple people speaking simultaneously
Such a model would have obvious applications to speaker source separation and simultaneous multiple-speaker speech recognition
We do not attempt to construct such complex models in this paper, however
Rather, our primary objective here will be to construct models that are simple enough to illustrate the interesting properties of our approach, yet complex enough to show that our approach is noise-robust, capable of learning from training data, and at least somewhat scalable
We hope that the results presented here will provide sufficient motivation for others to extend our ideas and begin experimenting with more sophisticated PFNs, perhaps applying them to the above-mentioned CASA problems
An existing area of research that is related to our approach is non-negative matrix factorization (NMF) and its extensions
NMF is a data modeling and analysis tool for approximating a non-negative matrix  SYMBOL  as the product of two non-negative matrices  SYMBOL  and  SYMBOL  so that the reconstruction error between  SYMBOL  and   SYMBOL  is minimized under a suitable cost function
NMF was originally proposed by Paatero as  positive matrix factorization   CITATION
Lee and Seung later developed robust and simple to implement multiplicative update rules for iteratively performing the factorization  CITATION
Various sparse versions of NMF have also been recently proposed  CITATION ,  CITATION ,  CITATION
NMF has recently been applied to many applications where a representation of non-negative data as an additive combination of non-negative basis vectors seems reasonable
Such applications include object modeling in computer vision, magnitude spectra modeling of audio signals  CITATION , and various source separation applications  CITATION
The non-negative basis decomposition provided by NMF is, by itself, not capable of representing complex model structure
For this reason, extensions have been proposed to make NMF more expressive
Smaragdis extended NMF in  CITATION  to model the temporal dependencies in successive spectrogram time slices
His NMF extension, which he termed  Convolutive NMF , also appears to be a special case of one of our example models in Section~
We are unaware of any existing work in the literature that allow for the general graphical representation of complex hidden variable models, particularly sequential data models, that is provided by our approach, however
A second existing area of research that is related to our approach is probabilistic graphical models  CITATION  and in particular, dynamic Bayesian networks (DBNs)  CITATION ,  CITATION , which are probabilistic graphical models for sequential data
We note that the Hidden Markov Model (HMM) is a special case of a DBN
DBNs are widely used for speech recognition and other sequential data modeling applications
Probabilistic graphical models are appealing because they they can represent complex model structure using an intuitive and modular graphical modeling representation
A drawback is that the corresponding exact and/or approximate inference and learning algorithms can be complex and difficult to implement, and overcoming tractability issues can be a challenge
Our objective in this paper is to present a framework for modeling non-negative data that retains the non-negative linear representation of NMF, while also supporting more structured hidden variable data models with a graphical means for representing variable interdependencies analogously to that of the probabilistic graphical models framework
We will be particularly interested in developing models for sequential data consisting of the spectrograms of audio recordings
Our framework is essentially a modular extension of NMF in which the full graphical model corresponds to several coupled NMF sub-models
The overall model then corresponds to a system of coupled vector or matrix factorization equations
Throughout this paper, we will refer to a particular system of factorizations and the corresponding graphical model as a  positive factor network (PFN)
We will refer to the dynamical extension of a PFN as a  dynamic positive factor network (DPFN)
Given an observed subset of the PFN model variables, we define inference as solving for the values of the hidden subset of variables and learning as solving for the model parameters in the system of factorization equations
Note that our definition of inference is distinct from the probabilistic notion of inference
In a PFN, inference corresponds to solving for actual values of the hidden variables, whereas in a probabilistic model inference corresponds to solving for probability distributions over the hidden variables given the values of the observed variables
Performing inference in a PFN is therefore more analogous to computing the MAP estimates for the hidden variables in a probabilistic model
One could obtain an analogous probabilistic model from a PFN by considering the model variables to be non-negative continuous-valued random vectors and defining suitable conditional probability distributions that are consistent with the non-negative linear variable model
Let us call this class of models  probabilistic PFNs
Exact inference is generally intractable in such a model since the hidden variables are continuous-valued and the model is not linear-Gaussian
However, one could consider deriving algorithms for performing approximate inference and developing a corresponding EM-based learning algorithm
We are unaware of any existing algorithms for performing tractable approximate inference in a probabilistic PFN
It is possible that our PFN inference algorithm may also have a probabilistic interpretation, but exploring the idea further is outside the scope of this paper
Rather, in this paper our objective is to to develop and motivate the inference and learning algorithms by taking a modular approach in which existing NMF algorithms are used and coupled in a way that seems to be intuitively reasonable
We will be primarily interested in empirically characterizing the performance of the proposed inference and learning algorithms on various example PFNs and test data sets in order to get a sense of the utility of this approach to interesting real-world applications
We propose general joint inference and learning algorithms for PFNs which correspond to performing NMF update steps independently (and therefore potentially also in parallel) on the various factorization equations while simultaneously enforcing coupling constraints so that variables that appear in multiple factorization equations are constrained to have identical values
Our empirical results show that the proposed inference and learning algorithms are fairly robust to additive noise and have good convergence properties
By leveraging existing NMF multiplicative update algorithms, the PFN inference and learning algorithms have the advantage of being straightforward to implement, even for relatively large networks
Sparsity constraints can also be added to a module in a PFN model by leveraging existing sparse NMF algorithms
We note that the algorithms for performing inference and learning in PFNs should be understandable by anyone with a knowledge of elementary linear algebra and basic graph theory, and do not require a background in probability theory
Similar to existing NMF algorithms, our algorithms are highly parallel and can be optimized to take advantage of parallel hardware such as multi-core CPUs and potentially also stream processing hardware such as GPUs
More research will be needed to determine how well our approach will scale to very large or complex networks
The remainder of this paper has the following structure
In Section~, we present the basic PFN model
In Section~, we present an example of how a DPFN can be used to represent a transition model and present empirical results
In Section~, we present an example of using a PFN to model sequential data with hierarchical structure and present empirical results for a regular expression example
In Section~, we present a target tracking example and provide results for synthetic observation data which serve to illustrate the interesting properties of PFNs and motivate their potential usefulness in applications such as music transcription, source separation, and speech recognition
We show how a target process characterized by a hierarchical state transition model can be represented by a PFN
Our results illustrate that a PFN which is defined in terms of a single target observation can then be used to effectively track the states of multiple simultaneous targets in the observed data
In Section~ we present results for an example in which meaningful hierarchical features are extracted from a spectrogram
Such a hierarchical representation could be useful for music transcription and source separation applications
In Section~, we propose a DPFN for modeling the sequence of words or characters in a text document as an additive factored transition model of word features
We also propose slightly modified versions Lee and Seung's update rules to avoid numerical stability issues
The resulting modified update rules are presented in Appendix~
### abstract ###
We prove that mutual information is actually negative copula entropy, based on which a method for mutual information estimation is proposed
### introduction ###
In information theory, mutual information (MI) is a difference concept with entropy
CITATION  In this paper, we prove with copula  CITATION  that they are essentially same -- mutual information is also a kind of entropy, called  copula entropy
Based on this insightful result, We propose a simple method for estimating mutual information
Copula is a theory on dependence and measurement of association
CITATION  Sklar  CITATION  proved that joint distribution  SYMBOL  can be represented with copula  SYMBOL  and margins  SYMBOL  in the following form:  SYMBOL *} Derived by separating the margins from joint distribution, copula has all the dependence information of random variables, which is believed that mutual information does as well
Here gives notation
SYMBOL  denote copula function and copula density;  SYMBOL  denotes joint distribution and marginal distribution;  SYMBOL  denote entropy, mutual information, and copula entropy respectively
Finally, bold letters represent vectors while normal letters single variable
### abstract ###
In many fields where human understanding plays a crucial role, such as bioprocesses, the capacity of extracting knowledge from data is of critical importance
Within this framework, fuzzy learning methods, if properly used, can greatly help human experts
Amongst these methods, the aim of orthogonal transformations, which have been proven to be mathematically robust, is to build rules from a set of training data and to select the most important ones by linear regression or rank revealing techniques
The OLS algorithm is a good representative of those methods
However, it was originally designed so that it only cared about numerical performance
Thus, we propose some modifications of the original method to take interpretability into account
After recalling the original algorithm, this paper presents the changes made to the original method, then discusses some results obtained from benchmark problems
Finally, the algorithm is applied to a real-world fault detection depollution problem
### introduction ###
Fuzzy learning methods, unlike ``black-box'' models such as neural networks, are likely to give interpretable results, provided that some constraints are respected
While this ability is somewhat meaningless in some applications such as stock market prediction, it becomes essential when human experts want to gain insight into a complex problem (e g industrial  CITATION  and biological  CITATION  processes, climate evolution  CITATION )
These considerations explain why interpretability issues in Fuzzy Modeling have become an important research topic, as shown in recent literature  CITATION
Even so, the meaning given to interpretability in Fuzzy Modeling is not always the same
By interpretability, some authors mean mathematical interpretability, as in  CITATION  where a structure is developed in Takagi-Sugeno systems, that leads to the interpretation of every consequent polynomial as a Taylor series expansion about the rule center
Others mean linguistic interpretability, as in  CITATION ,  CITATION
The present paper is focused on the latter approach
Commonly admitted requirements for interpretability are a small number of consistent membership functions and a reasonable number of rules in the fuzzy system
Orthogonal transformation methods provide a set of tools for building rules from data and selecting a limited subset of rules
Those methods were originally designed for linear optimization, but subject to some conditions they can be used in fuzzy models
For instance, a zero order Takagi Sugeno model can be written as a set of r fuzzy rules, the  SYMBOL  rule being:   SYMBOL }  where  SYMBOL  are the fuzzy sets associated to the  SYMBOL  variables for that given rule, and  SYMBOL  is the corresponding crisp rule conclusion
Let  SYMBOL  be  SYMBOL  input-output pairs of a data set, where  SYMBOL  and  SYMBOL
For the  SYMBOL  pair, the above Takagi Sugeno model output is calculated as follows:  SYMBOL } In equation ,  SYMBOL  is the conjunction operator used to combine elements in the rule premise,  SYMBOL  represents, within the  SYMBOL  rule, the membership function value for  SYMBOL
Let us introduce the rule firing strength  SYMBOL
Thus equation  can be rewritten as:  SYMBOL }  Once the fuzzy partitions have been set, and provided a given data set, the  SYMBOL  can be computed for all  SYMBOL  in the data set
Then equation  allows to reformulate the fuzzy model as a linear regression problem, written in matrix form as:  SYMBOL
In that matrix form, y is the sample output vector, P is the firing strength matrix,  SYMBOL  is the rule consequent vector and E is an error term
Orthogonal transformation methods can then be used to determine the  SYMBOL  to be kept, and to assign them optimal values in order to design a zero order Takagi Sugeno model from the data set
A thorough review of the use of orthogonal transformation methods (SVD, QR, OLS) to select fuzzy rules  can be found in  CITATION
They can be divided into two main families: the methods that select rules using the  SYMBOL  matrix decomposition only, and others that also use the output  SYMBOL  to do a best fit
The first family of methods (rank revealing techniques) is particularly interesting when the input fuzzy partitions include redundant or quasi redundant fuzzy sets
The orthogonal least squares (OLS) technique belongs to the second family and allows a rule selection based on the rule respective contribution to the output inertia or variance
With respect to this criterion, it gives a good summary of the system to be modeled, which explains why it has been widely used in Statistics, and also why it is particularly suited for rule induction, as shown for instance in  CITATION
The aim of the present paper is to establish, by using the OLS method as an example, that orthogonal transformation results can be made interpretable, without suffering too much loss of accuracy
This is achieved by building interpretable fuzzy partitions  and by reducing the number of rule conclusions
This turns orthogonal transformations into useful tools for modeling regression problems and extracting knowledge from data
Thus they are worth a careful study as there are few available techniques for achieving this double objective, contrary to knowledge induction in classification problems
In section , we recall how the original OLS works
Section  introduces the learning criteria that will be used in our modified OLS algorithm
Section  presents the modifications necessary to respect the interpretability constraints
In the next section, the modified algorithm is applied to benchmark problems, compared to the original one and to reference results found in the literature
A real-world application is presented and analyzed in section
Finally we give some conclusions and perspectives for future work
### abstract ###
In this paper, we propose the MIML ( Multi-Instance Multi-Label learning ) framework where an example is described by multiple instances and associated with multiple class labels
Compared to traditional learning frameworks, the MIML framework is more convenient and natural for representing complicated objects which have multiple semantic meanings
To learn from MIML examples, we propose the \textsc{MimlBoost} and \textsc{MimlSvm} algorithms based on a simple degeneration strategy, and experiments show that solving problems involving complicated objects with multiple semantic meanings in the MIML framework can lead to good performance
Considering that the degeneration process may lose information, we propose the \textsc{D-MimlSvm} algorithm which tackles MIML problems directly in a regularization framework
Moreover, we show that even when we do not have access to the real objects and thus cannot capture more information from real objects by using the MIML representation, MIML is still useful
We propose the \textsc{InsDif} and \textsc{SubCod} algorithms \textsc{InsDif} works by transforming single-instances into the MIML representation for learning, while \textsc{SubCod} works by transforming single-label examples into the MIML representation for learning
Experiments show that in some tasks they are able to achieve better performance than learning the single-instances or single-label examples directly
### introduction ###
In  traditional supervised learning , an object is represented by an instance, i e , a feature vector, and associated with a class label
Formally, let  SYMBOL  denote the instance space (or feature space) and  SYMBOL  the set of class labels
The task is to learn a function  SYMBOL  from a given data set  SYMBOL , where  SYMBOL  is an instance and  SYMBOL  is the known label of  SYMBOL
Although this formalization is prevailing and successful, there are many real-world problems which do not fit in this framework well
In particular, each object in this framework belongs to only one concept and therefore the corresponding instance is associated with a single class label
However, many real-world objects are complicated, which may belong to multiple concepts simultaneously
For example, an image can belong to several classes simultaneously, eg ,  grasslands ,  lions ,  Africa , etc ; a text document can be classified to several categories if it is viewed from different aspects, eg ,  scientific novel ,  Jules Verne's writing  or even  books on traveling ; a web page can be recognized as  news page ,  sports page ,  soccer page , etc
In a specific real task, maybe only one of the multiple concepts is the right semantic meaning
For example, in image retrieval when a user is interested in an image with lions, s/he may be only interested in the concept  lions  instead of the other concepts  grasslands  and  Africa  associated with that image
The difficulty here is caused by those objects that involve multiple concepts
To choose the right semantic meaning for such objects for a specific scenario is the fundamental difficulty of many tasks
In contrast to starting from a large universe of all possible concepts involved in the task, it may be helpful to get the subset of concepts associated with the concerned object at first, and then make a choice in the small subset later
However, getting the subset of concepts, that is, assigning proper class labels to such objects, is still a challenging task
We notice that as an alternative to representing an object by a single instance, in many cases it is possible to represent a complicated object using a set of instances
For example, multiple patches can be extracted from an image where each patch is described by an instance, and thus the image can be represented by a set of instances; multiple sections can be extracted from a document where each section is described by an instance, and thus the document can be represented by a set of instances; multiple links can be extracted from a web page where each link is described by an instance, and thus the web page can be represented by a set of instances
Using multiple instances to represent those complicated objects may be helpful because some inherent patterns which are closely related to some labels may become explicit and clearer
In this paper, we propose the MIML ( Multi-Instance Multi-Label learning ) framework, where an example is described by multiple instances and associated with multiple class labels
Compared to traditional learning frameworks, the MIML framework is more convenient and natural for representing complicated objects
To exploit the advantages of the MIML representation, new learning algorithms are needed
We propose the \textsc{MimlBoost} algorithm and the \textsc{MimlSvm} algorithm based on a simple degeneration strategy, and experiments show that solving problems involving complicated objects with multiple semantic meanings under the MIML framework can lead to good performance
Considering that the degeneration process may lose information, we also propose the \textsc{D-MimlSvm} (i e , Direct \textsc{MimlSvm}) algorithm which tackles MIML problems directly in a regularization framework
Experiments show that this ``direct'' algorithm outperforms the ``indirect'' \textsc{MimlSvm} algorithm
In some practical tasks we do not have access to the real objects themselves such as the real images and the real web pages; instead, we are given observational data where each real object has already been represented by a single instance
Thus, in such cases we cannot capture more information from the real objects using the MIML representation
Even in this situation, however, MIML is still useful
We propose the \textsc{InsDif} (i e , INStance DIFferentiation) algorithm which transforms single-instances into MIML examples for learning
This algorithm is able to achieve a better performance than learning the single-instances directly in some tasks
This is not strange because for an object associated with multiple class labels, if it is described by only a single instance, the information corresponding to these labels are mixed and thus difficult for learning; if we can transform the single-instance into a set of instances in some proper ways, the mixed information might be detached to some extent and thus less difficult for learning
MIML can also be helpful for learning single-label objects
We propose the \textsc{SubCod} (i e , SUB-COncept Discovery) algorithm which works by discovering sub-concepts of the target concept at first and then transforming the data into MIML examples for learning
This algorithm is able to achieve a better performance than learning the single-label examples directly in some tasks
This is also not strange because for a label corresponding to a high-level complicated concept, it may be quite difficult to learn this concept directly since many different lower-level concepts are mixed; if we can transform the single-label into a set of labels corresponding to some sub-concepts, which are relatively clearer and easier for learning, we can learn these labels at first and then derive the high-level complicated label based on them with a less difficulty
The rest of this paper is organized as follows
In Section~, we review some related work
In Section~, we propose the MIML framework
In Section~ we propose the \textsc{MimlBoost} and \textsc{MimlSvm} algorithms, and apply them to tasks where the objects are represented as MIML examples
In Section~ we present the \textsc{D-MimlSvm} algorithm and compare it with the ``indirect'' \textsc{MimlSvm} algorithm
In Sections~ and , we study the usefulness of MIML when we do not have access to real objects
Concretely, in Section~, we propose the \textsc{InsDif} algorithm and show that using MIML can be better than learning single-instances directly; in Section~ we propose the \textsc{SubCod} algorithm and show that using MIML can be better than learning single-label examples directly
Finally, we conclude the paper in Section~
### abstract ###
Using the game-theoretic framework for probability, Vovk and Shafer~ CITATION  have shown that it is always possible, using randomization, to make sequential probability forecasts that pass any countable set of well-behaved statistical tests
This result generalizes work by other authors, who consider only tests of calbration
We complement this result with a lower bound
We show that Vovk and Shafer's result is valid only when the forecasts are computed with unrestrictedly increasing degree of accuracy
When some level of discreteness is fixed, we present a game-theoretic generalization of Oakes' example for randomized forecasting that is a test failing any given method of deferministic forecasting; originally, this example was presented for deterministic calibration
### introduction ###
Using the game-theoretic framework for probability~ CITATION , Vovk and Shafer have shown in~ CITATION  that it is always possible, using randomization, to make sequential probability forecasts that pass any countable set of well-behaved statistical tests
This result generalizes work by other authors, among them are Foster and Vohra~ CITATION , Kakade and Foster~ CITATION , Lehrer~ CITATION , Sandrony et al ~ CITATION , who consider only tests of calibration
We complement this result with a lower bound
We show that Vovk and Shafer's result is valid only when the forecasts are computed with unrestrictedly increasing degree of accuracy
When some level of discreteness is fixed, we present a game-theoretic version of Oakes' example for randomized forecasting that is a test failing any given method of deterministic forecasting; originally, this example was presented for deterministic calibration
To formulate this example, we use the forecasting game presented by Vovk and Shafer~ CITATION , namely Binary Forecasting Game II
We discuss details of the randomized forecasting algorithms in Section~
The Shafer and Vovk's~ CITATION  game-theoretic framework is considered in Section~
We present in this section the original Vovk and Shafer's~ CITATION  result on universal randomized forecasting and prove our result which gives the limits for such forecasting - a game-theoretic version of the Oakes' example for randomized forecasting
### abstract ###
Recognizing analogies, synonyms, anto\-nyms, and associations appear to be four distinct tasks, requiring distinct NLP algorithms
In the past, the four tasks have been treated independently, using a wide variety of algorithms
These four semantic classes, however, are a tiny sample of the full range of semantic phenomena, and we cannot afford to create ad hoc algorithms for each semantic phenomenon; we need to seek a unified approach
We propose to subsume a broad range of phenomena under analogies
To limit the scope of this paper, we restrict our attention to the subsumption of synonyms, antonyms, and associations
We introduce a supervised corpus-based machine learning algorithm for classifying analogous word pairs, and we show that it can solve multiple-choice SAT analogy questions, TOEFL synonym questions, ESL synonym-antonym questions, and similar-associated-both questions from cognitive psychology
### introduction ###
A pair of words (petrify:stone) is  analogous  to another pair (vaporize:gas) when the semantic relations between the words in the first pair are highly similar to the relations in the second pair
Two words (levied and imposed)  are  synonymous  in a context (levied a tax) when they can be interchanged (imposed a tax), they are are  antonymous  when they have opposite meanings (black and white), and they are  associated  when they tend to co-occur (doctor and hospital)
On the surface, it appears that these are four distinct semantic classes, requiring distinct NLP algorithms, but we propose a uniform approach to all four
We subsume synonyms, antonyms, and associations under analogies
In essence, we say that  SYMBOL  and  SYMBOL  are antonyms when the pair  SYMBOL : SYMBOL  is analogous to the pair black:white,  SYMBOL  and  SYMBOL  are synonyms when they are analogous to the pair levied:imposed, and  SYMBOL  and  SYMBOL  are associated when they are analogous to the pair doctor:hospital
There is past work on recognizing analogies  CITATION , synonyms  CITATION , antonyms  CITATION , and associations  CITATION , but each of these four tasks has been examined separately, in isolation from the others
As far as we know, the algorithm proposed here is the first attempt to deal with all four tasks using a uniform approach
We believe that it is important to seek NLP algorithms that can handle a broad range of semantic phenomena, because developing a specialized algorithm for each phenomenon is a very inefficient research strategy
It might seem that a lexicon, such as WordNet  CITATION , contains all the information we need to handle these four tasks
However, we prefer to take a corpus-based approach to semantics
Veale \shortcite{veale04} used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43\%, but the best corpus-based approach attains an accuracy of 56\%  CITATION
Another reason to prefer a corpus-based approach to a lexicon-based approach is that the former requires less human labour, and thus it is easier to extend to other languages
In Section~, we describe our algorithm for recognizing analogies
We use a standard supervised machine learning approach, with feature vectors based on the frequencies of patterns in a large corpus
We use a support vector machine (SVM) to learn how to classify the feature vectors  CITATION
Section~ presents four sets of experiments
We apply our algorithm for recognizing analogies to multiple-choice analogy questions from the SAT college entrance test, multiple-choice synonym questions from the TOEFL (test of English as a foreign language), ESL (English as a second language) practice questions for distinguishing synonyms and antonyms, and a set of word pairs that are labeled  similar ,  associated , and  both , developed for experiments in cognitive psychology
We discuss the results of the experiments in Section~
The accuracy of the algorithm is competitive with other systems, but the strength of the algorithm is that it is able to handle all four tasks, with no tuning of the learning parameters to the particular task
It performs well, although it is competing against specialized algorithms, developed for single tasks
Related work is examined in Section~ and limitations and future work are considered in Section~
We conclude in Section~
### abstract ###
Quantum classification is defined as the task of predicting the associated class of an unknown quantum state drawn from an ensemble of pure states given a finite number of copies of this state
By recasting the state discrimination problem within the framework of Machine Learning (ML), we can use the notion of learning reduction coming from classical ML to solve different variants of the classification task, such as the weighted binary and the multiclass versions
### introduction ###
Suppose that you are given an unknown quantum state drawn from an ensemble of possible pure states where each state is labeled after the class from which it originated
How well can you predict the class of this unknown state
This general question is often referred to in the literature as (quantum)  state discrimination ~ CITATION  and has been studied at least as far back as the seminal work of Helstrom in the seventies in the field of  quantum detection and estimation theory ~ CITATION
Of course, the answer will depend on parameters such as the structure and your knowledge of the ensemble of pure states, the dimension of the Hilbert space in which the quantum states live and the number of copies of the unknown state you received
In this paper, we take a Machine Learning (ML) view of the problem by recasting it as a learning task called  quantum classification
Our main goal by doing so is to bring new ideas and insights from ML to help solve this task and some of its variants
Other motivations include the characterization of these learning tasks in terms of the amount of information needed to complete them (measured for instance by the number of copies of the quantum states) and the development of a framework that can be used to relate and compare these tasks
This approach of performing learning on quantum states was originally taken and defined in~ CITATION , where it was illustrated by giving an explicit algorithm for the task of  quantum clustering , where the goal is to group in clusters quantum states that are similar (using the fidelity as a similarity measure) while putting states that are dissimilar in different clusters
The model of learning on quantum states put forward in this paper is complementary to a model proposed by Aaronson~ CITATION , where the training dataset is composed of POVM's ( Positive-Operator Valued Measurement ), and not quantum states
In Aaronson's model, we receive a finite number of copies of an unknown quantum state and the goal is, by ``training'' this state on a few POVM's, to produce with high probability a hypothesis that can generalize with a reasonable accuracy on unobserved POVM's belonging to this training dataset
The outline of this paper is as follows
First, the model of performing learning in a quantum world is introduced in Section~ along with the notion of learning reduction which allows us to relate together different learning tasks
Afterwards, in Section~, the task of binary classification is described, and the weighted and multiclass versions of this task are defined respectively in Sections~ and~
Finally, Section~ concludes with a discussion
### abstract ###
We give a characterization of Maximum Entropy/Minimum Relative Entropy inference by providing two `strong entropy concentration' theorems
These theorems unify and generalize Jaynes' `concentration phenomenon' and Van Campenhout and Cover's `conditional limit theorem'
The theorems characterize exactly in what sense a prior distribution  SYMBOL  conditioned on a given constraint and the distribution  SYMBOL  minimizing  SYMBOL  over all  SYMBOL  satisfying the constraint are `close' to each other
We then apply our theorems to establish the relationship between entropy concentration and a game-theoretic characterization of Maximum Entropy Inference due to Tops{\o}e and others
### introduction ###
Jaynes' Maximum Entropy (MaxEnt) Principle is a well-known principle for inductive inference  CITATION
It has been applied to statistical and machine learning problems ranging from protein modeling to stock market prediction  CITATION
One of its characterizations (some would say `justifications') is the so-called  concentration phenomenon\/   CITATION
Here is an informal version of this phenomenon,  in the words of  CITATION :  For the case in which a prior distribution over the domain at hand is available,  CITATION  have proven the related  conditional limit theorem
In Sections~-, we provide a strong generalization of both the concentration phenomenon and the conditional limit theorem
In Section~, the results of Section~ are used to   extend an existing game-theoretic characterization (again, some would say ``justification'')  of Maximum Entropy due to  CITATION
In this way, we provide sharper results on two of the most frequently  cited characterizations of the maximum entropy principle
### abstract ###
While statistics focusses on hypothesis testing and on estimating (properties of) the true sampling distribution, in machine learning the performance of learning algorithms on future data is the primary issue
In this paper we bridge the gap with a general principle (PHI) that identifies hypotheses with best predictive performance
This includes predictive point and interval estimation, simple and composite hypothesis testing, (mixture) model selection, and others as special cases
For concrete instantiations we will recover well-known methods, variations thereof, and new ones
PHI nicely justifies, reconciles, and blends (a reparametrization invariant variation of) MAP, ML, MDL, and moment estimation
One particular feature of PHI is that it can genuinely deal with nested hypotheses
### introduction ###
Consider data  SYMBOL  sampled from some distribution  SYMBOL  with unknown  SYMBOL
The likelihood function or the posterior contain the complete statistical information of the sample
Often this information needs to be summarized or simplified for various reasons (comprehensibility, communication, storage, computational efficiency, mathematical tractability, etc )
Parameter estimation, hypothesis testing, and model (complexity) selection can all be regarded as ways of summarizing this information, albeit in different ways or context
The posterior might either be summarized by a single point  SYMBOL  (e g \ ML or MAP or mean or stochastic model selection), or by a convex set  SYMBOL  (e g \ confidence or credible interval), or by a finite set of points  SYMBOL  (mixture models) or a sample of points (particle filtering), or by the mean and covariance matrix (Gaussian approximation), or by more general density estimation, or in a few other ways  CITATION
I have roughly sorted the methods in increasing order of complexity
This paper concentrates on set estimation, which includes (multiple) point estimation and hypothesis testing as special cases, henceforth jointly referred to as `` hypothesis identification '' (this nomenclature seems uncharged and naturally includes what we will do: estimation and testing of simple and complex hypotheses but not density estimation)
We will briefly comment on generalizations beyond set estimation at the end
There are many desirable properties any hypothesis identification principle ideally should satisfy
It should \parskip=0ex\parsep=0exsep=0ex  lead to good predictions (that's what models are ultimately for),  be broadly applicable,  be analytically and computationally tractable,  be defined and make sense also for non- iid  \ and non-stationary data,  be reparametrization and representation invariant,  work for simple and composite hypotheses,  work for classes containing nested and overlapping hypotheses,  work in the estimation, testing, and model selection regime,  reduce in special cases (approximately) to existing other methods
Here we concentrate on the first item, and will show that the resulting principle nicely satisfies many of the other items
We address the problem of identifying hypotheses (parameters/models) with good  predictive performance  head on
If  SYMBOL  is the true parameter, then  SYMBOL  is obviously the best prediction of the  SYMBOL  future observations  SYMBOL
If we don't know  SYMBOL  but have prior belief  SYMBOL  about its distribution, the predictive distribution  SYMBOL  based on the past  SYMBOL  observations  SYMBOL  (which averages the likelihood  SYMBOL  over  SYMBOL  with posterior weight  SYMBOL ) is by definition the best Bayesian predictor Often we cannot use full Bayes (for reasons discussed above) but predict with hypothesis  SYMBOL , i e \ use  SYMBOL  as prediction
The closer  SYMBOL  is to  SYMBOL  or  SYMBOL  the better is  SYMBOL 's prediction (by definition), where we can measure closeness with some distance function  SYMBOL
Since  SYMBOL  and  SYMBOL  are (assumed to be) unknown, we have to sum or average over them
Predictive hypothesis identification  (PHI) minimizes the losses w r t \ some  hypothesis class   SYMBOL
Our formulation is general enough to cover point and interval estimation, simple and composite hypothesis testing, (mixture) model (complexity) selection, and others
The general idea of inference by maximizing predictive performance is not new  CITATION
Indeed, in the context of model (complexity) selection it is prevalent in machine learning and implemented primarily by empirical cross validation procedures and variations thereof  CITATION  or by minimizing test and/or train set (generalization) bounds; see  CITATION  and references therein
There are also a number of statistics papers on predictive inference; see  CITATION  for an overview and older references, and  CITATION  for newer references
Most of them deal with distribution free methods based on some form of cross-validation discrepancy measure, and often focus on model selection
A notable exception is MLPD  CITATION , which maximizes the predictive likelihood including future observations
The full decision-theoretic setup in which a decision based on  SYMBOL  leads to a loss depending on  SYMBOL , and minimizing the expected loss, has been studied extensively  CITATION , but scarcely in the context of hypothesis identification
On the natural progression of estimation SYMBOL prediction SYMBOL action, approximating the predictive distribution by minimizing \req{LPT} lies between traditional parameter estimation and optimal decision making
Formulation \req{LPT} is quite natural but I haven't seen it elsewhere
Indeed, besides ideological similarities the papers above bear no resemblance to this work
The main purpose of this paper is to investigate the predictive losses above and in particular their minima, i e \ the best predictor in  SYMBOL
Section  introduces notation, global assumptions, and illustrates PHI on a simple example
This also shows a shortcoming of MAP and ML esimtation
Section  formally states PHI, possible distance and loss functions, their minima, In Section , I study exact properties of PHI: invariances, sufficient statistics, and equivalences
Sections  investigates the limit  SYMBOL  in which PHI can be related to MAP and ML
Section  derives large sample approximations  SYMBOL  for which PHI reduces to sequential moment fitting (SMF)
The results are subsequently used for Offline PHI
Section  contains summary, outlook and conclusions
Throughout the paper, the Bernoulli example will illustrate the general results \paranodot{The main aim} of this paper is to introduce and motivate PHI, demonstrate how it can deal with the difficult problem of selecting composite and nested hypotheses, and show how PHI reduces to known principles in certain regimes
The latter provides additional justification and support of previous principles, and clarifies their range of applicability
In general, the treatment is exemplary, not exhaustive
### abstract ###
For supervised and unsupervised learning, positive definite kernels allow to use large and potentially infinite dimensional feature spaces with a computational cost that only depends on the number of observations
This is usually done through the penalization of predictor functions by  Euclidean or Hilbertian norms
In this paper, we explore penalizing by sparsity-inducing norms such as the  SYMBOL -norm or the block  SYMBOL -norm
We assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework,  in polynomial time in the number of selected kernels
This framework is naturally applied to non linear variable selection; our extensive simulations on synthetic datasets and datasets from the UCI repository show that efficiently exploring the large feature space through sparsity-inducing norms leads to state-of-the-art predictive performance
### introduction ###
In the last two decades,  kernel methods have been a prolific  theoretical and algorithmic machine learning framework
By using appropriate regularization by Hilbertian norms, representer theorems enable to consider large and potentially infinite-dimensional feature spaces while working within an implicit feature space no larger than the number of observations
This has led to numerous works on kernel design adapted to specific data types and generic kernel-based algorithms for many learning tasks (see, eg ,  CITATION )
Regularization by sparsity-inducing norms, such as the  SYMBOL -norm has also attracted a lot of interest in recent years
While early work has focused on efficient algorithms to solve the convex optimization problems, recent research has looked at the model selection properties and predictive performance of such methods, in the linear case~ CITATION  or within the multiple kernel learning framework~ CITATION
In this paper, we aim to bridge the gap between these two lines of research by trying to use  SYMBOL -norms  inside  the feature space
Indeed, feature spaces are large and we expect the estimated predictor function to require only a small number of features, which is exactly the situation where  SYMBOL -norms have proven advantageous
This leads to two natural questions that we try to answer in this paper: (1) Is it feasible to perform optimization in this very large feature space with cost which is polynomial in the size of the input space (2) Does it lead to better predictive performance and feature selection
More precisely, we consider a positive definite kernel that can be expressed as a large sum of positive definite  basis  or  local kernels
This exactly corresponds to the situation where a large feature space is the concatenation of  smaller feature spaces, and we aim to do selection among these many kernels, which may be done through  multiple kernel learning~ CITATION
One major difficulty however is that the number of these smaller kernels is usually exponential in the dimension of the input space and applying multiple kernel learning directly in this decomposition would be intractable
In order to peform selection efficiently, we make the extra assumption that these small kernels can be embedded in a  directed acyclic graph  (DAG)
Following~ CITATION , we consider in \mysec{mkl} a specific combination of  SYMBOL -norms that is adapted to the DAG, and will restrict the authorized sparsity patterns; in our specific kernel framework, we are able to use the DAG to design an optimization algorithm which has polynomial complexity in the number of selected kernels (\mysec{optimization})
In simulations (\mysec{simulations}), we focus on   directed grids , where our framework allows to perform non-linear variable selection
We provide extensive experimental validation of our novel regularization framework; in particular, we compare it to the regular  SYMBOL -regularization and shows that it is always competitive and often leads to better performance, both on synthetic examples, and standard regression and classification datasets from the UCI repository
Finally, we extend in \mysec{consistency} some of the known consistency results of the Lasso and multiple kernel learning~ CITATION , and give a partial answer to the model selection capabilities of our regularization framework by giving necessary and sufficient conditions for model consistency
In particular, we show that our framework is adapted to estimating consistently only the  hull   of the relevant variables
Hence, by restricting the statistical power of our method, we gain computational efficiency
### abstract ###
The adaptation rule for Vector Quantization algorithms, and consequently the convergence of the generated sequence, depends on the  existence and properties of a function called the energy function, defined on a topological manifold
Our aim is to investigate the conditions of existence of such a function for a class of algorithms examplified by the initial "K-means"  CITATION  and Kohonen algorithms  CITATION
The results presented here supplement previous studies, including  CITATION ,  CITATION ,  CITATION , CITATION  and  CITATION
Our work shows that the energy function is not always a potential but at least the uniform limit of a series of potential functions which we call a pseudo-potential
It also shows that a large number of existing vector quantization algorithms developed by the Artificial Neural Networks community fall into this category
The framework we define opens the way to study the convergence of all the corresponding adaptation rules at once, and a theorem gives  promising insights in that direction
We also demonstrate that the "K-means" energy function is a pseudo-potential but not a potential in general
Consequently, the energy function associated to the "Neural-Gas"  is not a potential in general
### introduction ###
In vector quantization theory  CITATION , a set of prototypes    SYMBOL  is placed on a manifold  SYMBOL , in order to minimize the following integral function, called the "energy function":   SYMBOL } where  SYMBOL  indicates the probability density defined on  SYMBOL
We focus on the stochastic iterative approaches where at each time step, a datum  SYMBOL  is drawn from the probability density function (pdf)  SYMBOL , and the prototypes  SYMBOL  are adapted according to  SYMBOL  using the adaptation rule:  SYMBOL } where the adaptation step is tuned using the parameter  SYMBOL  generally decreasing over the time ( SYMBOL  is taken thereafter equal to 1 without restricting the general results), and  SYMBOL  is a "neighborhood" function particular to each vector quantization algorithm
Here we focus on discontinuous  SYMBOL  functions
A main concern in the field of Vector Quantization, is to decide whether the adaptation rule () corresponds or not to a stochastic gradient descent along the energy function (),  i e whether this energy function is or is not a potential onto the entire manifold  SYMBOL
On one hand, if the energy function is a potential then the convergence of the prototypes obeying their adaptation rule toward a minimum of this energy function is well established, in particular in the stochastic optimization framework  CITATION  with which this paper is concerned
For example, the energy function associated to the K-means algorithm  CITATION , stochastic version of the LBG algorithm of Linde  et al CITATION , is a potential as long as the pdf  SYMBOL  is continuous  CITATION
On the other hand, if the energy function is not a potential, then very few is known about the convergence of the corresponding adaptation rule
For example, several results  CITATION  have already shown that for a continuous density  SYMBOL , the corresponding vector adaptation rule of the Kohonen Self-Organizing Map (SOM) algorithm  CITATION   CITATION  does not correspond to a stochastic gradient descent along a global energy function, and the convergence, although being observed in practice, turns out to be very difficult to prove, not to mention that most of the efforts have been carried out on the Kohonen rule  CITATION
All the vector quantization algorithms we study in this paper  are variants of the K-means algorithm as we will see in section
We know these algorithms converge in practice toward acceptable value of their energy functions whenever they are proved to be associated or not to potentials
However, the theoretical study of their convergence is not available, so they remain largely heuristics
Among all these algorithms, the Neural-Gas  CITATION  deserves a particular attention
It has been claimed by its authors  to be associated to a global potential in general, hence to a converging adaptation rule
We propose a counter-example with a discontinuous pdf  SYMBOL  which demonstrates that this claim is not true
This shows that the study of the convergence of all these algorithms is still in its infancy and motivates the present work
In this paper, we propose a framework which encompasses all these algorithms
We study this framework and we demonstrate that the energy function associated to these algorithms is not a potential in general
We also demonstrate that this energy function belongs to a broad class of functions which includes potential functions as a special case
The energy functions within this class are called "pseudo-potentials"
The results we obtain do not depend on the continuity of the probability density function  SYMBOL , and give a first step toward an explanation why all the algorithms shown to belong to this framework succeed, in practice, in minimizing their associated energy function whether they are potentials or not
This framework should open up further avenues for a general study of the convergence properties of all the algorithms it contains at once
In section 2, we present the framework of this study
In section 3, we define  a "pseudo-potential" function, which can be approximated by a series of potential functions: we define the concept of cellular manifold and this series of potentials
In section 4, we give the main theorem which states that an energy function of that framework is necessarily a pseudo-potential
We consider the K-means to show that pseudo-potentials are not always potentials
We discuss the consequence on the convergence of the corresponding adaptation rule
In section 5, we show that most of the common vector quantization algorithms belong to that framework
At last we conclude in section 6
### abstract ###
{ We consider a general class of regularization methods which learn a vector of parameters on the basis of linear measurements
It is well known that if the regularizer is a nondecreasing function of the inner product then the learned vector is a linear combination of the input data
This result, known as the  representer theorem , is at the basis of kernel-based methods in machine learning
In this paper, we prove the necessity of the above condition, thereby completing the characterization of kernel methods based on regularization
We further extend our analysis to regularization methods which learn a matrix, a problem which is motivated by the application to multi-task learning
In this context, we study a more general representer theorem, which holds for a larger class of regularizers
We provide a necessary and sufficient condition for these class of matrix regularizers and highlight them with some concrete examples of practical importance
Our analysis uses basic principles from matrix theory, especially the useful notion of matrix nondecreasing function }
### introduction ###
Regularization in Hilbert spaces is an important methodology for learning from examples and has a long history in a variety of fields
It has been studied, from different perspectives, in statistics  CITATION , in optimal estimation  CITATION  and recently has been a focus of attention in machine learning theory -- see, for example,  CITATION  and references therein
Regularization is formulated as an  optimization problem  involving an  error term  and a  regularizer
The regularizer plays an important role, in that it favors solutions with certain desirable properties
It has long been observed that certain regularizers exhibit an appealing property, called the  representer theorem , which states that there exists a solution of the regularization problem that is a linear combination of the data  CITATION
This property has important computational implications in the context of regularization with positive semidefinite  kernels , because it makes high or infinite-dimensional problems of this type into finite dimensional problems of the size of the number of available data  CITATION
The topic of interest in this paper will be to determine the conditions under which representer theorems hold
In the first half of the paper, we describe a property which a regularizer should satisfy in order to give rise to a representer theorem
It turns out that this property has a simple geometric interpretation and that the regularizer can be equivalently expressed as a  nondecreasing  function of the Hilbert space norm
Thus, we show that this condition, which has already been known to be sufficient for representer theorems, is also  necessary
In the second half of the paper, we depart from the context of Hilbert spaces and focus on a class of problems in which a  matrix structure  plays an important role
For such problems, which have recently appeared in several machine learning applications, we show a modified version of the representer theorem that holds for a class of regularizers significantly larger than in the former context
As we shall see, these matrix regularizers are important in the context of multi-task learning: the matrix columns are the parameters of different regression tasks and the regularizer encourages certain dependences across the tasks
In general, we consider problems in the framework of  Tikhonov regularization   CITATION
This regularization approach receives a set of input/output data  SYMBOL   SYMBOL  and selects a vector in  SYMBOL  as the solution of an optimization problem
Here,  SYMBOL  is a prescribed Hilbert space equipped with the inner product  SYMBOL  and  SYMBOL  a set of possible output values
The optimization problems encountered in regularization are of the type \min\left\{ \bigl( \left( w,x_1\rb,\dots,w,x_m \right) , \left( y_1, \dots, y_m \right) \bigr) + \, \Omega(w): w \right\} \,,   where  SYMBOL  is a regularization parameter
The function  SYMBOL  is called an  error function  and  SYMBOL  is called a  regularizer
The error function measures the error on the data
Typically, it decomposes as a sum of univariate functions
For example, in regression, a common choice would be the sum of square errors,  SYMBOL
The function  SYMBOL , called the regularizer, favors certain regularity properties of the vector  SYMBOL  (such as a small norm) and can be chosen based on available prior information about the target vector
In some Hilbert spaces such as Sobolev spaces the regularizer is measure of smoothness: the smaller the norm the smoother the function
This framework includes several well-studied learning algorithms, such as ridge regression  CITATION , support vector machines  CITATION , and many more -- see  CITATION  and references therein
An important aspect of the practical success of this approach is the observation that, for certain choices of the regularizer, solving \eqref{eq:reg_intro} reduces to identifying  SYMBOL  parameters and not  SYMBOL
Specifically, when the regularizer is the square of the Hilbert space norm, the representer theorem holds: there exists a solution  SYMBOL  of \eqref{eq:reg_intro} which is a linear combination of the input vectors,  {w} = \sum_{i=1}^m c_i x_i,   where  SYMBOL  are some real coefficients
This result is simple to prove and dates at least from the 1970's, see, for example,  CITATION
It is also known that it extends to any regularizer that is a  nondecreasing  function of the norm  CITATION
Several other variants and results about the representation form \eqref{eq:RT} have also appeared in recent years  CITATION
Moreover, the representer theorem has been important in machine learning, particularly within the context of learning in reproducing kernel Hilbert spaces  CITATION  -- see  CITATION  and references therein
Our first objective in this paper is to derive necessary and sufficient conditions for representer theorems to hold
Even though one is mainly interested in regularization problems, it is more convenient to study  interpolation  problems, that is, problems of the form  \min\left\{ \Omega(w): w , w,x_i= y_i,~i=1,\dots,m \right\} \,
Thus, we begin this paper (Section ) by showing how representer theorems for interpolation and regularization relate
On one side, a representer theorem for interpolation easily implies such a theorem for regularization with the same regularizer and any error function
Therefore,  all representer theorems obtained in this paper apply equally to interpolation and regularization
On the other side, though, the converse implication is true under certain weak qualifications on the error function
Having addressed this issue, we concentrate in Section  on proving that an interpolation  problem \eqref{eq:int_intro} admits solutions representable in the form \eqref{eq:RT}  if and only if  the regularizer is  a nondecreasing function of the Hilbert space norm
That is, we provide a complete characterization of regularizers that give rise to representer theorems, which had been an open question
Furthermore, we discuss how our proof is motivated by a geometric understanding of the representer theorem, which is equivalently expressed as a monotonicity property of the regularizer
Our second objective is to formulate and study the novel question of representer theorems for  matrix problems
To make our discussion concrete, let us consider the problem of learning  SYMBOL  linear regression vectors, represented by the parameters  SYMBOL , respectively
Each vector can be thought of as a ``task'' and the goal is to  jointly  learn these  SYMBOL  tasks
In such problems, there is usually prior knowledge that  relates  these tasks and it is often the case that learning can improve if this knowledge is appropriately taken into account
Consequently, a good regularizer should favor such task relations and involve  all tasks jointly
In the case of interpolation, this learning framework can be formulated concisely as  SYMBOL } where  SYMBOL  denotes the set of  SYMBOL  real matrices and the column vectors  SYMBOL  form the matrix  SYMBOL
Each task   SYMBOL  has its own input data  SYMBOL  and corresponding  output values  SYMBOL
An important feature of such problems that distinguishes them from the type \eqref{eq:int_intro} is the appearance of  matrix products  in the constraints, unlike the inner products in \eqref{eq:int_intro}
In fact, as we will discuss in Section  , problems of the type \eqref{eq:matrix_intro} can be written in the form \eqref{eq:int_intro}
Consequently, the representer theorem applies if the matrix regularizer is a nondecreasing function of the Frobenius norm
However, the optimal vector  SYMBOL  for each task can be represented as a linear combination of  only those input vectors corresponding to this particular task
Moreover, with such regularizers it is easy to see that each task in \eqref{eq:matrix_intro} can be optimized independently
Hence, these regularizers are of no practical interest if the tasks are expected to be related
This observation leads us to formulate a  modified representer theorem , which is appropriate for matrix problems, namely,  where  SYMBOL  are scalar coefficients, for  SYMBOL
In other words, we now allow for  all input vectors  to be present in the linear combination representing each column of the optimal matrix
As a result, this definition greatly expands the class  of regularizers that give rise to representer theorems
Moreover, this framework can be applied to many applications where matrix optimization problems are involved
Our immediate motivation, however,  has been more specific than that, namely  multi-task learning
Learning multiple tasks jointly has been a growing area of interest in machine learning, especially during the past few years  CITATION
For instance, some of these works use regularizers which involve the  trace norm  of matrix  SYMBOL
The general idea behind this methodology is that a small trace norm favors low-rank matrices
This means that the tasks (the columns of  SYMBOL ) are related in that they all lie in a low-dimensional subspace of  SYMBOL
In the case of the trace norm, the representer theorem \eqref{eq:rep_matrix_intro} is known to hold -- see  CITATION , also discussed in Section
It is natural, therefore, to ask a question similar to that in the standard Hilbert space (or single-task) setting
That is, under which conditions on the regularizer a representer theorem holds
In Section , we provide an answer by  proving a necessary and sufficient condition for representer theorems to hold, expressed as a simple monotonicity property
This property is analogous to the one in the Hilbert space setting, but its geometric interpretation is now algebraic in nature
We also give a functional description equivalent to this property, that is,  we show that the regularizers of interest are the matrix nondecreasing functions of the quantity  SYMBOL
Our results cover matrix problems of the type \eqref{eq:matrix_intro} which have already been studied in the literature
But they also point towards some new learning methods that may perform well in practice and can now be made computationally efficient
Thus, we close the paper with a discussion of possible regularizers that satisfy our conditions and have been used or can be used in the future in machine learning problems
### abstract ###
In this paper, we show a connection between a certain online low-congestion routing problem and an online prediction of graph labeling
More specifically, we prove that if there exists a routing scheme that guarantees a congestion of  SYMBOL  on any edge, there exists an online prediction algorithm with mistake bound  SYMBOL  times the cut size, which is the size of the cut induced by the label partitioning of graph vertices
With previous known bound of  SYMBOL  for  SYMBOL  for the routing problem on trees with  SYMBOL  vertices, we obtain an improved prediction algorithm for graphs with high effective resistance
In contrast to previous approaches that move the graph problem into problems in vector space using graph Laplacian and rely on the analysis of the perceptron algorithm, our proof are purely combinatorial
Further more, our approach directly generalizes to the case where labels are not binary
### introduction ###
We are interested in an online prediction problem on graphs
Given a connected graph  SYMBOL  and a labeling  SYMBOL , unknown to the prediction algorithm, in each round  SYMBOL , for  SYMBOL , an adversary asks for a label of a vertex  SYMBOL , the prediction algorithm provides the answer  SYMBOL , and then receives the correct label  SYMBOL
The goal is to minimize the number of rounds that the algorithm makes a mistake, i e , rounds  SYMBOL  such that  SYMBOL
To make our presentation clean, in this work we do not count the mistake made on the first question  SYMBOL
This problem has been studied with standard online learning tools such as the perceptron algorithm
Herbster, Pontil, and Wainer~ CITATION , and Herbster and Pontil~ CITATION  use pseudoinverse of graph Laplacian as a kernel and provide a mistake bound that depends on the size of the cut induced by the partition based on the real labeling of vertices and the largest effective resistance between any pair of vertices in the graph
Recently, Herbster~ CITATION  exploits the cluster structure of the labeling on the graph, and provides an improved mistake bounds
Pelckmans and Suykens~ CITATION  present a combinatorial algorithm for the problem that predicts a label of a given vertex based on known labels of its neighbors
They also prove a bound on the number of mistakes when the labels of adjacent vertices are known
However, their bound is very loose since it does not count every mistakes and their proof is still based on graph Laplacian
We shall compare the bound that we obtain with previous bounds of Herbster  et
al ~ CITATION  and of Pelckmans and Suykens~ CITATION  in Section~
This work follows the initiation of Pelckmans and Suykens
We show connection between the prediction problem and the following online routing problem, first introduced by Awerbuch and Azar~ CITATION  in their study of online multicast routing
Given a connected graph  SYMBOL , the algorithm receives a sequence of requests  SYMBOL , where  SYMBOL , and, for each  SYMBOL , where  SYMBOL , has to route one unit of flow from  SYMBOL  to some previous know  SYMBOL  where  SYMBOL
The algorithm works in an online fashion, i e , it has to return a route for  SYMBOL  before receiving other requests  SYMBOL , where  SYMBOL
Given a set of routes, we define the  congestion   SYMBOL  incurred on edge  SYMBOL , defined as the number of routes that use  SYMBOL
The performance of the algorithm is measured by the maximum congestion incurred on any edge
We prove, in Section~, that if there exists an algorithm  SYMBOL  with a guarantee that the congestion incurred on any edge will be no greater than  SYMBOL , there exists an online prediction algorithm with the mistake bound of   SYMBOL  where  SYMBOL  be the set of edges joining pairs of vertices with different labels, i e ,  SYMBOL
In Section~, we apply the known congestion bound to show the mistake bound for the graph prediction problem, and compare the bound obtained with the bounds from previous results
We note that our approach directly generalizes to the case when labels are not binary (i e , when the labeling function  SYMBOL  maps  SYMBOL  to an arbitrary set  SYMBOL  of labels) with the same mistake bound
### abstract ###
In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may benefit from the others
In the context of learning linear functions for supervised classification or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other
In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors
We design a new spectral norm that encodes this a priori assumption, without the prior knowledge of the partition of tasks into groups, resulting in a new convex optimization formulation for multi-task learning
We show in simulations on synthetic examples and on the \textsc{iedb} MHC-I binding dataset, that our approach outperforms well-known convex methods for multi-task learning, as well as related non convex methods dedicated to the same problem
### introduction ###
Regularization has emerged as a dominant theme in machine learning and statistics, providing an intuitive and principled tool for learning from high-dimensional data
In particular, regularization by squared Euclidean norms or squared Hilbert norms has been thoroughly studied in various settings, leading to efficient practical algorithms based on linear algebra, and to very good theoretical understanding (see, eg ,  CITATION )
In recent years, regularization by non Hilbert norms, such as  SYMBOL  norms with  SYMBOL , has also generated considerable interest for the inference of linear functions in supervised classification or regression
Indeed, such norms can sometimes both make the problem statistically and numerically better-behaved, and impose various a priori knowledge on the problem
For example, the  SYMBOL -norm (the sum of absolute values) imposes some of the components to be equal to zero and is widely used to estimate sparse functions~ CITATION , while various combinations of  SYMBOL  norms can be defined to impose various sparsity patterns
While most recent work has focused on studying the properties of simple well-known norms, we take the opposite approach in this paper
That is, assuming a given prior knowledge, how can we design a norm that will enforce it
More precisely, we consider the problem of multi-task learning, which has recently emerged as a very promising research direction for various applications  CITATION
In multi-task learning several related inference tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each one may benefit from the others
When linear functions are estimated, each task is associated with a weight vector, and a common strategy to design multi-task learning algorithm is to translate some prior hypothesis about how the tasks are related to each other into constraints on the different weight vectors
For example, such constraints are typically that the weight vectors of the different tasks belong (a) to a Euclidean ball centered at the origin~ CITATION , which implies no sharing of information between tasks apart from the size of the different vectors, i e , the amount of regularization, (b) to a ball of unknown center~ CITATION , which enforces a similarity between the different weight vectors, or (c) to an unknown low-dimensional subspace~ CITATION
In this paper, we consider a different prior hypothesis that we believe could be more relevant in some applications: the hypothesis that  the different tasks are in fact clustered into different groups, and that the weight vectors of tasks within a group are similar to each other
A key difference with  CITATION , where a similar hypothesis is studied, is that we don't assume that the groups are known a priori, and in a sense our goal is both to identify the clusters and to use them for multi-task learning
An important situation that motivates this hypothesis is the case where most of the tasks are indeed related to each other, but a few ``outlier'' tasks are very different, in which case it may be better to impose similarity or low-dimensional constraints only to a subset of the tasks (thus forming a cluster) rather than to all tasks
Another situation of interest is when one can expect a natural organization of the tasks into clusters, such as when one wants to model the preferences of customers and believes that there are a few general types of customers with similar preferences within each type, although one does not know beforehand which customers belong to which types
Besides an improved performance if the hypothesis turns out to be correct, we also expect this approach to be able to identify the cluster structure among the tasks as a by-product of the inference step, eg , to identify outliers or groups of customers, which can be of interest for further understanding of the structure of the problem
In order to translate this hypothesis into a working algorithm, we follow the general strategy mentioned above which is to design a norm or a penalty over the set of weights which can be used as regularization in classical inference algorithms
We construct such a penalty by first assuming that the partition of the tasks into clusters is known, similarly to~ CITATION
We then attempt to optimize the objective function of the inference algorithm over the set of partitions, a strategy that has proved useful in other contexts such as multiple kernel learning~ CITATION
This optimization problem over the set of partitions being computationally challenging, we propose a convex relaxation of the problem which results in an efficient algorithm
### abstract ###
We introduce  algorithmic information theory , also known as the theory of  Kolmogorov complexity
We explain the main concepts of this quantitative approach to defining `information'
We discuss the extent to which Kolmogorov's and Shannon's information theory have a common purpose, and where they are fundamentally different
We indicate how recent developments within the theory allow one to formally distinguish between  `structural' (meaningful) and `random' information\/  as measured by the  Kolmogorov structure function , which leads to a mathematical formalization of Occam's razor in inductive inference
We end by discussing some of the philosophical implications of the theory
### introduction ###
How should we measure the amount of information about a phenomenon that is given to us by an observation concerning the phenomenon
Both `classical' (Shannon) information theory (see the chapter by  CITATION ) and algorithmic information theory start with the idea that this amount can be measured by  the minimum number of bits needed to describe the observation
But whereas Shannon's  theory considers description methods that are optimal relative to some given probability distribution, Kolmogorov's algorithmic theory takes a different, nonprobabilistic approach: any computer program that first computes (prints) the string representing the observation, and then terminates, is viewed as a valid description
The amount of information in the string is then defined as the size (measured in bits) of the  shortest\/  computer program that outputs the string and then terminates
A similar definition can be given for infinite strings, but in this case the program produces element after element forever
Thus, a long sequence of 1's such as  SYMBOL } contains little information because a program of size about  SYMBOL  bits outputs it:  SYMBOL  SYMBOL = 3 1415


SYMBOL \pi$ forever)
Such a definition would appear to make the amount of information in a string (or other object) depend on the particular programming language used
Fortunately, it can be shown that all reasonable choices of programming languages lead to quantification of the amount of `absolute' information in individual objects that is invariant up to an additive constant
We call this quantity the `Kolmogorov complexity' of the object
While regular strings have small Kolmogorov complexity, random strings have Kolmogorov complexity about equal to their own length
Measuring complexity and information in terms of program size has turned out to be a very powerful idea with applications in areas such as theoretical computer science, logic, probability theory, statistics and physics \paragraph{This Chapter} Kolmogorov complexity was introduced independently and with different motivations by R J Solomonoff (born 1926), A N Kolmogorov (1903--1987) and G
Chaitin (born 1943) in 1960/1964, 1965 and 1966 respectively  CITATION
During the last forty years, the subject has developed into a major and mature area of research
Here, we give a brief overview of the subject geared towards an audience specifically interested in the philosophy of information
With the exception of the recent work on the Kolmogorov structure function and parts of the discussion on philosophical implications, all material we discuss here can also be found in the standard textbook  CITATION
The chapter is structured as follows: we start with an introductory section in which we define Kolmogorov complexity and list its most important properties
We do this in a much simplified (yet formally correct) manner, avoiding both technicalities and all questions of motivation (why this definition and not another one )
This is followed by Section~ which provides an informal overview of the more technical topics discussed later in this chapter, in Sections~--~
The final Section~, which discusses the theory's philosophical implications, as well as Section~, which discusses the connection to inductive inference, are less technical again, and should perhaps be glossed over before delving into the technicalities of Sections~--~
### abstract ###
We show how text from news articles can be used to predict intraday price movements of financial assets using support vector machines
Multiple kernel learning is used to combine equity returns with text as predictive features to increase classification performance and we develop an analytic center cutting plane method to solve the kernel learning problem efficiently
We observe that while the direction of returns is not predictable using either text or returns, their size is, with text features producing significantly better performance than historical returns alone
### introduction ###
Asset pricing models often describe the arrival of novel information by a jump process, but the characteristics of the underlying jump process are only coarsely, if at all, related to the underlying source of information
Similarly, time series models such as ARCH and GARCH have been developed to forecast volatility using asset returns data but these methods also ignore one key source of market volatility: financial news
Our objective here is to show that text classification techniques allow a much more refined analysis of the impact of news on asset prices
Empirical studies that examine stock return predictability can be traced back to  CITATION  among others, who showed that there is no significant autocorrelation in the daily returns of thirty stocks from the Dow-Jones Industrial Average
Similar studies were conducted by  CITATION  and  CITATION , who find significant autocorrelation in squared and absolute returns (i e volatility)
These effects are also observed on intraday volatility patterns as demonstrated by  CITATION  and by  CITATION  on absolute returns
These findings tend to demonstrate that, given solely historical stock returns, future stock returns are not predictable while volatility is
The impact of news articles has also been studied extensively
CITATION  for example studied price fluctuations in interest rate and foreign exchange futures markets following macroeconomic announcements and showed that prices mostly adjusted within one minute of major announcements
CITATION  aggregated daily announcements by  Dow Jones \& Company  into a single variable and  found no correlation with market absolute returns and weak correlation with firm-specific absolute returns
However,  CITATION  aggregated intraday news concerning companies listed on the Australian Stock Exchange into an exogenous variable in a GARCH model and found significant predictive power
These findings are attributed to the conditioning of volatility on news
Results were further improved by restricting the type of news articles included
The most common techniques for forecasting volatility are often based on Autoregressive Conditional Heteroskedasticity (ARCH) and Generalized ARCH (GARCH) models mentioned above
For example, intraday volatility in foreign exchange and equity markets is modeled with MA-GARCH in  CITATION  and ARCH in  CITATION
See  CITATION  for a survey of ARCH and GARCH models and various other applications
Machine learning techniques such as neural networks and support vector machines have also been used to forecast volatility
Neural networks are used in  CITATION  to forecast implied volatility of options on the SP100 index, and support vector machines are used to forecast volatility of the SP500 index using daily returns in  CITATION
Here, we show that information from press releases can be used to predict intraday abnormal returns with relatively high accuracy
Consistent with  CITATION  and  CITATION , however, the direction of returns is not found to be predictable
We form a text classification problem where press releases are labeled positive if the absolute return jumps at some (fixed) time after the news is made public
Support vector machines (SVM) are used to solve this classification problem using both equity returns and word frequencies from press releases
Furthermore, we use multiple kernel learning (MKL) to optimally combine equity returns with text as predictive features and increase classification performance
Text classification is a well-studied problem in machine learning, ( CITATION  and  CITATION  among many others show that SVM significantly outperform classic methods such as naive bayes)
Initially, naive bayes classifiers were used in  CITATION  to do three-class classification of an index using daily returns for labels
News is taken from several sources such as  Reuters  and  The Wall Street Journal
Five-class classification with naive bayes classifiers is used in  CITATION  to classify intraday price trends when articles are published at the  YAHOO
Finance  website
Support vector machines were also used to classify intraday price trends in  CITATION  using  Reuters  articles and in  CITATION  to do four-class classification of stock returns using press releases by  PRNewswire
Text classification has also been used to directly predict volatility (see  CITATION  for a survey of trading systems that use text)
Recently,  CITATION  used SVM to predict if articles from the  Bloomberg service  are followed by abnormally large volatility; articles deemed important are then aggregated into a variable and used in a GARCH model similar to  CITATION
CITATION  use Support Vector Regression (SVR) to forecast stock return volatility based on text in SEC mandated 10-K reports
They found that reports published after the Sarbanes-Oxley Act of 2002 improved forecasts over baseline methods that did not use text
Generating trading rules with genetic programming (GP) is another way to incorporate text for financial trading systems
Trading rules are created in  CITATION  using GP for foreign exchange markets based on technical indicators and extended in  CITATION  to combine technical indicators with non-publicly available information
Ensemble methods were used in  CITATION  on top of GP to create rules based on headlines posted on  Yahoo  internet message boards
Our contribution here is twofold
First, abnormal returns are predicted using text classification techniques similar to  CITATION
Given a press release, we predict whether or not an abnormal return will occur in the next  SYMBOL  minutes using text and past absolute returns
The algorithm in  CITATION  uses text to predict whether returns jump up 3\%, down 3\%, remain within these bounds, or are ``unclear'' within 15 minutes of a press release
They consider a nine months subset of the eight years of press releases used here
Our experiments analyze predictability of absolute returns at many horizons and demonstrate significant initial intraday predictability that decreases throughout the trading day
Second, we optimally combine text information with asset price time series to significantly enhance classification performance using multiple kernel learning (MKL)
We use an analytic center cutting plane method (ACCPM) to solve the resulting MKL problem
ACCPM is particularly efficient on problems where the objective function and gradient are hard to evaluate but whose feasible set is simple enough so that analytic centers can be computed efficiently
Furthermore, because it does not suffer from conditioning issues, ACCPM can achieve higher precision targets than other first-order methods
The rest of the paper is organized as follows
Section  details the text classification problem we solve here and provides predictability results using using either text or absolute returns as features
Section  describes the multiple kernel learning framework and details the analytic center cutting plane algorithm used to solve the resulting optimization problem
Finally, we use MKL to enhance the prediction performance
### abstract ###
This paper generalizes the traditional statistical concept of prediction intervals for arbitrary probability density functions in high-dimen\-sional feature spaces by introducing significance level distributions, which provides interval-independent probabilities for continuous random variables
The advantage of the transformation of a probability density function into a significance level distribution is that it enables one-class classification or outlier detection in a direct manner
### introduction ###
A prediction interval is an interval that will, with a specified degree of confidence, contain future realizations or, in the terminology of pattern recognition, feature vectors  CITATION
The appeal of this concept is its clear stochastic meaning
The great disadvantage is that this definition is usually too restricted, for example for multimodal distributions
It is intuitively clear that, in this case, more than one interval for probable feature vectors can exist and it would be better to speak of prediction  regions
Even more complicated is the situation for high-dimensional feature spaces
This lack of generality is probably the reason why prediction intervals are rarely used in pattern recognition
This is actually a pity, because prediction regions would be very useful, for example, for the recognition of outliers  CITATION  or the detection of novelty or normality
Instead of prediction intervals, numerous other methods are used for this purpose
They can be grouped roughly into two categories:   Distance-based and novelty or normality score-based approaches  CITATION ,  Methods that introduce a separate rejection class in combination with a classifier  CITATION
If applying the method I propose here to outlier detection, it belongs to the first category with a probability as normality score
Before going into the details, I will give a short overview of related works
Simple distance-based methods rely on the concept of the neighborhood of a point, for example, the  SYMBOL  nearest neighborhood  CITATION
Outliers are those points for which there are less than  SYMBOL  points within a distance  SYMBOL  in the dataset
CITATION  propose a method to choose this threshold  SYMBOL  automatically based upon a dataset
The idea is to consider as outliers the set of points with the highest distances to their  SYMBOL th nearest neighbors
Of course, here is also a threshold necessary, but it has now a statistical reasoning as quartile of the  SYMBOL th nearest neighbor distance distribution, which simplifies the choice
A more recent article based on this idea is published by  CITATION , who apply a weighted sum of the  SYMBOL th nearest distances per point
Although the idea is quite simple, the methods have low computation costs
Furthermore, they make only minor assumptions about the underlying distribution
Another category of algorithms that are related to outlier detection is robust regression
The outlier detection is here more a means to an end, because the goal is to avoid that outliers influence the estimation of the regression function
This means that it is in this case sufficient to detect outliers indirectly
CITATION , for example, apply an outlier-score to control the influence that a point has in the parameter estimation process of the regression function
For this purpose, weights are introduced, which are estimated based on the assumption that the noise is Gaussian distributed
This is often sufficient, for example for most sensor signals
The algorithm is real-time capable, but far away from generality
This method also belongs to category one
The idea of the second category is very different
At the first glance, it seems to be impossible to use classifiers to detect outliers, because classifiers need for the estimation of their parameters samples from inliers  and  outliers
Usually, only samples for inliers are available
The idea is to create a enclosing cloud of outlier samples synthetically with a random generator
Afterwards, it is possible to train the classifier
CITATION , for example, apply a neural network for this purpose
Other classifiers are also possible, for example, an SVM  CITATION
Regardless of the applied classifier, these probabilistic methods need for the generation of the hull a measure in which degree a generated sample point is an outlier
CITATION , for example, use for this purpose simple prediction intervals ( SYMBOL  ranges)
In conclusion, both categories have to solve the same problem: to find an appropriate zero level set for the inlier generating density
In the subsequent sections I will show that this problem can be mapped to a choice of a significance level and that it is possible to generalize the traditional statistical concept of prediction intervals to prediction regions
### abstract ###
Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption
However, real shapes from image datasets, even when expected to be related by ``almost isometric'' transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale
In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction
The outcome is a model for near-rigid shape matching which is  robust  in the sense that it is able to capture the possibly limited but still important scale and appearance variations
Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times
### introduction ###
Matching shapes in images has many applications, including image retrieval, alignment, and registration  CITATION
Typically, matching is approached by selecting features for a set of landmark points in both images; a correspondence between the two is then chosen such that some distance measure between these features is minimised
A great deal of attention has been devoted to defining complex features which are robust to changes in rotation, scale etc
CITATION
An important class of matching problems is that of  near-isometric  shape matching
In this setting, it is assumed that shapes are defined up to an isometric transformation (allowing for some noise), and therefore distance features are typically used to encode the shape
Some traditional methods for related settings focus on optimisation over the space of rigid transformations so as to minimise least-squares criteria  CITATION
Recently, this class of problems has been approached from a different perspective, as direct optimisation over the space of correspondences  CITATION
Although apparently more expensive, there it is shown that the rigidity assumption imposes a convenient algebraic structure in the correspondence space so as to allow for efficient algorithms (exact inference in chordal graphical models of small clique size)
More recently, these methods have been made substantially faster  CITATION
The  key idea  in these methods is to  explicitly encode rigidity constraints  into a tractable graphical model whose MAP solution corresponds to the best match
However, the main advantages of correspondence-based optimisation over transformation-based optimisation, namely the flexibility of encoding powerful local features, has not been further explored in this framework
Other lines of work that optimise directly over the correspondence space are those based on Graph Matching, which explicitly model all pairwise compatibilities and solve for the best match with some  relaxation  (since the Graph Matching problem is NP-hard for general pairwise compatibilities)  CITATION
Recently, it was shown both in  CITATION  and in  CITATION  that if some form of  structured optimisation  is used to optimise graph matching scores, relaxed quadratic assignment predictors can improve the power of pairwise features
The  key idea  in these methods is to  learn the compatibility scores  for the graph matching objective function, therefore enriching the representability of features
A downside of these graph matching methods however is that they do not typically make explicit use of the geometry of the scene in order to improve computational efficiency and/or accuracy
In this paper, we combine these two lines of work into a single framework
We produce an exact, efficient model to solve near-isometric shape matching problems using not only isometry-invariant features, but also appearance and scale-invariant features, all encoded in a  tractable graphical model
By doing so we can  learn via large-margin structured prediction  the relative importances of variations in appearance and scale with regard to variations in shape  per se
Therefore, even knowing that we are in a near-isometric setting, we will still capture the eventual variations in appearance and scale into our matching criterion in order to produce a  robust  near-isometric matcher
In terms of learning, we introduce a two-stage structured learning approach to address the speed and memory efficiency of this model
The remainder of this paper is structured as follows: in section , we give a brief introduction to shape matching (), graphical models (), and discriminative structured learning ()
In section , we present our model, and experiments follow in section
### abstract ###
The Baum-Welch algorithm together with its derivatives and variations has been the main technique for learning Hidden Markov Models (HMM) from observational data
We present an HMM learning algorithm based on the non-negative matrix factorization (NMF) of higher order Markovian statistics that is structurally different from the Baum-Welch and its associated approaches
The described algorithm supports estimation of the number of recurrent states of an HMM and iterates the non-negative matrix factorization (NMF) algorithm to improve the learned HMM parameters
Numerical examples are provided as well
### introduction ###
Hidden Markov Models (HMM) have been successfully used to model stochastic systems arising in a variety of applications ranging from biology to engineering to finance~ CITATION
Following accepted notation for representing the parameters and structure of HMM's (see  CITATION  for example), we will use the following terminology and definitions:    SYMBOL  is the number of states of the Markov chain underlying the HMM
The state space is  SYMBOL  and the system's state process at time  SYMBOL  is denoted by  SYMBOL ;   SYMBOL  is the number of distinct observables or symbols generated by the HMM
The set of possible observables is  SYMBOL  and the observation process at time  SYMBOL  is denoted by  SYMBOL
We denote by  SYMBOL  the subprocess  SYMBOL ;  The joint probabilities  SYMBOL  SYMBOL S_j SYMBOL t+1 SYMBOL v_k SYMBOL t SYMBOL S_i SYMBOL v_k SYMBOL S_i SYMBOL S_j SYMBOL A(k)=(a_{ij}(k)) SYMBOL v_k SYMBOL A=\sum_{k}A(k) SYMBOL x_t SYMBOL t=1 SYMBOL \Gamma = \{\gamma_1 ,

,  \gamma_N\} SYMBOL \gamma_i = P(x_1 = S_i) 0 SYMBOL \sum_i \gamma_i = 1 SYMBOL A(k) SYMBOL SYMBOL = ( \{A(k)\ |\ 1kM\}, )$
We present an algorithm for  learning  an HMM from single or multiple observation sequences
The traditional approach for learning an HMM is the Baum-Welch Algorithm~ CITATION  which has been extended in a variety of ways by others  CITATION
Recently, a novel and promising approach to the HMM approximation problem was proposed by Finesso et al ~ CITATION
That approach is based on Anderson's HMM stochastic realization technique~ CITATION  which demonstrates that a positive factorization of a certain Hankel matrix (consisting of observation string probabilities) can be used to recover the hidden Markov model's probability matrices
Finesso and his coauthors used recently developed non-negative matrix factorization (NMF) algorithms~ CITATION  to express those stochastic realization techniques as an operational algorithm
Earlier ideas in that vein were anticipated by Upper in 1997~ CITATION , although that work did not benefit from HMM stochastic realization techniques or NMF algorithms, both of which were developed after 1997
Methods based on stochastic realization techniques, including the one presented here, are fundamentally different from Baum-Welch based methods in that the algorithms use as input observation sequence  probabilities  as opposed to raw observation {\em sequences}
Anderson's and Finesso's approaches use system realization methods while our algorithm is in the spirit of the Myhill-Nerode~ CITATION  construction for building automata from languages
In the Myhill-Nerode construction, states are defined as equivalence classes of pasts which produce the same futures
In an HMM, the ``future'' of a state is a probability distribution over future observations
Following this intuition we derive our result in a manner that appears comparatively more concise and elementary, in relation to the aforementioned approaches by Anderson and Finesso
At a conceptual level, our algorithm operates as follows
We first estimate the matrix of an observation sequence's high order statistics
This matrix has a natural non-negative matrix factorization (NMF) ~ CITATION  which can be interpreted in terms of the probability distribution of future observations given the current state of the underlying Markov Chain
Once estimated, these probability distributions can be used to directly estimate the transition probabilities of the HMM
The estimated HMM parameters can be used, in turn, to compute the NMF matrix factors as well as the underlying higher order correlation matrix from data generated by the estimated HMM
We present a simple example in which an NMF factorization is exact but does not correspond to any HMM
This is a fact that can be established by comparing the factors  computed by the NMF with the factors computed by the estimated HMM parameters
This kind of comparison is not possible with other approaches  CITATION
It is important to point out that the optimal non-negative matrix factorization of a positive matrix is known to be NP-Hard in the general case ~ CITATION , so in practice one computes only locally optimal factorizations
As we will show through examples, the repeated iteration of the factorization and transition probability estimation steps improves the factorizations and overall model estimation
Details are provided below
### abstract ###
We consider the task of learning a classifier from the feature space  SYMBOL  to the set of classes  SYMBOL , when the features can be partitioned into class-conditionally independent feature sets  SYMBOL  and  SYMBOL
We show the surprising fact that the class-conditional independence can be used to represent the original learning task in terms of 1) learning a classifier from  SYMBOL  to  SYMBOL  and 2) learning the class-conditional distribution of the feature set  SYMBOL
This fact can be exploited for semi-supervised learning because the former task can be accomplished purely from unlabeled samples
We present experimental evaluation of the idea in two real world applications
### introduction ###
Semi-supervised learning is said to occur when the learner exploits (a presumably large quantity of) unlabeled data to supplement a relatively small labeled sample, for accurate induction
The high cost of labeled data and the simultaneous plenitude of unlabeled data in many application domains, has led to considerable interest in semi-supervised learning in recent years
We show a somewhat surprising consequence of class-conditional feature independence that leads to a simple semi-supervised learning algorithm
When the feature set can be partitioned into two class-conditionally independent sets, we show that the original learning problem can be reformulated in terms of the problem of learning a predictor from  one  of the partitions to the other
That is, the latter partition acts as a  surrogate  for the class variable
Since such a predictor can be learned from only unlabeled samples, an effective semi-supervised algorithm results
In the next section we present the simple yet interesting result on which our semi-supervised learning algorithm (which we call  surrogate learning ) is based
We present examples to clarify the intuition behind the approach and present a special case of our approach that is used in the applications section
We then examine related ideas in previous work and situate our algorithm among previous approaches to semi-supervised learning
We present empirical evaluation on two real world applications where the required assumptions of our algorithm are satisfied
### abstract ###
In a multi-armed bandit problem, an online algorithm chooses from a set of strategies in a sequence of  SYMBOL  trials so as to maximize the total payoff of the chosen strategies
While the performance of bandit algorithms with a small finite strategy set is quite well understood, bandit problems with large strategy sets are still a topic of very active investigation, motivated by practical applications such as online auctions and web advertisement
The goal of such research is to identify broad and natural classes of strategy sets and payoff functions which enable the design of efficient solutions
In this work we study a very general setting for the multi-armed bandit problem in which the strategies form a metric space, and the payoff function satisfies a Lipschitz condition with respect to the metric
We refer to this problem as the  Lipschitz MAB problem
We present a solution for the multi-armed problem in this setting
That is, for every metric space  SYMBOL  we define an isometry invariant  SYMBOL  which bounds from below the performance of Lipschitz MAB algorithms for  SYMBOL , and we present an algorithm which comes arbitrarily close to meeting this bound
Furthermore, our technique gives even better results for benign payoff functions
### introduction ###
\newcommand{\willcite}[1][Cite]{{[#1]}}  In a multi-armed bandit problem, an online algorithm must choose from a set of strategies in a sequence of  SYMBOL  trials so as to maximize the total payoff of the chosen strategies
These problems are the principal theoretical tool for modeling the exploration/exploitation tradeoffs inherent in  sequential decision-making under uncertainty
Studied intensively for the last three decades~ CITATION , bandit problems are having an increasingly visible impact on computer science because of their diverse applications including online auctions, adaptive routing, and the theory of learning in games
The performance of a multi-armed bandit algorithm is often evaluated in terms of its  regret , defined as the gap between the expected payoff of the algorithm and that of an optimal strategy
While the performance of bandit algorithms with a small finite strategy set is quite well understood, bandit problems with exponentially or infinitely large strategy sets are still a topic of very active investigation~ CITATION
Absent any assumptions about the strategies and their payoffs, bandit problems with large strategy sets allow for no non-trivial solutions --- any multi-armed bandit algorithm performs as badly, on some inputs, as random guessing
But in most applications it is natural to assume a structured class of payoff functions, which often enables the design of efficient learning algorithms~ CITATION
In this paper, we consider a broad and natural class of problems in which the structure is induced by a metric on the space of strategies
While bandit problems have been studied in a few specific metric spaces (such as a one-dimensional interval) ~ CITATION , the case of general metric spaces has not been treated before, despite being an extremely natural setting for bandit problems
As a motivating example, consider the problem faced by a website choosing from a database of thousands of banner ads to display to users, with the aim of maximizing the click-through rate of the ads displayed by matching ads to users' characterizations and the web content that they are currently watching
Independently experimenting with each advertisement is infeasible, or at least highly inefficient, since the number of ads is too large
Instead, the advertisements are usually organized into a taxonomy based on metadata (such as the category of product being advertised) which allows a similarity measure to be defined
The website can then attempt to optimize its learning algorithm by generalizing from experiments with one ad to make inferences about the performance of similar ads~ CITATION
Abstractly, we have a bandit problem of the following form: there is a strategy set  SYMBOL , with an unknown payoff function  SYMBOL  satisfying a set of predefined constraints of the form  SYMBOL  for some  SYMBOL  and  SYMBOL
In each period the algorithm chooses a point  SYMBOL  and observes an independent random sample from a payoff distribution whose expectation is   SYMBOL
A moment's thought reveals that this abstract problem can be regarded as a bandit problem in a metric space
Specifically, if  SYMBOL  is defined to be the infimum, over all finite sequences  SYMBOL  in  SYMBOL , of the quantity  SYMBOL , then  SYMBOL  is a metric and the constraints  SYMBOL  may be summarized by stating that  SYMBOL  is a Lipschitz function (of Lipschitz constant  SYMBOL ) on the metric space  SYMBOL
We refer to this problem as the  Lipschitz MAB problem  on  SYMBOL , and we refer to the ordered triple  SYMBOL  as an  instance  of the Lipschitz MAB problem \xhdr{Prior work }  While our work is the first to treat the Lipschitz MAB problem in general metric spaces, special cases of the problem are implicit in prior work on the continuum-armed bandit problem~ CITATION  --- which corresponds to the space  SYMBOL  under the metric  SYMBOL ,  SYMBOL  --- and the experimental work on ``bandits for taxonomies''~ CITATION , which corresponds to the case in which  SYMBOL  is a tree metric
Before describing our results in greater detail, it is helpful to put them in context by recounting the nearly optimal bounds for the one-dimensional continuum-armed bandit problem, a problem first formulated by R ~Agrawal in 1995~ CITATION  and recently solved (up to logarithmic factors) by various authors~ CITATION
In the following theorem and throughout this paper, the  regret  of a multi-armed bandit algorithm  SYMBOL  running on an instance  SYMBOL  is defined to be the function  SYMBOL  which measures the difference between its expected payoff at time  SYMBOL  and the quantity  SYMBOL
The latter quantity is the expected payoff of always playing a strategy  SYMBOL  if such strategy exists \OMIT{ %%%%%%%%%%%% For any  SYMBOL , there is an algorithm  SYMBOL  for the Lipschitz MAB problem on  SYMBOL  whose regret on any instance  SYMBOL  satisfies  SYMBOL  For any  SYMBOL  there does not exist an algorithm  SYMBOL  for the Lipschitz MAB problem on  SYMBOL  which satisfies  SYMBOL  for every  SYMBOL  and every instance  SYMBOL  } %%%%%%%%%%%%%%%%  In fact, if the time horizon  SYMBOL  is known in advance, the upper bound in the theorem can be achieved by an extremely na\"{i}ve algorithm which simply uses an optimal  SYMBOL -armed bandit algorithm (such as the \textsc{ucb1} algorithm~ CITATION ) to choose strategies from the set  SYMBOL , for a suitable choice of the parameter  SYMBOL
While the regret bound in Theorem~ is essentially optimal for the Lipschitz MAB problem in  SYMBOL , it is strikingly odd that it is achieved by such a simple algorithm
In particular, the algorithm approximates the strategy set by a fixed mesh  SYMBOL  and does not refine this mesh as it gains information about the location of the optimal strategy
Moreover, the metric contains seemingly useful proximity information, but the algorithm ignores this information after choosing its initial mesh
Is this really the best algorithm
A closer examination of the lower bound proof raises further reasons for suspicion: it is based on a contrived, highly singular payoff function  SYMBOL  that alternates between being constant on some distance scales and being very steep on other (much smaller) distance scales, to create a multi-scale ``needle in haystack'' phenomenon which nearly obliterates the usefulness of the proximity information contained in the metric  SYMBOL
Can we expect algorithms to do better when the payoff function is more benign
For the Lipschitz MAB problem on  SYMBOL , the question was answered affirmatively in~ CITATION  for some classes of instances, with algorithms that are tuned to the specific classes \OMIT{ %%%%%%%%%%%%%%%%%%%%%%% For the Lipschitz MAB problem on  SYMBOL , the question was answered affirmatively by Cope~ CITATION  and an even stronger affirmative answer was provided by Auer  et
al ~ CITATION
For example, a special case of the main result in~ CITATION  shows that if the payoff function  SYMBOL  is twice differentiable with finitely many maxima each having a nonzero second derivative, then regret  SYMBOL  can be achieved by modifying the na\"{i}ve algorithm described above to sample uniformly at random from the interval  SYMBOL  instead of deterministically playing  SYMBOL
Our Theorem~, stated below, reveals a similar phenomenon in general metric spaces: it is possible to define algorithms whose regret outperforms the per-metric optimal algorithm when the input instance is sufficiently benign } %%%%%%%%%%%%%%%%%%%%%%%%%%  \xhdr{Our results and techniques }  In this paper we consider the Lipschitz MAB problem on arbitrary metric spaces
We are concerned with the following two main questions motivated by the discussion above:  [(i)] What is the best possible bound on regret for a given metric space [(ii)] Can one take advantage of benign payoff functions
In this paper we give a complete solution to (i), by describing for every metric space  SYMBOL  a family of algorithms which come arbitrarily close to achieving the best possible regret bound for  SYMBOL
We also give a satisfactory answer to (ii); our solution is arbitrarily close to optimal in terms of the zooming dimension defined below
In fact, our algorithm for (i) is an extension of the algorithmic technique used to solve (ii) \OMIT{ %%%%%%%%%%%%%%%%%%%% Our main technical contribution is a new algorithm, the  zooming algorithm , that combines the upper confidence bound technique used in earlier bandit algorithms such as \textsc{ucb1} with a novel  adaptive refinement  step that uses past history to zoom in on regions near the apparent maxima of  SYMBOL  and to explore a denser mesh of strategies in these regions
This algorithm is a key ingredient in our design of an optimal bandit algorithm for every metric space  SYMBOL
Moreover, we show that the zooming algorithm can perform significantly better on benign problem instances
That is, for every instance  SYMBOL  we define a parameter called the  zooming dimension  which is often significantly smaller than  SYMBOL , and we bound the algorithm's performance in terms of the zooming dimension of the problem instance
Since the zooming algorithm is self-tuning, it achieves this bound without requiring prior knowledge of the zooming dimension } %%%%%%%%%%%%%%%%%%%%%%%   Our main technical contribution is a new algorithm, the  zooming algorithm , that combines the upper confidence bound technique used in earlier bandit algorithms such as \textsc{ucb1} with a novel  adaptive refinement  step that uses past history to zoom in on regions near the apparent maxima of  SYMBOL  and to explore a denser mesh of strategies in these regions
This algorithm is a key ingredient in our design of an optimal bandit algorithm for every metric space  SYMBOL
Moreover, we show that the zooming algorithm can perform significantly better on benign problem instances
That is, for every instance  SYMBOL  we define a parameter called the  zooming dimension , and use it to bound the algorithm's performance in a way that is often significantly stronger than the corresponding per-metric bound
Note that the zooming algorithm is  self-tuning , i e it achieves this bound without requiring prior knowledge of the zooming dimension
To state our theorem on the per-metric optimal solution for (i), we need to sketch a few definitions which arise naturally as one tries to extend the lower bound from~ CITATION  to general metric spaces
Let us say that a subset  SYMBOL  in a metric space  SYMBOL  has covering dimension  SYMBOL  if it can be covered by  SYMBOL  sets of diameter  SYMBOL  for all  SYMBOL
A point  SYMBOL  has local covering dimension  SYMBOL  if it has an open neighborhood of covering dimension  SYMBOL
The space  SYMBOL  has max-min-covering dimension  SYMBOL  if it has no subspace whose local covering dimension is uniformly bounded below by a number greater than  SYMBOL  \OMIT{ %%%%%%%%%%%%%%% For metric spaces which are highly homogeneous (in the sense that any two \eps-balls are isometric to one another) the theorem follows easily from a refinement of the techniques introduced in~ CITATION ; in particular, the upper bound can be achieved using a generalization of the na\"{i}ve algorithm described earlier } %%%%%%%%%%%%%%%  In general  SYMBOL  is bounded above by the covering dimension of  SYMBOL
For metric spaces which are highly homogeneous (in the sense that any two \eps-balls are isometric to one another) the two dimensions are equal, and the upper bound in the theorem can be achieved using a  generalization of the na\"{i}ve algorithm described earlier
The difficulty in Theorem~ lies in dealing with inhomogeneities in the metric space
It is important to treat the problem at this level of generality, because some of the most natural applications of the Lipschitz MAB problem, eg the web advertising problem described earlier, are based on highly inhomogeneous metric spaces (That is, in web taxonomies, it is unreasonable to expect different categories at the same level of a topic hierarchy to have the roughly the same number of descendants )  The algorithm in Theorem~ combines the zooming algorithm described earlier with a delicate transfinite construction over closed subsets consisting of ``fat points'' whose local covering dimension exceeds a given threshold  SYMBOL
For the lower bound, we craft a new dimensionality notion, the max-min-covering dimension introduced above, which captures the inhomogeneity of a metric space, and we connect this notion with the transfinite construction that underlies the algorithm
For ``benign'' input instances we provide a  better performance guarantee for the zooming algorithm
The lower bounds in Theorems~ and~ are based on contrived, highly singular, ``needle in haystack'' instances in which the set of near-optimal strategies is astronomically larger than the set of precisely optimal strategies
Accordingly, we quantify the tractability of a problem instance in terms of the number of near-optimal strategies
We define the  zooming dimension  of an instance  SYMBOL  as the smallest  SYMBOL  such that the following covering property holds: for every  SYMBOL  we require only  SYMBOL  sets of diameter  SYMBOL  to cover the set of strategies whose payoff falls short of the maximum by an amount between  SYMBOL  and  SYMBOL
The zooming dimension can be significantly smaller than the max-min-covering dimension \OMIT{ve algorithm from Theorem~ performs poorly compared to the zooming algorithm }} Let us illustrate this point with two examples (where for simplicity the max-min-covering dimension is equal to the covering dimension) \OMIT{ %%% First, if  SYMBOL  is the Euclidean metric on a unit interval, and  SYMBOL  is a twice-differentiable function with negative second derivative at the optimal strategy  SYMBOL , then the zooming dimension is only  SYMBOL  whereas the covering dimension is  SYMBOL } %%% For the first example, consider a metric space consisting of a high-dimensional part and a low-dimensional part
For concreteness, consider a rooted tree  SYMBOL  with two top-level branches  SYMBOL  and  SYMBOL  which are complete infinite  SYMBOL -ary trees,  SYMBOL
Assign edge weights in  SYMBOL  that are exponentially decreasing with distance to the root, and let  SYMBOL  be the resulting shortest-path metric on the leaf set  SYMBOL
If there is a unique optimal strategy that lies in the low-dimensional part  SYMBOL  then the zooming dimension is bounded above by the covering dimension of  SYMBOL , whereas the ``global'' covering dimension is that of  SYMBOL
In the second example, let  SYMBOL  be a homogeneous high-dimensional metric, eg the Euclidean metric on the unit  SYMBOL -cube, and the payoff function is  SYMBOL  for some subset  SYMBOL
Then the zooming dimension is equal to the covering dimension of  SYMBOL , eg it is  SYMBOL  if  SYMBOL  is a finite point set { %%%%%%%%%%%%%%%%%%%%%%%%%


SYMBOL  with the standard metric  SYMBOL ,


than the local covering dimension at the point  SYMBOL  where  SYMBOL  is maximized } %%%%%%%%%%%%%%%%     \xhdr{Discussion } In stating the theorems above, we have been imprecise about specifying the model of computation
In particular, we have ignored the thorny issue of how to provide an algorithm with an input containing a metric space which may have an infinite number of points
The simplest way to interpret our theorems is to ignore implementation details and interpret ``algorithm'' to mean an abstract decision rule, i e a (possibly randomized) function mapping a history of past observations  SYMBOL  to a strategy  SYMBOL  which is played in the current period
All of our theorems are valid under this interpretation, but they can also be made into precise algorithmic results provided that the algorithm is given appropriate oracle access to the metric space
In most cases, our algorithms require only a  covering oracle  which takes a finite collection of open balls and either declares that they cover  SYMBOL  or outputs an uncovered point
We refer to this setting as the \standardMAB
For example, the zooming algorithm uses only a covering oracle for  SYMBOL , and requires only one oracle query per round (with at most  SYMBOL  balls in round  SYMBOL )
However, the per-metric optimal algorithm in Theorem~  uses more complicated oracles, and we defer the definition of these oracles to Section~ \OMIT{ %%%%%% the algorithm is very efficient, requiring only  SYMBOL  operations in total (including oracle queries) to choose its first  SYMBOL  strategies \BobbyNote{Prove the  SYMBOL  bound in "body" } } %%%%%  While our definitions and results so far have been tailored for the Lipschitz MAB problem on infinite metrics, some of them can be extended to the finite case as well
In particular, for the zooming algorithm we obtain sharp results (that are meaningful for both finite and infinite metrics) using a more precise,  non-asymptotic  version of the zooming dimension
Extending the notions in Theorem~ to the finite case is an open question \OMIT{ While our definitions and results so far have been tailored for the Lipschitz MAB problem on infinite metrics, they can be extended to the finite case as well
In particular, for the zooming algorithm we obtain sharp results (that are meaningful for both finite and infinite metrics) using a more precise,  non-asymptotic  version of the zooming dimension
Extending the notions in Theorem~ to the finite case is feasible but more complicated; we leave it to the full version } %%%    \xhdr{Extensions } We provide a number of extensions in which we elaborate on our analysis of the zooming algorithm
First, we provide sharper bounds for several examples in which the reward from playing each strategy  SYMBOL  is  SYMBOL  plus an independent  noise  of a known and ``benign" shape
Second, we upgrade the zooming algorithm so that it satisfies the guarantee in Theorem~  and  enjoys a better guarantee if the maximal reward is exactly 1
Third, we apply this result to a version where  SYMBOL  for some  target set   SYMBOL  which is not revealed to the algorithm
Fourth, we relax some assumptions in the analysis of the zooming algorithm, and use this generalization to analyze the version in which  SYMBOL  for some known function  SYMBOL
Finally, we extend our analysis from reward distributions supported on  SYMBOL  to those with unbounded support and finite absolute third moment \OMIT{ Some of our initial motivation for this project came from the online advertizing scenario described in the introduction
We follow this motivation further in Appendix~ and consider a multi-round game such that in each round an adversary selects a webpage and the algorithm selects an ad which it places on this webpage
We assume that we have a Lipschitz condition on the product (webpages SYMBOL ads) space, and we give an algorithm whose regret dimension (as defined in Section~) is upper-bounded in terms of (essentially) the covering dimension
Although the algorithm is based in the ``na\"{i}ve'' algorithm from Theorem~, the adversarial aspect of the problem creates considerable technical challenges
In future work we hope to pursue more refined guarantees in the style of Section~ }  \OMIT{ %%%%%%%%% Ideally, it would be desirable to have a matching lower bound constituting a  per-instance optimality  guarantee for the zooming algorithm or some other algorithm
The goal, when stated in this form, is plainly unachievable
For any given instance  SYMBOL , if  SYMBOL  is a point where  SYMBOL  achieves its maximum, then the algorithm which always plays strategy  SYMBOL  has zero regret
Nevertheless, one might hope for a subtler characterization of per-instance optimality, eg asserting that no algorithm can outperform  SYMBOL  on one instance  SYMBOL  without performing significantly worse than  SYMBOL  on highly similar instances  SYMBOL
While we have been unable to prove such guarantees for the zooming algorithm, the question of per-instance optimality is an attractive topic for further investigation } %%%%%%%%%%%%%%%%%   \xhdr{Follow-up work } For metric spaces whose max-min-covering dimension is exactly 0, this paper provides an upper bound  SYMBOL  for any  SYMBOL , but no matching lower bound
Characterizing the optimal regret for such metric spaces remained an open question
Following the publication of the conference version, this question has been settled in~ CITATION , revealing the following dichotomy: for every metric space, the optimal regret of a Lipschitz MAB algorithm is either bounded above by any  SYMBOL , or bounded below by any  SYMBOL , depending on whether the completion of the metric space is compact and countable
### abstract ###
We consider semi-supervised classification when part of the available data is unlabeled
These unlabeled data can be useful for the classification problem when we make an assumption relating the behavior of the regression function to that of the marginal distribution
Seeger  CITATION  proposed the well-known  cluster assumption  as a reasonable one
We propose a mathematical formulation of this assumption and a method based on density level sets estimation that takes advantage of it to achieve fast rates of convergence both in the number of unlabeled examples and the number of labeled examples
### introduction ###
\setcounter{equation}{0} Semi-supervised classification has been of growing interest over the past few years and many methods have been proposed
The methods try to give an answer to the question: ``How to improve classification accuracy using unlabeled data together with the labeled data
''
Unlabeled data can be used in different ways depending on the assumptions on the model
There are two types of assumptions
The first one consists in assuming that we have a set of potential classifiers and we want to aggregate them
In that case, unlabeled data is used to measure the  compatibility  between the classifiers and reduces the complexity of the resulting classifier (see, eg ,  CITATION ,  CITATION )
The second approach is the one that we use  here
It assumes that the data contains clusters that have homogeneous labels and the unlabeled observations are used to identify these clusters
This is the so-called  cluster assumption
This idea can be put in practice in several ways giving rise to various methods
The simplest is the one presented here: estimate the clusters, then label each cluster uniformly
Most of these methods use Hartigan's  CITATION  definition of clusters, namely the connected components of the density level sets
However, they use a parametric (usually mixture) model to estimate the underlying density which can be far from reality
Moreover, no generalization error bounds are available for such methods
In the same spirit,   CITATION  and  CITATION  propose methods that learn a distance using unlabeled data in order to have intra-cluster distances smaller than inter-clusters distances
The whole family of graph-based methods aims also at using unlabeled data to learn the distances between points
The edges of the graphs reflect the proximity between points
For a detailed survey on graph methods we refer to  CITATION
Finally, we mention kernel methods, where unlabeled data are used to build the kernel
Recalling that the kernel measures proximity between points, such methods can also be viewed as learning a distance using unlabeled data (see  CITATION ,  CITATION ,  CITATION )
The cluster assumption can be interpreted in another way, i e , as the requirement that the decision boundary has to lie in low density regions
This interpretation has been widely used in learning since it can be used in the design of standard algorithms such as Boosting  CITATION ,  CITATION  or SVM  CITATION ,  CITATION , which are closely related to kernel methods mentioned above
In these algorithms, a greater penalization is given to decision boundaries that cross a cluster
For more details, see, eg ,  CITATION ,  CITATION ,  CITATION
Although most methods make, sometimes implicitly, the cluster assumption, no formulation in probabilistic terms has been provided so far
The formulation that we propose in this paper remains very close to its original text formulation and allows to derive generalization error bounds
We also discuss what can and cannot be done using unlabeled data
One of the conclusions is that considering the whole excess-risk is too ambitious and we need to concentrate on a smaller part of it to observe the improvement of semi-supervised classification over standard classification
Outline of the paper
After describing the model, we formulate the cluster assumption and discuss why and how it can improve classification performance in the next section
In Section~, we study the population case when the marginal density  SYMBOL  is known, to get an idea of our target
Indeed, such a population case corresponds  in some way to the case when the amount of unlabeled data is infinite
Section~ contains the main result: we propose an algorithm for which we derive rates of convergence for the  SYMBOL -thresholded excess-risk as a measure of performance
An exemple of consistent density level set estimators is given in Section~
Section~ is devoted to discussion on the choice of  SYMBOL   and possible improvements
Proofs of the results are gathered in Section~
Notation
Throughout the paper, we denote by  SYMBOL  positive constants
We write  SYMBOL  for the complement of the set  SYMBOL
For two sequences  SYMBOL  and  SYMBOL  (in that paper,  SYMBOL  will be  SYMBOL  or  SYMBOL ), we write  SYMBOL  if there exists a constant  SYMBOL  such that  SYMBOL  and we write  SYMBOL  if  SYMBOL  for some constants  SYMBOL
Thus, if  SYMBOL , we have  SYMBOL , for any  SYMBOL
### abstract ###
We consider the design of cognitive Medium Access Control (MAC) protocols enabling an unlicensed (secondary) transmitter-receiver pair to communicate over the idle periods of a set of licensed channels, ie , the primary network
The objective is to maximize data throughput while maintaining the synchronization between secondary users and avoiding interference with licensed (primary) users
No statistical information about the primary traffic is assumed to be available  a-priori  to the secondary user
We investigate two distinct sensing scenarios
In the first, the secondary transmitter is capable of sensing all the primary channels, whereas it senses one channel only in the second scenario
In both cases, we propose MAC protocols that efficiently learn the statistics of the primary traffic on-line
Our simulation results demonstrate that the proposed blind protocols asymptotically achieve the throughput obtained when prior knowledge of primary traffic statistics is available
### introduction ###
Most of licensed spectrum resources are under-utilized
This observation has encouraged the emergence of dynamic and opportunistic spectrum access concepts, where unlicensed (secondary) users equipped with cognitive radios are allowed to opportunistically access the spectrum as long as they do not interfere with licensed (primary) users
To achieve this goal, secondary users must monitor the primary traffic in order to identify spectrum holes or opportunities which can be exploited to transfer data~ CITATION
The main goal of a cognitive MAC protocol is to sense the radio spectrum, detect the occupancy state of different primary spectrum channels, and then opportunistically communicate over unused channels (spectrum holes) with minimal interference to the primary users
Specifically, the cognitive MAC protocol should continuously make efficient decisions on which channels to sense and access in order to obtain the most benefit from the available spectrum opportunities
Several cognitive MAC protocols have been proposed in previous studies
For example, in~ CITATION , MAC protocols were constructed assuming each secondary user is equipped with two transceivers, a control transceiver tuned to a dedicated control channel and a software defined radio SDR-based transceiver tuned to any available channels to sense, receive, and transmit signals/packets
On the other hand,~ CITATION  proposed a sensing-period optimization mechanism and an optimal channel-sequencing algorithm, as well as an environment adaptive channel-usage pattern estimation method
The slotted Markovian structure for the primary network traffic, adopted here, was also considered in~ CITATION  where the optimal policy was characterized and a simple greedy policy for secondary users was constructed
The authors of~ CITATION , however, assumed that the primary traffic statistics (i e , Markov chain transition probabilities) were available  a-priori  to the secondary users
Here, our focus is on the blind scenario where the cognitive MAC protocol must learn the transition probabilities on-line
In this work, we differentiate between two scenarios
The first assumes that the secondary transmitter can sense all the available primary channels before making the decision on which one to access
The secondary receiver, however, does not participate in the sensing process and can  wait to decode  on only one channel
This is the model adopted in~ CITATION
In the sequel, we propose an efficient algorithm that optimizes the on-line learning capabilities of the secondary transmitter and ensures perfect synchronization between the secondary pair
The proposed protocol does not assume a separate control channel, and hence, piggybacks the synchronization information on the same data packet
Our numerical results demonstrate the superiority of the proposed protocol over the one in~ CITATION  where the primary transmitter and receiver are assumed to access the channel in a predetermined sequence, which they agreed upon  a-priori
The second scenario assumes that both the secondary transmitter and receiver can sense only one primary channel in each time slot
This problem can be re-casted as a restless multi-armed bandit problem where the optimal algorithm must strike a balance between exploration and exploitation~ CITATION
Unfortunately, finding the optimal solution for this problem remains an elusive task~ CITATION
Inspired by the recent results of~ CITATION  and~ CITATION , an efficient MAC protocol is constructed which can be viewed as the Whittle index strategy of~ CITATION  augmented with a similar learning phase to the one proposed in~ CITATION  for the multi-armed bandit scenario
Our numerical results show that the performance of this protocol converges to the Whittle index strategy with known transition probabilities~ CITATION
### abstract ###
Support vector machines (SVMs) are an extremely successful type of classification and regression algorithms
Building an SVM entails solving a constrained convex quadratic programming problem, which is quadratic in the number of training samples
We introduce an efficient parallel implementation of an support vector regression solver, based on the Gaussian Belief Propagation algorithm (GaBP)
In this paper, we demonstrate that methods from the complex system domain could be utilized for performing efficient distributed computation
We compare the proposed algorithm to previously proposed distributed and single-node SVM solvers
Our comparison shows that the proposed algorithm is just as accurate as these solvers, while being significantly faster, especially for large datasets
We demonstrate scalability of the proposed algorithm to up to 1,024 computing nodes and hundreds of thousands of data points using an IBM Blue Gene supercomputer
As far as we know, our work is the largest parallel implementation of belief propagation ever done, demonstrating the applicability of this algorithm for large scale distributed computing systems
### introduction ###
Support-vector machines (SVMs) are a class of algorithms that have, in recent years, exhibited superior performance compared to other pattern classification algorithms
There are several formulations of the SVM problem, depending on the specific application of the SVM (e g , classification, regression, etc )
One of the difficulties in using SVMs is that building an SVM requires solving a constrained quadratic programming problem, whose size is quadratic in the number of training examples
This fact has led to extensive research on efficient SVM solvers
Recently, several researchers have suggested using multiple computing nodes in order to increase the computational power available for solving SVMs
In this article, we introduce a distributed SVM solver based on the Gaussian Belief Propagation (GaBP) algorithm
We improve on the original GaBP algorithm by reducing the communication load, as represented by the number of messages sent in each optimization iteration, from  SYMBOL  to  SYMBOL  aggregated messages, where  SYMBOL  is the number of data points
Previously, it was known that the GaBP algorithm is very efficient for sparse matrices
Using our novel construction, we demonstrate that the algorithm exhibits very good performance for dense matrices as well
We also show that the GaBP algorithm can be used with kernels, thus making the algorithm more powerful than what was considered previously thought possible
Using extensive simulation we demonstrate the applicability of our protocol vs the state-of-the-art existing parallel SVM solvers
Using a Linux cluster of up to a hundred machines and the IBM Blue Gene supercomputer we managed to solve very large data sets up to hundreds of thousands data point, using up to 1,024 CPUs working in parallel
Our comparison shows that the proposed algorithm is just as accurate as these previous solvers, while being significantly faster
A preliminary version of this paper appeared as a poster in~ CITATION
### abstract ###
The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application
The repeatability is importand because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations~ CITATION
The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate
Three advances are described in this paper
First, we present a new heuristic for feature detection, and using machine learning we derive a feature detector from this which can fully process live PAL video using  less than 5\%  of the available processing time
By comparison, most other detectors cannot even operate at frame rate (Harris detector 115\%, SIFT 195\%)
Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency
Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes
We show that despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors
Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and very high quality
### introduction ###
\PARstart{C}{orner} detection is used as the first step of many vision tasks such as tracking, localisation, SLAM (simultaneous localisation and mapping), image matching and recognition
This need has driven the development of a large number of corner detectors
However, despite the massive  increase in computing power since the inception of corner detectors, it is still true that when processing live video streams at full frame rate, existing feature detectors leave little if any time for further processing
In the applications described above, corners are typically detected and matched into a database, thus it is important that the same real-world points are detected repeatably from multiple views  CITATION
The amount of variation in viewpoint under which this condition should hold depends on the application
### abstract ###
The LETOR website    contains three information retrieval datasets used as a benchmark for testing machine learning ideas for ranking
Algorithms participating in the challenge are required to assign score values to  search results for a collection of queries, and are measured using standard IR ranking measures (NDCG, precision, MAP) that depend only the relative score-induced order of the results
Similarly to many of the ideas proposed in the participating algorithms, we train a linear classifier
In contrast with other participating algorithms, we define an additional free variable (intercept, or benchmark) for each query
This allows expressing the fact that results for different queries are incomparable for the purpose of determining relevance
The cost of this idea is the addition of relatively few nuisance parameters
Our approach is simple,  and we used  a standard logistic regression library to test it
The results beat the reported participating algorithms
Hence, it seems promising to combine our approach with other more complex ideas
### introduction ###
The LETOR benchmark dataset  CITATION    {http://research
microsoft
com/users/LETOR/}  (version 2 0) contains three information retrieval datasets used as a benchmark for testing machine learning ideas for ranking
Algorithms participating in the challenge are required to assign score values to  search results for a collection of queries, and are measured using standard IR ranking measures (NDCG@ SYMBOL , precision@ SYMBOL  and MAP - see  CITATION  for details), designed in such a way that only the relative order of the results matters
The input to the learning problem is a list of query-result records, where each record is a vector of standard IR features together with a relevance label and a query id
The label is either binary (irrelevant or relevant) or trinary (irrelevant, relevant or very relevant)
All reported algorithms used for this task on LETOR website  CITATION   rely on the fact that records corresponding to the same query id are in some sense comparable to each other, and cross query records are incomparable
The rationale is that the IR measures are computed as a sum over the queries, where for each query  a nonlinear function is computed
For example, RankSVM  CITATION  and RankBoost  CITATION  use pairs of results for the same query to penalize a cost function, but never cross-query pairs of results
The following approach seems at first too naive compared to others: Since the training  information is given as relevance labels, why not simply train a linear classifier to predict the relevance labels, and use prediction confidence  as score
Unfortunately this approach fares poorly
The hypothesized reason is that judges' relevance response may depend on the query
To check this hypothesis, we define an additional free variable ( intercept  or  benchmark ) for each query
This allows expressing the fact that results for different queries are incomparable for the purpose of determining relevance
The cost of this idea is the addition of relatively few nuisance parameters
Our approach is extremely simple, and we used a standard logistic regression library to test it on the data
This work is not the first to suggest query dependent ranking, but it is arguably the simplest, most immediate way to address this dependence using linear classification before other complicated ideas should be tested
Based on our judgment, other reported algorithms used for the challenge are more complicated, and our solution is overall better on the given data
### abstract ###
The exploration-exploitation dilemma has been an intriguing and unsolved problem within the framework of reinforcement learning ``Optimism in the face of uncertainty'' and model building play central roles in advanced exploration methods
Here, we integrate several concepts and obtain a fast and simple algorithm
We show that the proposed algorithm finds a near-optimal policy in polynomial time, and give experimental evidence that it is robust and efficient compared to its ascendants
### introduction ###
Reinforcement learning (RL) is the art of maximizing long-term rewards in a stochastic, unknown environment
In the construction of RL algorithms, the choice of exploration strategy is of central significance
We shall examine the problem of exploration in the Markov decision process (MDP) framework
While simple methods like  SYMBOL -greedy and Boltzmann exploration are commonly used, it is known that their behavior can be extremely poor  CITATION
Recently, a number of efficient exploration algorithms have been published, and for some of them, formal proofs of efficiency also exist
We review these methods in Section~
By combining ideas from several sources, we construct a new algorithm for efficient exploration
The new algorithm,  optimistic initial model  (\ourmethod), is described in Section~
In Section~, we show that many of the advanced algorithms, including ours, can be treated in a unified way
We use this fact to sketch a proof that \ourmethod\ finds a near-optimal policy in polynomial time with high probability
Section~ provides experimental comparison between \ourmethod\ and a number of other methods on some benchmark problems
Our results are summarized in Section~
In the rest of this section, we review the necessary preliminaries, Markov decision processes and the exploration task
### abstract ###
% This paper proposes a method to construct an adaptive agent that is universal with respect to a given class of experts, where each expert is an agent that has been designed specifically for a particular environment
This adaptive control problem is formalized as the problem of minimizing the relative entropy of the adaptive agent from the expert that is most suitable for the unknown environment
If the agent is a passive observer, then the optimal solution is the well-known Bayesian predictor
However, if the agent is active, then its past actions need to be treated as causal interventions on the I/O stream rather than normal probability conditions
Here it is shown that the solution to this new variational problem is given by a stochastic controller called the Bayesian control rule, which implements adaptive behavior as a mixture of experts
Furthermore, it is shown that under mild assumptions, the Bayesian control rule converges to the control law of the most suitable expert
### introduction ###
When the behavior of an environment under any control signal is fully known, then the designer can choose an agent that produces the desired dynamics
Instances of this problem include hitting a target with a cannon under known weather conditions, solving a maze having its map and controlling a robotic arm in a manufacturing plant
However, when the behavior of the plant is unknown, then the designer faces the problem of  adaptive control
For example, shooting the cannon lacking the appropriate measurement equipment, finding the way out of an unknown maze and designing an autonomous robot for Martian exploration
Adaptive control turns out to be far more difficult than its non-adaptive counterpart
This is because any good policy has to carefully trade off explorative versus exploitative actions, i e actions for the identification of the environment's dynamics versus actions to control it in a desired way
Even when the environment's dynamics are known to belong to a particular class for which optimal agents are available, constructing the corresponding optimal adaptive agent is in general computationally intractable even for simple toy problems  CITATION
Thus, finding tractable approximations has been a major focus of research
Recently, it has been proposed to reformulate the problem statement for some classes of control problems based on the minimization of a relative entropy criterion
For example, a large class of optimal control problems can be solved very efficiently if the problem statement is reformulated as the minimization of the deviation of the dynamics of a controlled system from the uncontrolled system  CITATION
In this work, a similar approach is introduced
If a class of agents is given, where each agent solves a different environment, then adaptive controllers can be derived from a minimum relative entropy principle
In particular, one can construct an adaptive agent that is universal with respect to this class by minimizing the average relative entropy from the environment-specific agent
However, this extension is not straightforward
There is a syntactical difference between actions and observations that has to be taken into account when formulating the variational problem
More specifically, actions have to be treated as interventions obeying the rules of causality  CITATION
If this distinction is made, the variational problem has a unique solution given by a stochastic control rule called the Bayesian control rule
This control rule is particularly interesting because it translates the adaptive control problem into an on-line inference problem that can be applied forward in time
Furthermore, this work shows that under mild assumptions, the adaptive agent converges to the environment-specific agent
The paper is organized as follows
Section~ introduces notation and sets up the adaptive control problem
Section~ formulates adaptive control as a minimum relative entropy problem
After an initial, na\"{\i}ve approach, the need for causal considerations is motivated
Then, the Bayesian control rule is derived from a revised relative entropy criterion
In Section~, the conditions for convergence are examined and a proof is given
Section~ illustrates the usage of the Bayesian control rule for the multi-armed bandit problem and the undiscounted Markov decision problem
Section~ discusses properties of the Bayesian control rule and relates it to previous work in the literature
Section~ concludes
### abstract ###
The key approaches for machine learning, especially learning in unknown probabilistic environments are new representations and computation mechanisms
In this paper, a novel quantum reinforcement learning (QRL) method is proposed by combining quantum theory and reinforcement learning (RL)
Inspired by the state superposition principle and quantum parallelism, a framework of value updating algorithm is introduced
The state (action) in traditional RL is identified as the eigen state (eigen action) in QRL
The state (action) set can be represented with a quantum superposition state and the eigen state (eigen action) can be obtained by randomly observing the simulated quantum state according to the collapse postulate of quantum measurement
The probability of the eigen action is determined by the probability amplitude, which is parallelly updated according to rewards
Some related characteristics of QRL such as convergence, optimality and balancing between exploration and exploitation are also analyzed, which shows that this approach makes a good tradeoff between exploration and exploitation using the probability amplitude and can speed up learning through the quantum parallelism
To evaluate the performance and practicability of QRL, several simulated experiments are given and the results demonstrate the effectiveness and superiority of QRL algorithm for some complex problems
The present work is also an effective exploration on the application of quantum computation to artificial intelligence
### introduction ###
\PARstart{L}{earning} methods are generally classified into supervised, unsupervised and  reinforcement learning  (RL)
Supervised learning requires explicit feedback provided by input-output pairs and gives a map from inputs to outputs
Unsupervised learning only processes on the input data
In contrast, RL uses a scalar value named  reward  to evaluate the input-output pairs and learns a mapping from  states  to  actions  by interaction with the environment through trial-and-error
Since 1980s, RL has become an important approach to machine learning  CITATION - CITATION , and is widely used in artificial intelligence, especially in robotics  CITATION - CITATION ,  CITATION , due to its good performance of on-line adaptation and powerful learning ability to complex nonlinear systems
However there are still some difficult problems in practical applications
One problem is the exploration strategy, which contributes a lot to better balancing of  exploration  (trying previously unexplored strategies to find better policy) and  exploitation  (taking the most advantage of the experienced knowledge)
The other is its slow learning speed, especially for the complex problems sometimes known as ``the curse of dimensionality" when the state-action space becomes huge and the number of parameters to be learned grows exponentially with its dimension
To combat those problems, many methods have been proposed in recent years
Temporal abstraction and decomposition methods have been explored to solve such problems as RL and dynamic programming (DP) to speed up learning  CITATION - CITATION
Different kinds of learning paradigms are combined to optimize RL
For example, Smith  CITATION  presented a new model for representation and generalization in model-less RL based on the self-organizing map (SOM) and standard Q-learning
The adaptation of Watkins' Q-learning with fuzzy inference systems for problems with large state-action spaces or with continuous state spaces is also proposed  CITATION ,  CITATION ,  CITATION ,  CITATION
Many specific improvements are also implemented to modify related RL methods in practice  CITATION ,  CITATION ,  CITATION ,  CITATION ,  CITATION ,  CITATION
In spite of all these attempts more work is needed to achieve satisfactory successes and new ideas are necessary to explore more effective representation methods and learning mechanisms
In this paper, we explore to overcome some difficulties in RL using quantum theory and propose a novel quantum reinforcement learning method
Quantum information processing is a rapidly developing field
Some results have shown that quantum computation can more efficiently solve some difficult problems than the classical counterpart
Two important quantum algorithms, the Shor algorithm  CITATION ,  CITATION  and the Grover algorithm  CITATION ,  CITATION  have been proposed in 1994 and 1996, respectively
The Shor algorithm can give an exponential speedup for factoring large integers into prime numbers and it has been realized  CITATION  for the factorization of integer 15 using nuclear magnetic resonance (NMR)
The Grover algorithm can achieve a square speedup over classical algorithms in unsorted database searching and its experimental implementations have also been demonstrated using NMR  CITATION - CITATION  and quantum optics  CITATION ,  CITATION  for a system with four states
Some methods have also been explored to connect quantum computation and machine learning
For example, the quantum computing version of artificial neural network has been studied from the pure theory to the simple simulated and experimental implementation  CITATION - CITATION
Rigatos and Tzafestas  CITATION  used quantum computation for the parallelization of a fuzzy logic control algorithm to speed up the fuzzy inference
Quantum or quantum-inspired evolutionary algorithms have been proposed to improve the existing evolutionary algorithms  CITATION
Hogg and Portnov  CITATION  presented a quantum algorithm for combinatorial optimization of overconstrained satisfiability (SAT) and asymmetric travelling salesman (ATSP)
Recently the quantum search technique has been used to dynamic programming  CITATION
Taking advantage of quantum computation, some novel algorithms inspired by quantum characteristics will not only improve the performance of existing algorithms on traditional computers, but also promote the development of related research areas such as quantum computers and machine learning
Considering the essence of computation and algorithms, Dong and his co-workers  CITATION  have presented the concept of  quantum reinforcement learning  (QRL) inspired by the state superposition principle and quantum parallelism
Following this concept, we in this paper give a formal quantum reinforcement learning algorithm framework and specifically demonstrate the advantages of QRL for speeding up learning and obtaining a good tradeoff between exploration and exploitation of RL through simulated experiments and some related discussions
This paper is organized as follows
Section II contains the prerequisite and problem description of standard reinforcement learning, quantum computation and related quantum gates
In Section III, quantum reinforcement learning is introduced systematically, where the state (action) space is represented with the quantum state, the exploration strategy based on the collapse postulate is achieved and a novel QRL algorithm is proposed specifically
Section IV analyzes related characteristics of QRL such as the convergence, optimality and the balancing between exploration and exploitation
Section V describes the simulated experiments and the results demonstrate the effectiveness and superiority of QRL algorithm
In Section VI, we briefly discuss some related problems of QRL for future work
Concluding remarks are given in section VII
### abstract ###
We develop the concept of  ABC -Boost ( A daptive  B ase  C lass Boost) for  multi-class classification and  present   ABC -MART, a concrete implementation of  ABC -Boost
The original MART ( M ultiple  A dditive  R egression  T rees) algorithm has been very successful in large-scale applications
For binary classification, ABC-MART recovers MART
For multi-class  classification,  ABC-MART considerably improves MART, as  evaluated on several public data sets
### introduction ###
Classification is a basic task in machine learning
A training data set  SYMBOL  consists of  SYMBOL  feature vectors (samples)  SYMBOL , and  SYMBOL  class labels,  SYMBOL ,  SYMBOL  to  SYMBOL
Here  SYMBOL  and  SYMBOL  is the number of classes
The  task is to predict the class labels
This study focuses on multi-class classification ( SYMBOL )
Many classification algorithms are based on  boosting  CITATION , which is  regarded one of most significant breakthroughs in machine learning
MART CITATION  ( M ultiple  A dditive  R egression  T rees) is a successful boosting algorithm, especially for large-scale applications in industry practice
For example, the regression-based ranking method developed in Yahoo
CITATION  used an underlying learning algorithm based on MART
McRank  CITATION , the classification-based ranking method, also used MART as the underlying learning procedure
This study proposes  ABC -Boost ( A daptive  B ase  C lass Boost) for  multi-class classification
We present   ABC -MART, a concrete implementation of {ABC}-Boost
ABC-Boost  is based on the following two key ideas:   For multi-class classification, popular loss functions for  SYMBOL  classes usually assume a constraint CITATION   such that only the values for  SYMBOL  classes are needed
Therefore, we can choose a  base class  and derive  algorithms only for   SYMBOL  classes
At each boosting step, although the base class is not explicitly trained, it will implicitly benefit from  the training on  SYMBOL  classes, due to the constraint
Thus, we  adaptively  choose the base class which  has the ``worst'' performance
The idea of assuming a constraint on the loss function and  using a base class  may not be at all surprising
For binary ( SYMBOL ) classification, a ``sum-to-zero'' constraint on the loss function is automatically considered so that we only need to train the algorithm for one (instead of  SYMBOL ) class
For multi-class ( SYMBOL ) classification, the sum-to-zero constraint on the loss function is also ubiquitously adopted CITATION
In particular, the multi-class  Logitboost  CITATION  algorithm was derived by explicitly averaging over  SYMBOL  base classes
The loss function adopted in our ABC-MART is the same as in MART CITATION  and  Logitboost  CITATION
All three algorithms assume the ``sum-to-zero'' constraint
However, we obtain different first and second derivatives of the loss function, from MART CITATION  and  Logitboost  CITATION
See Section  for details
In terms of implementation, our proposed ABC-MART differs from the original MART algorithm only in a few lines of code
Since MART is known to be a successful algorithm, much of our work is devoted to the empirical comparisons of ABC-MART with MART
Our experiment results on publicly available data sets will demonstrate that ABC-MART could considerably improves MART
Also, ABC-MART reduces both the training and testing time by  SYMBOL , which may be quite beneficial when  SYMBOL  is small
We notice that data sets in industry applications are often quite large (e g , several million samples CITATION )
Publicly available data sets (e g , UCI repository), however, are mostly small
In our study, the  Covertype  data set from the UCI repository is reasonably large with 581,012 observations \\   We first review the original MART algorithm and functional gradient boosting CITATION
### abstract ###
Lasso, or  SYMBOL  regularized least squares, has been explored extensively for its remarkable sparsity properties
It is shown in this paper  that the solution to Lasso, in addition to its sparsity, has robustness properties: it is the solution to a robust optimization problem
This has two important consequences
First, robustness provides a connection of the regularizer to a physical property, namely, protection from noise
This allows a principled selection of the regularizer, and in particular, generalizations of Lasso that also yield convex optimization problems are obtained by considering different uncertainty sets
Secondly, robustness can itself be used as an avenue to exploring different properties of the solution
In particular, it is shown that robustness of the solution  explains why the solution is sparse
The analysis as well as the specific results obtained differ from standard sparsity results, providing different geometric intuition
Furthermore, it is shown that the robust optimization formulation is related to kernel density estimation, and based on this approach,  a proof that Lasso is consistent is given using robustness directly
Finally, a  theorem saying that sparsity and algorithmic stability contradict each other, and hence Lasso is not stable, is presented
### introduction ###
In this paper we consider linear regression problems with least-square error
The problem is to find a vector  SYMBOL  so that the  SYMBOL  norm of the residual  SYMBOL  is minimized, for a given matrix  SYMBOL  and vector  SYMBOL
From a learning/regression perspective, each row of  SYMBOL  can be regarded as a training sample, and the corresponding element of  SYMBOL  as the target value of this observed sample
Each column of  SYMBOL  corresponds to a feature, and the objective is to find a set of weights so that the weighted sum of the feature values approximates the target value
It is well known that minimizing the least squared error can lead to sensitive solutions  CITATION
Many regularization methods have been proposed to decrease this sensitivity
Among them, Tikhonov regularization  CITATION  and Lasso~ CITATION  are two widely known and cited algorithms
These methods minimize a weighted sum of the residual norm and a certain regularization term,  SYMBOL  for Tikhonov regularization and  SYMBOL  for Lasso
In addition to providing regularity, Lasso is also known for the tendency to select sparse solutions
Recently this has attracted much attention for its ability to reconstruct sparse solutions when sampling occurs far below the Nyquist rate, and also for its ability to recover the sparsity pattern exactly with probability one, asymptotically as the number of observations increases (there is an extensive literature on this subject, and we refer the reader to  CITATION  and references therein)
The first result of this paper is that the solution to Lasso has robustness properties: it is the solution to a robust optimization problem
In itself, this interpretation of Lasso as the solution to a robust least squares problem is a development in line with the results of  CITATION
There, the authors propose an alternative approach of reducing sensitivity of linear regression by considering a robust version of the regression problem, i e , minimizing the worst-case residual for the observations under some unknown but bounded disturbance
Most of the research in this area considers either the case where the disturbance is row-wise uncoupled  CITATION , or the case where the Frobenius norm of the disturbance matrix is bounded  CITATION
None of these robust optimization approaches produces a solution that has sparsity properties (in particular, the solution to Lasso does not solve any of these previously formulated robust optimization problems)
In contrast, we investigate the robust regression problem where the uncertainty set is defined by feature-wise constraints
Such a noise model is of interest when values of features are obtained with some noisy pre-processing steps, and the magnitudes of such noises are known or bounded
Another situation of interest is where features are meaningfully coupled
We define  coupled  and  uncoupled  disturbances and uncertainty sets precisely in Section  below
Intuitively, a disturbance is feature-wise coupled if the variation or disturbance across features satisfy joint constraints, and uncoupled otherwise
Considering the solution to Lasso as the solution  of a robust least squares problem has two important consequences
First, robustness provides a connection of the regularizer to a physical property, namely, protection from noise
This allows more principled selection of the regularizer, and in particular, considering different uncertainty sets, we construct generalizations of Lasso that also yield convex optimization problems
Secondly, and perhaps most significantly, robustness  is a strong property that can itself be used as an avenue to investigating different properties of the solution
We show that robustness of the solution can explain why the solution is sparse
The analysis as well as the specific results we obtain differ from standard sparsity results, providing different geometric intuition, and extending beyond the least-squares setting
Sparsity results obtained for Lasso ultimately depend on the fact that introducing additional features incurs larger  SYMBOL -penalty than the least squares error reduction
In contrast, we exploit the fact that a robust solution is, by definition, the optimal solution under a worst-case perturbation
Our results show that, essentially, a coefficient of the solution is nonzero if the corresponding feature is relevant under all allowable perturbations
In addition to sparsity, we also use robustness directly to prove consistency of Lasso
We briefly list the main contributions as well as the organization of this paper
In Section~, we formulate the robust regression problem with feature-wise independent disturbances, and show that this formulation is equivalent to a least-square problem with a weighted  SYMBOL  norm regularization term
Hence, we provide an interpretation of Lasso from a robustness perspective
% which can be helpful in choosing the regularization parameter
We generalize the robust regression formulation to loss functions of arbitrary norm in Section~
We also consider uncertainty sets that require disturbances of different features to satisfy joint conditions
This can be used to mitigate the conservativeness of the robust solution  and to obtain solutions with additional properties
%We call these features ``coupled''
In Section~, we present new sparsity results for the robust regression problem with feature-wise independent disturbances
This provides a new robustness-based explanation to the sparsity of Lasso
Our approach gives new analysis and also geometric intuition, and furthermore allows one to obtain sparsity results for more general loss functions, beyond the squared loss
Next, we relate Lasso to kernel density estimation in Section~
This allows us to re-prove consistency in a statistical learning setup, using the new robustness tools and formulation we introduce
Along with our results on sparsity, this illustrates the power of robustness in explaining and also exploring different properties of the solution
Finally, we prove in Section~ a ``no-free-lunch'' theorem, stating that an algorithm that encourages sparsity cannot be stable {Notation}
We use capital letters to represent matrices, and boldface letters to represent column vectors
Row vectors are represented as the transpose of column vectors
For a vector  SYMBOL ,  SYMBOL  denotes its  SYMBOL  element
Throughout the paper,  SYMBOL  and  SYMBOL  are used to denote the  SYMBOL  column and the  SYMBOL  row of the observation matrix  SYMBOL , respectively
We use  SYMBOL  to denote the  SYMBOL  element of  SYMBOL , hence it is the  SYMBOL  element of  SYMBOL , and  SYMBOL  element of  SYMBOL
For a convex function  SYMBOL ,  SYMBOL  represents any of its sub-gradients evaluated at  SYMBOL
A vector with length  SYMBOL  and each element equals  SYMBOL  is denoted as  SYMBOL
### abstract ###
Solomonoff completed the Bayesian framework by providing a rigorous, unique, formal, and universal choice for the model class and the prior
We discuss in breadth how and in which sense universal (non- iid  )\ sequence prediction solves various (philosophical) problems of traditional Bayesian sequence prediction
We show that Solomonoff's model possesses many desirable properties: Fast convergence and strong bounds, and in contrast to most classical continuous prior densities has no zero p(oste)rior problem, ie \ can confirm universal hypotheses, is reparametrization and regrouping invariant, and avoids the old-evidence and updating problem
It even performs well (actually better) in non-computable environments
### introduction ###
Given the weather in the past, what is the probability of rain tomorrow
What is the correct answer in an IQ test asking to continue the sequence 1,4,9,16,
Given historic stock-charts, can one predict the quotes of tomorrow
Assuming the sun rose 5000 years every day, how likely is doomsday (that the sun does not rise) tomorrow
These are instances of the important problem of inductive inference or time-series forecasting or sequence prediction
Finding prediction rules for every particular (new) problem is possible but cumbersome and prone to disagreement or contradiction
What we are interested in is a formal general theory for prediction
The Bayesian framework is the most consistent and successful framework developed thus far  CITATION
A Bayesian considers a set of environments=\-hypotheses=\-models  SYMBOL  which includes the true data generating probability distribution  SYMBOL
From one's prior belief  SYMBOL  in environment  SYMBOL  and the observed data sequence  SYMBOL , Bayes' rule yields one's posterior confidence in  SYMBOL
In a predictive setting, one directly determines the predictive probability of the next symbol  SYMBOL  without the intermediate step of identifying a (true or good or causal or useful) model
Note that classification and regression can be regarded as special sequence prediction problems, where the sequence  SYMBOL  of  SYMBOL -pairs is given and the class label or function value  SYMBOL  shall be predicted
The Bayesian framework leaves open how to choose the model class  SYMBOL  and prior  SYMBOL
General guidelines are that  SYMBOL  should be small but large enough to contain the true environment  SYMBOL , and  SYMBOL  should reflect one's prior (subjective) belief in  SYMBOL  or should be non-informative or neutral or objective if no prior knowledge is available
But these are informal and ambiguous considerations outside the formal Bayesian framework
Solomonoff's  CITATION  rigorous, essentially unique, formal, and universal solution to this problem is to consider a single large universal class  SYMBOL  suitable for  all  induction problems
The corresponding universal prior  SYMBOL  is biased towards simple environments in such a way that it dominates=\-superior to all other priors
This leads to an a priori probability  SYMBOL  which is equivalent to the probability that a universal Turing machine with random input tape outputs  SYMBOL
Many interesting, important, and deep results have been proven for Solomonoff's universal distribution  SYMBOL   CITATION
The motivation and goal of this paper is to provide a broad discussion of how and in which sense universal sequence prediction solves all kinds of (philosophical) problems of Bayesian sequence prediction, and to present some recent results
Many arguments and ideas could be further developed
I hope that the exposition stimulates such a future, more detailed, investigation
In Section  we review the excellent predictive performance of Bayesian sequence prediction for generic (non- iid  )\ countable and continuous model classes
Section  critically reviews the classical principles (indifference, symmetry, minimax) for obtaining objective priors, introduces the universal prior inspired by Occam's razor and quantified in terms of Kolmogorov complexity
In Section  (for  iid  \  SYMBOL ) and Section  (for universal  SYMBOL ) we show various desirable properties of the universal prior and class (non-zero p(oste)rior, confirmation of universal hypotheses, reparametrization and regrouping invariance, no old-evidence and updating problem) in contrast to (most) classical continuous prior densities
Finally, we show that the universal mixture performs better than classical continuous mixtures, even in uncomputable environments
Section  contains critique and summary
### abstract ###
Hidden Markov Models (HMMs) are one of the most fundamental and widely used statistical tools for modeling discrete time series
In general, learning HMMs from data is computationally hard (under cryptographic assumptions), and practitioners typically resort to search heuristics which suffer from the usual local optima issues
We prove that under a natural separation condition (bounds on the smallest singular value of the HMM parameters), there is an efficient and provably correct algorithm for learning HMMs
The sample complexity of the algorithm does not explicitly depend on the number of distinct (discrete) observations---it implicitly depends on this quantity through spectral properties of the underlying HMM
This makes the algorithm particularly applicable to settings with a large number of observations, such as those in natural language processing where the space of observation is sometimes the words in a language
The algorithm is also simple, employing only a singular value decomposition and matrix multiplications
### introduction ###
Hidden Markov Models (HMMs)  CITATION  are the workhorse statistical model for discrete time series, with widely diverse applications including automatic speech recognition, natural language processing (NLP), and genomic sequence modeling
In this model, a discrete hidden state evolves according to some Markovian dynamics, and observations at a particular time depend only on the hidden state at that time
The learning problem is to estimate the model only with observation samples from the underlying distribution
Thus far, the predominant learning algorithms have been local search heuristics, such as the Baum-Welch / EM algorithm  CITATION
It is not surprising that practical algorithms have resorted to heuristics, as the general learning problem has been shown to be hard under cryptographic assumptions  CITATION
Fortunately, the hardness results are for HMMs that seem divorced from those that we are likely to encounter in practical applications
The situation is in many ways analogous to learning mixture distributions with samples from the underlying distribution
There, the general problem is also believed to be hard
However, much recent progress has been made when certain separation assumptions are made with respect to the component mixture distributions ( eg ~ CITATION )
Roughly speaking, these separation assumptions imply that with high probability, given a point sampled from the distribution, one can determine the mixture component that generated the point
In fact, there is a prevalent sentiment that we are often only interested in clustering when such a separation condition holds
Much of the theoretical work here has focused on how small this separation can be and still permit an efficient algorithm to recover the model
We present a simple and efficient algorithm for learning HMMs under a certain natural separation condition
We provide two results for learning
The first is that we can approximate the joint distribution over observation sequences of length  SYMBOL  (here, the quality of approximation is measured by total variation distance)
As  SYMBOL  increases, the approximation quality degrades polynomially
Our second result is on approximating the  conditional  distribution over a future observation, conditioned on some history of observations
We show that this error is asymptotically bounded--- i e ~for any  SYMBOL , conditioned on the observations prior to time  SYMBOL , the error in predicting the  SYMBOL -th outcome is controlled
Our algorithm can be thought of as `improperly' learning an HMM in that we do not explicitly recover the transition and observation models
However, our model does maintain a hidden state representation which is closely (in fact, linearly) related to the HMM's, and can be used for interpreting the hidden state
The separation condition we require is a spectral condition on both the observation matrix and the transition matrix
Roughly speaking, we require that the observation distributions arising from distinct hidden states be distinct (which we formalize by singular value conditions on the observation matrix)
This requirement can be thought of as being weaker than the separation condition for clustering in that the observation distributions can overlap quite a bit---given one observation, we do not necessarily have the information to determine which hidden state it was generated from (unlike in the clustering literature)
We also have a spectral condition on the correlation between adjacent observations
We believe both of these conditions to be quite reasonable in many practical applications
Furthermore, given our analysis, extensions to our algorithm which relax these assumptions should be possible
The algorithm we present has both polynomial sample and computational complexity
Computationally, the algorithm is quite simple---at its core is a singular value decomposition (SVD) of a correlation matrix between past and future observations
This SVD can be viewed as a Canonical Correlation Analysis (CCA)~ CITATION  between past and future observations
The sample complexity results we present do not explicitly depend on the number of distinct observations; rather, they implicitly depend on this number through spectral properties of the HMM
This makes the algorithm particularly applicable to settings with a large number of observations, such as those in NLP where the space of observations is sometimes the words in a language
### abstract ###
Many databases store data in relational format, with different types of entities and information about links between the entities
The field of statistical-relational learning (SRL) has developed a number of new statistical models for such data
In this paper we focus on learning class-level or first-order dependencies, which model the general database statistics over attributes of linked objects and links (e g , the percentage of A grades given in computer science classes)
Class-level statistical relationships are important in themselves, and they support applications like policy making, strategic planning, and query optimization
Most current SRL methods find class-level dependencies, but their main task is to support instance-level predictions about the attributes or links of specific entities
We focus only on class-level prediction, and describe algorithms for learning class-level models that are orders of magnitude faster for this task
Our algorithms learn Bayes nets with relational structure, leveraging the efficiency of single-table nonrelational Bayes net learners
An evaluation of our methods on three data sets shows that they are computationally feasible for realistic table sizes, and that the learned structures represent the statistical information in the databases well
After learning compiles the database statistics into a Bayes net, querying these statistics via Bayes net inference is faster than with SQL queries, and does not depend on the size of the database
### introduction ###
Many real-world applications store data in relational format, with different tables for entities and their links
Standard machine learning techniques are applied to data stored in a single table, that is, in nonrelational, propositional or ``flat" format  CITATION
The field of statistical-relational learning (SRL) aims to extend machine learning algorithms to relational data  CITATION
One of the major machine learning tasks is to use data to build a  generative statistical model  for the variables in an application domain  CITATION
In the single-table learning setting, the goal is often to represent predictive dependencies between the attributes of a single individual (e g , between the intelligence and ranking of a student)
In the SRL setting, the goal is often to represent, in addition, dependencies between attributes of different individuals that are related or linked to each other (e g , between the intelligence of a student and the difficulty of a course given that the student is registered in the course)
### abstract ###
In the past few years powerful generalizations to the Euclidean k-means problem have been made, such as Bregman clustering~ CITATION , co-clustering (i e , simultaneous clustering of rows and columns of an input matrix)~ CITATION , and tensor clustering~ CITATION
Like k-means, these more general problems also suffer from the NP-hardness of the associated optimization
Researchers have developed approximation algorithms of varying degrees of sophistication for k-means, k-medians, and more recently also for Bregman clustering~ CITATION
However, there seem to be no approximation algorithms for Bregman co- and tensor clustering
In this paper we derive the first (to our knowledge) guaranteed methods for these increasingly important clustering settings
Going beyond Bregman divergences, we also prove an approximation factor for tensor clustering with arbitrary separable metrics
Through extensive experiments we evaluate the characteristics of our method, and show that it also has practical impact
### introduction ###
Partitioning data points into clusters is a fundamentally hard problem
The well-known Euclidean k-means problem that partitions the input data points (vectors in  SYMBOL ) into  SYMBOL  clusters while minimizing sums of their squared distances to corresponding cluster centroids, is an NP hard problem~ CITATION  (exponential in  SYMBOL )
However, simple and frequently used procedures that rapidly obtain local minima exist since a long time~ CITATION
Because of its wide applicability and importance, the Euclidean k-means problem has been generalized in several directions
Specific examples relevant to this paper include:  \setlength{sep}{-1pt}   Bregman clustering ~ CITATION , where instead of minimizing squared Euclidean distances one minimizes Bregman divergences (which are generalized distance functions, see~() or~ CITATION  for details),   Bregman co-clustering ~ CITATION  (which includes both Euclidean~ CITATION  and information-theoretic co-clustering~ CITATION  as special cases), where the set of input vectors is viewed as a matrix and one  simultaneously  clusters rows and columns to obtain coherent submatrices (co-clusters), while minimizing a Bregman divergence, and   Tensor clustering  or multiway clustering~ CITATION , especially the version based on Bregman divergences~ CITATION , where one simultaneously clusters along various dimensions of the input tensor
For these problems too, the commonly used heuristics perform well, but do not provide theoretical guarantees (or at best assure local optimality)
For k-means type clustering problems---i e , problems that group together input vectors into clusters while minimizing ``distance'' to cluster centroids---there exist several algorithms that approximate a globally optimal solution
We refer the reader to~ CITATION , and the numerous references therein for more details
In stark contrast, approximation algorithms for tensor clustering are much less studied
We are aware of only two very recent attempts (both papers are from 2008) for the two-dimensional special case of co-clustering, namely,~ CITATION  and  CITATION ---and both of the papers  follow similar approaches to obtain their approximation guarantees
Both prove a  SYMBOL -approximation for Euclidean co-clustering,  CITATION  an additional factor of  SYMBOL  for binary matrices and an  SYMBOL  norm objective, and  CITATION  a factor of  SYMBOL  for co-clustering real matrices with  SYMBOL  norms
In all factors  SYMBOL  is an approximation guarantee for clustering either rows or columns
In this paper, we build upon~ CITATION  and obtain approximation algorithms for tensor clustering with Bregman divergences and arbitrary separable metrics such as  SYMBOL -norms
The latter result is of particular interest for  SYMBOL -norm based tensor clustering, which may be viewed as a generalization of k-medians to tensors
In the terminology of~ CITATION , we focus on the ``block average'' versions of co- and tensor clustering
Additional discussion and relevant references for co-clustering can be found in~ CITATION , while for the lesser known problem of tensor clustering more background can be gained by referring to~ CITATION
### abstract ###
The enormous successes have been made by quantum algorithms during the last decade
In this paper, we combine the quantum game with the problem of data clustering, and then develop a quantum-game-based clustering algorithm, in which data points in a dataset are considered as players who can make decisions and implement quantum strategies in quantum games
After each round of a quantum game, each player's expected payoff is calculated
Later, he uses an link-removing-and-rewiring (LRR) function to change his neighbors and adjust the strength of links connecting to them in order to maximize his payoff
Further, algorithms are discussed and analyzed in two cases of strategies, two payoff matrixes and two LRR functions
Consequently, the simulation results have demonstrated that data points in datasets are clustered reasonably and efficiently, and the clustering algorithms have fast rates of convergence
Moreover, the comparison with other algorithms also provides an indication of the effectiveness of the proposed approach \\ \\  Keywords : Unsupervised learning; Data clustering; Quantum computation; Quantum game
### introduction ###
Quantum computation is an extremely exciting and rapidly growing field
More recently, an increasing number of researchers with different backgrounds, ranging from physics, computer sciences and information theory to mathematics and philosophy, are involved in researching properties of quantum-based computation~ CITATION
During the last decade, a series of significant breakthroughs had been made
One was that in 1994 Peter Shor surprised the world by proposing a polynomial-time quantum algorithm for integer factorization  CITATION , while in the classical world the best-known classical factoring algorithm works in superpolynomial time
Three years later, in 1997, Lov Grover proved that a quantum computer could search an unsorted database in the square root of the time  CITATION
Meanwhile, Gilles Brassard et al combined ideas from Grover's and Shor's quantum algorithms to propose a quantum counting algorithm  CITATION
In recent years, many interests focus on the quantum game theory and considerable work has been done
For instance, D A Meyer~ CITATION  studied the Penny Flip game in the quantum world firstly
His result showed that if a player was allowed to implement quantum strategies, he would always defeat his opponent who played the classical strategies and increase his expected payoff as well J Eisert et al ~ CITATION  quantized the Prisoners' Dilemma and demonstrated that the dilemma could be escaped when both players resort to quantum strategies A P
Flitney et al ~ CITATION  generalized Eisert's result, the miracle move, i e , the result of the game would move towards the quantum player's preferred result, while the other player used classical strategies L Marinatto et al ~ CITATION  investigated the Battle of the Sexes game in quantum domain
Their result showed that there existed a unique equilibrium in the game, when the entangled strategies were allowed C F
Lee et al ~ CITATION  reported that the quantum game is more efficient than the classical game, and they found an upper bound for this efficiency
Besides, some experiments about the quantum games have also been implemented on different quantum computers~ CITATION
For more details about quantum games, see~ CITATION
Successes achieved by quantum algorithms make us guess that powerful quantum computers can figure out solutions faster and better than the best known classical counterparts for certain types of problems
Furthermore, it is more important that they offer a new way to find potentially dramatic algorithmic speed-ups
Therefore, we may ask naturally: can we construct quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantum computer
Following this idea, some researchers have proposed their novel methods and demonstrated exciting results  CITATION
In addition, data clustering is a main branch of Pattern Recognition, which is widely used in many fields such as pattern analysis, data mining, information retrieval and image segmentation
In these fields, however, there is usually little priori knowledge available about the data
In response to these restrictions, clustering methodology come into being which is particularly suitable for the exploration of interrelationships among data points
Data clustering is the formal study of algorithms and methods for grouping or classifying unlabeled data points~ CITATION
In other words, its task is to find the inherent structure of a given collection of unlabeled data points and group them into meaningful clusters~ CITATION
In this paper, we attempt to combine the quantum game with the problem of data clustering in order to establish a novel clustering algorithm based on quantum games
In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games
On a time-varying network formed by players, each player is permitted to use quantum strategies and plays a  SYMBOL  entangled quantum game against every one of his neighbors respectively
Later, he applies a link-removing-and-rewiring (LRR) function to remove the links of neighbors with small payoffs and create new links to neighbors with higher payoffs at the same time
Furthermore, the strength of links between a player and his neighbors is different from one another, which is updated by the Grover iteration
During quantum games, the structure of network and the strength of links between players tend toward stability gradually
Finally, if each player only connects to the neighbor with the highest strength, the network will naturally divide into several separate parts, each of which corresponds to a cluster
The remainder of this paper is organized as follows: Section 2 introduces some important concepts about the quantum computation and the quantum Prisoners' Dilemma briefly
In Section 3, the algorithms are established in two cases of strategies, payoff matrices and link-removing-and-rewiring (LRR) functions, and then they are elaborated and analyzed
In Section 4, the relationship between the number of nearest neighbors and the number of clusters is discussed
Next, the effect of the cost in the SD-like payoff matrix is analyzed, and the relationship between the total payoffs and the rates of convergence of algorithms is explained
In Section 5, those datasets used in the simulations are introduced briefly, and then results of algorithms are demonstrated
The conclusion is given in Section 6
### abstract ###
We consider a multi-round auction setting motivated by pay-per-click auctions for Internet advertising
In each round the auctioneer selects an advertiser and shows her ad, which is then either clicked or not
An advertiser derives value from clicks; the value of a click is her private information
Initially, neither the auctioneer nor the advertisers have any information about the likelihood of clicks on the advertisements
The auctioneer's goal is to design a (dominant strategies) truthful mechanism that (approximately) maximizes the social welfare
If the advertisers bid their true private values, our problem is equivalent to the  multi-armed bandit problem , and thus can be viewed as a strategic version of the latter
In particular, for both problems the quality of an algorithm can be characterized by  regret , the difference in social welfare between the algorithm and the benchmark which always selects the same ``best" advertisement
We investigate how the design of multi-armed bandit algorithms is affected by the restriction that the resulting mechanism must be truthful
We find that deterministic truthful mechanisms have certain strong structural properties -- essentially, they must separate exploration from exploitation --  and  they incur much higher regret than the optimal multi-armed bandit algorithms
Moreover, we provide a truthful mechanism which (essentially) matches our lower bound on regret
### introduction ###
In recent years there has been much interest in understanding the implication of strategic behavior on the performance of algorithms whose input is distributed among selfish agents
This study was mainly motivated by the Internet, the main arena of large scale interaction of agents with conflicting goals
The field of Algorithmic Mechanism Design~ CITATION  studies the design of mechanisms in computational settings (for background see the recent book~ CITATION  and survey~ CITATION )
Much attention has been drawn to the market for sponsored search (e g ~ CITATION ), a multi-billion dollar market with numerous auctions running every second
Research on sponsored search mostly focus on equilibria of the Generalized Second Price (GSP) auction~ CITATION , the auction that is most commonly used in practice (e g by Google and Bing), or on the design of truthful auctions~ CITATION
All these auctions rely on knowing the rates at which users click on the different advertisements (a k a
click-through rates, or CTRs), and do not consider the process in which these CTRs are learned or refined over time by observing users' behavior
We argue that strategic agents would take this process into account, as it influences their utility
While prior work~ CITATION  focused on the influence of click fraud on methods for learning CTRs, we are interested in the implications of the  strategic bidding  by the agents
Thus, we consider the problem of designing truthful sponsored search auctions when the process of learning the CTRs is a part of the game
We are mainly interested in the interplay between the online learning and the strategic bidding
To isolate this issue, we consider the following setting, which is a natural  strategic  version of the multi-armed bandit (MAB) problem
In this setting, there are  SYMBOL  agents
Each agent  SYMBOL  has a single advertisement, and a  private  value  SYMBOL  for every click she gets
The mechanism is an online algorithm that first solicits bids from the agents, and then runs for  SYMBOL  rounds
In each round the mechanism picks an agent (using the bids and the clicks observed in the past rounds), displays her advertisement, and receives a feedback -- if there was a click or not
Payments are charged after round  SYMBOL
Each agent tries to maximize her own utility: the value that she derives from clicks minus the payment she pays
We assume that initially no information is known about the likelihood of each agent to be clicked, and in particular there are no Bayesian priors
We are interested in designing mechanisms which are truthful (in dominant strategies): every agent maximizes her utility by bidding truthfully, for any bids of the others and  for any clicks  that would have been received
The goal is to maximize the social welfare \OMIT{}% Since the payments cancel out, this is equivalent to maximizing the total value derived from clicks, where an agent's contribution to that total is her private value times the number of clicks she receives
We call this setting the   \OMIT{} In the absence of strategic behavior this problem reduces to a standard MAB formulation in which an algorithm repeatedly chooses one of the  SYMBOL  alternatives (``arms") and observes the associated payoff: the value-per-click of the corresponding ad if the ad is clicked, and  SYMBOL  otherwise
The crucial aspect in MAB problems is the tradeoff between acquiring more information ( exploration ) and using the current information to choose a good agent ( exploitation )
MAB problems have been studied intensively for the past three decades
In particular, the above formulation is well-understood~ CITATION  in terms of  regret  relative to the benchmark which always chooses the same ``best" alternative ( time-invariant benchmark )
This notion of regret naturally extends to the strategic setting outlined above, the total payoff being exactly equal to the social welfare, and the regret being exactly the loss in social welfare relative to the time-invariant benchmark
Thus one can directly compare MAB algorithms and MAB mechanisms in terms of welfare loss (regret)
Broadly, we ask how the design of MAB algorithms is affected by the restriction of truthfulness: what is the difference between the best  algorithms  and the best  truthful mechanisms
We are interested both in terms of the structural properties and the gap in performance (in terms of regret)
We are not aware of any prior work that characterizes truthful online learning algorithms or proves negative results on their performance
### abstract ###
We present an algorithm, called the  SYMBOL , for learning to make decisions in situations where the payoff of only one choice is observed, rather than all choices
The algorithm reduces this setting to binary classification, allowing one to reuse of any existing, fully supervised binary classification algorithm in this partial information setting
We show that the Offset Tree is an optimal reduction to binary classification
In particular, it has regret at most  SYMBOL  times the regret of the binary classifier it uses (where  SYMBOL  is the number of choices), and no reduction to binary classification can do better
This reduction is also computationally optimal, both at training and test time, requiring just  SYMBOL  work to train on an example or make a prediction
Experiments with the  SYMBOL  show that it generally performs better than several alternative approaches
### introduction ###
This paper is about learning to make decisions in partial feedback settings where the payoff of only one choice is observed rather than all choices
As an example, consider an internet site recommending ads or other content based on such observable quantities as user history and search engine queries, which are unique or nearly unique for every decision
After the ad is displayed, a user either clicks on it or not
This type of feedback differs critically from the standard supervised learning setting since we don't observe whether or not the user would have clicked had a different ad beed displayed instead
In an online version of the problem, a policy chooses which ads to display and uses the observed feedback to improve its future ad choices
A good solution to this problem must explore different choices and properly exploit the feedback
The problem faced by an internet site, however, is more complex
They have observed many interactions historically, and would like to exploit them in forming an initial policy, which may then be improved by further online exploration
Since exploration decisions have already been made, online solutions are not applicable
To properly use the data, we need  non-interactive  methods for learning with partial feedback
This paper is about constructing a family of algorithms for non-interactive learning in such partial feedback settings
Since any non-interactive solution can be composed with an exploration policy to form an algorithm for the online learning setting, the algorithm proposed here can also be used online
Indeed, some of our experiments are done in an online setting
### abstract ###
A client-server architecture to simultaneously solve multiple learning tasks from distributed datasets is described
In such architecture, each client is associated with an individual learning task and the associated dataset of examples
The goal of the architecture is to perform information fusion from multiple datasets while preserving privacy of individual data
The role of the server is to collect data in real-time from the clients and codify the information in a common database
The information coded in this database can be used by all the clients to solve their individual learning task, so that each client can exploit the informative content of all the datasets without actually having access to private data of others
The proposed algorithmic framework, based on regularization theory and kernel methods, uses a suitable class of mixed effect kernels
The new method is illustrated through a simulated music recommendation system
### introduction ###
The solution of learning tasks by joint analysis of multiple datasets is receiving increasing attention in different fields and under various perspectives
Indeed, the information provided by data for a specific task may serve as a domain-specific inductive bias for the others
Combining datasets to solve multiple learning tasks is an approach known in the machine learning literature as  multi-task learning  or  learning to learn   CITATION
In this context, the analysis of the  inductive transfer  process and the investigation of general methodologies for the simultaneous learning of multiple tasks are important topics of research
Many theoretical and experimental results support the intuition that, when relationships exist between the tasks, simultaneous learning performs better than separate (single-task) learning  CITATION
Theoretical results include the extension to the multi-task setting of generalization bounds and the notion of VC-dimension  CITATION  and a methodology for learning multiple tasks exploiting unlabeled data (the so-called semi-supervised setting)  CITATION
Importance of combining datasets is especially evident in biomedicine
In pharmacological experiments, few training examples are typically available for a specific subject due to technological and ethical constraints  CITATION
This makes hard to formulate and quantify models from experimental data
To obviate this problem, the so-called  population method  has been studied and applied with success since the seventies in pharmacology  CITATION
Population methods are based on the knowledge that subjects, albeit different, belong to a population of similar individuals, so that data collected in one subject may be informative with respect to the others  CITATION
Such population approaches belongs to the family of so-called  mixed-effect  statistical methods
In these methods, clinical measurements from different subjects are combined to simultaneously learn individual features of physiological responses to drug administration  CITATION
Population methods have been applied with success also in other biomedical contexts such as medical imaging and bioinformatics  CITATION
Classical approaches postulate finite-dimensional nonlinear dynamical systems whose unknown parameters can be determined by means of optimization algorithms  CITATION
Other strategies include Bayesian estimation with stochastic simulation  CITATION  and nonparametric population methods  CITATION
Information fusion from different but related datasets is widespread also in econometrics and marketing analysis, where the goal is to learn user preferences by analyzing both user-specific information and information from related users, see eg CITATION
The so-called  conjoint analysis  aims to determine the features of a product that mostly influence customer's decisions
In the web, collaborative approaches to estimate user preferences have become standard methodologies in many commercial systems and social networks, under the name of  collaborative filtering  or  recommender systems , see eg CITATION
Pioneering collaborative filtering systems include Tapestry  CITATION , GroupLens  CITATION , ReferralWeb  CITATION , PHOAKS  CITATION
More recently, the collaborative filtering problem has been attacked with machine learning methodologies such as Bayesian networks  CITATION , MCMC algorithms  CITATION , mixture models  CITATION , dependency networks  CITATION , maximum margin matrix factorization  CITATION
Coming back to the machine learning literature, in the single-task context much attention has been given in the last years to non-parametric techniques such as kernel methods  CITATION  and Gaussian processes  CITATION
These approaches are powerful and theoretically sound, having their mathematical foundations in regularization theory for inverse problems, statistical learning theory and Bayesian estimation  CITATION
The flexibility of kernel engineering allows for the estimation of functions defined on generic sets from arbitrary sources of data
These methodologies have been recently extended to the multi-task setting
In  CITATION , a general framework to solve multi-task learning problems using kernel methods and regularization has been proposed, relying on the theory of reproducing kernel Hilbert spaces (RKHS) of vector-valued functions  CITATION
In many applications (e-commerce, social network data processing, recommender systems), real-time processing of examples is required
On-line multi-task learning schemes find their natural application in data mining problems involving very large datasets, and are therefore required to scale well with the number of tasks and examples
In  CITATION , an on-line task-wise algorithm to solve multi-task regression problems has been proposed
The learning problem is formulated in the context of on-line Bayesian estimation, see eg CITATION , within which Gaussian processes with suitable covariance functions are used to characterize a non-parametric mixed-effect model
One of the key features of the algorithm is the capability to exploit shared inputs between the tasks in order to reduce computational complexity
However, the algorithm in  CITATION  has a centralized structure in which tasks are sequentially analyzed, and is not able to address neither architectural issues regarding the flux of information nor privacy protection
In this paper, multi-task learning from distributed datasets is addressed using a client-server architecture
In our scheme, clients are in a one-to-one correspondence with tasks and their individual database of examples
The role of the server is to collect examples from different clients in order to summarize their informative content
When a new example associated with any task becomes available, the server executes an on-line update algorithm
While in  CITATION  different tasks are sequentially analyzed, the architecture presented in this paper can process examples coming in any order from different learning tasks
The summarized information is stored in a  disclosed database  whose content is available for download enabling each client to compute its own estimate exploiting the informative content of all the other datasets
Particular attention is paid to confidentiality issues, especially valuable in commercial and recommender systems, see eg CITATION
First, we require that each specific client cannot access other clients data
In addition, individual datasets cannot be reconstructed from the disclosed database
Two kind of clients are considered:  active  and  passive  ones
An active client sends its data to the server, thus contributing to the collaborative estimate
A passive client only downloads information from the disclosed database without sending its data
A regularization problem with a parametric bias term is considered in which a  mixed-effect kernel  is used to exploit relationships between the tasks
Albeit specific, the mixed-effect non-parametric model is quite flexible, and its usefulness has been demonstrated in several works  CITATION
The paper is organized as follows
Multi-task learning with regularized kernel methods is presented in section , in which a class of mixed-effect kernels is also introduced
In section , an efficient centralized off-line algorithm for multi-task learning is described that solves the regularization problem of section
In section , a rather general client-server architecture is described, which is able to efficiently solve online multi-task learning from distributed datasets
The server-side algorithm is derived and discussed in subsection , while the client-side algorithm for both active and passive clients is derived in subsection
In section , a simulated music recommendation system is employed to test performances of our algorithm
Conclusions (section ) end the paper
The Appendix contains technical lemmas and proofs
### abstract ###
Many AI researchers and cognitive scientists have argued that analogy is the core of cognition
The most influential work on computational modeling of analogy-making is Structure Mapping Theory (SMT) and its implementation in the Structure Mapping Engine (SME)
A limitation of SME is the requirement for complex hand-coded representations
We introduce the Latent Relation Mapping Engine (LRME), which combines ideas from SME and Latent Relational Analysis (LRA) in order to remove the requirement for hand-coded representations
LRME builds analogical mappings between lists of words, using a large corpus of raw text to automatically discover the semantic relations among the words
We evaluate LRME on a set of twenty analogical mapping problems, ten based on scientific analogies and ten based on common metaphors
LRME achieves human-level performance on the twenty problems
We compare LRME with a variety of alternative approaches and find that they are not able to reach the same level of performance
### introduction ###
When we are faced with a problem, we try to recall similar problems that we have faced in the past, so that we can transfer our knowledge from past experience to the current problem
We make an analogy between the past situation and the current situation, and we use the analogy to transfer knowledge \shortcite{gentner83,minsky86,holyoak95,hofstadter01,hawkins04}
In his survey of the computational modeling of analogy-making, French  CITATION  cites Structure Mapping Theory (SMT) \shortcite{gentner83} and its implementation in the Structure Mapping Engine (SME)  CITATION  as the most influential work on modeling of analogy-making
In SME, an analogical mapping  SYMBOL  is from a source  SYMBOL  to a target  SYMBOL
The source is more familiar, more known, or more concrete, whereas the target is relatively unfamiliar, unknown, or abstract
The analogical mapping is used to transfer knowledge from the source to the target
Gentner  CITATION  argues that there are two kinds of similarity, attributional similarity and relational similarity
The distinction between attributes and relations may be understood in terms of predicate logic
An attribute is a predicate with one argument, such as {large}( SYMBOL ), meaning  SYMBOL  is large
A relation is a predicate with two or more arguments, such as {collides\_with}( SYMBOL ), meaning  SYMBOL  collides with  SYMBOL
The Structure Mapping Engine prefers mappings based on relational similarity over mappings based on attributional similarity \shortcite{falkenhainer89}
For example, SME is able to build a mapping from a representation of the solar system (the source) to a representation of the Rutherford-Bohr model of the atom (the target)
The sun is mapped to the nucleus, planets are mapped to electrons, and mass is mapped to charge
Note that this mapping emphasizes relational similarity
The sun and the nucleus are very different in terms of their attributes: the sun is very large and the nucleus is very small
Likewise, planets and electrons have little attributional similarity
On the other hand, planets revolve around the sun like electrons revolve around the nucleus
The mass of the sun attracts the mass of the planets like the charge of the nucleus attracts the charge of the electrons
Gentner  CITATION  provides evidence that children rely primarily on attributional similarity for mapping, gradually switching over to relational similarity as they mature
She uses the terms  mere appearance  to refer to mapping based mostly on attributional similarity,  analogy  to refer to mapping based mostly on relational similarity, and  literal similarity  to refer to a mixture of attributional and relational similarity
Since we use analogical mappings to solve problems and make predictions, we should focus on structure, especially causal relations, and look beyond the surface attributes of things \shortcite{gentner83}
The analogy between the solar system and the Rutherford-Bohr model of the atom illustrates the importance of going beyond mere appearance, to the underlying structures
Figures  and  show the LISP representations used by SME as input for the analogy between the solar system and the atom \shortcite{falkenhainer89}
Chalmers, French, and Hofstadter  CITATION  criticize SME's requirement for complex hand-coded representations
They argue that most of the hard work is done by the human who creates these high-level hand-coded representations, rather than by SME }  }  Gentner, Forbus, and their colleagues have attempted to avoid hand-coding in their recent work with SME
The CogSketch system can generate LISP representations from simple sketches  CITATION
The Gizmo system can generate LISP representations from qualitative physics models  CITATION
The Learning Reader system can generate LISP representations from natural language text \shortcite{forbus07}
These systems do not require LISP input
However, the CogSketch user interface requires the person who draws the sketch to identify the basic components in the sketch and hand-label them with terms from a knowledge base derived from OpenCyc
Forbus et al CITATION  note that OpenCyc contains more than 58,000 hand-coded concepts, and they have added further hand-coded concepts to OpenCyc, in order to support CogSketch
The Gizmo system requires the user to hand-code a physical model, using the methods of qualitative physics \shortcite{yan05}
Learning Reader uses more than 28,000 phrasal patterns, which were derived from ResearchCyc \shortcite{forbus07}
It is evident that SME still requires substantial hand-coded knowledge
The work we present in this paper is an effort to avoid complex hand-coded representations
Our approach is to combine ideas from SME \shortcite{falkenhainer89} and Latent Relational Analysis (LRA) \shortcite{turney06}
We call the resulting algorithm the Latent Relation Mapping Engine (LRME)
We represent the semantic relation between two terms using a vector, in which the elements are derived from pattern frequencies in a large corpus of raw text
Because the semantic relations are automatically derived from a corpus, LRME does not require hand-coded representations of relations
It only needs a list of terms from the source and a list of terms from the target
Given these two lists, LRME uses the corpus to build representations of the relations among the terms, and then it constructs a mapping between the two lists
Tables  and  show the input and output of LRME for the analogy between the solar system and the Ruther\-ford-Bohr model of the atom
Although some human effort is involved in constructing the input lists, it is considerably less effort than SME requires for its input (contrast Figures  and  with Table~) }  }  Scientific analogies, such as the analogy between the solar system and the Rutherford-Bohr model of the atom, may seem esoteric, but we believe analogy-making is ubiquitous in our daily lives
A potential practical application for this work is the task of identifying semantic roles \shortcite{gildea02}
Since roles are relations, not attributes, it is appropriate to treat semantic role labeling as an analogical mapping problem
For example, the {Judgement} semantic frame contains semantic roles such as {judge}, {evaluee}, and {reason}, and the {Statement} frame contains roles such as {speaker}, {addressee}, {message}, {topic}, and {medium} \shortcite{gildea02}
The task of identifying semantic roles is to automatically label sentences with their roles, as in the following examples \shortcite{gildea02}:     If we have a training set of labeled sentences and a testing set of unlabeled sentences, then we may view the task of labeling the testing sentences as a problem of creating analogical mappings between the training sentences (sources) and the testing sentences (targets)
Table~ shows how ``She blames the Government for failing to do enough to help
'' might be mapped to ``They blame the company for polluting the environment
'' Once a mapping has been found, we can transfer knowledge, in the form of semantic role labels, from the source to the target }  In Section~, we briefly discuss the hypotheses behind the design of LRME
We then precisely define the task that is performed by LRME, a specific form of analogical mapping, in Section~
LRME builds on Latent Relational Analysis (LRA), hence we summarize LRA in Section~
We discuss potential applications of LRME in Section~
To evaluate LRME, we created twenty analogical mapping problems, ten science analogy problems \shortcite{holyoak95} and ten common metaphor problems \shortcite{lakoff80}
Table~ is one of the science analogy problems
Our intended solution is given in Table~
To validate our intended solutions, we gave our colleagues the lists of terms (as in Table~) and asked them to generate mappings between the lists
Section~ presents the results of this experiment
Across the twenty problems, the average agreement with our intended solutions (as in Table~) was 87 6\%
The LRME algorithm is outlined in Section~, along with its evaluation on the twenty mapping problems
LRME achieves an accuracy of 91 5\%
The difference between this performance and the human average of 87 6\% is not statistically significant
Section~ examines a variety of alternative approaches to the analogy mapping task
The best approach achieves an accuracy of 76 8\%, but this approach requires hand-coded part-of-speech tags
This performance is significantly below LRME and human performance
In Section~, we discuss some questions that are raised by the results in the preceding sections
Related work is described in Section~, future work and limitations are considered in Section~, and we conclude in Section~
### abstract ###
General purpose intelligent learning agents cycle through (complex,non-MDP) sequences of observations, actions, and rewards
On the other hand, reinforcement learning is well-developed for small finite state Markov Decision Processes (MDPs)
So far it is an art performed by human designers to extract the right state representation out of the bare observations, ie \ to reduce the agent setup to the MDP framework
Before we can think of mechanizing this search for suitable MDPs, we need a formal objective criterion
The main contribution of this article is to develop such a criterion
I also integrate the various parts into one learning algorithm
Extensions to more realistic dynamic Bayesian networks are developed in the companion article  CITATION  {Keywords:} evolutionary algorithms, ranking selection, tournament selection, equivalence, efficiency
### introduction ###
Artificial General Intelligence (AGI) is concerned with designing agents that perform well in a wide range of environments  CITATION
Among the well-established ``narrow'' AI approaches, arguably Reinforcement Learning (RL) pursues most directly the same goal
RL considers the general agent-environment setup in which an agent interacts with an environment (acts and observes in cycles) and receives (occasional) rewards
The agent's objective is to collect as much reward as possible
Most if not all AI problems can be formulated in this framework
The simplest interesting environmental class consists of finite state fully observable Markov Decision Processes (MDPs)  CITATION , which is reasonably well understood
Extensions to continuous states with (non)linear function approximation  CITATION , partial observability (POMDP)  CITATION , structured MDPs (DBNs)  CITATION , and others have been considered, but the algorithms are much more brittle
In any case, a lot of work is still left to the designer, namely to extract the right state representation (``features'') out of the bare observations
Even if  potentially  useful representations have been found, it is usually not clear which one will turn out to be better, except in situations where we already know a perfect model
Think of a mobile robot equipped with a camera plunged into an unknown environment
While we can imagine which image features are potentially useful, we cannot know which ones will actually be useful
Before we can think of mechanically searching for the ``best'' MDP representation, we need a formal objective criterion
Obviously, at any point in time, if we want the criterion to be effective it can only depend on the agents past experience
The main contribution of this article is to develop such a criterion
Reality is a non-ergodic partially observable uncertain unknown environment in which acquiring experience can be expensive
So we want/need to exploit the data (past experience) at hand optimally, cannot generate virtual samples since the model is not given (need to be learned itself), and there is no reset-option
In regression and classification, penalized maximum likelihood criteria  CITATION  have successfully been used for semi-parametric model selection
It is far from obvious how to apply them in RL
Ultimately we do not care about the observations but the rewards
The rewards depend on the states, but the states are arbitrary in the sense that they are model-dependent functions of the data
Indeed, our derived Cost function cannot be interpreted as a usual model+data code length
As partly detailed later, the suggested  SYMBOL MDP model could be regarded % as a scaled-down practical instantiation of AIXI  CITATION , % as a way to side-step the open problem of learning POMDPs, % as extending the idea of state-aggregation from planning (based on bi-simulation metrics  CITATION ) to RL (based on code length), % as generalizing U-Tree  CITATION  to arbitrary features, % or as an alternative to PSRs  CITATION  for which proper learning algorithms have yet to be developed
%   Throughout this article,  SYMBOL  denotes the binary logarithm, %  SYMBOL  the empty string, % and  SYMBOL  if  SYMBOL  and  SYMBOL  else is the Kronecker symbol
% I generally omit separating commas if no confusion arises, in particular in indices
For any  SYMBOL  of suitable type (string,vector,set), I define string  SYMBOL , % sum  SYMBOL , union  SYMBOL , and vector  SYMBOL , % where  SYMBOL  ranges over the full range  SYMBOL  and  SYMBOL  is the length or dimension or size of  SYMBOL
%  SYMBOL  denotes an estimate of  SYMBOL
SYMBOL  denotes a probability over states and rewards or parts thereof
I do not distinguish between random variables  SYMBOL  and realizations  SYMBOL , and abbreviation  SYMBOL  never leads to confusion
More specifically,  SYMBOL  denotes the number of states, %  SYMBOL  any state index, %  SYMBOL  the current time, % and  SYMBOL  any time
% Further, in order not to get distracted at several places I gloss over initial conditions or special cases where inessential
Also 0 SYMBOL undefined=0 SYMBOL infinity:=0
### abstract ###
Feature Markov Decision Processes ( SYMBOL MDPs)  CITATION  are well-suited for learning agents in general environments
Nevertheless, unstructured ( SYMBOL )MDPs are limited to relatively simple environments
Structured MDPs like Dynamic Bayesian Networks (DBNs) are used for large-scale real-world problems
In this article I extend  SYMBOL MDP to  SYMBOL DBN
The primary contribution is to derive a cost criterion that allows to automatically extract the most relevant features from the environment, leading to the ``best'' DBN representation
I discuss all building blocks required for a complete general learning algorithm
Keywords:  Reinforcement learning; dynamic Bayesian network; structure learning; feature learning; global vs local reward; explore-exploit
### introduction ###
The agent-environment setup in which an  Agent  interacts with an  Environment  is a very general and prevalent framework for studying intelligent learning systems  CITATION
In cycles  SYMBOL , the environment provides a (regular)  observation   SYMBOL  (e g \ a camera image) to the agent; then the agent chooses an  action   SYMBOL  (e g \ a limb movement); finally the environment provides a real-valued  reward   SYMBOL  to the agent
The reward may be very scarce, eg \ just +1 (-1) for winning (losing) a chess game, and 0 at all other times  CITATION
Then the next cycle  SYMBOL  starts
The agent's objective is to maximize his reward
For example,  sequence prediction  is concerned with environments that do not react to the agents actions (e g \ a weather-forecasting ``action'')  CITATION ,  planning  deals with the case where the environmental function is known  CITATION ,  classification  and  regression  is for conditionally independent observations  CITATION ,  Markov Decision Processes  (MDPs) assume that  SYMBOL  and  SYMBOL  only depend on  SYMBOL  and  SYMBOL   CITATION , POMDPs deal with  Partially Observable MDPs   CITATION , and  Dynamic Bayesian Networks  (DBNs) with structured MDPs  CITATION
Concrete real-world problems can often be  modeled  as MDPs
For this purpose, a  designer  extracts relevant features from the history (e g \ position and velocity of all objects), i e \ the  history   SYMBOL  is summarized by a  feature  vector  SYMBOL
The feature vectors are regarded as  states  of an MDP and are assumed to be (approximately) Markov
Artificial General Intelligence (AGI)  CITATION  is concerned with designing  agents that perform well in a very large range of environments   CITATION , including all of the mentioned ones above and more
In this general situation, it is not a priori clear what the useful features are
Indeed, any observation in the (far) past may be relevant in the future
A solution suggested in  CITATION  is to learn  SYMBOL  itself
If  SYMBOL  keeps too much of the history (e g \  SYMBOL ), the resulting MDP is too large (infinite) and cannot be learned
If  SYMBOL  keeps too little, the resulting state sequence is not Markov
The  Cost  criterion I develop formalizes this tradeoff and is minimized for the ``best''  SYMBOL
At any time  SYMBOL , the best  SYMBOL  is the one that minimizes the Markov code length of  SYMBOL  and  SYMBOL
This reminds but is actually quite different from MDL, which minimizes model+data code length  CITATION
The use of ``unstructured'' MDPs  CITATION , even our  SYMBOL -optimal ones, is clearly limited to relatively simple tasks
Real-world problems are structured and can often be represented by dynamic Bayesian networks (DBNs) with a reasonable number of nodes  CITATION
Bayesian networks in general and DBNs in particular are powerful tools for modeling and solving complex real-world problems
Advances in theory and increase in computation power constantly broaden their range of applicability  CITATION
The primary contribution of this work is to extend the   SYMBOL  selection principle  developed in  CITATION  for MDPs to the conceptually much more demanding DBN case
The major extra complications are approximating, learning and coding the rewards, the dependence of the Cost criterion on the DBN structure, learning the DBN structure, and how to store and find the optimal value function and policy
Although this article is self-contained, it is recommended to read  CITATION  first
### abstract ###
A fundamental problem in artificial intelligence is that nobody really knows what intelligence is
The problem is especially acute when we need to consider artificial systems which are significantly different to humans
In this paper we approach this problem in the following way: We take a number of well known informal definitions of human intelligence that have been given by experts, and extract their essential features
These are then mathematically formalised to produce a general measure of intelligence for arbitrary machines
We believe that this measure formally captures the concept of machine intelligence in the broadest reasonable sense
### introduction ###
Most of us think that we recognise intelligence when we see it, but we are not really sure how to precisely define or measure it
We informally judge the intelligence of others by relying on our past experiences in dealing with people
Naturally, this naive approach is highly subjective and imprecise
A more principled approach would be to use one of the many standard intelligence tests that are available
Contrary to popular wisdom, these tests, when correctly applied by a professional, deliver statistically consistent results and have considerable power to predict the future performance of individuals in many mentally demanding tasks
However, while these tests work well for humans, if we wish to measure the intelligence of other things, perhaps of a monkey or a new machine learning algorithm, they are clearly inappropriate
One response to this problem might be to develop specific kinds of tests for specific kinds of entities; just as intelligence tests for children differ to intelligence tests for adults
While this works well when testing humans of different ages, it comes undone when we need to measure the intelligence of entities which are profoundly different to each other in terms of their cognitive capacities, speed, senses, environments in which they operate, and so on
To measure the intelligence of such diverse systems in a meaningful way we must step back from the specifics of particular systems and establish the underlying fundamentals of what it is that we are really trying to measure
That is, we need to establish a notion of intelligence that goes beyond the specifics of particular kinds of systems
The difficulty of doing this is readily apparent
Consider, for example, the memory and numerical computation tasks that appear in some intelligence tests and which were once regarded as defining hallmarks of human intelligence
We now know that these tasks are absolutely trivial for a machine and thus do not test the machine's intelligence
Indeed even the mentally demanding task of playing chess has been largely reduced to brute force search
As technology advances, our concept of what intelligence is continues to evolve with it
How then are we to develop a concept of intelligence that is applicable to all kinds of systems
Any proposed definition must encompass the essence of human intelligence, as well as other possibilities, in a consistent way
It should not be limited to any particular set of senses, environments or goals, nor should it be limited to any specific kind of hardware, such as silicon or biological neurons
It should be based on principles which are sufficiently fundamental so as to be unlikely to alter over time
Furthermore, the intelligence measure should ideally be formally expressed, objective, and practically realisable
This paper approaches this problem in the following way
In  Section  we consider a range of definitions of human intelligence that have been put forward by well known psychologists
From these we extract the most common and essential features and use them to create an informal definition of intelligence
Section  then introduces the framework which we use to construct our formal measure of intelligence
This framework is formally defined in  Section
In  Section  we use our developed formalism to produce a formal definition of intelligence
Section  closes with a short summary
A preliminary sketch of the ideas in this paper appeared in the poster  CITATION
It can be shown that the intelligence measure presented here is in fact a variant of the Intelligence Order Relation that appears in the theory of AIXI, the provably optimal universal agent  CITATION
A long journal version of this paper is being written in which we give the proposed measure of machine intelligence and its relation to other such tests a much more comprehensive treatment
Naturally, we expect such a bold initiative to be met with resistance
However, we hope that the reader will appreciate the value of our approach: With a formally precise definition put forward we aim to better our understanding of what is a notoriously subjective and slippery concept
### abstract ###
This paper introduces a model based upon games on an evolving network, and develops three clustering algorithms according to it
In the clustering algorithms, data points for clustering are regarded as players who can make decisions in games
On the network describing relationships among data points, an edge-removing-and-rewiring (ERR) function is employed to explore in a neighborhood of a data point, which removes edges connecting to neighbors with small payoffs, and creates new edges to neighbors with larger payoffs
As such, the connections among data points vary over time
During the evolution of network, some strategies are spread in the network
As a consequence, clusters are formed automatically, in which data points with the same evolutionarily stable strategy are collected as a cluster, so the number of evolutionarily stable strategies indicates the number of clusters
Moreover, the experimental results have demonstrated that data points in datasets are clustered reasonably and efficiently, and the comparison with other algorithms also provides an indication of the effectiveness of the proposed algorithms \\ \\  Keywords : Unsupervised learning, data clustering, evolutionary game theory, evolutionarily stable strategy
### introduction ###
Cluster analysis is an important branch of Pattern Recognition, which is widely used in many fields such as pattern analysis, data mining, information retrieval and image segmentation
For the past thirty years, many excellent clustering algorithms have been presented, say,  K -means  CITATION , C4 5~ CITATION , support vector clustering (SVC)  CITATION , spectral clustering~ CITATION , etc , in which the data points for clustering are fixed, and various functions are designed to find separating hyperplanes
In recent years, however, a significant change has been made
Some researchers thought about that why not those data points could move by themselves, just like agents or something, and collect together automatically
Therefore, following their ideas, they created a few exciting algorithms  CITATION , in which data points move in space according to certain simple local rules preset in advance
Game theory came into being with the book named "Theory of Games and Economic Behavior" by John von Neumann and Oskar Morgenstern  CITATION  in 1940
In this period, Cooperative Game was widely studied
Till 1950's, John Nash published two well-known papers to present the theory of non-cooperative game, in which he proposed the concept of Nash equilibrium, and proved the existence of equilibrium in a finite non-cooperative game  CITATION
Although non-cooperative game was established on the rigorous mathematics, it required that players in a game must be perfect rational or even hyper-rational
If this assumption could not hold, the Nash equilibrium might not be reached sometimes
On the other hand, evolutionary game theory  CITATION  stems from the researches in biology which are to analyze the conflict and cooperation between animals or plants
It differs from classical game theory by focusing on the dynamics of strategy change more than the properties of strategy equilibria, and does not require perfect rational players
Besides, an important concept, evolutionarily stable strategy  CITATION , in evolutionary game theory was defined and introduced by John Maynard Smith and George R
Price in 1973, which was often used to explain the evolution of social behavior in animals
To the best of our knowledge, the problem of data clustering has not been investigated based on evolutionary game theory
So, if data points in a dataset are considered as players in games, could clusters be formed automatically by playing games among them
This is the question that we attempt to answer
In our clustering algorithm, each player hopes to maximize his own payoff, so he constantly adjusts his strategies by observing neighbors' payoffs
In the course of strategies evolving, some strategies are spread in the network of players
Finally, some parts will be formed automatically in each of which the same strategy is used
According to different strategies played, data points in the dataset can be naturally collected as several different clusters
The remainder of this paper is organized as follows: Section 2 introduces some basic concepts and methods about the evolutionary game theory and evolutionary game on graph
In Section 3, the model based upon games on evolving network is proposed and described specifically
Section 4 gives three algorithms based on this model, and the algorithms are elaborated and analyzed in detail
Section 5 introduces those datasets used in the experiments briefly, and then demonstrates experimental results of the algorithms
Further, the relationship between the number of clusters and the number of nearest neighbors is discussed, and three edge-removing-and-rewiring (ERR) functions employed in the clustering algorithms are compared
The conclusion is given in Section 6
### abstract ###
Cooperative decision making is a vision of future network management and control
Distributed connection preemption is an important example where nodes can make intelligent decisions on allocating resources and controlling traffic flows for multi-class service networks
A challenge is that nodal decisions are spatially dependent as traffic flows trespass multiple nodes in a network
Hence the performance-complexity trade-off becomes important, ie , how accurate decisions are versus how much information is exchanged among nodes
Connection preemption is known to be NP-complete
Centralized preemption is optimal but computationally intractable
Decentralized preemption is computationally efficient but may result in a poor performance
This work investigates distributed preemption where nodes decide whether and which flows to preempt using only local information exchange with neighbors
In this work, we first model a large number of distributed preemption-decisions using a probabilistic graphical model
We then define the near-optimality of distributed preemption as its approximation to the optimal centralized preemption within a given error bound
We show that a sufficient condition for distributed preemption to be optimal is that local decisions should constitute a Markov Random Field
The decision variables, however, do not possess an exact spatial Markov dependence in reality due to the flows passing through multiple links
Hence we study traffic patterns of flows, and derive sufficient conditions on flows for the distributed preemption to be near-optimal
We develop, based on the probabilistic graphical models, a near-optimal distributed algorithm
The algorithm is used by each node to make collectively near-optimal preemption decisions
We study trade-offs between near-optimal performance and complexity that corresponds to the amount of information-exchange of the distributed algorithm
The algorithm is validated by both analysis and simulation
### introduction ###
A vision of future network management is to involve nodes to make intelligent decisions on allocating resources and controlling traffic flows
This includes admitting new flows by preempting less important existing flows, which is well studied in the policy based admission control (i e ,  admission is based on the priority of flows)  CITATION   CITATION
Specifically, preemption is defined  at a prioritized multi-class network, where a new call needs  to be set up with a high priority between a source (S) and a destination  (D)  CITATION   CITATION   CITATION   CITATION   CITATION
When the capacity is insufficient at all feasible routes between the source-destination (S-D) pair, some existing flows of the lower priorities need to be forced to reduce their bandwidth, move to the lowest service class (e g , best-effort-service), or simply preempted to accommodate the new call
Preemption decisions is to decide which lower priority flows to remove to free the reserved bandwidth for the new call at a chosen route  CITATION   CITATION
The goal is to decide whether to preempt an active flow so that the total preempted bandwidth can be minimal under such constraints as bandwidth demand of a new call and available free bandwidth at each link  \\   The benefit of preemption has been described in the prior works
For example, preemption allows a new high-priority connection to access heavily crowded core networks, eg , multi-protocol label switched (MPLS) networks  CITATION
Connection preemption also improves resource utilization by allowing low-priority flows to access unused bandwidths  CITATION   CITATION
Preemption sees potential applications in emerging networks
For example, in 802 11e Wireless LAN, delay sensitive IP packets in expedited forwarding (EF) class can be served earlier than the best-effort packets through preemption  CITATION
Multi-level preemption and precedence (MLPP) is proposed to classify calls by their importance, which can be used for military as well as commercial networks  CITATION  \\  There are two significant challenges for preemption which are performance and complexity
Performance corresponds to whether right flows are preempted to result in the minimal bandwidth to accommodate a new flow
Complexity corresponds to the amount of information needed for preemption decision
Preemption is known to be NP-complete  CITATION
The complexity results from a large number of active flows supported by a core network for which preemption decisions need to be made
For example, for a 1Gbps link, if the bandwidth of each flow is in the order of Kbps, there would be thousands of flows supported per link
In addition, a flow generally passes through multiple nodes, making preemption decisions among nodes dependent and thus difficult to be done with local information
Thus preemption is network-centric, and may require a huge amount of information to perform in a large network \\  For centralized preemption decisions, a centralized node maintains the routed-path information of active flows, their priorities and bandwidth occupancies at the entire route
The centralized node then decides which active flows to preempt upon the request of a new call
Therefore, centralized preemption can always be optimal, resulting in minimal preempted bandwidth
But the amount of management information needed can be overwhelming at the centralized node
For example, let  SYMBOL  be the total number of distinct flows per priority class at the route of a new call
Each flow has two states, preempted or not preempted
The total number of possible states is  SYMBOL  for making a centralized decision
When  SYMBOL  is in the order of hundreds or thousands  CITATION , centralized preemption becomes computationally intractable
Decentralized preemption is then adopted for reducing the amount of management information  CITATION  \\ Decentralized preemption is done at each node individually, and thus requires a node to maintain its local information, i e , active flows at the adjacent links, their priorities and bandwidth occupancy
Such information is available locally at nodes
A node then decides, independently from the other nodes, which connections to preempt
This, however, may cause conflicting local decisions on the same flows that pass multiple links on the route, resulting in more preempted bandwidth than necessary
In other words, decentralized preemption decision neglects the spatial dependence for the flows across multiple links, and may perform poorly
But the amount of management information are greatly reduced compared with centralized preemption
For example, let  SYMBOL  be the maximum number of active flows per link
The total number of states is  SYMBOL  at each link
Since  SYMBOL   SYMBOL   SYMBOL , compared with centralized preemption, decentralized schemes have a much smaller search space for preemption decisions
Therefore, most algorithms in the literature focus on decentralized preemption (see  CITATION   CITATION  and references there in) \\ This work studies distributed decisions, that take into account spatial dependence among neighboring links through local information exchange
In fact, distributed preemption can be considered as a generalization of centralized and decentralized preemption
Centralized preemption corresponds to one extreme case of distributed preemption that an entire route is  the neighborhood for information exchange; whereas, decentralized decisions correspond to another extreme case where the neighborhood size is zero
Therefore, the communication complexity can be characterized in terms of neighborhood size
There is a trade-off between the optimality and the complexity \\  In general, it has been shown to be a difficult problem to develop a distributed algorithm whose performance is predictable and within a tolerable degradation (i e , given error bound) from that of the optimal scheme  CITATION
Hence, the open issues are: (a)  When  can distributed decisions collectively result in a near-optimal global preemption (b)  How  to model a large number of dependent decision variables and to obtain near-optimal local decisions using distributed algorithms
We apply machine learning to study these issues \\  {Machine learning perspective:} A machine learning view of distributed preemption is that individual nodes ``learn to make decisions" collectively and iteratively
Ideally, if each node has complete information on all active flows at the route of a new flow, the node will be able to make correct decisions on which flows to preempt
However, at any given time, a node has only partial information on the active flows on the route and its neighbors' decisions on the flows to preempt
But a node can adapt, i e , learn to make decisions based on those of its neighbors'
As neighbors learn from neighbors' neighbors, a node would indirectly learn what farther nodes decide only with a delay
Eventually, all nodes would make local decisions, collectively resulting in a near-optimal preemption at the entire route \\  How would machine learning benefit distributed preemption
The problem of collective learning and decision-making has been a keen interest in machine learning and adaptive control  CITATION   CITATION , but has just begun to see applications in networking
In particular,  CITATION  proposes using Markov Random Fields as a general model of decision-making in Ad hoc wireless networks
The model is then applied to routing in wireless networks
Our prior work   CITATION   CITATION  obtain probabilistic graphical models for ad hoc wireless and wireline networks starting from network properties  CITATION  CITATION , and the resulting probabilistic models turn out to be multi-layer
This work focuses on distributed decisions on network flows
We view machine learning as a framework in which a large number of decision variables can be treated jointly
Spatial dependence among these variables poses a key challenge to preemption, is an origin of high communication complexity,  and has not been dealt with sufficiently in prior works
Machine learning provides feasible approaches for this problem as summarized below \\ (a)  Global model of distributed preemption decisions:  We first develop a probabilistic model that represents explicitly the spatial dependence of distributed preemption decisions over a pre-determined preempting route of a new flow
The randomness results from randomly arriving/departing active flows and their locations
The preemption decisions made on flows at each node are also random due to incomplete and inaccurate local information for distributed  preemption
We first obtain a cost function for preemption as a ``Hamiltonian" (or ``system potential energy")  CITATION
A Hamiltonian combines local preemption decisions and constraints into a single quantity
The constraints include link capacity, unused bandwidths and bandwidth-demand of a new flow at each link
The Hamiltonian is then used to obtain a spatial probabilistic model as a Gibbs distribution  CITATION  \\ (b)  Markov Random Field (MRF) and sufficient conditions:   Spatial dependence can be characterized through a probabilistic dependency graph of graphical models  CITATION  CITATION  CITATION  in machine learning
A probabilistic dependency graph provides a simple yet explicit representation of the spatial dependence among random variables
We show that if the dependence of decision variables is spatially Markovian, a globally optimal preemption decision can be obtained collectively by iterative local decisions through information exchange only with neighboring nodes
Such a probabilistic model is known as a Markov Random Field  CITATION
In general, distributed decisions may not be spatially Markov, since the spatial dependence is caused by flows across multiple links
Hence we identify traffic patterns of active flows that result in approximately spatial Markov dependence
We then define the near-optimality of distributed decisions as the difference between the centralized and distributed decisions, measured in the Hamiltonian, and obtain sufficient conditions for the difference to reside within an error bound \\ (c)  Distributed Decision Algorithm:  A near-optimal distributed algorithm is derived based on the Markov Random Field
The algorithms can be implemented through either message passing  CITATION  or Gibbs sampling  CITATION  \\ (d)  Trade-offs:  A challenging issue is the performance-complexity trade-off, i e , ``when" and ``how" distributed preemption can achieve  a near-optimal performance with a moderate complexity
Here the  performance  measures the optimality of distributed preemption decision relative to that of the centralized optimal decision
The communication complexity of distributed preemption can be characterized by the amount of information used in distributed decision making
Distributed decisions reduce complexity using information exchange only with neighbors, but may deviate from the optimal performance
Hence we study performance and complexity trade-off through both analysis and simulation \\ The rest of this paper is organized as follows
Section  provides a problem formulation on connection preemption
Section  develops a probabilistic spatial model of distributed preemption, utilizing the graphical models in machine learning and interpreting the derived model in terms of optimality and complexity
Section  proposes a distributed preemption algorithm based on the derived model, using probabilistic inference
Section  analyzes the performance of distributed preemption
Section  validates the performance of distributed preemption through simulation
Section  provides a further literature review and discussions
Section  concludes the paper
### abstract ###
The emergence of low-cost sensor architectures for diverse modalities has made it possible to deploy sensor arrays that capture a single event from a large number of vantage points and using multiple modalities
In many scenarios, these sensors acquire very high-dimensional data such as audio signals, images, and video
To cope with such high-dimensional data, we typically rely on low-dimensional models
Manifold models provide a particularly powerful model that captures the structure of high-dimensional data when it is governed by a low-dimensional set of parameters
However, these models do not typically take into account dependencies among multiple sensors
We thus propose a new  joint manifold  framework for data ensembles that exploits such dependencies
We show that simple algorithms can exploit the joint manifold structure to improve their performance on standard signal processing applications
Additionally, recent results concerning dimensionality reduction for manifolds enable us to formulate a network-scalable data compression scheme that uses random projections of the sensed data
This scheme efficiently fuses the data from all sensors through the addition of such projections, regardless of the data modalities and dimensions
### introduction ###
The geometric notion of a low-dimensional manifold is a common, yet powerful, tool for modeling high-dimensional data
Manifold models arise in cases where ( i ) a  SYMBOL -dimensional parameter  SYMBOL  can be identified that carries the relevant information about a signal and ( ii ) the signal  SYMBOL  changes as a continuous (typically nonlinear) function of these parameters
Some typical examples include a one-dimensional (1-D) signal shifted by an unknown time delay (parameterized by the translation variable), a recording of a speech signal (parameterized by the underlying phonemes spoken by the speaker), and an image of a 3-D object at an unknown location captured from an unknown viewing angle (parameterized by the 3-D coordinates of the object and its roll, pitch, and yaw)
In these and many other cases, the geometry of the signal class forms a nonlinear  SYMBOL -dimensional manifold in  SYMBOL ,  SYMBOL } where  SYMBOL  is the  SYMBOL -dimensional parameter space~ CITATION
Low-dimensional manifolds have also been proposed as approximate models for nonparametric signal classes such as images of human faces or handwritten digits~ CITATION
In many scenarios, multiple observations of the same event may be performed simultaneously, resulting in the acquisition of multiple manifolds that share the same parameter space
For example, sensor networks --- such as camera networks or microphone arrays --- typically observe a single event from a variety of vantage points, while the underlying phenomenon can often be described by a set of common global parameters (such as the location and orientation of the objects of interest)
Similarly, when sensing a single phenomenon using multiple modalities, such as video and audio, the underlying phenomenon may again be described by a single parameterization that spans all modalities
In such cases, we will show that it is advantageous to model this joint structure contained in the ensemble of manifolds as opposed to simply treating each manifold independently
Thus we introduce the concept of the  joint manifold : a model for the concatenation of the data vectors observed by the group of sensors
Joint manifolds enable the development of improved manifold-based learning and estimation algorithms that exploit this structure
Furthermore, they can be applied to data of any modality and dimensionality
In this work we conduct a careful examination of the theoretical properties of joint manifolds
In particular, we compare joint manifolds to their component manifolds to see how quantities like geodesic distances, curvature, branch separation, and condition number are affected
We then observe that these properties lead to improved performance and noise-tolerance for a variety of signal processing algorithms when they exploit the joint manifold structure, as opposed to processing data from each manifold separately
We also illustrate how this joint manifold structure can be exploited through a simple and efficient data fusion algorithm that uses random projections, which can also be applied to multimodal data
Related prior work has studied  manifold alignment , where the goal is to discover maps between several datasets that are governed by the same underlying low-dimensional structure
Lafon et al \ proposed an algorithm to obtain a one-to-one matching between data points from several manifold-modeled classes~ CITATION
The algorithm first applies dimensionality reduction using diffusion maps to obtain data representations that encode the intrinsic geometry of the class
Then, an affine function that matches a set of landmark points is computed and applied to the remainder of the datasets
This concept was extended by Wang and Mahadevan, who apply Procrustes analysis on the dimensionality-reduced datasets to obtain an alignment function between a pair of manifolds~ CITATION
Since an alignment function is provided instead of a data point matching, the mapping obtained is applicable for the entire manifold rather than for the set of sampled points
In our setting, we assume that either ( i ) the manifold alignment is provided intrinsically via synchronization between the different sensors or ( ii ) the manifolds have been aligned using one of the approaches described above
Our main focus is a theoretical analysis of the benefits provided by analyzing the joint manifold versus solving our task of interest separately on each of the manifolds observed by individual sensors
This paper is organized as follows
Section~ introduces and establishes some basic properties of joint manifolds
Section~ considers the application of joint manifolds to the tasks of classification and manifold learning
Section~ then describes an efficient method for processing and aggregating data when it lies on a joint manifold, and Section~ concludes with discussion
                                                                                                                                                                                                                                                                                                                                                                                                                                                                 jam-paper
bbl                                                                                       0000644 0000000 0000000 00000012053 11307647155 012123  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         jam-paper
tex                                                                                       0000644 0000000 0000000 00000014040 11307647375 012166  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   \documentclass[12pt]{article} \input{preamble}  \title{A Theoretical Analysis of Joint Manifolds}  Mark A
Davenport, Chinmay Hegde, Marco F
Duarte, \\ and Richard G
Baraniuk \protect\\\protect\\ Rice University \protect\\ Department of Electrical and Computer Engineering\protect\\ Technical Report TREE0901}     \end{document}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 jam
### abstract ###
We consider the problem of joint universal variable-rate lossy coding and identification for parametric classes of stationary  SYMBOL -mixing sources with general (Polish) alphabets
Compression performance is measured in terms of Lagrangians, while identification performance is measured by the variational distance between the true source and the estimated source
Provided that the sources are mixing at a sufficiently fast rate and satisfy certain smoothness and Vapnik--Chervonenkis learnability conditions, it is shown that, for bounded metric distortions, there exist universal schemes for joint lossy compression and identification whose Lagrangian redundancies converge to zero as  SYMBOL  as the block length  SYMBOL  tends to infinity, where  SYMBOL  is the Vapnik--Chervonenkis dimension of a certain class of decision regions defined by the  SYMBOL -dimensional marginal distributions of the sources; furthermore, for each  SYMBOL , the decoder can identify  SYMBOL -dimensional marginal of the active source up to a ball of radius  SYMBOL  in variational distance, eventually with probability one
The results are supplemented by several examples of parametric sources satisfying the regularity conditions \\ \\  Index Terms--- Learning, minimum-distance density estimation, two-stage codes, universal vector quantization, Vapnik--Chervonenkis dimension
### introduction ###
It is well known that lossless source coding and statistical modeling are complementary objectives
This fact is captured by the Kraft inequality (see Section~5 2 in Cover and Thomas  CITATION ), which provides a correspondence between uniquely decodable codes and probability distributions on a discrete alphabet
If one has full knowledge of the source statistics, then one can design an optimal lossless code for the source, and  vice versa
However, in practice it is unreasonable to expect that the source statistics are known precisely, so one has to design  universal  schemes that perform asymptotically optimally within a given class of sources
In universal coding, too, as Rissanen has shown in  CITATION , the coding and modeling objectives can be accomplished jointly: given a sufficiently regular parametric family of discrete-alphabet sources, the encoder can acquire the source statistics via maximum-likelihood estimation on a sufficiently long data sequence and use this knowledge to select an appropriate coding scheme
Even in nonparametric settings (e g , the class of all stationary ergodic discrete-alphabet sources), universal schemes such as Ziv--Lempel  CITATION  amount to constructing a probabilistic model for the source
In the reverse direction, Kieffer  CITATION  and Merhav  CITATION , among others, have addressed the problem of statistical modeling (parameter estimation or model identification) via universal lossless coding
Once we consider  lossy  coding, though, the relationship between coding and modeling is no longer so simple
On the one hand, having full knowledge of the source statistics is certainly helpful for designing optimal rate-distortion codebooks
On the other hand, apart from some special cases (e g , for  iid 
Bernoulli sources and the Hamming distortion measure or for  iid 
Gaussian sources and the squared-error distortion measure), it is not at all clear how to extract a reliable statistical model of the source from its reproduction via a rate-distortion code (although, as shown recently by Weissman and Ordentlich  CITATION , the joint empirical distribution of the source realization and the corresponding codeword of a ``good" rate-distortion code converges to the distribution solving the rate-distortion problem for the source)
This is not a problem when the emphasis is on compression, but there are situations in which one would like to compress the source and identify its statistics at the same time
For instance, in  indirect adaptive control  (see, eg , Chapter~7 of Tao  CITATION ) the parameters of the plant (the controlled system) are estimated on the basis of observation, and the controller is modified accordingly
Consider the discrete-time stochastic setting, in which the plant state sequence is a random process whose statistics are governed by a finite set of parameters
Suppose that the controller is geographically separated from the plant and connected to it via a noiseless digital channel whose capacity is  SYMBOL  bits per use
Then, given the time horizon  SYMBOL , the objective is to design an encoder and a decoder for the controller to obtain reliable estimates of both the plant parameters and the plant state sequence from the  SYMBOL  possible outputs of the decoder
To state the problem in general terms, consider an information source emitting a sequence  SYMBOL  of random variables taking values in an alphabet  SYMBOL
Suppose that the process distribution of  SYMBOL  is not specified completely, but it is known to be a member of some parametric class  SYMBOL
We wish to answer the following two questions:   Is the class  SYMBOL  universally encodable with respect to a given single-letter distortion measure  SYMBOL , by codes with a given structure (e g , all fixed-rate block codes with a given per-letter rate, all variable-rate block codes, etc )
In other words, does there exist a scheme that is asymptotically optimal for each  SYMBOL ,  SYMBOL
If the answer to Question 1) is positive, can the codes be constructed in such a way that the decoder can not only reconstruct the source, but also identify its process distribution  SYMBOL , in an asymptotically optimal fashion
In previous work  CITATION , we have addressed these two questions in the context of fixed-rate lossy block coding of stationary memoryless ( iid  ) continuous-alphabet sources with parameter space  SYMBOL  a bounded subset of  SYMBOL  for some finite  SYMBOL
We have shown that, under appropriate regularity conditions on the distortion measure and on the source models, there exist joint universal schemes for lossy coding and source identification whose redundancies (that is, the gap between the actual performance and the theoretical optimum given by the Shannon distortion-rate function) and source estimation fidelity both converge to zero as  SYMBOL , as the block length  SYMBOL  tends to infinity
The code operates by coding each block with the code matched to the source with the parameters estimated from the preceding block
Comparing this convergence rate to the  SYMBOL  convergence rate, which is optimal for redundancies of fixed-rate lossy block codes  CITATION , we see that there is, in general, a price to be paid for doing compression and identification simultaneously
Furthermore, the constant hidden in the  SYMBOL  notation increases with the ``richness" of the model class  SYMBOL , as measured by the Vapnik--Chervonenkis (VC) dimension  CITATION  of a certain class of measurable subsets of the source alphabet associated with the sources
The main limitation of the results of  CITATION  is the  iid 
assumption, which is rather restrictive as it excludes many practically relevant model classes (e g , autoregressive sources, or Markov and hidden Markov processes)
Furthermore, the assumption that the parameter space  SYMBOL  is bounded may not always hold, at least in the sense that we may not know the diameter of  SYMBOL   a priori
In this paper we relax both of these assumptions and study the existence and the performance of universal schemes for joint lossy coding and identification of stationary sources satisfying a mixing condition, when the sources are assumed to belong to a parametric model class  SYMBOL ,  SYMBOL  being an open subset of  SYMBOL  for some finite  SYMBOL
Because the parameter space is not bounded, we have to use variable-rate codes with countably infinite codebooks, and the performance of the code is assessed by a composite Lagrangian functional  CITATION  which captures the trade-off between the expected distortion and the expected rate of the code
Our result is that, under certain regularity conditions on the distortion measure and on the model class, there exist universal schemes for joint lossy source coding and identification such that, as the block length  SYMBOL  tends to infinity, the gap between the actual Lagrangian performance and the optimal Lagrangian performance achievable by variable-rate codes at that block length, as well as the source estimation fidelity at the decoder, converge to zero as  SYMBOL , where  SYMBOL  is the VC dimension of a certain class of decision regions induced by the collection  SYMBOL  of the  SYMBOL -dimensional marginals of the source process distributions
This result shows very clearly that the price to be paid for universality, in terms of both compression and identification, grows with the richness of the underlying model class, as captured by the VC dimension sequence  SYMBOL
The richer the model class, the harder it is to learn, which affects the compression performance of our scheme because we use the source parameters learned from past data to decide how to encode the current block
Furthermore, comparing the rate at which the Lagrangian redundancy decays to zero under our scheme with the  SYMBOL  result of Chou, Effros and Gray  CITATION , whose universal scheme is not aimed at identification, we immediately see that, in ensuring to satisfy the twin objectives of compression and modeling, we inevitably sacrifice some compression performance
The paper is organized as follows
Section~ introduces notation and basic concepts related to sources, codes and Vapnik--Chervonenkis classes
Section~ lists and discusses the regularity conditions that have to be satisfied by the source model class, and contains the statement of our result
The result is proved in Section~
Next, in Section~ we give three examples of parametric source families (namely,  iid 
Gaussian sources, Gaussian autoregressive sources and hidden Markov processes) which fit the framework of this paper under suitable regularity conditions
We conclude in Section~ and outline directions for future research
Finally, the Appendix contains some technical results on Lagrange-optimal variable-rate quantizers
### abstract ###
The problem of statistical learning is to construct an accurate predictor of a random variable as a function of a correlated random variable on the basis of an  iid  \ training sample from their joint distribution
Allowable predictors are constrained to lie in some specified class, and the goal is to approach asymptotically the performance of the best predictor in the class
We consider two settings in which the learning agent only has access to rate-limited descriptions of the training data, and present information-theoretic bounds on the  predictor performance achievable in the presence of these communication constraints
Our proofs do not assume any separation structure between compression and learning and rely on a new class of operational criteria specifically tailored to joint design of encoders and learning algorithms in rate-constrained settings
### introduction ###
Let  SYMBOL  and  SYMBOL  be jointly distributed random variables
The problem of statistical learning is to design an accurate predictor of the  output variable   SYMBOL  from the  input variable   SYMBOL  on the basis of a number of independent  training samples  drawn from their joint distribution, with very little or no prior knowledge of that distribution
The present paper focuses on the achievable performance of learning schemes when the learning agent only has access to a finite-rate description of the training samples
This problem of  learning under communication constraints  arises in a variety of contexts, such as distributed estimation using a sensor network, adaptive control, or repeated games
In these and other scenarios, it is often the case that the agents who gather the training data are geographically separated from the agents who use these data to make inferences and decisions, and communication between these two types of agents is possible only over rate-limited channels
Hence, there is a trade-off between the communication rate and the quality of the inference, and it is of interest to characterize this trade-off mathematically
This paper follows on our earlier work  CITATION  and presents improved bounds on the achievable performance of statistical learning schemes operating under two kinds of communication constraints: (a) the entire training sequence is delivered to the learning agent over a rate-limited noiseless digital channel, and (b) the input part of the training sequence is available to the learning agent with arbitrary precision, while the output part is delivered, as before, over a rate-limited channel
Whereas  CITATION  has looked at schemes where the finite-rate description of the training data was obtained through vector quantization, effectively imposing a separation structure between compression and learning, here we remove this restriction
We show that, under certain regularity conditions, there is no penalty for compression of the training sequence in the setting (a)
This is due to the fact that the encoder can reliably estimate the underlying distribution (in the metric specifically tailored for the learning problem at hand) and then communicate the finite-rate description to the learning agent, who can then find the optimum predictor for the estimated distribution
The setting (b), however, is radically different: because the encoder has no access to the input part of the training sample, it cannot estimate the underlying distribution
Instead, the encoder constructs a finite-rate description of the output part using a specific kind of a vector quantizer, namely one designed to minimize the expected distance between the underlying distribution (whatever it may happen to be) and the empirical distribution of the input/quantized output pairs
Our achievability result for the setting (b) uses a learning-theoretic generalization of recent work by Kramer and Savari  CITATION  on rate-constrained communication of probability distributions
The problem of learning a pattern classifier under rate constraints was also treated in a recent paper by Westover and O'Sullivan  CITATION
They assumed that the underlying probability distribution is known, and the rate constraint arises from the limitations on the memory of the learning agent; then the problem is to design the best possible classifier (without any constraints on its structure)
The motivation for the work in  CITATION  comes from biologically inspired models of learning
The approach of the present paper is complementary to that of  CITATION
We consider a more general, decision-theoretic formulation of learning that includes regression as well as classification, but allow only vague prior knowledge of the underlying distribution and assume that the class of available predictors is constrained
Thus, while  CITATION  presents information-theoretic bounds on the performance of  any  classifier (including ones that are fully cognizant of the generative model for the data), here we are concerned with the performance of constrained learning schemes that must perform well in the presence of uncertainty about the underlying distribution
The novel element of our approach is that both the operational criteria used to design the encoders and the learning algorithm, and the regularity conditions that must hold for rate-constrained learning to be possible, involve a tight coupling between the available prior knowledge about the underlying distribution and the set of predictors available to the learning agent
Planned future work includes obtaining converse theorems (lower bounds) and applying our formalism to specific classes of predictors used in statistical learning theory
### abstract ###
In statistical problems, a set of parameterized  probability distributions is used to estimate  the true probability distribution
If Fisher  information matrix at the true distribution is singular,  then it has been left unknown what we can estimate about the  true distribution from random samples
In this paper, we study a singular regression problem and  prove a limit theorem which shows the relation between  the singular regression problem and two birational invariants,  a real log canonical threshold and a singular fluctuation
The obtained theorem has an important application to statistics,  because it enables us to estimate the generalization error from the training error  without any knowledge of the true probability distribution
### introduction ###
Let  SYMBOL  and  SYMBOL  be natural numbers, and  SYMBOL  and  SYMBOL  be   SYMBOL  and  SYMBOL  dimensional real Euclidean spaces respectively
Assume that  SYMBOL  is a probability space and that   SYMBOL  is an  SYMBOL -valued random variable which is subject to a simultaneous probability density function,   SYMBOL  where  SYMBOL  is a probability density function on  SYMBOL ,  SYMBOL  is a constant,  SYMBOL  is a measurable function from  SYMBOL  to  SYMBOL , and  SYMBOL  is the Euclidean norm of  SYMBOL
The function  SYMBOL  is called a regression function of  SYMBOL
Assume that  SYMBOL  is a set of random variables which are independently subject to the same probability distribution as  SYMBOL
Let  SYMBOL  be a subset of  SYMBOL
Let  SYMBOL  be a function from  SYMBOL  to  SYMBOL
The square error  SYMBOL  is a real function on  SYMBOL ,   SYMBOL  An expectation operator  SYMBOL  on  SYMBOL  is defined by  SYMBOL } where  SYMBOL  is a measurable function,   SYMBOL  is a probability density function on  SYMBOL , and   SYMBOL  is a constant called an inverse temperature
Note that  SYMBOL  is not a constant but a random variable because  SYMBOL  depends on random variables
Two random variables  SYMBOL  and  SYMBOL  are defined by  SYMBOL *} These random variables  SYMBOL  and  SYMBOL  are called the generalization  and training errors respectively
Since  SYMBOL , it is expected  on some natural conditions that  both  SYMBOL  and  SYMBOL  converge to  SYMBOL   when  SYMBOL  tends to infinity  if there exists  SYMBOL  such that  SYMBOL
In this paper,  we ask how fast such convergences are, in  other words, our study concerns with a limit theorem  which shows the convergences   SYMBOL  and  SYMBOL , when  SYMBOL
If Fisher information matrix   SYMBOL  where  SYMBOL , is positive definite for arbitrary  SYMBOL , then this problem  is well known as a regular regression problem
In fact,  in a regular regression problem, convergences   SYMBOL  and   SYMBOL  hold
However, if  SYMBOL  is singular, that is to say, if  SYMBOL , then the problem is called a singular regression problem and convergences of  SYMBOL  and  SYMBOL  have been left unknown
In general it has been difficult to study a limit theorem  for the case when Fisher information matrix is singular
However, recently, we have shown that a limit theorem  can be established based on resolution of singularities, and that  there are mathematical relations between the limit theorem  and two birational invariants in singular density estimation  CITATION
In this paper we prove a new limit theorem for the singular regression problem, which enables us to estimate birational invariants from random samples
The limit theorem proved in this paper has an important application to  statistics, because the expectation value of the  generalization error  SYMBOL  can be estimated from that of the training error  SYMBOL  without any knowledge of the true probability distribution \vskip3mm {Example} Let  SYMBOL ,  SYMBOL ,  SYMBOL ,  and  SYMBOL
If the function  SYMBOL  is defined by   SYMBOL  and  SYMBOL , then the set  SYMBOL  is not one point, and Fisher information matrix at  SYMBOL   is singular
A lot of functions used in statistics, information science, brain informatics,  and bio-informatics are singular, for example, artificial neural networks, radial basis functions, and wavelet functions
### abstract ###
Let  SYMBOL  be an  SYMBOL  matrix of rank  SYMBOL ,  and assume that a uniformly random subset  SYMBOL   of its entries is observed
We describe an efficient algorithm that  reconstructs  SYMBOL  from  SYMBOL  observed entries with relative root mean square error   SYMBOL *}  Further, if   SYMBOL  and  SYMBOL  is sufficiently unstructured, then it can be reconstructed   exactly   from  SYMBOL  entries
This settles (in the case of bounded rank) a question left open by Cand{\`e}s and Recht  and improves over the guarantees for their reconstruction algorithm
The complexity of our algorithm is  SYMBOL , which opens the way to its use for massive  data sets
In the process of proving these statements, we obtain a generalization of a celebrated result by Friedman-Kahn-Szemer\'edi and Feige-Ofek on the spectrum of sparse random  matrices
### introduction ###
Imagine that each of  SYMBOL  customers watches and rates a subset  of the  SYMBOL  movies available through a movie rental service
This yields a dataset of customer-movie pairs  SYMBOL  and, for each such pair, a rating  SYMBOL
The objective of  collaborative filtering  is to predict  the rating for the missing pairs in such a way as to provide targeted  suggestions
made public such a dataset with  SYMBOL ,  SYMBOL  and  SYMBOL  and challenged the research community to predict the missing ratings with root mean square error below  SYMBOL   CITATION  } The general question we address here is: Under which conditions do the known ratings provide sufficient information to infer the unknown ones
Can this inference problem be solved efficiently
The second question is particularly important in view of the  massive size of actual data sets
### abstract ###
We consider the least-square linear regression problem with regularization by the  SYMBOL -norm, a problem usually referred to as the Lasso
In this paper, we first present a detailed asymptotic analysis of model consistency of the Lasso in low-dimensional settings
For various decays of the regularization parameter, we compute asymptotic equivalents of the probability of correct model selection
For a specific rate decay, we show that the Lasso selects all the variables that should enter the model with probability tending to one exponentially fast, while it selects all other variables with strictly positive probability
We show that this property implies that if we run the Lasso for several bootstrapped replications of a given sample, then intersecting the supports of the Lasso bootstrap estimates leads to consistent model selection
This novel variable selection procedure, referred to as the Bolasso, is extended to high-dimensional settings by a provably consistent two-step procedure
### introduction ###
Regularization by the  SYMBOL -norm has attracted a lot of interest in recent years in statistics, machine learning and signal processing
In the context of least-square linear regression, the problem is usually referred to as the  Lasso ~ CITATION  or  basis pursuit ~ CITATION
Much of the early effort has been dedicated to algorithms to solve the optimization problem efficiently, either through first-order methods~ CITATION , or through homotopy methods that leads to the entire regularization path (i e , the set of solutions for all values of the regularization parameters) at the cost of a single matrix inversion~ CITATION
A well-known property of the  regularization by the  SYMBOL -norm is the  sparsity  of the solutions, i e ,  it leads to  loading vectors with many zeros, and thus performs model selection on top of regularization
Recent works  CITATION  have looked precisely at the model consistency of the Lasso, i e , if we know that the data were generated from a sparse loading vector, does the Lasso actually recover the sparsity pattern when the number of observations grows
In the case of a fixed number of covariates (i e , low-dimensional settings), the Lasso does recover the sparsity pattern if and only if a certain simple condition on the generating covariance matrices is satisfied~ CITATION
In particular, in low correlation settings, the Lasso is indeed consistent
However, in presence of strong correlations between relevant variables and irrelevant variables, the Lasso cannot be model-consistent, shedding light on potential problems of such procedures for variable selection
Various extensions of the Lasso have been designed to fix its inconsistency, based on thresholding~ CITATION , data-dependent weights~ CITATION  or two-step procedures~ CITATION
The main contribution of this paper is to propose and analyze an alternative approach based on resampling
Note that recent work~ CITATION  has also looked at resampling methods for the Lasso, but focuses on resampling the weights of the  SYMBOL -norm rather than resampling the observations (see \mysec{support} for more details)
In this paper, we first derive a detailed asymptotic analysis of sparsity pattern selection of the Lasso estimation procedure, that extends previous analysis~ CITATION  by focusing on a specific decay of the regularization parameter
Namely, in  low-dimensional  settings where the number of variables  SYMBOL  is much smaller than the number of observations  SYMBOL , we show that when the decay of  SYMBOL  is proportional to  SYMBOL , then the Lasso will select all the variables that should enter the model (the  relevant  variables) with probability tending to one exponentially fast with~ SYMBOL , while it selects all other variables (the  irrelevant  variables) with strictly positive probability
If several datasets generated from the same distribution were available, then the latter property  would suggest to consider the intersection of the supports of the Lasso estimates for each dataset: all relevant variables would always be selected for all datasets, while irrelevant variables would enter the models randomly, and intersecting the supports from sufficiently many different datasets would simply eliminate them
However, in practice, only one dataset is given; but resampling methods such as the  bootstrap  are exactly dedicated to mimic the availability of several datasets by resampling from the same unique dataset~ CITATION
In this paper, we show that when using the bootstrap and intersecting the supports, we actually get a consistent model estimate,  without  the consistency condition required by the regular Lasso
We refer to this new procedure as the  Bolasso  ( bo otstrap-enhanced  l east  a b s olute  s hrinkage  o perator)
Finally, our Bolasso framework could be seen as a voting scheme applied to the supports of the bootstrap Lasso estimates; however, our procedure may rather be considered as a consensus combination scheme, as we keep the (largest) subset of variables on which  all  regressors agree in terms of variable selection, which is in our case provably consistent and also allows to get rid of a potential additional hyperparameter
We consider the two usual ways of using the bootstrap in regression settings, namely bootstrapping pairs and bootstrapping residuals~ CITATION
In \mysec{support}, we show that the two types of bootstrap lead to consistent model selection in low-dimensional settings
Moreover, in \mysec{simulations}, we provide empirical evidence that in high-dimensional settings, bootstrapping pairs does not lead to consistent estimation, while bootstrapping residuals still does
While we are currently unable to prove the consistency of bootstrapping residuals in high-dimensional settings, we prove in \mysec{highdim} the model consistency of a related two-step procedure:  the Lasso is run once on the original data, with a larger regularization parameter, and then bootstrap replications (pairs or residuals) are run within the support of the first Lasso estimation
We show in \mysec{highdim} that this procedure is consistent
In order to do so, we consider new sufficient conditions for the consistency of the Lasso, which do not rely on sparse eigenvalues~ CITATION , low correlations~ CITATION  or finer conditions~ CITATION
In particular, our new assumptions allow to prove that the Lasso will select not only a few variables when the regularization parameter is properly chosen, but always the same variables with high probability
In \mysec{algorithms}, we derive efficient algorithms for the bootstrapped versions of the Lasso
When bootstrapping pairs, we simply run an efficient homotopy algorithm, such as  Lars ~ CITATION , multiple times; however, when bootstrapping residuals, more efficient ways may be designed to obtain a running time complexity which is less than running Lars multiple times
Finally, in \mysec{experiments-low} and \mysec{experiments-high}, we illustrate our results on synthetic examples, in low-dimensional and high-dimensional settings
This work is a follow-up to earlier work~ CITATION : in particular, it refines and extends the analysis to high-dimensional settings and boostrapping of the residuals \paragraph{Notations} For  SYMBOL  and  SYMBOL , we  denote by  SYMBOL  its  SYMBOL -norm, defined as  SYMBOL
We also denote by  SYMBOL  its  SYMBOL -norm
For rectangular matrices  SYMBOL , we denote by  SYMBOL  its largest singular value,  SYMBOL  the largest magnitude of all its elements, and  SYMBOL  its Frobenius norm
We let denote  SYMBOL  and  SYMBOL  the largest and smallest eigenvalue of a symmetric matrix  SYMBOL
For    SYMBOL ,  SYMBOL  denotes the sign of  SYMBOL , defined as  SYMBOL  if  SYMBOL ,  SYMBOL  if  SYMBOL , and  SYMBOL  if  SYMBOL
For a vector  SYMBOL ,  SYMBOL  denotes the   vector of signs of elements of  SYMBOL
Given a set  SYMBOL ,  SYMBOL  is the indicator function of the set  SYMBOL
We also denote, for  SYMBOL , by  SYMBOL , the smallest (in magnitude) of non-zero elements of  SYMBOL
Moreover, given a vector  SYMBOL  and a subset  SYMBOL  of  SYMBOL ,  SYMBOL  denotes the vector in  SYMBOL  of elements of  SYMBOL  indexed by  SYMBOL
Similarly, for a matrix  SYMBOL ,  SYMBOL   denotes the submatrix of   SYMBOL  composed of elements of  SYMBOL  whose rows are in  SYMBOL  and columns are in  SYMBOL
Moreover,  SYMBOL  denotes the cardinal of the set  SYMBOL
For a positive definite matrix  SYMBOL  of size  SYMBOL , and two disjoint subsets of indices  SYMBOL  and  SYMBOL  included in  SYMBOL , we denote  SYMBOL  the matrix  SYMBOL , which is the conditional covariance of variables indexed by  SYMBOL  given variables indexed by  SYMBOL , for a Gaussian vector with covariance matrix  SYMBOL
Finally, we let denote  SYMBOL  and  SYMBOL  general probability measures and expectations \paragraph{Least-square regression with  SYMBOL -norm penalization} Throughout this paper,  we consider  SYMBOL  pairs of observations    SYMBOL ,  SYMBOL
The data are given in the form of a vector  SYMBOL  and a design matrix  SYMBOL
We consider the normalized square loss function   SYMBOL  SYMBOL \ell^1 SYMBOL 0 SYMBOL SYMBOL \hat{J} = \{ j  \{1,\dots,p\}, \  \hat{w}_j  0\} SYMBOL SYMBOL p/n$
When this ratio is much smaller than one, as in \mysec{lowdim}, we refer to this setting as low-dimensional estimation, while in other cases, where this ratio is potentially much larger than one, we refer to this setting as a high-dimensional problem (see \mysec{highdim})
### abstract ###
We study boosting algorithms from a new perspective
We show that the Lagrange dual problems of  SYMBOL  norm regularized \adaboost, and soft-margin with generalized hinge loss  are all entropy maximization problems
By looking at the dual problems of these boosting algorithms, we show that the success of boosting algorithms can be understood in terms of maintaining a better margin distribution by maximizing margins and at the same time controlling the margin variance
We also theoretically prove that, approximately,  SYMBOL  norm regularized  maximizes the average margin, instead of the minimum margin
The duality formulation also enables us to  develop column generation based optimization algorithms, which are totally corrective
We show that they exhibit almost identical classification results to that of standard stage-wise additive boosting algorithms but  with much faster convergence rates
Therefore fewer weak classifiers are needed to build the ensemble using our proposed optimization technique
### introduction ###
\IEEEPARstart{B}{oosting}  has attracted a lot of research interests since the first practical boosting algorithm, \adaboost, was introduced by Freund and Schapire  CITATION
The machine learning community has spent much effort on understanding how the algorithm works  CITATION
However, up to date there are still questions about the success of boosting that are left unanswered   CITATION
In boosting,  one is given a set of training examples  SYMBOL , with binary labels  SYMBOL  being either  SYMBOL  or  SYMBOL
A boosting algorithm finds a convex linear  combination of weak classifiers (base learners, weak hypotheses) that can achieve much better classification accuracy than an individual base classifier
To do so, there are two unknown variables to be optimized
The first one is the base classifiers
An oracle is needed to produce base classifiers
The second one is the positive weights associated with each base classifier
is one of the first and the most popular boosting algorithms for classification
Later, various boosting algorithms have been advocated
For example,  by Friedman  CITATION  replaces \adaboost's exponential cost function with the function of logistic regression
MadaBoost  CITATION  instead uses a modified exponential loss
The authors of  CITATION   consider boosting algorithms with a generalized additive model framework
Schapire  CITATION  showed  that converges to a large margin solution
However, recently it is pointed out that  does not converge to the maximum margin solution  CITATION
Motivated by the success of the margin theory associated with support vector machines (SVMs), was invented by   CITATION  with the intuition of maximizing the minimum margin of all training examples
The final optimization problem can be formulated as a linear program (LP)
It is observed that the hard-margin does not perform well in most cases although it usually produces larger minimum margins
More often has worse generalization performance
In other words, a higher minimum margin would not necessarily  imply a lower test error
Breiman  CITATION  also noticed the same phenomenon: his algorithm has a minimum margin that provably converges to the optimal but is inferior in terms of generalization capability
Experiments on and have put the margin theory into serious doubt
Until recently, Reyzin and Schapire  CITATION  re-ran Breiman's experiments by controlling weak classifiers' complexity
They found that  the minimum margin is indeed larger for \arcgv, but the overall margin distribution is typically better for \adaboost
The conclusion is that the minimum margin is important, but not always at the expense of other factors
They also conjectured that maximizing the average margin, instead of the minimum margin, may result in better boosting algorithms
Recent theoretical work  CITATION   has shown the important role of the margin distribution   on bounding the generalization error of combined classifiers such as boosting and bagging
As the soft-margin SVM usually has a better classification accuracy than the hard-margin SVM,  the soft-margin also performs better by relaxing  the constraints that all training examples must be correctly classified
Cross-validation is required to determine an optimal value for the soft-margin trade-off parameter
R\"atsch  CITATION  showed the equivalence between SVMs and boosting-like algorithms
Comprehensive overviews on boosting are given by  CITATION  and   CITATION
We show in this work that the Lagrange duals of  SYMBOL  norm regularized \adaboost, and with generalized hinge loss are all   entropy maximization problems
Previous work like      CITATION  noticed the connection between boosting techniques and entropy maximization based on Bregman distances
They did not   show that the duals of boosting algorithms are  actually entropy regularized as we show in  \eqref{EQ:dual_ada0},  \eqref{EQ:LPBoost10} and \eqref{EQ:dual_logit1}
By knowing this duality equivalence,  we derive a general column generation (CG) based optimization framework that can be used to optimize arbitrary convex loss functions
In other words, we can easily design totally-corrective \adaboost, and boosting  with generalized hinge loss, \etc
Our major contributions are the following:    We derive the Lagrangian duals of boosting algorithms and show that most of them are entropy maximization problems
The authors of  CITATION   conjectured that                   ``it may be fruitful to consider boosting algorithms that greedily maximize the average or median margin rather than the minimum one''
We theoretically prove that, actually,  SYMBOL   norm regularized approximately maximizes the average margin, instead of the minimum margin
This is an important result in the sense that it provides an alternative theoretical explanation that is consistent with the margins theory and agrees with the empirical observations made by  CITATION
We propose \adaboost-QP that directly optimizes the asymptotic cost function of \adaboost
The experiments confirm our theoretical analysis
Furthermore, based on the duals we derive, we design column generation based optimization techniques for boosting learning
We show that the new algorithms have almost identical results to that of standard stage-wise additive boosting algorithms but with much faster convergence rates
Therefore fewer weak classifiers are needed to build the ensemble
The following notation is used
Typically, we use bold letters  SYMBOL  to denote vectors, as opposed to scalars  SYMBOL  in lower case letters
We use capital letters  SYMBOL  to denote matrices
All vectors are column vectors unless otherwise specified
The inner product of two column vectors  SYMBOL  and  SYMBOL  are  SYMBOL
Component-wise inequalities are expressed using  symbols  SYMBOL ; \eg,  SYMBOL  means for all the entries  SYMBOL
SYMBOL  and  SYMBOL  are column vectors with each entry being  SYMBOL  and  SYMBOL  respectively
The length will be clear from the context
The abbreviation  SYMBOL  means ``subject to''
We denote the domain of a function  SYMBOL  as  SYMBOL
The paper is organized as follows
Section  briefly reviews several boosting algorithms for self-completeness
Their corresponding duals are derived in Section
Our main results are also presented in Section
In Section , we then present numerical experiments to illustrate various aspects of our new algorithms obtained in Section
We conclude the paper in the last section
### abstract ###
Consider an agent interacting with an environment in cycles
In every interaction cycle the agent is rewarded for its performance
We compare the average reward  SYMBOL  from cycle  SYMBOL  to  SYMBOL  (average value) with the future discounted reward  SYMBOL  from cycle  SYMBOL  to  SYMBOL  (discounted value)
We consider essentially arbitrary (non-geometric) discount sequences and arbitrary reward sequences (non-MDP environments)
We show that asymptotically  SYMBOL  for  SYMBOL  and  SYMBOL  for  SYMBOL  are equal, provided both limits exist
Further, if the effective horizon grows linearly with  SYMBOL  or faster, then the existence of the limit of  SYMBOL  implies that the limit of  SYMBOL  exists
Conversely, if the effective horizon grows linearly with  SYMBOL  or slower, then existence of the limit of  SYMBOL  implies that the limit of  SYMBOL  exists
### introduction ###
We consider the reinforcement learning setup  CITATION , where an agent interacts with an environment in cycles
In cycle  SYMBOL , the agent outputs (acts)  SYMBOL , then it makes observation  SYMBOL  and receives reward  SYMBOL , both provided by the environment
Then the next cycle  SYMBOL  starts
For simplicity we assume that agent and environment are deterministic
Typically one is interested in action sequences, called plans or policies, for agents that result in high reward
The simplest reasonable measure of performance is the total reward sum or equivalently the average reward, called average value  SYMBOL , where  SYMBOL  should be the lifespan of the agent
One problem is that the lifetime is often not known in advance, eg \ often the time one is willing to let a system run depends on its displayed performance
More serious is that the measure is indifferent to whether an agent receives high rewards early or late if the values are the same
A natural (non-arbitrary) choice for  SYMBOL  is to consider the limit  SYMBOL
While the indifference may be acceptable for finite  SYMBOL , it can be catastrophic for  SYMBOL
Consider an agent that receives no reward until its first action is  SYMBOL , and then once receives reward  SYMBOL
For finite  SYMBOL , the optimal  SYMBOL  to switch from action  SYMBOL  to  SYMBOL  is  SYMBOL
Hence  SYMBOL  for  SYMBOL , so the reward maximizing agent for  SYMBOL  actually always acts with  SYMBOL , and hence has zero reward, although a value arbitrarily close to 1 would be achievable (Immortal agents are lazy  CITATION )
More serious, in general the limit  SYMBOL  may not even exist
Another approach is to consider a moving horizon
In cycle  SYMBOL , the agent tries to maximize  SYMBOL , where  SYMBOL  increases with  SYMBOL , eg \  SYMBOL  with  SYMBOL  being the horizon
This naive truncation is often used in games like chess (plus a heuristic reward in cycle  SYMBOL ) to get a reasonably small search tree
While this can work in practice, it can lead to inconsistent optimal strategies, i e \ to agents that change their mind
Consider the example above with  SYMBOL
In every cycle  SYMBOL  it is better first to act  SYMBOL  and then  SYMBOL  ( SYMBOL ), rather than immediately  SYMBOL  ( SYMBOL ), or  SYMBOL  ( SYMBOL )
But entering the next cycle  SYMBOL , the agent throws its original plan overboard, to now choose  SYMBOL  in favor of  SYMBOL , followed by  SYMBOL
This pattern repeats, resulting in no reward at all
The standard solution to the above problems is to consider geometrically=exponentially discounted reward  CITATION
One discounts the reward for every cycle of delay by a factor  SYMBOL , i e \ considers  SYMBOL
The  SYMBOL  maximizing policy is consistent in the sense that its actions  SYMBOL  coincide with the optimal policy based on  SYMBOL
At first glance, there seems to be no arbitrary lifetime  SYMBOL  or horizon  SYMBOL , but this is an illusion
SYMBOL  is dominated by contributions from rewards  SYMBOL , so has an effective horizon  SYMBOL
While such a sliding effective horizon does not cause inconsistent policies, it can nevertheless lead to suboptimal behavior
For every (effective) horizon, there is a task that needs a larger horizon to be solved
For instance, while  SYMBOL  is sufficient for tic-tac-toe, it is definitely insufficient for chess
There are elegant closed form solutions for Bandit problems, which show that for any  SYMBOL , the Bayes-optimal policy can get stuck with a suboptimal arm (is not self-optimizing)  CITATION
For  SYMBOL ,  SYMBOL , and the defect decreases
There are various deep papers considering the limit  SYMBOL   CITATION , and comparing it to the limit  SYMBOL   CITATION
The analysis is typically restricted to ergodic MDPs for which the limits  SYMBOL  and  SYMBOL  exist
But like the limit policy for  SYMBOL , the limit policy for  SYMBOL  can display very poor performance, i e \ we need to choose  SYMBOL  fixed in advance (but how ), or consider higher order terms  CITATION
We also cannot consistently adapt  SYMBOL  with  SYMBOL
Finally, the value limits may not exist beyond ergodic MDPs
There is little work on other than geometric discounts
In the psychology and economics literature it has been argued that people discount a one day=cycle delay in reward more if it concerns rewards now rather than later, eg \ in a year (plus one day)  CITATION
So there is some work on ``sliding'' discount sequences  SYMBOL
One can show that this also leads to inconsistent policies if  SYMBOL  is non-geometric  CITATION
Is there any non-geometric discount leading to consistent policies
In  CITATION  the generally discounted value  SYMBOL  with  SYMBOL  has been introduced
It is well-defined for arbitrary environments, leads to consistent policies, and eg \ for quadratic discount  SYMBOL  to an increasing effective horizon (proportionally to  SYMBOL ), i e \ the optimal agent becomes increasingly farsighted in a consistent way, leads to self-optimizing policies in ergodic ( SYMBOL th-order) MDPs in general, Bandits in particular, and even beyond MDPs
See  CITATION  for these and  CITATION  for more results
The only other serious analysis of general discounts we are aware of is in  CITATION , but their analysis is limited to Bandits and so-called regular discount
This discount has bounded effective horizon, so also does not lead to self-optimizing policies
The  asymptotic  total average performance  SYMBOL  and future discounted performance  SYMBOL  are of key interest
For instance, often we do not know the exact environment in advance but have to  learn  it from past experience, which is the domain of reinforcement learning  CITATION  and adaptive control theory  CITATION
Ideally we would like a learning agent that performs  asymptotically  as well as the optimal agent that knows the environment in advance
The subject of study of this paper is the relation between  SYMBOL  and  SYMBOL  for  general discount   SYMBOL  and  arbitrary environment
The importance of the performance measures  SYMBOL  and  SYMBOL , and general discount  SYMBOL  has been discussed above
There is also a clear need to study general environments beyond ergodic MDPs, since the real world is neither ergodic (e g \ losing an arm is irreversible) nor completely observable
The only restriction we impose on the discount sequence  SYMBOL  is summability ( SYMBOL ) so that  SYMBOL  exists, and monotonicity ( SYMBOL )
Our main result is that if both limits  SYMBOL  and  SYMBOL  exist, then they are necessarily equal (Section , Theorem )
Somewhat surprisingly this holds for  any  discount sequence  SYMBOL  and  any  environment (reward sequence  SYMBOL ), whatsoever
Note that limit  SYMBOL  may exist or not, independent of whether  SYMBOL  exists or not
We present examples of the four possibilities in Section
Under certain conditions on  SYMBOL , existence of  SYMBOL  implies existence of  SYMBOL , or vice versa
We show that if (a quantity closely related to) the effective horizon grows linearly with  SYMBOL  or faster, then existence of  SYMBOL  implies existence of  SYMBOL  and their equality (Section , Theorem )
Conversely, if the effective horizon grows linearly with  SYMBOL  or slower, then existence of  SYMBOL  implies existence of  SYMBOL  and their equality (Section , Theorem )
Note that apart from discounts with oscillating effective horizons, this implies (and this is actually the path used to prove) the first mentioned main result
In Sections  and  we define and provide some basic properties of average and discounted value, respectively
### abstract ###
Scenarios for the emergence or bootstrap of a lexicon involve the repeated interaction between at least two agents  who must reach a consensus on how to name  SYMBOL  objects using   SYMBOL  words
Here we consider minimal models of  two types of learning algorithms: cross-situational learning, in which the individuals determine the meaning of a  word by looking for something in common across all observed uses of that word, and supervised operant conditioning learning,  in which there is strong feedback between individuals about the intended meaning of the words
Despite the  stark differences between these learning schemes, we show that they yield the same communication accuracy in the realistic  limits of large   SYMBOL  and  SYMBOL , which coincides with the result of the classical occupancy problem of randomly  assigning  SYMBOL  objects to  SYMBOL   words
### introduction ###
How a coherent lexicon can emerge in a group of interacting agents is a major open issue in the language evolution and  acquisition research area (Hurford, 1989; Nowak \& Krakauer, 1999; Steels, 2002; Kirby, 2002; Smith, Kirby, \& Brighton, 2003)
In addition, the dynamics in the self-organization of shared lexicons is one of the issues to which computational and mathematical  modeling can contribute the most, as the emergence of a lexicon from scratch implies some type of self-organization and, possibly,  threshold phenomenon
This cannot be completely understood without a thorough exploration of the parameter space of the models  (Baronchelli, Felici, Loreto, Caglioli, \& Steels, 2006)
There are two main research avenues to investigate the emergence or bootstrapping of a lexicon
The first approach,  inspired by the seminal work of Pinker and Bloom (1990) who argued that natural selection is the main design principle  to explain the emergence and complex structure of language, resorts to evolutionary algorithms to evolve the shared lexicon
The key element here is that an improvement on the communication ability of an individual results, in average, in an increase  of the number of offspring it produces (Hurford, 1989; Nowak \& Krakauer, 1999; Cangelosi, 2001; Fontanari \& Perlovsky, 2007, 2008)
The second research avenue, which we will follow in this paper, argues for a culturally based view of language evolution and so  it assumes that the lexicons are acquired and modified solely through learning during the individual's lifetime  (Steels, 2002; Smith, Kirby, \& Brighton, 2003)
Of course, if there is a fact about language which is uncontroversial, it is that the lexicon must be learned from the active or  passive interaction between children and language-proficient adults
The issue of whether this ability to learn the lexicon is  due to some domain-general learning mechanism, or  is an innate ability, unique to humans, is still on the table (Bates \& Elman, 1996)
In the problem we address here, there is simply no language-proficient individuals, so it is not so far-fetched to put forward a  biological rather than a cultural explanation for the emergence of a self-organized lexicon
Nevertheless, in this contribution  we will use many insights produced by research on language acquisition by children (see, eg , Gleitman, 1990; Bloom, 2000) to  study different learning strategies
From a developmental perspective, there are basically two competing schemes for lexicon acquisition by children  (Rosenthal \& Zimmerman, 1978)
The first scheme, termed cross-situational or observational learning, is based on the  intuitive idea that one way that a learner can determine the meaning of a word is to find something in common across all  observed uses of that word (Pinker, 1984; Gleitman, 1990; Siskind, 1996)
Hence learning takes place through the statistical  sampling of the contexts in which a word appears
Since the learner receives no feedback about its inferences, we refer to  this scheme as unsupervised learning
The second scheme, known generally as operant conditioning, involves the active  participation of the agents in the learning process, with exchange of non-linguistic cues to provide feedback on the  hearer inferences
This supervised learning scheme has been applied to the design of a system for communication by  autonomous robots -- the so-called language game in the Talking Heads experiments (Steels, 2003)
Despite the technological  appeal, the empirical evidence is that most part of the lexicon is acquired by children as a product of unsupervised learning  (Pinker, 1984; Gleitman, 1990; Bloom, 2000)
Interestingly, from the perspective of evolving or bootstrapping a lexicon, the unsupervised scheme is very attractive too,  since it eliminates altogether the issue of honest signaling (Dawkins \& Krebs, 1978), as no signaling is involved in the  learning process, which requires only observation and some elements of intuitive psychology (e g Theory of Mind)
Many different computational implementations and variants of these two schemes for bootstrapping a lexicon have  been proposed in the literature
For example, Smith (2003a, 2003b), Smith, Smith, Blythe, \& Vogt (2006),  and De Beule, De Vylder, \& Belpaeme (2006) have addressed the unsupervised learning scheme,  whereas Steels \& Kaplan (1999), Ke, Minett, Au, Wang (2002), Smith, Kirby, \& Brighton, (2003),  and  Lenaerts, Jansen,  Tuyls, \& De Vylder (2005), the supervised scheme
However, except for the extensive statistical  analysis of a variant of the supervised learning algorithm which reduces the problem to that of naming a single object  (Baronchelli, Felici, Loreto,  Caglioli, \& Steels, 2006), the study of the effects of changing the parameters of those  models have been usually limited to the display of the time evolution of some measure of the communication accuracy of the  population
Although at first sight the supervised learning scheme may seem to be clearly superior to the unsupervised  one (albeit less realistic in the context of language acquisition by children), we are not aware of any thorough  comparison between the performances of these two learning scenarios
In fact, in this contribution we show that in  a realistic limit of very large lexicon sizes the supervised and unsupervised learning performances are essentially identical
In this paper we study minimal models of the supervised and unsupervised learning schemes which preserve the main  ingredients of these two classical language acquisition paradigms
For the sake of simplicity, here we interpret the  lexicon as a mapping between objects and words (or sounds) rather than as a mapping between meanings (conceptual structures)  and sounds
A more complete scenario would involve first the creation of meanings, i e , the bootstrapping of an object-meaning  mapping (Steels, 1996; Fontanari, 2006) and then the emergence of a meaning-sound mapping  (see, eg , Smith, 2003a, 2003b; Fontanari \& Perlovsky, 2006)
### abstract ###
Walley's Imprecise Dirichlet Model (IDM) for categorical  iid  \ data extends the classical Dirichlet model to a set of priors
It overcomes several fundamental problems which other approaches to uncertainty suffer from
Yet, to be useful in practice, one needs efficient ways for computing the imprecise=robust sets or intervals
The main objective of this work is to derive exact, conservative, and approximate, robust and credible interval estimates under the IDM for a large class of statistical estimators, including the entropy and mutual information
### introduction ###
This work derives interval estimates under the Imprecise Dirichlet Model (IDM)  CITATION  for a large class of statistical estimators
In the IDM one considers an  iid  \ process with unknown chances  SYMBOL  for outcome  SYMBOL
The prior uncertainty about  SYMBOL  is modeled by a set of Dirichlet priors  SYMBOL , where%  %  SYMBOL , and  SYMBOL  is a hyper-parameter, typically chosen between 1 and 2
Sets of probability distributions are often called Imprecise probabilities, hence the name IDM for this model
We avoid the term  imprecise  and use  robust  instead, or capitalize  Imprecise
The IDM overcomes several fundamental problems which other approaches to uncertainty suffer from  CITATION
For instance, the IDM satisfies the representation invariance principle and the symmetry principle, which are mutually exclusive in a pure Bayesian treatment with proper prior  CITATION
SYMBOL  The counts  SYMBOL  for  SYMBOL  form a minimal sufficient statistic of the data of size  SYMBOL
Statistical estimators  SYMBOL  usually also depend on the chosen prior: so a set of priors leads to a set of estimators  SYMBOL
For instance, the expected chances  SYMBOL  lead to a robust interval estimate  SYMBOL
Robust intervals for the variance  SYMBOL   CITATION  and for the mean and variance of linear-combinations  SYMBOL  have also been derived  CITATION
Bayesian estimators (like expectations) depend on  SYMBOL  and  SYMBOL  only through  SYMBOL  (and  SYMBOL  which we suppress), i e \  SYMBOL
The main objective of this work is to derive approximate, conservative, and exact intervals  SYMBOL  for general  SYMBOL , and for the expected (also called predictive) entropy and the expected mutual information in particular
These results are key building blocks for applying the IDM
Walley suggests, for instance, to use  SYMBOL  for inference problems and  SYMBOL  for decision problems  CITATION , where  SYMBOL  is some function of  SYMBOL
One application is the inference of robust tree-dependency structures  CITATION , in which edges are partially ordered based on Imprecise mutual information
Section  gives a brief introduction to the IDM and describes our problem setup
In Section  we derive exact robust intervals for concave functions  SYMBOL , such as the entropy
Section  derives approximate robust intervals for arbitrary  SYMBOL
In Section  we show how bounds of elementary functions can be used to get bounds for composite function, especially for sums and products of functions
The results are used in Section  for deriving robust intervals for the mutual information
The issue of how to set up IDM models on product spaces is discussed in Section
Section  addresses the problem of how to combine Bayesian credible intervals with the robust intervals of the IDM
Conclusions are given in Section
Appendix  lists properties of the  SYMBOL  function, which occurs in the expressions for the expected entropy and mutual information
Appendix  contains a table of used notation
### abstract ###
Gaussian belief propagation (GaBP) is an iterative message-passing algorithm for inference in Gaussian graphical models
It is known that when GaBP converges it converges to the correct MAP estimate of the Gaussian  random vector and simple sufficient conditions for its  convergence have been established
In this paper we develop a double-loop algorithm for forcing convergence of GaBP
Our method computes the correct MAP estimate even in cases where standard GaBP would not have converged
We further extend this construction to compute least-squares solutions of over-constrained linear systems
We believe that our construction has numerous applications, since the GaBP algorithm is linked to solution of linear systems of equations, which is a fundamental problem in computer science and engineering
As a case study, we discuss the linear detection problem
We show that using our new construction, we are able to force convergence of Montanari's linear detection algorithm, in cases where it would originally fail
As a consequence, we are able to increase significantly the number of users that can transmit concurrently
### introduction ###
The Gaussian belief propagation algorithm is an efficient distributed message-passing algorithm for inference over a Gaussian graphical model
GaBP is also linked to the canonical problem of solving systems of linear equations~ CITATION , one of the fundamental problems in computer science and engineering, which explains the large number of algorithm variants and applications
For example, the GaBP algorithm is applied for signal processing~ CITATION , multiuser detection~ CITATION , linear programming~ CITATION , ranking in social networks~ CITATION , support vector machines~ CITATION  Furthermore, it was recently shown that some existing algorithms are specific instances of the GaBP algorithm, including Consensus propagation~ CITATION , local probability propagation~ CITATION , multiuser detection~ CITATION , Quadratic Min-Sum algorithm~ CITATION , Turbo decoding with Gaussian densities~ CITATION  and others
Two general sufficient conditions for convergence of GaBP in loopy graphs are known: diagonal-dominance  CITATION  and walk-summability  CITATION
See also numerous studies in specific settings~ CITATION
In this work, we propose a novel construction that fixes the convergence of the GaBP algorithm, for any Gaussian model with positive-definite information matrix (inverse covariance matrix), even when the currently known sufficient convergence conditions do not hold
We prove that our construction converges to the correct solution
Furthermore, we consider how this method may be used to solve for the least-squares solution of general linear systems
As a specific application, we discuss Montanari's multiuser detection algorithm~ CITATION
By using our construction we are able to show convergence in practical CDMA settings, where the original algorithm did not converge, supporting a significantly higher number of users on each cell
This paper is organized as follows
Section  outlines the problem model
Section  gives a brief introduction to the GaBP algorithm
Section  describes our novel double-loop construction for positive definite matrices
Section  extends the construction for computing least-squares solution of general linear systems
We provide experimental results of deploying our construction in the linear detection context in Section
We conclude in Section
### abstract ###
Grammar inference deals with determining (preferable simple) models/grammars consistent with a set of observations
There is a large body of research on grammar inference within the theory of formal languages
However, there is surprisingly little known on grammar inference for graph grammars
In this paper we take a further step in this direction and work within the framework of node label controlled (NLC) graph grammars
Specifically, we characterize, given a set of disjoint and isomorphic subgraphs of a graph  SYMBOL , whether or not there is a NLC graph grammar rule which can generate these subgraphs to obtain  SYMBOL
This generalizes previous results by assuming that the set of isomorphic subgraphs is disjoint instead of non-touching
This leads naturally to consider the more involved ``non-confluent'' graph grammar rules
### introduction ###
Grammar inference, also called grammar induction, is a general line of research where one is concerned with determining a ``simple'' grammar that is consistent with a given set of possible and impossible outcomes
Hence, one ``goes back'' in the derivation: instead of determining the generative power of a grammar, one determines the grammar given the generated output
This topic is well-studied for formal languages, especially with respect to context-free languages, see eg CITATION , however, relatively little is known for graph grammars
The topic of inference of graph grammars is considered in  CITATION  and uses their so-called Subdue scheme developed in  CITATION
In  CITATION  a rigorous approach of grammar inference within the framework of node label controlled (NLC) graph grammars  CITATION , a natural and well-studied class of graph grammars, is initiated
There it is characterized, given a set  SYMBOL  of non-touching isomorphic graphs of a graph  SYMBOL , whether or not there is a graph grammar consisting of one rule able to generate the graphs of  SYMBOL  to obtain  SYMBOL
We continue this research and generalize this result for the case where these graphs are disjoint instead of non-touching
Such a generalization requires one to deal with a number of issues
Most notably, one has to deal with non-confluency issues: the generated graph depends on the order in which touching subgraphs are generated \addconf{Due to space constraints, proofs of the results are omitted, but can be found in an extended version

of this paper }
### abstract ###
Research in reinforcement learning has produced algorithms for optimal decision making under uncertainty that fall within two main types
The first employs a Bayesian framework, where optimality improves with increased computational time
This is because the resulting planning task takes the form of a dynamic programming problem on a belief tree with an infinite number of states
The second type employs relatively simple algorithm which are shown to suffer small regret within a distribution-free framework
This paper presents a lower bound and a high probability upper bound on the optimal value function for the nodes in the Bayesian belief tree, which are analogous to similar bounds in POMDPs
The bounds are then used to create more efficient strategies for exploring the tree
The resulting algorithms are compared with the distribution-free algorithm UCB1, as well as a simpler baseline algorithm on multi-armed bandit problems
### introduction ###
In recent work~ CITATION , Bayesian methods for exploration in Markov decision processes (MDPs) and for solving known partially-observable Markov decision processes (POMDPs), as well as for exploration in the latter case, have been proposed
All such methods suffer from computational intractability problems for most domains of interest
The sources of intractability are two-fold
Firstly, there may be no compact representation of the current belief
This is especially true for POMDPs
Secondly, optimally behaving under uncertainty requires that we create an  augmented  MDP model in the form of a tree  CITATION , where the root node is the current belief-state pair and children are all possible subsequent belief-state pairs
This tree grows large very fast, and it is particularly problematic to grow in the case of continuous observations or actions
In this work, we concentrate on the second problem -- and consider algorithms for expanding the tree
Since the Bayesian exploration methods require a tree expansion to be performed, we can view the whole problem as that of  nested  exploration
For the simplest exploration-exploitation trade-off setting, bandit problems, there already exist nearly optimal, computationally simple methods~ CITATION
Such methods have recently been extended to tree search~ CITATION
This work proposes to take advantage of the special structure of belief trees in order to design nearly-optimal algorithms for expansion of nodes
In a sense, by recognising that the tree expansion problem in Bayesian look-ahead exploration methods is also an optimal exploration problem, we develop tree algorithms that can solve this problem efficiently
Furthermore, we are able to derive interesting upper and lower bounds for the value of branches and leaf nodes which can help limit the amount of search
The ideas developed are tested in the multi-armed bandit setting for which nearly-optimal algorithms already exist
The remainder of this section introduces the augmented MDP formalism employed within this work and discusses related work
Section~ discusses tree expansion in exploration problems and introduces some useful bounds
These bounds are used in the algorithms detailed in Section~, which are then evaluated in Section~
We conclude with an outlook to further developments
### abstract ###
Frequent episode discovery is a popular framework for pattern discovery in event streams
An episode is a partially ordered set of nodes with each node associated with an event type
Efficient (and separate) algorithms exist for episode discovery when the associated partial order is total  (serial episode) and trivial (parallel episode)
In this paper, we propose efficient algorithms for discovering frequent episodes with general partial orders
These algorithms can be easily specialized to discover serial or parallel episodes
Also, the algorithms are flexible enough to be specialized for mining in the space of certain interesting subclasses of partial orders
We point out that there is an inherent combinatorial explosion in frequent partial order mining and  most importantly, frequency alone is not a sufficient measure of interestingness
We propose a new interestingness measure for general partial order episodes and a discovery  method based on this measure, for filtering out uninteresting partial orders
Simulations demonstrate the effectiveness of our algorithms
### introduction ###
Frequent episode discovery  CITATION  is a popular framework for discovering temporal patterns in symbolic time series data, with applications in several domains like manufacturing  CITATION , telecommunication  CITATION , WWW  CITATION , biology  CITATION , finance  CITATION , intrusion detection  CITATION , text mining  CITATION  etc
The data in this framework is a single long time-ordered  stream of events and each temporal pattern (called an episode) is essentially a small, partially ordered  collection of nodes, with each node associated with a symbol (called event-type)
The partial order in the episode constrains the time-order in which events should appear in the data, in order for the events to constitute an occurrence of the episode
Patterns with a total order on their nodes are called  serial  episodes, while those with an empty partial order are called  parallel  episodes  CITATION
The task  is to unearth all episodes whose frequency in the data exceeds a user-defined threshold
Currently, separate algorithms exist in the literature for discovering frequent serial and parallel episodes in data streams  CITATION , while no algorithms are available for the case of episodes with general partial orders
Related work can be found in the context of sequential patterns  CITATION  where the data consists of multiple sequences and the sequential pattern is a small partially ordered collection of symbols
A sequential pattern is considered frequent  if there are enough sequences (in the data) in  which the pattern    occurs  atleast once
By contrast, in frequent episode discovery, we are looking for patterns that repeat often in  a single long stream of events
This makes the computational task quite different from that in sequential patterns
In this paper, we develop algorithms for discovering frequent episodes with general partial order constraints over their nodes
We restrict our attention to a subclass of patterns called  injective  episodes, where an event-type cannot appear more than once in a given episode
This facilitates the design of efficient algorithms with no restriction whatsoever on the partial orders of episodes
Further, our algorithms   can handle the usual expiry time constraints for episode occurrences (which limit the time-spans of valid occurrences to some user-defined maximum value)
Our algorithms can be easily specialized to either discover only frequent serial episodes or only frequent parallel episodes
Moreover, we can also specialize the method to focus the discovery process to certain classes   of partial order episodes which satisfy what we call as the  maximal subepisode property  (Serial episodes and parallel episodes are specific examples of classes that obey this property)
As we point out here, one of the difficulties in efficient discovery of general partial orders is that    there is an inherent combinatorial explosion in the number of frequent episodes of any given size
This is because, for any partial order episode with  SYMBOL  nodes,  there are an exponential number of subepisodes, also of size  SYMBOL , all of which would occur at least as often as the episode (Note that this problem does not arise in, eg , frequent serial episode discovery   because an  SYMBOL -node serial episode cannot have any  SYMBOL -node serial subepisode)
Thus, frequency alone is insufficient as a measure of interestingness for   episodes with general partial orders
To tackle this,    we propose a  new  measure called  bidirectional evidence , which captures some notion of entropy of relative frequencies of pairs of events occurring in either order   in the observed occurrences of an episode
The mining procedure now requires a user-defined threshold on bidirectional evidence in addition to the usual frequency threshold
We demonstrate the utility of our  algorithms through extensive empirical studies
The paper is organized as follows
In Sec ~, we briefly review the frequent episodes formalism  and define injective episodes
Sec ~ describes the finite state automata  (and its associated properties) for tracking occurrences of injective episodes
Algorithms for counting frequencies  of partial order episodes  are described in Sec ~
The candidate generation is described in Sec ~
Sec ~ describes our new interestingness measure
We present simulation results in Sec ~ and conclude in Sec ~
### abstract ###
Recently, different works proposed a new way to mine patterns in databases with pathological size
For example, experiments in genome biology usually provide databases with thousands of attributes (genes) but only tens of objects (experiments)
In this case, mining the ``transposed'' database runs through a smaller search space, and the Galois connection allows to infer the closed patterns of the original database
We focus here on constrained pattern mining for those unusual databases and give a theoretical framework for database and constraint transposition
We discuss the properties of constraint transposition and look into classical constraints
We then address the problem of generating the closed patterns of the original database satisfying the constraint, starting from those mined in the ``transposed'' database
Finally, we show how to generate all the patterns satisfying the constraint from the closed ones
### introduction ###
Frequent pattern mining is now well mastered, but these patterns, like association rules, reveal to be too numerous for the experts and very expensive to compute
They have to be filtered or constrained
However, mining and constraining have to be done jointly (pushing the constraint) in order to avoid combinatorial explosion~ CITATION
Mining under complex constraint has become today a hot topic and the subject of numerous works (e g ,~ CITATION )
Moreover, new domains are interested in our applications, and data schemes vary consequently
In genome biology, biological experiments are very expensive and time consuming
Therefore, only a small number of these experiments can be processed
However, thanks to new devices (such as biochips), experiments can provide the measurements of the activity of thousands of genes
This leads to databases with lots of columns (the genes) and few rows (the experiments)
Numerous works present efficient algorithms which mine the patterns satisfying a user defined constraint in large databases
This constraint can combine minimum and maximum frequency threshold together with other syntactical constraints
These algorithms are designed for databases with up to several millions of rows
However, their complexity is exponential in the number of columns and thus they are not suited for databases with too many columns, like those encountered in genome biology
Recently, two propositions were done to solve this problem: instead of mining the original database, these algorithms work on the ``transposed'' database, i e , columns of the original database become rows in the ``transposed'' database and rows becomes columns (this is indeed the same database but with a different representation)
Therefore the ``transposed'' database has significantly less columns than the original one
The CARPENTER algorithm  CITATION  is specifically designed for mining the frequent closed patterns, and our proposition  CITATION  uses a classical algorithm for mining closed patterns with a monotonic (or anti-monotonic) constraint
Both approaches use the transposition principle, however the problem of mining under constraints is not fully studied, specially for complex constraints (i e , conjunction and disjunction of simple constraints)
In this paper, we study this problem from a theoretical point of view
Our aim is to use classical algorithms (constrained pattern mining algorithms or closed patterns mining algorithms) in the ``transposed'' database and to use their output to regenerate patterns of the original database instead of directly mining in the original database
There are several interesting questions which we will therefore try to answer:   What kind of information can be gathered in the ``transposed'' database on the patterns of the original database
Is it possible to ``transpose'' the constraints  I e , given a database and a constraint, is it possible to find a ``transposed'' constraint such that  mining the ``transposed'' database with the ``transposed'' constraint gives information about the patterns which satisfy the original constraint in the original database
How can we regenerate the closed patterns in the original database from the patterns extracted in the ``transposed'' database
How can we generate  all  the itemsets satisfying a constraint using  the extracted closed patterns
These questions will be addressed respectively in Sec ~,  , ~and~
The organization of the paper is as follows: we start Sec ~ by recalling some usual definitions related to pattern mining and Galois connection
Then we show in Sec ~ how to transpose usual and complex constraints
Section~ is a complete discussion about mining constrained closed patterns using the ``transposed'' database and in Sec ~ we show how to use this to compute all (i e , not only closed) the patterns satisfying a constraint
Finally Sec ~ is a short conclusion
### abstract ###
We consider multi-label prediction problems with large output spaces under the assumption of  output sparsity  -- that the target (label) vectors have small support
We develop a general theory for a variant of the popular error correcting output code scheme, using ideas from compressed sensing for exploiting this sparsity
The method can be regarded as a simple reduction from multi-label regression problems to binary regression problems
We show that the number of subproblems need only be logarithmic in the total number of possible labels, making this approach radically more efficient than others
We also state and prove robustness guarantees for this method in the form of regret transform bounds (in general), and also provide a more detailed analysis for the linear prediction setting
### introduction ###
Suppose we have a large database of images, and we want to learn to predict who or what is in any given one
A standard approach to this task is to collect a sample of these images  SYMBOL  along with corresponding labels  SYMBOL , where  SYMBOL  if and only if person or object  SYMBOL  is depicted in image  SYMBOL , and then feed the labeled sample to a multi-label learning algorithm
Here,  SYMBOL  is the total number of entities depicted in the entire database
When  SYMBOL  is very large ( eg ~ SYMBOL ,  SYMBOL ), the simple one-against-all approach of learning a single predictor for each entity can become prohibitively expensive, both at training and testing time
Our motivation for the present work comes from the observation that although the output (label) space may be very high dimensional, the actual labels are often sparse
That is, in each image, only a small number of entities may be present and there may only be a small amount of ambiguity in who or what they are
In this work, we consider how this sparsity in the output space, or  output sparsity , eases the burden of large-scale multi-label learning {Exploiting output sparsity } A subtle but critical point that distinguishes output sparsity from more common notions of sparsity (say, in feature or weight vectors) is that we are interested in the sparsity of  SYMBOL  rather than  SYMBOL
In general,  SYMBOL  may be sparse while the actual outcome  SYMBOL  may not ( eg ~if there is much unbiased noise); and, vice versa,  SYMBOL  may be sparse with probability one but  SYMBOL  may have large support ( eg ~if there is little distinction between several labels)
Conventional linear algebra suggests that we must predict  SYMBOL  parameters in order to find the value of the  SYMBOL -dimensional vector  SYMBOL  for each  SYMBOL
A crucial observation -- central to the area of compressed sensing  CITATION  -- is that methods exist to recover  SYMBOL  from just  SYMBOL  measurements when  SYMBOL  is  SYMBOL -sparse
This is the basis of our approach {Our contributions } We show how to apply algorithms for compressed sensing to the output coding approach  CITATION
At a high level, the output coding approach creates a collection of subproblems of the form ``Is the label in this subset or its complement
'', solves these problems, and then uses their solution to predict the final label
The role of compressed sensing in our application is distinct from its more conventional uses in data compression
Although we do employ a sensing matrix to compress training data, we ultimately are not interested in recovering data explicitly compressed this way
Rather, we  learn to predict compressed label vectors , and then use sparse reconstruction algorithms to  recover uncompressed labels from these predictions
Thus we are interested in reconstruction accuracy of predictions, averaged over the data distribution
The main contributions of this work are:   A formal application of compressed sensing to prediction problems with output sparsity
An efficient output coding method, in which the number of required predictions is only logarithmic in the number of labels  SYMBOL , making it applicable to very large-scale problems
Robustness guarantees, in the form of regret transform bounds (in general) and a further detailed analysis for the linear prediction setting {Prior work } The ubiquity of multi-label prediction problems in domains ranging from multiple object recognition in computer vision to automatic keyword tagging for content databases has spurred the development of numerous general methods for the task
Perhaps the most straightforward approach is the well-known one-against-all reduction~ CITATION , but this can be too expensive when the number of possible labels is large (especially if applied to the power set of the label space  CITATION )
When structure can be imposed on the label space ( eg ~class hierarchy), efficient learning and prediction methods are often possible~ CITATION
Here, we focus on a different type of structure, namely output sparsity, which is not addressed in previous work
Moreover, our method is general enough to take advantage of structured notions of sparsity ( eg ~group sparsity) when available~ CITATION
Recently, heuristics have been proposed for discovering structure in large output spaces that empirically offer some degree of efficiency~ CITATION
As previously mentioned, our work is most closely related to the class of output coding method for multi-class prediction, which was first introduced and shown to be useful experimentally in  CITATION
Relative to this work, we expand the scope of the approach to multi-label prediction and provide bounds on regret and error which guide the design of codes
The loss based decoding approach~ CITATION  suggests decoding so as to minimize loss
However, it does not provide significant guidance in the choice of encoding method, or the feedback between encoding and decoding which we analyze here
The output coding approach is inconsistent when classifiers are used and the underlying problems being encoded are noisy
This is proved and analyzed in  CITATION , where it is also shown that using a Hadamard code creates a robust consistent predictor when reduced to binary regression
Compared to this method, our approach achieves the same robustness guarantees up to a constant factor, but requires training and evaluating exponentially (in  SYMBOL ) fewer predictors
Our algorithms rely on several methods from compressed sensing, which we detail where used
### abstract ###
Text of abstract We present a family of pairwise tournaments reducing  SYMBOL -class classification to binary classification
These reductions are provably robust against a constant fraction of binary errors, simultaneously matching the best possible computation  SYMBOL  and regret  SYMBOL
The construction also works for robustly selecting the best of  SYMBOL -choices by tournament
We strengthen previous results by defeating a more powerful adversary than previously addressed while providing a new form of analysis
In this setting, the error correcting tournament has depth  SYMBOL  while using  SYMBOL  comparators, both optimal up to a small constant
### introduction ###
We consider the classical problem of multiclass classification, where given an instance  SYMBOL , the goal is to predict  the most likely label  SYMBOL , according to some unknown  probability distribution
A common general approach to multiclass learning is to reduce a multiclass problem to a set of binary classification  problems~ CITATION
This approach is composable with any binary learning algorithm, including online algorithms, Bayesian algorithms, and even humans \shrink{ An alternative is to design a multiclass learning algorithm directly,  typically by extending an existing algorithm for binary classification
A difficulty with this direct approach is that  some algorithms cannot be easily modified to handle a different learning problem
For example, the first and still commonly used multiclass versions of the support vector machine may not even converge to the best possible predictor no matter how many examples are used (see  CITATION )
A single reduction yields a number of different multiclass algorithms in this way
A key technique for analyzing reductions is  regret analysis , bounding the regret of the resulting multiclass learner in terms of the  regret of the binary classifiers on the binary problems
Informally, regret is the difference in loss between the predictor and the best possible predictor on the same problem
Regret analysis is more refined than loss analysis as it bounds only avoidable, excess loss, thus the bounds remain meaningful for problems with high conditional noise }  A key technique for analyzing reductions is  regret analysis , which bounds the regret of the resulting multiclass classifier in terms of the average classification regret on the induced binary problems
Here  regret  (formally defined in Section~) is the difference between the incurred loss and the smallest achievable loss on the problem, i e , excess loss due to suboptimal prediction
The most commonly applied reduction is one-against-all, which creates a binary classification problem for each of the  SYMBOL  classes
The classifier for class  SYMBOL  is trained to predict whether the label is  SYMBOL  or not; predictions are then done by evaluating each binary classifier and randomizing over those that predict ``yes,'' or over all labels if all answers are ``no''
This simple reduction  is  inconsistent , in the sense that given optimal (zero-regret) binary classifiers, the reduction may not  yield an optimal multiclass classifier in the presence of noise
Optimizing squared loss of the binary predictions instead of the  SYMBOL  loss makes the approach consistent, but the resulting  multiclass regret scales as  SYMBOL  in the worst case, where  SYMBOL  is the average squared loss regret on the induced problems
The Probing reduction~ CITATION  upper bounds  SYMBOL  by  the average binary classification  regret
This composition gives a consistent reduction to binary classification, but it has a square root dependence on the binary regret  (which is undesirable as regrets are between 0 and 1)
The probabilistic error-correcting output code  approach (PECOC)~ CITATION  reduces  SYMBOL -class classification to learning  SYMBOL  regressors on the interval  SYMBOL , creating  SYMBOL  binary examples per multiclass example at both training and test time, with a test time computation of  SYMBOL
The resulting multiclass regret is bounded by  SYMBOL , removing the dependence on the number of classes  SYMBOL
When only a constant number of labels have non-zero probability given features, the computation can be reduced to  SYMBOL  per example~ CITATION
This state of the problem raises several questions:   Is there a consistent reduction from multiclass to binary classification  that does not have a square root dependence on  SYMBOL ~ CITATION
For example, an average binary regret of just  SYMBOL  may imply a PECOC multiclass regret of  SYMBOL
%At the level of  Is there a consistent reduction  that requires just  SYMBOL  computation,  matching the information theoretic lower bound
The well-known  SYMBOL  tree reduction distinguishes between  the labels using a balanced binary tree, with each non-leaf node predicting ``Is the correct multiclass label to the left or not
''~ CITATION
As shown in Section~, this method is inconsistent
Can the above be achieved with a reduction that only performs pairwise comparisons between classes
One fear associated with the PECOC approach is that it creates binary problems of the form ``What is the probability that the label is in a given random subset of labels ,''  which may be hard to solve
Although this fear is addressed by regret analysis (as the latter operates only on avoidable, excess loss), and is  overstated in some cases~ CITATION ,  it is still of some concern, especially with larger values of  SYMBOL
The error-correcting tournament family presented here answers all of these questions in the affirmative
It provides an exponentially faster in  SYMBOL  method for multiclass prediction with the resulting multiclass regret bounded by  SYMBOL , where  SYMBOL  is the average binary regret; and every binary classifier logically compares two distinct class labels
The result is based on a basic observation that if a non-leaf  node fails to predict its binary label, which may be unavoidable due to noise in the distribution,  nodes between this node and the root should have no preference for class label prediction
Utilizing this observation, we construct a reduction, called the  filter tree , which uses a  SYMBOL  computation per multiclass example at both training and test time, and whose multiclass regret is bounded by  SYMBOL  times the average binary regret
The decision process of a filter tree, viewed bottom up, can be viewed as a single-elimination tournament on a set of  SYMBOL  players
Using multiple independent single-elimination tournaments is of no use as it does not affect the  average  regret of an adversary controlling the binary classifiers
Somewhat surprisingly, it is possible to have  SYMBOL  complete single-elimination  tournaments between  SYMBOL  players in  SYMBOL  rounds, with no player playing twice in the same round
% ~ CITATION
An  error-correcting tournament ,  first pairs labels in such simultaneous single-elimination tournaments, followed by a final carefully weighted single-elimination tournament that decides among the  SYMBOL  winners of the first phase
As for the filter tree, test time evaluation can start at the root and proceed to a multiclass label with  SYMBOL  computation
This construction is also useful for the problem of robust search, yielding the first algorithm which allows the adversary  to err a constant fraction of the time in the ``full lie'' setting~ CITATION , where a comparator can missort any comparison
Previous work either applied to the ``half lie'' case where a comparator can fail to sort but can not actively missort~ CITATION , or to a ``full lie'' setting where an adversary has a fixed known bound on the number of lies~ CITATION  or a fixed budget on the fraction of errors so far~ CITATION
Indeed, it might even appear impossible to have an algorithm robust to a constant fraction of full lie errors since an error can always be reserved for the last comparison
Repeating the last comparison  SYMBOL  times defeats this strategy
The result here is also useful for the actual problem of tournament construction in games with real players
Our analysis does not assume that errors are   iid  ~ CITATION , or have known noise distributions~ CITATION  or known outcome distributions given player skills~ CITATION
Consequently, the tournaments we construct are robust against severe bias such as a biased referee or some forms of bribery and collusion
Furthermore, the tournaments we construct are shallow, requiring fewer rounds than  SYMBOL -elimination bracket tournaments, which do not satisfy the guarantee provided here
In an  SYMBOL - elimination bracket tournament , bracket  SYMBOL  is a single-elimination tournament on all players except the winners of brackets  SYMBOL
After the bracket winners are determined, the player winning the last bracket  SYMBOL  plays the winner of bracket  SYMBOL  repeatedly until one player has suffered  SYMBOL  losses (they start with  SYMBOL  and  SYMBOL  losses respectively)
The winner moves on to pair against the winner of bracket  SYMBOL , and the process continues until only one player remains
This method does not scale well to large  SYMBOL , as the final elimination phase takes  SYMBOL  rounds
Even for  SYMBOL  and  SYMBOL , our constructions have smaller maximum depth than bracketed  SYMBOL -elimination
To see that the bracketed  SYMBOL -elimination tournament does not satisfy our goal, note that the second-best player could defeat the first player in the first single elimination tournament, and then once more in the final elimination phase to win, implying that an adversary need control only two matches \paragraph{Paper overview} We begin by defining the basic concepts and introducing some of the  notation in Section~
Section~ shows that the simple divide-and-conquer tree approach is inconsistent, motivating the Filter Tree algorithm described in section~ (which applies to more general cost-sensitive multiclass problems)
Section~ proves that the algorithm has the best possible computational dependence, and gives two upper bounds on the regret of the returned (cost-sensitive) multiclass classifier
Subsection~ presents some experimental evidence that the Filter Tree is indeed a practical approach for multiclass classification
Section~ presents the error-correcting tournament family parametrized by an integer  SYMBOL , which controls the tradeoff between maximizing robustness ( SYMBOL  large) and minimizing depth ( SYMBOL  small)
Setting  SYMBOL  gives the Filter Tree, while  SYMBOL  gives a (multiclass to binary)  regret ratio of  SYMBOL  with  SYMBOL  depth
Setting  SYMBOL  gives regret ratio of  SYMBOL  with depth  SYMBOL
The results here provide a nearly free generalization of earlier work~ CITATION  in the robust search setting, to a more powerful adversary that can missort as well as fail to sort
%, and which is only charged according to two labels conditional  Section~ gives an algorithm independent lower bound of 2 on the regret ratio for large  SYMBOL
When the number of calls to a binary classifier is independent (or nearly independent) of the label predicted, we strengthen this lower bound to  SYMBOL  for large  SYMBOL
### abstract ###
We report a new optimal resolution for the statistical stratification problem under proportional sampling allocation among strata
Consider a finite population of  N  units, a random sample of  n  units selected from this population and a number  L  of strata
Thus, we have to define which units belong to each stratum so as to minimize the variance of a total estimator for one desired variable of interest in each stratum, and consequently reduce the overall variance for such quantity
In order to solve this problem, an exact algorithm based on the concept of minimal path in a graph is proposed and assessed
Computational results using real data from IBGE (Brazilian Central Statistical Office) are provided \\ [0 7em] {Keywords:} Stratification; Proportional Allocation; Variance; Minimal Path
### introduction ###
A common procedure in sampling surveys is partitioning the elements of a population, before distributing the sample on it, in such a way to obtain most useful information from the data to be collected
This procedure is called stratification
It may have different aims, such as to guarantee obtaining information for some or all the geopolitical regions of a country, or to provide more precision in estimating population quantities by identifying strata with more homogeneous elements into them, according to one or more variables
In this latter case, the stratification is also called statistical stratification
A principal use of statistical stratification, in order to obtain a better precision, is in defining what percentage of the sample must be taken from each stratum once we have chosen a non-uniform allocation scheme, that is, a non-trivial functional relation between the size of each stratum and the number of sample units to be collected in it
Thus, it is important to consider the allocation scheme itself in order to do a suitable statistical stratification
In this paper, we propose an exact algorithm to solve the statistical stratification problem, that we call simply stratification problem, considering a simple non-uniform allocation scheme
Specifically, this method intends to solve the problem of optimal stratification with stratified simple random sampling without replacement  CITATION  using proportional allocation
In this problem, we must divide a population of size  SYMBOL  into  SYMBOL  strata considering an auxiliary variable  SYMBOL , also called the size variable, whose values are known for all units in the population
The first stratum is defined as the set of units in the population whose  SYMBOL   values are lower than or equal to a constant value  SYMBOL  , the second one as the set of units whose  SYMBOL  values are greater than  SYMBOL   and lower than or equal  to  SYMBOL   and so on
Based on this definition the stratum  SYMBOL   SYMBOL  is defined as the set of units in population with values of  SYMBOL  belonging to the interval  SYMBOL , where   SYMBOL  are the boundaries of each stratum, and the stratum  SYMBOL  corresponds to the set of observations which values are greater than  SYMBOL
The problem of optimal stratification consists in to find boundaries  SYMBOL  which minimize the variance of the estimator of total for one or more variables  SYMBOL  of study that are supposed to have some correlation with the  SYMBOL  variable, or even the  SYMBOL  variable properly
Aiming to solve this problem, a new algorithm, when proportional allocation is used, is proposed using the idea of minimal path in graphs  CITATION
This paper is organized in five sections
In section 2, we present some basic concepts about stratified simple random sampling
In section 3, we define the problem of stratification to be tackled in this work and offer a brief discussion about different approaches to this topic
We propose, in section 4, an algorithm based on Graph Theory in order to provide exact solutions to the stratification problem defined in section 3
Finally, we present some computational results and considerations about the new algorithm
### abstract ###
In a recent breakthrough, [Bshouty et al , 2005] obtained the first passive-lear\-ning algorithm for DNFs under the uniform distribution
They showed that DNFs are learnable  in the Random Walk and Noise Sensitivity models
We extend their results in several directions
We first show that thresholds of parities, a natural class encompassing DNFs, cannot be learned efficiently in the Noise Sensitivity model  using only statistical queries
In contrast, we show that a cyclic version of the Random Walk model allows to learn efficiently  polynomially weighted thresholds of parities
We also extend the algorithm of Bshouty et al to the case of Unions of Rectangles, a natural generalization of DNFs to  SYMBOL
### introduction ###
Learning Boolean formulae in Disjunctive Normal Form (DNF)  has been a central problem in the computational learning theory literature since Valiant's seminal paper on PAC learning~ CITATION
In~ CITATION , it was shown that DNFs can be learned  using membership queries, a form of active learning
Jackson's algorithm, also known as Harmonic Sieve (\hs),  uses a clever combination of two fundamental techniques in learning, Harmonic Analysis and Boosting
The use of Harmonic Analysis in the study of Boolean functions was introduced in~ CITATION
It was subsequently used as the basis of a learning algorithm for  SYMBOL  circuits in~ CITATION
The Harmonic Analysis  used in the \hs\ algorithm is based on a parity-finding algorithm of Goldreich and Levin~ CITATION , which  was first applied to a learning problem by Kushilevitz and Mansour~ CITATION
Hypothesis boosting, a technique to reduce the classification error of a learning algorithm, was introduced by Schapire~ CITATION
The boosting algorithm used by \hs\ is actually due to Freund~ CITATION
In a recent breakthrough, Bshouty et al ~ CITATION  obtained the first passive learning algorithm for DNFs
Their algorithm is based on a modification of \hs\ which focuses on low-degree Fourier coefficients
That variant of \hs, called Bounded Sieve (\bs),  was first obtained in~ CITATION
In~ CITATION , \bs\ was used to learn DNFs under the uniform distribution in two natural passive learning models
The first one is the Random Walk model, where examples, instead of being  iid  , follow a random walk on the  Boolean cube (see also~ CITATION  for related work)
The second model is the closely related Noise Sensitivity model, where this time examples come in pairs, the second instance being a noisy version of the first one
The results of~ CITATION  are interesting in that they give a learning algorithm for DNFs in a case where the observer has no control over the examples provided
However the problem of learning DNFs under the uniform distribution when examples are  iid 
still remains open
It is known that DNFs cannot be learned in the more restrictive Statistical Query model (introduced in~ CITATION ) where one can ask only about statistics over random examples~ CITATION
Jackson~ CITATION  also showed that \hs\ applies to thresholds of parities (TOP), a class that can express DNFs and decision trees with only polynomial increase in size, and extended his algorithm to the non-Boolean case of unions of rectangles, a generalization of DNFs to  SYMBOL  (where  SYMBOL )
Whether those classes of functions can be learned in the Random Walk and Noise Sensitivity models was left open by~ CITATION
Our contribution is threefold
We first show that TOPs cannot be learned in the Noise Sensitivity model using statistical queries (SQs)
As far as we know, this is the first example of a negative result for ``second-order'' statistical queries, i e queries on pairs of examples
This does not rule out the possibility of learning TOPs in the Random Walk model although it provides evidence that the techniques of~ CITATION  cannot be easily extended to that case
On the other hand, we show that a simple variant of the Random Walk model where the component updates follow a fixed cycle allows to learn TOPs efficiently
This seems to be the first not-too-contrived passive model in which TOPs are efficiently learnable with respect to the uniform distribution
Actually, one can perform the Harmonic Sieve in this Cyclic Random Walk model, and we also show that this model is strictly weaker than the active setting under a standard cryptographic assumption
Finally we extend  the techniques of~ CITATION  and  CITATION  to  the non-Boolean domain  SYMBOL  and use this to learn unions of rectangles in the Noise Sensitivity and Random Walk models
This last result turns out to be rather straightforward once the proper analogues to the Boolean case are found
In Section~, we introduce the learning models and give a brief review of Fourier analysis
The negative result for learning TOPs is derived in Section~
The learning algorithms for TOPs and Unions of Rectangles are presented in Sections  and  respectively
### abstract ###
Fitness functions based on test cases are very common in Genetic Programming (GP)
This process can be assimilated to a learning task, with the inference of models from a limited number of samples
This paper is an investigation on two methods to improve generalization in GP-based learning: 1) the selection of the best-of-run individuals using a three data sets methodology, and 2) the application of parsimony pressure in order to reduce the complexity of the solutions
Results using GP in a binary classification setup show that while the accuracy on the test sets is preserved, with less variances compared to baseline results, the mean tree size obtained with the tested methods is significantly reduced
### introduction ###
GP is particularly suited for problems that can be assimilated to learning tasks, with the minimization of the error between the obtained and desired outputs for a limited number of test cases -- the training data, using a ML terminology
Indeed, the classical GP examples of symbolic regression, boolean multiplexer and artificial ant  CITATION  are only simple instances of well-known learning problems (i e respectively regression, binary classification and reinforcement learning)
In the early years of GP, these problems were tackled using a single data set, reporting results on the same data set that was used to evaluate the fitnesses during the evolution
This was justifiable by the fact that these are toy problems used only to illustrate the potential of GP
In the ML community, it is recognized that such methodology is flawed, given that the learning algorithm can overfit the data used during the training and perform poorly on unseen data of the same application domain  CITATION
Hence, it is important to report results on a set of data that was not used during the learning stage
This is what we call in this paper a  two data sets methodology , with a training set used by the learning algorithm and a test set used to report the performance of the algorithm on unseen data, which is a good indicator of the algorithm's generalization (or robustness) capability
Even though this methodology has been widely accepted and applied in the ML and PR communities for a long time, the EC community still lags behind by publishing papers that are reporting results on data sets that were used during the evolution (training) phase
This methodological problem has already been spotted (see  CITATION ) and should be less and less common in the future
The two data sets methodology prevents reporting flawed results of learning algorithms that overfit the training set
But this does not prevent by itself overfitting the training set
A common approach is to add a third data set -- the validation set -- which helps the learning algorithm to measure its generalization capability
This validation set is useful to interrupt the learning algorithm when overfitting occurs and/or select a configuration of the learning machine that maximizes the generalization performances
This third data set is commonly used to train classifiers such as back-propagation neural networks and can be easily applied to EC-based learning
But this approach has an important drawback: it removes a significant amount of data from the training set, which can be harmful to the learning process
Indeed, the richer the training set, the more representative it can be of the real data distribution, and the more the learning algorithm can be expected to converge toward robust solutions
In the light of these considerations, an objective of this paper is to investigate the effect of a validation set to select the best-of-run individuals for a GP-based learning application
Another concern of the ML and PR communities is to develop learning algorithms that generate simple solutions
An argument behind this is the Occam's Razor principle, which states that between solutions of comparable quality, the simplest solutions must be preferred
Another argument is the minimum description length principle  CITATION , which states that the ``best'' model is the one that minimizes the amount of information needed to encode the model and the data given the model
Preference for simpler solutions and overfitting avoidance are closely related: it is more likely that a complex solution incorporates specific information from the training set, thus overfitting the training set, compared to a simpler solution
But, as mentioned in  CITATION , this argumentation should be taken with care as too much emphasis on minimizing complexity can prevent the discovery of more complex yet more accurate solutions
There is a strong link between the minimization of complexity in GP-based learning and the control of code bloat  CITATION , that is an exaggerated growth of program size in the course of GP runs
Even though complexity and code bloat are not exactly the same phenomenon, as some kind of bloat is generated by neutral pieces of code that have no effect on the actual complexity of the solutions, most of the mechanisms proposed to control it  CITATION  can also be used to minimize the complexity of solutions obtained by GP-based learning
This paper is a study of GP viewed as a learning algorithm
More specifically, we investigate two techniques to increase the generalization performance and decrease the complexity of the models: 1) use of a validation set to select best-of-run individuals that generalize well, and 2) use of lexicographic parsimony pressure  CITATION  to reduce the complexity of the generated models
These techniques are tested using a GP encoding for binary classification problems, with vectors taken from the learning sets as terminals, and mathematical operations to manipulate these vectors as branches
This approach is tested on six different data sets from the UCI ML repository  CITATION
Even if the proposed techniques are tested in a specific context, we argue that they can be extended to the frequent situations where GP is used as a learning algorithm
### abstract ###
This paper addresses the general problem of domain adaptation which arises in a variety of applications where the distribution of the labeled sample available somewhat differs from that of the test data
Building on previous work by \emcite{bendavid}, we introduce a novel distance between distributions,  discrepancy distance , that is tailored to adaptation problems with arbitrary loss functions
We give Rademacher complexity bounds for estimating the discrepancy distance from finite samples for different loss functions
Using this distance, we derive novel generalization bounds for domain adaptation for a wide family of loss functions
We also present a series of novel adaptation bounds for large classes of regularization-based algorithms, including support vector machines and kernel ridge regression based on the empirical discrepancy
This motivates our analysis of the problem of minimizing the empirical discrepancy for various loss functions for which we also give novel algorithms
We report the results of preliminary experiments that demonstrate the benefits of our discrepancy minimization algorithms for domain adaptation
### introduction ###
In the standard PAC model  CITATION  and other theoretical models of learning, training and test instances are assumed to be drawn from the same distribution
This is a natural assumption since, when the training and test distributions substantially differ, there can be no hope for generalization
However, in practice, there are several crucial scenarios where the two distributions are more similar and learning can be more effective
One such scenario is that of  domain adaptation , the main topic of our analysis
The problem of domain adaptation arises in a variety of applications in natural language processing  CITATION , speech processing  CITATION , computer vision  CITATION , and many other areas
Quite often, little or no labeled data is available from the  target domain , but labeled data from a  source domain  somewhat similar to the target as well as large amounts of unlabeled data from the target domain are at one's disposal
The domain adaptation problem then consists of leveraging the source labeled and target unlabeled data to derive a hypothesis performing well on the target domain
A number of different adaptation techniques have been introduced in the past by the publications just mentioned and other similar work in the context of specific applications
For example, a standard technique used in statistical language modeling and other generative models for part-of-speech tagging or parsing is based on the maximum a posteriori adaptation which uses the source data as prior knowledge to estimate the model parameters  CITATION
Similar techniques and other more refined ones have been used for training maximum entropy models for language modeling or conditional models  CITATION
The first theoretical analysis of the domain adaptation problem was presented by \emcite{bendavid}, who gave VC-dimension-based generalization bounds for adaptation in classification tasks
Perhaps, the most significant contribution of this work was the definition and application of a distance between distributions, the  SYMBOL  distance, that is particularly relevant to the problem of domain adaptation and that can be estimated from finite samples for a finite VC dimension, as previously shown by \emcite{kifer}
This work was later extended by \emcite{blitzer} who also gave a bound on the error rate of a hypothesis derived from a weighted combination of the source data sets for the specific case of empirical risk minimization
A theoretical study of domain adaptation was presented by \emcite{nips09}, where the analysis deals with the related but distinct case of adaptation with multiple sources, and where the target is a mixture of the source distributions
This paper presents a novel theoretical and algorithmic analysis of the problem of domain adaptation
It builds on the work of \emcite{bendavid} and extends it in several ways
We introduce a novel distance, the  discrepancy distance , that is tailored to comparing distributions in adaptation
This distance coincides with the  SYMBOL  distance for 0-1 classification, but it can be used to compare distributions for more general tasks, including regression, and with other loss functions
As already pointed out, a crucial advantage of the  SYMBOL  distance is that it can be estimated from finite samples when the set of regions used has finite VC-dimension
We prove that the same holds for the discrepancy distance and in fact give data-dependent versions of that statement with sharper bounds based on the Rademacher complexity
We give new generalization bounds for domain adaptation and point out some of their benefits by comparing them with previous bounds
We further combine these with the properties of the discrepancy distance to derive data-dependent Rademacher complexity learning bounds
We also present a series of novel results for large classes of regularization-based algorithms, including support vector machines (SVMs)  CITATION  and kernel ridge regression (KRR)  CITATION
We compare the pointwise loss of the hypothesis returned by these algorithms when trained on a sample drawn from the target domain distribution, versus that of a hypothesis selected by these algorithms when training on a sample drawn from the source distribution
We show that the difference of these pointwise losses can be bounded by a term that depends directly on the empirical discrepancy distance of the source and target distributions
These learning bounds motivate the idea of replacing the empirical source distribution with another distribution with the same support but with the smallest discrepancy with respect to the target empirical distribution, which can be viewed as reweighting the loss on each labeled point
We analyze the problem of determining the distribution minimizing the discrepancy in both 0-1 classification and square loss regression
We show how the problem can be cast as a linear program (LP) for the 0-1 loss and derive a specific efficient combinatorial algorithm to solve it in dimension one
We also give a polynomial-time algorithm for solving this problem in the case of the square loss by proving that it can be cast as a semi-definite program (SDP)
Finally, we report the results of preliminary experiments showing the benefits of our analysis and discrepancy minimization algorithms
In section~, we describe the learning set-up for domain adaptation and introduce the notation and Rademacher complexity concepts needed for the presentation of our results
Section~ introduces the discrepancy distance and analyzes its properties
Section~ presents our generalization bounds and our theoretical guarantees for regularization-based algorithms
Section~ describes and analyzes our discrepancy minimization algorithms
Section~ reports the results of our preliminary experiments
### abstract ###
We discuss multi-task online learning when a decision maker has to deal simultaneously with  SYMBOL  tasks
The tasks are related, which is modeled by imposing that the  SYMBOL --tuple of actions taken by the decision maker needs to satisfy certain constraints
We give natural examples of such restrictions and then discuss a general class of tractable constraints, for which we introduce computationally efficient ways of selecting actions, essentially by reducing to an on-line shortest path problem
We briefly discuss ``tracking'' and ``bandit'' versions of the problem and extend the model in various ways, including non-additive global losses and uncountably infinite sets of tasks
### introduction ###
Multi-task learning has recently received considerable attention, see  CITATION
In multi-task learning problems, one simultaneously learns several tasks that are related in some sense
The relationship of the tasks has been modeled in different ways in the literature
In our setting, a decision maker chooses an action simultaneously for each of  SYMBOL  given tasks, in a repeated manner (To each of these tasks corresponds a game, and we will use interchangeably the concepts of game and task ) The relatedness is accounted for by putting some hard constraints on these simultaneous actions
As a motivating example, consider a distance-selling company that designs several commercial offers for its numerous customers, and the customers are ordered (say) by age
The company has to choose whom to send which offer
A loss of earnings is suffered whenever a customer does not receive the commercial offer that would have been best for him
Basic marketing considerations suggest that offers given to customers with similar age should not be very different, so the company selects a batch of offers that satisfy such a constraint
Additional budget constraint may limit further the set of batches from which the company may select
After the offers are sent out, the customers' responses are observed (at least partially) and new offers are selected and sent
We model such situations by playing many repeated games simultaneously with the restriction that the vector of actions that can be selected at a time needs to belong to a previously given set
This set in determined beforehand by the budget and marketing constraints discussed above
The goal of the decision maker is to minimize the total accumulated regret (across the many games and through time), that is, perform, on the long run, almost as well as the best constant vector of actions satisfying the constraint
The problem of playing repeatedly several games simultaneously has been considered by  CITATION  who studies convergence to Nash equilibria but does not address the issue of computational feasibility when a large number of games is played
On-line multi-task learning problems were also studied by  CITATION  and  CITATION
As the latter reference, we consider minimizing regret simultaneously in parallel, by enforcing however some hard constraints
As  CITATION , we measure the total loss as the sum of the losses suffered in each game but assume that all tasks have to be performed at each round (This assumption is, however relaxed in Section , where we consider global losses more general than the sums of losses ) The main additional difficulty we face is the requirement that the decision maker chooses from a restricted subset of vectors of actions
In previous models restrictions were only considered on the comparison class, but not on the way the decision maker plays
We formulate the problem in the framework of on-line regret minimization, see  CITATION  for a survey
The main challenge is to construct a strategy for playing the many games simultaneously with small regret such that the strategy has a manageable computational complexity
We show that in various natural examples the computational problem may be reduced to an online shortest path problem in an associated graph for which well-known efficient algorithms exist (We however propose a specific scheme for implementation that is slightly more effective )  The results can be extended easily to the ``tracking'' case in which the goal of the decision maker is to perform as well as the best strategy that can change the vector of actions (taken from the restricted set) at a limited number of times
We also consider the ``bandit'' version of the problem when the decision maker, instead of observing the losses of all actions in all games, only learns the sum of the losses of the chosen actions
Finally, we also consider cases when there are infinitely many tasks, indexed by real numbers
In such cases the decision maker chooses a function from a certain restricted class of functions
We show examples that are natural extensions of the cases we consider for finitely many tasks and discuss the computational issues that are closely related to the theory of exact simulation of continuous-time Markov chains
We concentrate on exponentially weighted average forecasters because, when compared to its most likely competitors, that is, follow-the-leader-type algorithms, they have better performance guarantees, especially in the case of bandit feedback
Besides, the two families of forecasters, as pointed out by  CITATION , usually have implementation complexities of the same order
### abstract ###
The problem of completing a low-rank matrix from a subset of its entries is often encountered in the analysis of incomplete data sets exhibiting an underlying factor model with applications in collaborative filtering, computer vision and control
Most recent work had been focused on constructing efficient algorithms for exact or approximate recovery of the missing matrix entries and proving lower bounds for the number of known entries that guarantee a successful recovery with high probability
A related problem from both the mathematical and algorithmic point of view is the distance geometry problem of realizing points in a Euclidean space from a given subset of their pairwise distances
Rigidity theory answers basic questions regarding the uniqueness of the realization satisfying a given partial set of distances
We observe that basic ideas and tools of rigidity theory can be adapted to determine uniqueness of low-rank matrix completion, where inner products play the role that distances play in rigidity theory
This observation leads to an efficient randomized algorithm for testing both local and global unique completion
Crucial to our analysis is a new matrix, which we call the  completion matrix , that serves as the analogue of the rigidity matrix
### introduction ###
Can the missing entries of an incomplete real valued matrix be recovered
Clearly, a matrix can be completed in an infinite number of ways by replacing the missing entries with arbitrary values
In order for the completion question to be of any value we must restrict the matrix to belong to a certain class of matrices
A popular class of matrices are the matrices of limited rank and the problem of completing a low-rank matrix from a subset of its entries has received a great deal of attention lately
The completion problem comes up naturally in a variety of settings
One of these is the  Netflix  problem  CITATION , where users submit rankings for only a small subset of movies, and one would like to infer their preference of unrated movies
The data matrix of all user-ratings may be approximately low-rank because it is believed that only a few factors contribute to an individual's preferences
The completion problem also arises in computer vision, in the problem of inferring three-dimensional structure from motion  CITATION , as well as in many other data analysis, machine learning  CITATION , control  CITATION  and other problems that are modeled by a factor model
Numerous completion algorithms have been proposed over the years, see eg ,  CITATION
Many of the algorithms relax the non-convex rank constraint by the convex set of semidefinite positive matrices and solve a convex optimization problem using semidefinite programming (SDP)  CITATION
Recently, using techniques from compressed sensing  CITATION , Cand\`es and Recht  CITATION  proved that if the pattern of missing entries is random then the minimization of the convex nuclear norm (the  SYMBOL  norm of the singular values vector) finds (with high probability) the exact completion of most  SYMBOL  matrices of rank  SYMBOL  as long as the number of observed entries  SYMBOL  satisfies  SYMBOL , where  SYMBOL  is some function
Even more recently, Keshavan, Oh, and Montanari  CITATION  improved the bound to  SYMBOL  and also provided an efficient completion algorithm
These fascinating recent results do not provide, however, a solution to the more practical case in which the pattern of missing entries is non-random
Given a specific pattern of missing entries, extremely desirable would be an algorithm that can determine the uniqueness of a rank- SYMBOL  matrix completion
Prior to running any of the numerous existing completion algorithms such as SDP it is important for the analyst to know if such a completion is indeed unique
Building on ideas from rigidity theory (see, eg ,  CITATION ) we propose an efficient randomized algorithm that determines whether or not it is possible to uniquely complete an incomplete matrix to a matrix of specified rank  SYMBOL
Our proposed algorithm does not attempt to complete the matrix but only determines if a unique completion is possible
We introduce a new matrix, which we call  the completion matrix  that serves as the analogue of the rigidity matrix in rigidity theory
The rank of the completion matrix determines a property which we call infinitesimal completion
Whenever the completion matrix is large and sparse its rank can be efficiently determined using iterative methods such as LSQR  CITATION
As in rigidity theory, we will also make the distinction between  local  completion and  global  completion
The analogy between rigidity and completion is quite striking, and we believe that many of the results in rigidity theory can be usefully translated to the completion setup
Our randomized algorithm for testing local completion is based on a similar randomized algorithm for testing local rigidity that was suggested by Hendrickson  CITATION , whereas our randomized algorithm for testing global completion is based on the recent randomized global rigidity testing algorithm of Gortler, Healy, and Thurston  CITATION  who proved a conjecture by Connelly  CITATION  for the characterization of globally rigid frameworks
Due to the large body of existing work in rigidity theory we postpone some of the translation efforts to the future
The organization of the paper is as follows
Section  contains a glossary of definitions and results in rigidity theory on which our algorithms are based
In Section  we analyze the low-rank completion problem for the particular case of positive semidefinite Gram matrices and present algorithms for testing local and global completion of such matrices
In Section  the analysis is generalized to the more common completion problem of general low-rank rectangular matrices and corresponding algorithms are provided
Section  is concerned with the combinatorial characterization of entry patterns that can be either locally completed or globally completed
In particular, we present a simple combinatorial characterization for rank-1 matrices and comment on the rank-2 and rank- SYMBOL  ( SYMBOL ) cases
In Section  we detail the results of extensive numerical simulations in which we tested the performance of our algorithms while verifying the theoretical bounds of  CITATION  for matrices with random missing patterns
Finally, Section  is a summary and discussion
### abstract ###
We introduce a new protocol for prediction with expert advice in which each expert evaluates the learner's and his own performance using a loss function that may change over time and may be different from the loss functions used by the other experts
The learner's goal is to perform better or not much worse than each expert, as evaluated by that expert, for all experts simultaneously
If the loss functions used by the experts are all proper scoring rules and all mixable, we show that the defensive forecasting algorithm enjoys the same performance guarantee as that attainable by the Aggregating Algorithm in the standard setting and known to be optimal
This result is also applied to the case of ``specialist'' (or ``sleeping'') experts
In this case, the defensive forecasting algorithm reduces to a simple modification of the Aggregating Algorithm
### introduction ###
We consider the problem of online sequence prediction
A process generates outcomes  SYMBOL  step by step
At each step  SYMBOL , a learner tries to guess the next outcome announcing his prediction  SYMBOL
Then the actual outcome  SYMBOL  is revealed
The quality of the learner's prediction is measured by a loss function: the learner's loss at step  SYMBOL  is  SYMBOL
Prediction with expert advice is a framework that does not make any assumptions about the generating process
The performance of the learner is compared to the performance of several other predictors called experts
At each step, each expert gives his prediction  SYMBOL , then the learner produces his own prediction  SYMBOL  (possibly based on the experts' predictions at the last step and the experts' predictions and outcomes at all the previous steps), and the accumulated losses are updated for the learner  and for the experts
There are many algorithms for the learner in this framework; for a review, see~ CITATION
In practical applications of the algorithms for prediction with expert advice, choosing the loss function is often a problem
The task may have no natural measure of loss, except the vague concept that the closer the prediction to the outcome the better
Thus one can select among several common loss functions, for example, the quadratic loss (reflecting the idea of least squares methods) or the logarithmic loss (which has an information theory background)
A similar issue arises when experts themselves are prediction algorithms that optimize some losses internally
Then it is unfair to these experts when the learner competes with them according to a ``foreign'' loss function
This paper introduces a new version of the framework of prediction with expert advice where there is no single fixed loss function but some loss function is linked to every expert
The performance of the learner is compared to the performance of each expert according to the loss function linked to that expert
Informally speaking, each expert has to be convinced that the learner performs almost as well as, or better than, that expert himself
We prove that a known algorithm for the learner, the defensive forecasting algorithm  CITATION , can be applied in the new setting and gives the same performance guarantee as that attainable in the standard setting, provided all loss functions are proper scoring rules \ifFULLThe only new requirement is that all loss functions used by the experts must be ``similar''
All strictly proper scoring rules (in particular, the quadratic and logarithmic loss functions) are similar to each other in this sense \blueend Another framework to which our methods can be fruitfully applied is that of ``specialist experts'': see, eg ,  CITATION ,  CITATION , and  CITATION
We generalize some of the known results in the case of mixable loss functions
To keep presentation as simple as possible, we restrict ourselves to binary outcomes  SYMBOL , predictions from  SYMBOL , and a finite number of experts
We formulate our results for mixable loss functions only
However, these results can be easily transferred  to more general settings (non-binary outcomes, arbitrary prediction spaces, countably many experts, second-guessing experts, etc )\ where the methods of~ CITATION  work
### abstract ###
We present  multiplicative updates for solving hard  and soft margin support  vector  machines  (SVM)  with non-negative  kernels
They follow as a natural extension of the updates for non-negative matrix factorization
No additional parameter  setting, such  as choosing learning,   rate   is   required
Experiments   demonstrate   rapid convergence to good classifiers
We analyze the rates of asymptotic convergence of the updates and  establish tight bounds
We test the performance on  several datasets using  various non-negative kernels and report  equivalent generalization errors  to that of  a standard SVM
### introduction ###
Support  vector  machines  (SVM)  are  now  routinely  used  for  many classification problems  in machine learning~ CITATION  due to their  ease of use and  ability to generalize
In  the basic case, the input data,  corresponding to two groups, is  mapped into a higher dimensional space,  where a  maximum-margin hyperplane is  computed to separate  them
The  ``kernel  trick''  is used  to  ensure that  the mapping into higher dimensional  space is never explicitly calculated
This can  be formulated as a non-negative  quadratic programming (NQP) problem    and    there   are    efficient    algorithms   to    solve it~ CITATION
SVM  can be  trained using  variants  of the  gradient descent  method applied   to  the   NQP
Although   these  methods   can   be  quite efficient~ CITATION , their drawback  is the requirement of setting  the   learning  rate
Subset  selection  methods   are  an alternative      approach     to      solving     the      SVM     NQP problem~ CITATION
At  a  high  level  they  work  by splitting the  arguments of the  quadratic function at  each iteration into two sets: a fixed set, where the arguments are held constant, and a  working  set  of  the  variables being  optimized  in  the  current iteration
These methods~ CITATION ,  though efficient in space  and time,  still require a  heuristic to  exchange arguments between the working and the fixed sets
An alternative algorithm for solving  the general NQP problem has been applied   to  SVM   in~ CITATION
The  algorithm,   called M\textsuperscript{3},  uses   multiplicative  updates  to  iteratively converge to the solution
It  does not require any heuristics, such as setting the learning rate or choosing how to split the argument set
In this  paper we reformulate the  dual SVM problem  and demonstrate a connection   to   the    non-negative   matrix   factorization   (NMF) algorithm~ CITATION
NMF employs multiplicative updates and is  very successful in practice  due to its  independence from the learning rate parameter, low  computational complexity and the ease of implementation
The   new   formulation   allows   us   to   devise multiplicative updates for solving  SVM with non-negative kernels (the output value of the kernel function is greater or equal to zero)
The requirement  of a non-negative  kernel is  not very  restrictive since their set includes many  popular kernels, such as Gaussian, polynomial of  even  degree  etc
The  new  updates possess  all  of  the  good properties   of  the   NMF  algorithm,   such  as   independence  from hyper-parameters,  low  computational   complexity  and  the  ease  of implementation
Furthermore, the  new algorithm converges faster than the   previous   multiplicative    solution   of   the   SVM   problem from~ CITATION  both asymptotically  (a proof is provided) and in practice
We also  show how  to solve the  SVM problem  with soft margin using the new algorithm
### abstract ###
A collaborative filtering system recommends to users products that similar users like
Collaborative filtering systems influence purchase decisions, and hence have become targets of manipulation by unscrupulous vendors
We provide theoretical and empirical results demonstrating that while common nearest neighbor algorithms, which are widely used in commercial systems, can be highly susceptible to manipulation, two classes of collaborative filtering algorithms which we refer to as  linear  and  asymptotically linear  are relatively robust
These results provide guidance for the design of future collaborative filtering systems
### introduction ###
While the expanding universe of products available via Internet commerce provides consumers with valuable options, sifting through the numerous alternatives to identify desirable choices can be challenging
Collaborative filtering (CF) systems aid this process by recommending to users products desired by similar individuals
At the heart of a CF system is an algorithm that predicts whether a given user will like various products based on his past behavior and that of other users
Nearest neighbor (NN) algorithms, for example, have enjoyed wide use in commercial CF systems, including those of Amazon, Netflix, and Youtube  CITATION
A prototypical NN algorithm stores each user's history, which may include, for instance, his product ratings and purchase decisions
To predict whether a particular user will like a particular product, the algorithm identifies a number of other users with similar histories
A prediction is then generated based on how these so-called neighbors have responded to the product
This prediction could be, for example, a weighted average of past ratings supplied by neighbors
Because purchase decisions are influenced by CF systems, they have become targets of manipulation by unscrupulous vendors
For instance, a vendor can create multiple online identities and use each to rate his own product highly and competitors' products poorly
As an example, Amazon's CF system was manipulated so that users who viewed a spiritual guide written by a well-known Christian evangelist were subsequently recommended a sex manual for gay men  CITATION
Although this incident may not have been driven by commercial motives, it highlights the vulnerability of CF systems
The research literature offers further empirical evidence that NN algorithms are susceptible to manipulation  CITATION
In order to curb manipulation, one might consider authenticating each user by asking for, say, a credit card number to limit the number of fake identities
This may be effective in some situations
However, in web services that do not facilitate financial transactions, such as Youtube, requiring authentication would intrude privacy and drive users away
One might also consider using only customer purchase data, when they are available, as a basis for recommendations because they are likely generated by honest users
Recommendation quality may be improved, however, if higher-volume data such as page views are also properly utilized
In this paper, we seek to understand the extent to which manipulators can hurt the performance of CF systems and how CF algorithms should be designed to abate their influence
We find that, while NN algorithms can be quite sensitive to manipulation, CF algorithms that carry out predictions based on a particular class of probabilistic models are surprisingly robust
For reasons that we will explain in the paper, we will refer to algorithms of this kind as  linear CF algorithms
We find that as a user rates an increasing number of products, the average accuracy of predictions made by a linear CF algorithm becomes insensitive to manipulated data
For instance, even if half of all ratings are provided by manipulators who try to promote half of the products, predictions for users with long histories will barely be distorted, on average
To provide some intuition for why our results should hold, we now offer an informal argument
A robust CF algorithm should learn from its mistakes
In particular, differences between its predictions and actual ratings should help improve predictions on future ratings
A linear CF algorithm generates predictions based on a probability distribution that is a convex combination of two distributions: one that it would learn given only data generated by honest users and one that it would learn given only manipulated data
As a user whose ratings we wish to predict provides more ratings, it becomes increasingly clear which of these two distributions better represents his preferences
As a result, the weight placed on manipulated data diminishes and distortion vanishes
The main theoretical result of this paper formalizes the above argument
In particular, we will define a notion of distortion induced by manipulators and establish an upper bound on distortion, which takes a particularly simple form:  SYMBOL  SYMBOL r SYMBOL n SYMBOL n SYMBOL 80\% SYMBOL 10\% SYMBOL 75\% SYMBOL 21$ products before receiving recommendations
To broaden the scope of our analysis, we will also study CF algorithms that behave like linear CF algorithms asymptotically as the size of the training set grows
This class of algorithms, which we refer to as  asymptotically linear , is more flexible in accommodating modeling assumptions that may improve prediction accuracy
We will establish that a relaxed version of our distortion bound for linear CF algorithms applies to asymptotically linear CF algorithms
We will also show that our distortion bound does not generally hold for NN algorithms
Intuitively, this is because prediction errors do not always improve the selection of neighbors
In particular, as a user provides more ratings, manipulated data that contribute to inaccurate predictions of his future ratings may remain in the set of neighbors while data generated by honest users may be eliminated from it
As a result, distortion of predictions may not decrease
We will later provide an example to illustrate this
In addition to theoretical results, this paper provides an empirical analysis using a publicly available set of movie ratings generated by users of Netflix's recommendation system
We produce a distorted version of this data set by injecting manipulated ratings generated using a manipulation technique studied in prior literature
We then compare results from application of three CF algorithms: an NN algorithm, a linear CF algorithm called the kernel density estimation algorithm, and an asymptotically linear CF algorithm called the naive Bayes algorithm
Results demonstrate that while performance of the NN algorithm is highly susceptible to manipulation, those of kernel density estimation and naive Bayes algorithms are relatively robust
In particular, the latter two experience distortion lower than the theoretical bound we provide, whereas the distortion for the former exceeds it by far
One might also wonder whether manipulation robustness of a CF algorithm comes at the expense of its prediction accuracy
As an example, consider an algorithm that fixes predictions for all ratings to be a constant, without regard to the training data
This algorithm is uninfluenced by manipulation but is likely to yield poor predictions, and is therefore not useful
In our experiments, the accuracy demonstrated by the three algorithms all seems reasonable
This suggests that accuracy of a CF algorithm may be achieved alongside robustness
Our theoretical and empirical results together suggest that commercial recommendation systems using NN algorithms can be made more robust by adopting approaches that we describe
Note that we are not proposing that real-world systems should implement the specific algorithms we present in this paper
Rather, our analysis highlights properties of CF algorithms that lead to robustness and practitioners may benefit from taking these properties into consideration when designing CF systems
This paper is organized as follows
In the next section, we discuss some related work
In Section , we formulate a simplified model that serves as a context for studying alternative CF algorithms
We then establish results concerning the manipulation robustness of NN, linear, and asymptotically linear CF algorithms in Section
In Section , we present our empirical study
We make some closing remarks in a final section
### abstract ###
Collecting large labeled data sets is a laborious and expensive task, whose scaling up requires division of the labeling workload between many teachers
When the number of classes is large, miscorrespondences between the labels given by the different teachers are likely to occur, which, in the extreme case, may reach total inconsistency
In this study we describe how globally consistent labels can be obtained, despite the absence of teacher coordination, and discuss the possible efficiency of this process in terms of human labor
We define a notion of label efficiency, measuring the ratio between the number of globally consistent labels obtained and the number of labels provided by distributed teachers
We show that the efficiency depends critically on the ratio  SYMBOL  between the number of data instances seen by a single teacher, and the number of classes
We suggest several algorithms for the distributed labeling problem, and analyze their efficiency as a function of  SYMBOL
In addition, we provide an upper bound on label efficiency for the case of completely uncoordinated teachers, and show that efficiency approaches  SYMBOL  as the ratio between the number of labels each teacher provides and the number of classes drops (i e SYMBOL )
### introduction ###
As applications of machine learning mature, larger training sets are required both in terms of the number of training instances and the number of classes considered
In recent years we have witnessed this trend for example in vision related tasks such as object class recognition or detection  CITATION
Specifically for object class recognition, current data sets such as the Caltech-256  CITATION  include tens of thousands of images from hundreds of classes
Collecting consistent data sets of this size is an intensive and expensive task
Scaling up naturally leads to a distributed labeling scenario, in which labels are provided by a large number of weakly coordinated teachers
For example, in the Label-me system  CITATION  the labels are contributed by dozens of researchers, while in the ESP game  CITATION  labels are supplied by thousands of uncoordinated players
As we turn toward distributed labeling, several practical considerations emerge which may disrupt the data integrity
In general, while it is reasonable to believe that a single teacher is relatively self-consistent (though not completely error-free), this is not the case with multiple uncoordinated teachers
Different teachers may have differences in their labeling systems due to several causes
First, different teachers may use different words to describe the same item class
For example, one teacher may use the word ``truck'' while the other uses ``lorry'' to describe the same class
Conversely, the same word may be used by two teachers to describe two totally different classes, hence one teacher may use ``greyhound'' to describe the breed of dog while the other uses it to describe the C-2 navy aircraft
Similar problems occur when different teachers label the data with different abstraction levels, so one generalizes over all dogs, while the other discriminates between a poodle, a Labrador and etc
Finally, teachers often do not agree on the exact demarcation of concepts, so a chair carved in stone may be labeled as a ``chair'' by one teacher, while the other describes it as ``a rock''
All these phenomena become increasingly pronounced as the number of classes is increased, thus their neglect essentially leads to a severe decrease in label purity and consequently in learning performance
In this paper we study the cost of obtaining globally consistent labels, while focusing on a specific distributed labeling scenario, in which only some of the difficulties described above are present
To enforce the distributed nature of the problem, we assume that a large data set with  SYMBOL  examples is to be labeled by a set of uncoordinated teachers, where each teacher agrees to label at most  SYMBOL  data points
While there is a one-to-one correspondence between the classes used by the different teachers, we assume that their labeling systems are entirely uncoordinated, so a class labeled as ``duck'' by one teacher may be labeled as a ``goat'' by another
In later stages of this paper, we relax this assumption, and consider a case in which partial consistency exists between the different teachers
Both scenarios are realistic in various problem domains
Consider for example a security system for which we have to label a large set of face images, including thousands of different people
Since teachers are not familiar with the persons to be labeled, the names they give to classes are entirely un-coordinated
The case of a partial consistency is exemplified in distributed labeling of flower images: the layman can easily distinguish between many different kinds of flowers but can name only a few
The difficulties of ``one-to-many'' label correspondence between teachers and concept demarcation disagreements are not met by our current analysis, which focuses on the preliminary difficulties of distributed labeling
Another related scenario, to which our analysis can be extended relatively easily, is the case in which the initial data is labeled by uncoordinated teachers right from the start
Consider for example, the task of unifying images labeled in a site like Flickr%  into a meaningful large training data set
Our suggested algorithms and analysis apply to this case with minor modifications
### abstract ###
In large systems, it is important for agents to learn to act effectively, but sophisticated multi-agent learning algorithms generally do not scale
An alternative approach is to find restricted classes of games where simple, efficient algorithms converge
It is shown that stage learning efficiently converges to Nash equilibria in large anonymous games if best-reply dynamics converge
Two features are identified that improve convergence
First, rather than making learning more difficult, more agents are actually beneficial in many settings
Second, providing agents with statistical information about the behavior of others can significantly reduce the number of observations needed
### introduction ###
Designers of distributed systems are frequently unable to determine how an agent in the system should behave, because optimal behavior depends on the user's preferences and the actions of others
A natural approach is to have agents use a learning algorithm
Many multiagent learning algorithms have been proposed including simple strategy update procedures such as  fictitious play ~ CITATION , multiagent versions of  Q-learning ~ CITATION , and  no-regret algorithms ~ CITATION
However, as we discuss in Section~, existing algorithms are generally unsuitable for large distributed systems
In a distributed system, each agent has a limited view of the actions of other agents
Algorithms that require knowing, for example, the strategy chosen by every agent cannot be implemented
Furthermore, the size of distributed systems requires fast convergence
Users may use the system for short periods of time and conditions in the system change over time, so a practical algorithm for a system with thousands or millions of users needs to have a convergence rate that is sublinear in the number of agents
Existing algorithms tend to provide performance guarantees that are polynomial or even exponential
Finally, the large number of agents in the system guarantees that there will be noise
Agents will make mistakes and will behave in unexpectedly
Even if no agent changes his strategy, there can still be noise in agent payoffs
For example, a gossip protocol will match different agents from round to round; congestion in the underlying network may effect message delays between agents
A learning algorithm needs to be robust to this noise
While finding an algorithm that satisfies these requirements for arbitrary games may be difficult, distributed systems have characteristics that make the problem easier
First, they involve a large number of agents
Having more agents may seem to make learning harder---after all, there are more possible interactions
However, it has the advantage that the  outcome of an action typically depends only weakly on what other agents do
This makes outcomes robust to noise
Having a large number of agents also make it less useful for an agent to  try to influence others; it becomes a better policy to try to learn an optimal response
In contrast, with a small number of agents, an agent can attempt to guide learning agents into an outcome that is beneficial for him
Second, distributed systems are often  anonymous ~ CITATION ; it does not matter  who  does something, but rather  how many  agents do it
For example, when there is congestion on a link, the experience of a single agent does not depend on who is sending the packets, but on how many are being sent
Finally, and perhaps most importantly, in a distributed system the system designer controls the game agents are playing
This gives us a somewhat different perspective than most work, which takes the game as given
We do not need to solve the hard problem of finding an efficient algorithm for all games
Instead, we can find algorithms that work efficiently for interesting classes of games, where for us ``interesting'' means ``the type of games a system designer might wish agents to play
''   Such games should  be ``well behaved,'' since it would be strange to design a  system where an agent's decisions can influence other agents in pathological ways
In Section~, we show that  stage learning ~ CITATION  is robust, implementable with minimal information, and converges efficiently for an interesting class of games
In this algorithm, agents divide the rounds of the game into a series of stages
In each stage, the agent uses a fixed strategy except that he occasionally explores
At the end of a stage, the agent chooses as his strategy for the next stage whatever strategy had the highest average reward in the current stage
We prove that, under appropriate conditions, a large system of stage learners will follow (approximate) best-reply dynamics despite errors and exploration
For games where best-reply dynamics converge, our theorem guarantees that learners will play an approximate Nash equilibrium
In contrast to previous results where the convergence guarantee scales poorly with the number of agents, our theorem guarantees convergence in a finite amount of time with an infinite number of agents
While the assumption that best-reply dynamics converge is a strong one, many interesting games converge under best-reply dynamics, including dominance solvable games and games with monotone best replies
Marden et al ~ CITATION  have observed that convergence of best-reply dynamics is often a property of games that humans design
Moreover, convergence of best-reply dynamics is a weaker assumption than a common assumption made in the mechanism design literature, that the games of interest have dominant strategies (each agent has a strategy that is optimal no matter what other agents do)
Simulation results, presented in Section~, show that convergence is fast in practice: a system with thousands of agents can converge in a few thousand rounds
Furthermore, we identify two factors that determine the rate and quality of convergence
One is the number of agents: having more agents makes the noise in the systen more consistent so agents can learn using fewer observations
The other is giving agents statistical information about the behavior of other agents; this can speed convergence by an order of magnitude
Indeed, even noisy statistical information about agent behavior, which should be relatively easy to obtain and disseminate,  can significantly improve performance
### abstract ###
We study the problem of decision-theoretic online learning (DTOL)
Motivated by practical applications, we focus on DTOL when the number of actions is very large
Previous algorithms for learning in this framework have a tunable learning rate parameter, and a barrier to using online-learning in practical applications is that it is not understood how to set this parameter optimally, particularly when the number of actions is large
In this paper, we offer a clean solution by proposing a novel and completely parameter-free algorithm for DTOL
We introduce a new notion of regret, which is more natural for applications with a large number of actions
We show that our algorithm achieves good performance with respect to this new notion of regret; in addition, it also achieves performance close to that of the best bounds achieved by previous algorithms with optimally-tuned parameters, according to previous notions of regret
### introduction ###
In this paper, we consider the problem of decision-theoretic online learning (DTOL), proposed by Freund and Schapire~ CITATION
DTOL is a variant of the problem of prediction with expert advice~ CITATION
In this problem, a learner must assign probabilities to a fixed set of actions in a sequence of rounds
After each assignment, each action incurs a loss (a value in  SYMBOL ); the learner incurs a loss equal to the expected loss of actions for that round, where the expectation is computed according to the learner's current probability assignment
The  regret  (of the learner) to an action is the difference between the learner's cumulative loss and the cumulative loss of that action
The goal of the learner is to achieve, on any sequence of losses, low regret to the action with the lowest cumulative loss (the best action)
DTOL is a general framework that captures many learning problems of interest
For example, consider tracking the hidden state of an object in a continuous state space from noisy observations~ CITATION
To look at tracking in a DTOL framework, we set each action to be a path (sequence of states) over the state space
The loss of an action at time  SYMBOL  is the distance between the observation at time  SYMBOL  and the state of the action at time  SYMBOL , and the goal of the learner is to predict a path which has loss close to that of the action with the lowest cumulative loss
The most popular solution to the DTOL problem is the Hedge algorithm~ CITATION
In Hedge, each action is assigned a probability, which depends on the cumulative loss of this action and a parameter  SYMBOL , also called the  learning rate
By appropriately setting the learning rate as a function of the iteration~ CITATION  and the number of actions, Hedge can achieve a regret upper-bounded by  SYMBOL , for each iteration  SYMBOL , where  SYMBOL  is the number of actions
This bound on the regret is optimal as there is a  SYMBOL  lower-bound~ CITATION
In this paper, motivated by practical applications such as tracking, we consider DTOL in the regime where \changeto{ SYMBOL , the number of actions,}{the number of actions  SYMBOL } is very large
A major barrier to using online-learning for practical problems is that when  SYMBOL  is large, it is not understood how to set the learning rate  SYMBOL
CITATION  suggest setting  SYMBOL  as a fixed function of the number of actions  SYMBOL
However, this can lead to poor performance, as we illustrate by an example in Section~, and the degradation in performance is particularly exacerbated as  SYMBOL  grows larger
One way to address this is by simultaneously running multiple copies of Hedge with multiple values of the learning rate, and choosing the output of the copy that performs the best in an online way
However, this solution is impractical for real applications, particularly as  SYMBOL  is already very large (For more details about these solutions, please see Section~ )     In this paper, we take a step towards making online learning more practical  by proposing a novel, completely adaptive algorithm for DTOL
Our algorithm is called NormalHedge
NormalHedge is very simple  and easy to implement, and in each round, it simply involves a single line search, followed by an updating of weights for all actions
A second issue with using online-learning in problems such as tracking,  where  SYMBOL  is very large, is that the regret to the  best action  is not an effective measure of performance
For problems such as tracking, one expects to have a lot of actions that are close to the action with the lowest loss
As these actions also have low loss, measuring performance with respect to a small group of actions that perform well is extremely reasonable -- see, for example, Figure~
In this paper, we address this issue by introducing a new notion of regret, which is more natural for practical applications
We order the cumulative losses of all actions from lowest to highest and define the  regret of the learner to the top  SYMBOL -quantile  to be the difference between the cumulative loss of the learner and the  SYMBOL -th element in the sorted list }   We prove that for NormalHedge, the regret to the top  SYMBOL -quantile of actions is at most  SYMBOL  which holds  simultaneously for all  SYMBOL  and  SYMBOL
If we set  SYMBOL , we get that the regret to the best action is upper-bounded by  SYMBOL , which is only slightly worse than the bound achieved by Hedge with optimally-tuned parameters
Notice that in our regret bound, the term involving  SYMBOL  has no dependence on  SYMBOL
In contrast, Hedge cannot achieve a regret-bound of this nature uniformly for all  SYMBOL  (For details on how Hedge can be modified to perform with our new notion of regret, see Section~)
NormalHedge works by assigning each action  SYMBOL  a potential; actions which have lower cumulative loss than the algorithm are assigned a potential  SYMBOL , where  SYMBOL  is the regret of action  SYMBOL  and  SYMBOL  is an adaptive scale parameter, which is adjusted from one round to the next, depending on the loss-sequences
Actions which have higher cumulative loss than the algorithm are assigned potential  SYMBOL
The weight assigned to an action in each round is then  proportional to the derivative of its potential
One can also interpret Hedge as a potential-based algorithm, and under this interpretation, the potential assigned by Hedge to action  SYMBOL  is proportional to  SYMBOL  \changeto{This potential used by Hedge and other related algorithms differs significantly from the one we use }{This potential used by Hedge differs significantly from the one we use } Although other potential-based methods have been considered in the context of online learning~ CITATION , our potential function is very novel, and to the best of our knowledge, has not been studied in prior work
Our proof techniques are also different from previous potential-based methods
Another useful property of NormalHedge, which Hedge does not possess, is that it assigns zero weight to any action whose cumulative loss is larger than the cumulative loss of the algorithm itself
In other words, non-zero weights are assigned only to actions which perform better than the algorithm
In most applications\changeto{ of DTOL}{,} we expect a small set of the actions to perform significantly better than most of the actions \changeto{As the regret of the hedging algorithm is guaranteed to be small, this means that the algorithm will perform better than most of the actions and will  therefore assign them zero probability }{The regret of the algorithm is guaranteed to be small, which means that the algorithm will perform better than most of the actions and thus assign them zero probability }   CITATION  have proposed more recent solutions to DTOL in which the regret of Hedge to the best action is upper bounded by a function of  SYMBOL , the loss of the best action, or by a function of the variations in the losses
These bounds can be sharper than the bounds with respect to  SYMBOL
Our analysis (and in fact, to our knowledge, any analysis based on potential functions in the style of~ CITATION ) do not directly yield these kinds of bounds
We therefore leave open the question of finding an adaptive algorithm for DTOL which has regret upper-bounded by a function that depends on the loss  of the best action
The rest of the paper is organized as follows
In Section 2, we provide NormalHedge
In Section 3, we provide an example that illustrates the suboptimality of standard online learning algorithms, when the parameter is not set properly
In Section 4, we discuss Related Work
In Section 5, we present some outlines of the proof
The proof details are in the Supplementary Materials
### abstract ###
We study the tracking problem, namely, estimating the hidden state of an object over time, from unreliable and noisy measurements
The standard framework for the tracking problem is the generative framework, which is the basis of solutions such as the Bayesian algorithm and its approximation, the particle filters
However, the problem with these solutions is that they are very sensitive to model mismatches
In this paper, motivated by online learning, we introduce a new framework -- an  explanatory  framework -- for tracking
We provide an efficient tracking algorithm for this framework
We provide experimental results comparing our algorithm to the Bayesian algorithm on simulated data
Our experiments show that when there are slight model mismatches, our algorithm vastly outperforms the Bayesian algorithm
### introduction ###
We study the tracking problem, which has numerous applications in AI, control and finance
In tracking, we are given noisy measurements over time, and the problem is to estimate the hidden state of an object
The challenge is to do this reliably, by combining measurements from multiple time steps and prior knowledge about the state dynamics, and the goal of tracking is to produce estimates that are as close to the true states as possible
The most popular solutions to the tracking problem are the Kalman filter~ CITATION , the particle filter~ CITATION , and their numerous extensions and variations ( eg ~ CITATION ), which are  based on a generative framework for the tracking problem
Suppose we want to track the state  SYMBOL  of an object at time  SYMBOL , given only measurement vectors  SYMBOL  \changeto{at time}{for times}  SYMBOL
In the generative approach, we think of the state  SYMBOL  and measurements  SYMBOL  as random variables
We represent our knowledge regarding the dynamics of the states using the transition process  SYMBOL  and our knowledge regarding the (noisy) relationship between the states and the observations by the measurement process  SYMBOL
Then, given only the observations, the goal of tracking is to estimate the hidden state sequence  SYMBOL
This is done by calculating the likelihood of each state sequence and then using as the estimate either the sequence with the highest posterior probability (maximum a posteriori, or MAP) or the expected value of the state with respect to the posterior distribution (the Bayesian algorithm)
In practice, one uses particle filters, which are an approximation to the Bayesian algorithm
The problem with the generative framework is that in practice, it is very difficult to precisely determine the distributions of the measurements
Moreover, the Bayesian algorithm is very sensitive to model mismatches, \changeto{and}{so} using a model which is slightly different from the model generating the measurements can lead to a large divergence between the estimated states and the true states
To address this, we introduce an online-learning-based framework for tracking
In our framework, called the   framework, we are given a set of state sequences or paths in the state space; but instead of assuming that the observations are \changeto{generated}{ generated } by a measurement model from \changeto{ a path in this set }{a path in this set}, we think of each path as a mechanism for  explaining  the observations
We emphasize that this is done regardless of how the observations are generated
Suppose \changeto{that the}{a} path \changeto{ SYMBOL }{ SYMBOL } is proposed as an explanation of the observations \changeto{ SYMBOL }{ SYMBOL } \changeto{Then, we}{We} measure the quality of this \explanatory\ path using a predefined  loss function , which depends only on the measurements (and not on the hidden true state)
The tracking algorithm selects its own \explanatory\ path by taking a weighted average of the best \explanatory\ paths according the past observations
The theoretical guarantee we provide is that the loss of the \explanatory\ path generated in this online way by the tracking algorithm is close to that of the \explanatory\ path with the minimum \changeto{loss, where}{such loss; here,} the loss is measured according to the loss function supplied to the algorithm
Such guarantees are analogous to competitive analysis used in online learning~ CITATION , and it is important to note that such guarantees hold uniformly for  any  sequence of observations, regardless of any probabilistic assumptions
Our next contribution is to provide an online-learning-based algorithm for tracking in the \explanatory\ framework
Our algorithm is based on \nhedge~ CITATION , which is a general online learning algorithm \nhedge\ can be instantiated with  any loss function
When supplied with a bounded loss function, it is guaranteed to produce a path with loss close to that of the path with the minimum loss, from a set of candidate paths
As it is inefficient to directly apply \nhedge\ to tracking, we derive a Sequential \changeto{Monte-Carlo-based}{Monte Carlo} approximation to \nhedge, and we show that this approximation is efficient
To demonstrate the robustness of our tracking algorithm, we perform simulations on a simple one-dimensional tracking problem
We evaluate tracking performance by measuring the average distance between the states estimated by the algorithms, and the true hidden states
We instantiate our algorithm with a simple clipping loss function
Our simulations show that our algorithm consistently outperforms the Bayesian algorithm, under high measurement noise, and a wide range of levels of model mismatch
We note that Bayesian algorithm can also be interpreted in the \explanatory\ framework
In particular, if the loss of a path is the negative log-likelihood (the log-loss) under some measurement model, then, the Bayesian algorithm can be shown to produce a path with log-loss close to that of the path with the minimum log-loss
One may be tempted to think that our tracking solution follows the same approach; however, the point of our paper is that one can use loss functions that are different from log-loss, and in particular, we show a scenario \changeto{where}{in which} using other loss functions produces better tracking performance than the Bayesian algorithm (or its approximations)
The rest of the paper is organized as follows
In Section 2, we explain in detail our explanatory model for tracking
In Section 3, we present \changeto{Normalhedge }{NormalHedge, on which our tracking algorithm is based}
In Section 4, we provide our \changeto{actual tracking algorithm}{tracking algorithm} \changeto{Section 5 presents some experiments that compare our algorithm with the Bayesian algorithm on simulated data }{Section 5 presents the experimental comparison of our algorithm with the Bayesian algorithm } \changeto{Finally, in Section 6, we report on our experiments with face-tracking }{Finally, we discuss related work in Section 6 }  The detailed bounds and proofs for NormalHedge are provided in the supplementary material
We feel that the algorithm NormalHedge may be of more general interest, and hence these details for NormalHedge have been submitted to NIPS in a companion paper
### abstract ###
In this paper, we are interested in optimal decisions in a partially observable universe
Our approach is to directly approximate an optimal strategic tree depending on the observation
This approximation is made by means of a parameterized probabilistic law
A particular family of hidden Markov models, with input  and  output, is considered as a model of policy
A method for optimizing the parameters of these HMMs is proposed and applied
This optimization is based on the cross-entropic principle for rare events simulation developed by Rubinstein
### introduction ###
There are different degrees of difficulty in planning and control problems
In most problems, the planner have to start from a given state and terminate in a required final state
There are several transition rules, which condition the sequence of decision
For example, a robot may be required to move from room A, starting state, to room B, final state; its decision could be  go forward ,  turn right  or  turn left , and it cannot cross a wall; these are the conditions over the decision
A first degree in the difficulty is to find at least one solution for the planning
When the states are only partially known or the resulting actions are not deterministic, the difficulty is quite enhanced: the planner has to take into account the various observations
Now, the problem becomes much more complex, when this planning is required to be optimal or near-optimal
For example, find the shortest trajectory which moves the robot from room A to room B
There are again different degrees in the difficulty, depending on the problem to be deterministic or not, depending on the model of the future observations
In the particular case of a Markovian problem with the full observation hypothesis, the dynamic programming principle CITATION  could be efficiently applied (Markov Decision Process theory/MDP)
This solution has been extended to the case of partial observation (Partially Observable Markov Decision Process/POMDP), but this solution is generally not practicable, owing to the huge dimension of the variables CITATION  \\\\ For such reason, different methods for approximating this problem has been introduced
For example, Reinforcement Learning methods  CITATION  are able to learn an evaluation table of the decision conditionnally to the known universe states and an observation short range
In this case, the range of observation is indeed limited in time, because of an exponential grow of the table to learn
Recent works CITATION  are investigating the case of hierarchical RL, in order to go beyond this range limitation
Whatever, these methods are generally based on an additivity hypothesis about the reward
Another viewpoint is based on the direct learning of the policy CITATION
Our approach is of this kind
It is particularly based on the Cross-Entropy optimisation algorithm developed by Rubinstein CITATION
This simulation method relies both on a probabilistic modelling of the policies (in this paper, these models are Bayesian Networks) and on an efficient and robust iterative algorithm for optimizing the model parameters
More precisely, the policy will be modelled by conditional probabilistic law,  i e decisions depending on observations, which are involving memories; typically hidden Markov models are used
Also are implemented a hierachical modelling of the policies by means of hierarchical hidden Markov models \\\\ The next section introduces some formalism and gives a quick description of the optimal planning in partially observable universes
It is proposed a near-optimal planning method, based on the direct approximation of the optimal decision tree
The third section introduces the family of Hierarchical Hidden Markov Models being in use for approximating the decision trees
The fourth section describes the method for optimizing the parameters of the HHMM, in order to approximate the optimal decision tree for the POMDP problem
The cross-entropy method is described and applied
The fifth section gives an example of application
A comparison with a Reinforcement Learning method, the Q-learning, is made
The paper is then concluded
### abstract ###
A  SYMBOL -adic modification of the split-LBG classification method is presented in which first clusterings and then cluster centers  are computed which locally minimise an energy function
The outcome for a fixed dataset  is independent of the prime number  SYMBOL  with finitely many exceptions
The methods are applied to the construction of  SYMBOL -adic classifiers in the context of learning
### introduction ###
The field  SYMBOL  of   SYMBOL -adic numbers is of interest  in hierarchical classification  because of its inherent hierarchical structure  CITATION
A great amount of work deals with finding  SYMBOL -adic data representation (e g \  CITATION )
In  CITATION , the use of more general   SYMBOL -adic numbers for encoding hierarchical data was advocated in order to be able to include the case of non-binary dendrograms into the scheme without having to resort to a larger prime number  SYMBOL
This was applied in  CITATION  to the special case of data consisting in words over a given alphabet and where proximity of words is defined by the length of the common initial part
There,  an agglomerative  hierarchic  SYMBOL -adic clustering algorithm was described
However, the question of finding optimal clusterings of  SYMBOL -adic data was not raised
Already in  CITATION , the performance of classical and  SYMBOL -adic classification algorithms was compared in the segmentation of moving images
It was observed that the  SYMBOL -adic ones were often more efficient
Learning algorithms using  SYMBOL -adic neural networks are described in  CITATION
Inspired by   CITATION , our main concern in this article will be a  SYMBOL -adic adaptation of the so-called split-LBG method  which finds energy-optimal clusterings of data
The name ``LBG'' refers to the initials of the authors of  CITATION , where it is described first
Their method is to find cluster centers, and then to group the data around the centers
In the next step, the cluster centers are split, and more clusters are obtained
This process is repeated until the desired class number is attained
For  SYMBOL -adic data, this approach does not make sense:  first of all, cluster centers are in general not unique; and secondly, because the dendrogram is already determined by data, an arbitrary choice of cluster centers is not possible---this can lead to incomplete clusterings
Hence, we first find clusterings by refining in the direction of highest energy reduction, until the class number exceeds a prescribed bound
Thereafter, candidates for cluster centers are computed: they minimise the cluster energy
The result is a sub-optimal method for   SYMBOL -adic classification which splits a given cluster into its maximal proper subclusters
A variant discards first all quasi-singletons, i e \ clusters of  energy below a threshold value
The  a posteriori  choice of centers turns out useful for  constructing % efficient classifiers
A first application of some of the methods described here to event history data of building stocks is described in  CITATION
There,  the classification algorithm is performed on different  SYMBOL -adic encodings of the data in order to compare the dynamics of some sampled municipal building stocks
After introducing notations in Section , we briefly describe the classical split-LBG method in Section
Section  reformulates the minimisation task of split-LBG in  the  SYMBOL -adic setting, and describes the corresponding algorithms
The issue on the choice of the prime  SYMBOL  is dealt with in Section
Section   constructs classifiers and presents an adaptive learning method in which accumulated clusters of large energy are split
### abstract ###
Many reinforcement learning exploration techniques are overly optimistic and try to explore every state
Such exploration is impossible in environments with the unlimited number of states
I propose to use simulated exploration with an optimistic model to discover promising paths for real exploration
This reduces the needs for the real exploration
### introduction ###
In reinforcement learning CITATION  an agent collects rewards in an environment
The environment is not known in advance
The agent has to explore it to learn where to go
A reward could be received when taking an action in a state
The agent aims to maximize her long-term reward in the environment
She should not miss any state with an important reward or a shorter path to it
There are many existing exploration techniques CITATION  that are optimistic in the face of uncertainty
Their optimism assumes that a greater reward will be obtained when taking an unknown action
The problem is how to do exploration in environments with the unlimited number of states
In these environments, it is not possible to try every action in every possible state
I study a new way to do exploration in environments with the unlimited number of states
I use simulated exploration as an incentive for real exploration
The simulated exploration proposes promising paths to explore
I describe how to use this kind of exploration in section
My experiments in section  demonstrate how simulated exploration reduced the needed amount of real exploration
I also discuss when it is possible
Many works touched related problems
They inspired me and I discuss them in section
### abstract ###
Real-time object detection has many applications in video surveillance, teleconference and multimedia retrieval \etc
Since Viola and Jones  CITATION  proposed the first real-time AdaBoost based face detection system, much effort has been spent on improving the boosting method
In this work, we first show that feature selection methods other than boosting can also be used for training an efficient object detector
In particular, we introduce Greedy Sparse Linear Discriminant Analysis (GSLDA)  CITATION  for its conceptual simplicity and  computational efficiency; and slightly better detection performance is achieved compared with  CITATION
Moreover, we propose a new technique, termed Boosted Greedy Sparse Linear Discriminant Analysis (BGSLDA), to efficiently train a detection cascade
BGSLDA exploits the sample re-weighting property of boosting and the class-separability criterion of GSLDA
Experiments in the domain of highly skewed data distributions, \eg, face detection, demonstrates that classifiers trained with the proposed BGSLDA outperforms AdaBoost and its variants
This finding provides a significant opportunity to argue that AdaBoost and similar approaches are not the only methods that can achieve high classification results for high dimensional data in  object detection
### introduction ###
\IEEEPARstart{R}{eal-time} objection detection such as face detection has numerous computer vision applications, \eg,  intelligent video surveillance, vision based teleconference systems and content based image retrieval
Various detectors have been proposed in the literature  CITATION
Object detection is challenging due to the variations of the visual appearances, poses and illumination conditions
Furthermore, object detection is a  highly-imbalanced   classification task
A typical natural image contains many more negative background patterns than object patterns
The number of background patterns can be  SYMBOL  times larger than the number of object patterns
That means, if one wants to achieve a high detection rate, together with a low false detection rate, one needs a specific classifier
The cascade classifier takes this imbalanced distribution into consideration  CITATION
Because of the huge success of Viola and Jones' real-time AdaBoost based face detector  CITATION , a lot of incremental work has been proposed
Most of them have focused on improving the underlying boosting method or accelerating the training process
For example, AsymBoost was introduced in  CITATION  to alleviate the limitation of AdaBoost in the context of highly skewed example distribution
Li  CITATION  proposed FloatBoost for a better detection accuracy by introducing a backward feature elimination step into the AdaBoost training procedure
Wu  CITATION  used forward feature selection for fast training by ignoring the re-weighting scheme in AdaBoost
Another technique based on the statistics of the weighted input data was used in  CITATION  for even faster  training
KLBoost was proposed in  CITATION  to train a strong classifier
The weak classifiers of KLBoost are based on histogram divergence of linear features
Therefore in the detection phase, it is not as efficient as Haar-like features
Notice that in KLBoost, the classifier design is separated from feature selection
In this work (part of which was published in preliminary form in  CITATION ),  we propose an improved learning algorithm for face detection, dubbed Boosted Greedy Sparse Linear Discriminant Analysis (BGSLDA)
Viola and Jones  CITATION  introduced a framework for selecting discriminative features and training classifiers in a cascaded manner as shown in Fig ~
The cascade framework allows most non-face patches to be rejected quickly before reaching the final node, resulting in fast performance
A test image patch is reported as a face only if it passes tests in all nodes
This way, most non-face patches are rejected by these early nodes
Cascade detectors lead to very fast detection speed and high detection rates
Cascade classifiers have also been used in the context of support vector machines (SVMs) for faster face detection  CITATION
In  CITATION , soft-cascade is developed to  reduce the training and design complexity
The idea was further developed in  CITATION
We have followed Viola and Jones' original cascade classifiers in this work
One issue that contributes to the efficacy of the system comes from the use of AdaBoost algorithm for training  cascade nodes
AdaBoost is a forward stage-wise additive modeling with the weighted exponential loss function
The algorithm combines an ensemble of weak classifiers to produce a final strong classifier with high classification accuracy
AdaBoost chooses a small subset of weak classifiers and assign them with proper coefficients
The linear combination of weak classifiers can be interpreted as a decision hyper-plane in the weak classifier space
The proposed BGSLDA differs from the original AdaBoost in the following aspects
Instead of selecting decision stumps with minimal weighted error as in AdaBoost, the proposed algorithm finds a new weak leaner that maximizes the class-separability criterion
As a result, the coefficients of selected weak classifiers are updated repetitively during the learning process according to this criterion
Our technique  differs from  CITATION  in the following  aspects
CITATION  proposed the concept of Linear Asymmetric Classifier (LAC) by addressing the asymmetries and   asymmetric node learning  goal in the cascade framework
Unlike our work where the features are selected based on the  Linear Discriminant Analysis (LDA) criterion,  CITATION  selects features using AdaBoost SYMBOL AsymBoost algorithm
Given the selected features, Wu then build an optimal linear classifier for the node learning goal using LAC or LDA
Note that similar techniques have also been applied in neural network
In  CITATION , a nonlinear adaptive feed-forward layered network with linear output units has been introduced
The input data is nonlinearly transformed into a space in which classes can be separated more easily
Since LDA considers the number of training samples of each class, applying LDA at the output of neural network hidden units has been shown to increase the classification accuracy of two-class problem with unequal class membership
As our experiments show, in terms of feature selection,  the proposed BGSLDA methods is superior than AdaBoost and AsymBoost   for object detection }     The key contributions of this work are as follows
We introduce GSLDA  as an alternative approach for training face detectors
Similar results are obtained compared with Viola and Jones' approach
We propose a new algorithm, BGSLDA, which combines the sample re-weighting schemes typically used in boosting into GSLDA
Experiments show that BGSLDA can achieve better detection performances
We show that feature selection and classifier training techniques can have different objective functions (in other words, the two processes can be separated) in the context of training a visual detector
This offers more flexibility and even better performance
Previous boosting based approaches select features and train a classifier simultaneously
Our results confirm that it is beneficial to consider the highly skewed data distribution when training a detector
LDA's learning criterion already incorporates this imbalanced data information
Hence it is better than standard AdaBoost's exponential loss for training an object detector
The remaining parts of the paper are structured as follows
In Section~, the GSLDA algorithm is introduced as an alternative learning technique to object detection problems
We then discuss how LDA incorporates imbalanced data information when training a classifier in Section~
Then, in Sections~ and , the proposed BGSLDA algorithm is described and the training time complexity is discussed
Experimental results are shown in Section~ and the paper is concluded in Section~
### abstract ###
Detecting outliers which are grossly different from or inconsistent with the remaining dataset is a major challenge in real-world KDD applications
Existing outlier detection methods are ineffective on scattered real-world datasets due to implicit data patterns and parameter setting issues
We define a novel  Local Distance-based Outlier Factor  (LDOF) to measure the {outlier-ness} of objects in scattered datasets which addresses these issues
LDOF uses the relative location of an object to its neighbours to determine the degree to which the object deviates from its neighbourhood
Properties of LDOF are theoretically analysed including LDOF's lower bound and its false-detection probability, as well as parameter settings
In order to facilitate parameter settings in real-world applications, we employ a top- SYMBOL  technique in our outlier detection approach, where only the objects with the highest LDOF values are regarded as outliers
Compared to conventional approaches (such as top- SYMBOL  KNN and top- SYMBOL  LOF), our method top- SYMBOL  LDOF is more effective at detecting outliers in scattered data
It is also easier to set parameters, since its performance is relatively stable over a large range of parameter values, as illustrated by experimental results on both real-world and synthetic datasets
### introduction ###
Of all the data mining techniques that are in vogue, outlier detection comes closest to the metaphor of mining for nuggets of information in real-world data
It is concerned with discovering the exceptional behavior of certain objects~ CITATION
Outlier detection techniques have widely been applied in medicine (e g adverse reactions analysis), finance (e g financial fraud detection), security (e g counter-terrorism), information security (e g intrusions detection) and so on
In the recent decades, many outlier detection approaches have been proposed, which can be broadly classified into several categories: distribution-based~ CITATION , depth-based~ CITATION , distance-based (e g KNN)~ CITATION , cluster-based (e g DBSCAN)~ CITATION  and density-based (e g LOF)~ CITATION  methods
However, these methods are often unsuitable in real-world applications due to a number of reasons
Firstly, real-world data usually have a scattered distribution, where objects are loosely distributed in the domain feature space
That is, from a `local' point of view, these objects cannot represent explicit patterns (e g clusters) to indicate normal data `behavior'
However, from a `global' point of view, scattered objects constitute several {mini-clusters}, which represent the pattern of a subset of objects
Only the objects which do not belong to any other object groups are genuine outliers
Unfortunately, existing outlier definitions depend on the assumption that most objects are crowded in a few main clusters
They are incapable of dealing with scattered datasets, because {mini-clusters} in the dataset evoke a high false-detection rate (or low precision)
Secondly, it is difficult in current outlier detection approaches to set accurate parameters for real-world datasets
Most outlier algorithms must be tuned through {trial-and-error}~ CITATION
This is impractical, because real-world data usually do not contain labels for anomalous objects
In addition, it is hard to evaluate detection performance without the confirmation of domain experts
Therefore, the detection result will be uncontrollable if parameters are not properly chosen
To alleviate the parameter setting problem, researchers proposed top- SYMBOL  style outlier detection methods
Instead of a binary outlier indicator, top- SYMBOL  outlier methods provide a ranked list of objects to represent the degree of {`outlier-ness'} for each object
The users (domain experts) can {re-examine} the selected top- SYMBOL  (where  SYMBOL  is typically far smaller than the cardinality of dataset) anomalous objects to locate real outliers
Since this detection procedure can provide a good interaction between data mining experts and users, top- SYMBOL  outlier detection methods become popular in real-world applications
Distance-based, top- SYMBOL  { SYMBOL -Nearest} Neighbour distance~ CITATION  is a typical top- SYMBOL  style outlier detection approach
In order to distinguish from the original {distance-based} outlier detection method in~ CITATION , we denote { SYMBOL -Nearest} Neighbour distance outlier as {top- SYMBOL  KNN} in this paper
In {top- SYMBOL  KNN} outlier, the distance from an object to its  SYMBOL  nearest neighbour (denoted as { SYMBOL -distance} for short) indicates {outlier-ness} of the object
Intuitively, the larger the { SYMBOL -distance} is, the higher {outlier-ness} the object has {Top- SYMBOL  KNN} outlier regards the  SYMBOL  objects with the highest values of { SYMBOL -distance} as outliers~ CITATION
A {density-based} outlier, Local Outlier Factor (LOF)~ CITATION , was proposed in the same year as top- SYMBOL  KNN
In LOF, an outlier factor is assigned for each object w r t its surrounding neighbourhood
The outlier factor depends on how the data object is closely packed in its locally reachable neighbourhood~ CITATION
Since LOF uses a threshold to differentiate outliers from normal objects~ CITATION , the same problem of parameter setting arises
A lower {outlier-ness} threshold will produce high false-detection rate, while a high threshold value will result in missing genuine outliers
In recent real-world applications, researchers have found it more reliable to use LOF in a top- SYMBOL  manner~ CITATION , i e \ only objects with the highest LOF values will be considered outliers
Hereafter, we call it top- SYMBOL  LOF
Besides top- SYMBOL  KNN and top- SYMBOL  LOF, researchers have proposed other methods to deal with real-world data, such as the {connectivity-based} (COF)~ CITATION , and Resolution {cluster-based} ({RB-outlier})~ CITATION
Although the existing top- SYMBOL  style outlier detection techniques alleviate the difficulty of parameter setting, the detection precision of these methods (in this paper, we take {top- SYMBOL  KNN} and top- SYMBOL  LOF as typical examples) is low on scattered data
In Section~, we will discuss further problems of top- SYMBOL  KNN and top- SYMBOL  LOF
In this paper we propose a new outlier detection definition, named Local Distance-based Outlier Factor (LDOF), which is sensitive to outliers in scattered datasets
LDOF uses the relative distance from an object to its neighbours to measure how much objects deviate from their scattered neighbourhood
The higher the violation degree an object has, the more likely the object is an outlier
In addition, we theoretically analyse the properties of LDOF, including its lower bound and false-detection probability, and provide guidelines for choosing a suitable neighbourhood size
In order to simplify parameter setting in real-world applications, the top- SYMBOL  technique is employed in our approach
To validate LDOF, we perform various experiments on both synthetic and real-world datasets, and compare our outlier detection performance with top- SYMBOL  KNN and top- SYMBOL  LOF
The experimental results illustrate that our proposed top- SYMBOL  LDOF represents a significant improvement on outlier detection capability for scattered datasets
The paper is organised as follows: In Section~, we illustrate and discuss the problems of top- SYMBOL  KNN and top- SYMBOL  LOF on a real-world data
In Section~, we formally introduce the outlier definition of our approach, and mathematically analyse properties of our {outlier-ness} factor in Section~
In Section~, the top- SYMBOL  LDOF outlier detection algorithm is described, together with an analysis of its complexity
Experiments are reported in Section~, which show the superiority of our method to previous approaches, at least on the considered datasets
Finally, conclusions are presented in Section~
### abstract ###
This paper introduces a new approach to solve sensor management problems
Classically sensor management problems can be well formalized as Partially-Observed Markov Decision Processes (POMPD)
The original approach developped here consists in deriving the optimal parameterized policy based on stochastic gradient estimation
We assume in this work that it is possible to learn the optimal policy off-line (in simulation ) using models of the environement and of the sensor(s)
The learned policy can then be used to manage the sensor(s)
In order to approximate the gradient in a stochastic context, we introduce a new method to approximate the gradient, based on Infinitesimal Approximation (IPA)
The effectiveness of this general framework is illustrated by the managing of an Electronically Scanned Array Radar
### introduction ###
Years after years the complexity and the performances of many sensors have increased leading to more and more complex sensor(s)-based systems which supply the decision centers with an increasing amount of data
The number, the types and the agility of sensors along with the increased quality of data far outstrip the ability of a human to manage them: it is often difficult to compare how much information can be gained by way of a given management scheme  CITATION
It results from this the necessity to derive unmanned sensing platforms that have the capacity to adapt to their environment  CITATION
This problem is often refered as the  Sensor(s) Management Problem
In more simple situations, the operational context may lead to works on sensor(s) management like in the  radar - infrared sensor  case  CITATION
A general definition of this problem could then be : sensor management is the effective use of available sensing and database capabilities to meet the mission goals
Many applications deal with military applications,a classical one being to detect, to track and tp identify smart targets (a smart target can change its way of moving or its way of sensing when it detects it is under analysis) with several sensors
The questions are then the following at each time: how must we group the sensors, how long, in which direction, and with which functioning mode
The increasing complexity of the targets to be detected, tracked and identified, makes the management even more difficult and led to the development of researches on the definition of an optimal sensor management scheme in which the targets and the sensors are treated altogether in a complex dynamic system  CITATION
Sensor Management has become very popular this last years and many approaches can be found in the litterature
In  CITATION  and  CITATION  the authors use a the modelling of the detection process of an Electronically Scanned Array (ESA) Radar to propose management scheme during the detection step
In  CITATION  an information-based approach is use to manage a set of sensors
From a theorical point of view the sensor management can be modelled as a Partially Observable Markov Decision Process (POMDP)  CITATION
Whatever the underlying application, the sensor management problem consists in choosing at each time  SYMBOL  an action  SYMBOL  within the set  SYMBOL  of available actions
The choice of  SYMBOL  is generally based on the density state vector  SYMBOL  describing the environment of the system and variables of the system itself
It is generally assumed that the state or at least a part of this state is Markovian
Moreover in most of the applications, we only have access to a partial information of the state and  SYMBOL  must be estimated from the measurements  SYMBOL
This estimation process is often derived within a Bayesian framework where we use state-dynamics and observation models such as:   SYMBOL }   SYMBOL }  where  SYMBOL ,  SYMBOL ,  SYMBOL  and  SYMBOL  respectively stands for the state noise, the measurements noise, the state-dynamics and the measurement function
SYMBOL  and  SYMBOL  are generally time varying functions
The control problem consists in finding the scheduling policy  SYMBOL  i e select  SYMBOL  given the past and the possible futures
However, this control problem may have a theorical solution, it is generally untractable in practice
However few works propose optimal solution in the frame of POMDPs like  CITATION
Beside, several works have been carried out to find sub-optimal policies like for instance myopic policies
Reinforcement Learning and Q-Learning have also been used to propose a solution ( CITATION )
We propose in this paper to look for a policy within a class of parametrized policy  SYMBOL  and to learn it which means learn the optimal value of  SYMBOL
Funding our work on the approach described in  CITATION  we assume that it is possible to learn this policy  in simulation  using models of the overall system
Once the optimal parameter has been found it is used to manage the sensor(s)
The frame of this work being the detection and localization of targets, we show in the last part of this paper how it may be applied the the management of an ESA radar
The section  described the modelling of a sensor management problem using a POMDP approach
In the section  we derive the algorithm to learn the parameter of the policy
In section  we show how this method may be used for the tasking of an ESA radar
Finally section  exhibits firts simulations results
### abstract ###
Given a random binary sequence  SYMBOL  of random variables,  SYMBOL   SYMBOL , for instance, one that is generated by a Markov source of order  SYMBOL  (each state represented by  SYMBOL  bits)
Let  SYMBOL  be the probability of  SYMBOL  and assume it is constant with respect to  SYMBOL  (due to stationarity)
Consider a learner based on a parametric model, for instance a Markov model of order  SYMBOL , who trains on a sample sequence  SYMBOL  which is randomly drawn by the source
Test the learner's performance by giving it a sequence  SYMBOL  (generated by the source) and check its predictions on every bit of  SYMBOL  An error occurs at time  SYMBOL  if the  prediction  SYMBOL  differs from the true bit value  SYMBOL
Denote by  SYMBOL  the sequence of errors where the error bit  SYMBOL  at time  SYMBOL  equals  SYMBOL  or  SYMBOL  according to whether the event of an error occurs or not, respectively
Consider the subsequence  SYMBOL  of  SYMBOL  which corresponds to the errors of predicting a  SYMBOL , ie ,  SYMBOL  consists of the bits of  SYMBOL  only at times  SYMBOL  such that  SYMBOL  In this paper we compute an upper bound on the deviation of the frequency of  SYMBOL s of  SYMBOL  from  SYMBOL  showing dependence on  SYMBOL ,  SYMBOL ,  SYMBOL
### introduction ###
From basic theory on finite Markov chains, since the matrix  SYMBOL  is stochastic (i e , the sum of the elements in any row equals  SYMBOL ) then  SYMBOL  has a stationary joint probability distribution  SYMBOL *} which is not necessarily unique
To keep the notation simple we use  SYMBOL  to denote also any marginal distribution derived from the stationary joint distribution
For instance,  SYMBOL
Henceforth, all random binary sequences are assumed to be drawn according to this probability distribution  SYMBOL
Thus for any  SYMBOL  and  SYMBOL  satisfying  SYMBOL  the probability of a string  SYMBOL  can be expressed as  SYMBOL } Let us denote by  SYMBOL } the stationary probability of the event  SYMBOL  at time  SYMBOL
Data generation : We henceforth assume that the source reached stationarity and produces the data sequence  SYMBOL  with respect to  SYMBOL
Consider the learner's model  SYMBOL
Its set of parameters are the true (unknown) probability values of transitions between states in  SYMBOL  where the probability values are assigned according to the source distribution  SYMBOL
We denote them by  SYMBOL  For instance, suppose  SYMBOL  and  SYMBOL  and consider two states  SYMBOL  and  SYMBOL
The corresponding transition probability is  SYMBOL  Based on  SYMBOL  the learner estimates  SYMBOL  by  SYMBOL  where for a state  SYMBOL ,  SYMBOL  denotes the number of times that  SYMBOL  appears in  SYMBOL  and  SYMBOL  denotes the number of times there is a transition from state  SYMBOL  to  SYMBOL  in  SYMBOL
For instance, if  SYMBOL ,  SYMBOL  and  SYMBOL  then  SYMBOL
Thus  SYMBOL  are the frequency of state-transitions in  SYMBOL
Note that  SYMBOL ,  SYMBOL , are dependent random variables since the Markov chain may visit each state a random number of times and they must satisfy  SYMBOL
After training, the learner is tested on the remaining  SYMBOL  bits of the data  SYMBOL
It makes a binary prediction  SYMBOL  for  SYMBOL ,  SYMBOL  based on the maximum  a posteriori  probability which is defined as follows: suppose that the current state is  SYMBOL  then the prediction is   SYMBOL } where  SYMBOL  is defined as  SYMBOL  for the state  SYMBOL  obtained from  SYMBOL  by a type-1 transition, i e , if  SYMBOL  then  SYMBOL
The corresponding true probability value is denoted by  SYMBOL
Note that () may be expressed alternatively as SYMBOL }   We claim that  SYMBOL ,  SYMBOL , are independent random variables when conditioned on the vector  SYMBOL
We now prove the claim which will be used in Section
Let us denote by  SYMBOL ,  SYMBOL ,  SYMBOL , the particular sequence of states corresponding to the sequence  SYMBOL
To show the dependence of  SYMBOL  on  SYMBOL  we will sometimes write  SYMBOL
Then by () we have SYMBOL *} Since at every bit there are only two types of transitions then not every sequence  SYMBOL  is possible
For instance, if  SYMBOL  then the state sequence  SYMBOL  is valid but  SYMBOL  is not valid
Denote by  SYMBOL  the set of  valid  state sequences  SYMBOL
We now show that if  SYMBOL  is in  SYMBOL  then, conditioned on  SYMBOL , any other state sequence that visits the same states as  SYMBOL  the same number of times (perhaps in a different order) must have the same probability
For any state  SYMBOL  denote by  SYMBOL  the random variable whose value is the number of type-1 transitions from state  SYMBOL  in a sequence of random states  SYMBOL
Define by  SYMBOL  the number of type-1 transitions from state  SYMBOL  in the sequence  SYMBOL
Since all state transitions are either type-0 or type-1  then we have SYMBOL } where  SYMBOL  was defined above
Let  SYMBOL  be a non-negative integer parameter and define the random variable  SYMBOL
Associate a conditional probability function with parameter  SYMBOL  for the random variable  SYMBOL  as  SYMBOL  Then the right side of () equals SYMBOL } For a fixed value of  SYMBOL  the event {}`` SYMBOL '' is equivalent to the event {}`` SYMBOL ''
Hence alternatively, the right side of () can be expressed as  SYMBOL } The right side of () is a product of probability functions of the random variables  SYMBOL
So conditioned on  SYMBOL  and on the event that  SYMBOL  corresponds to a valid state sequence  SYMBOL , the event that  SYMBOL  is generated by the source Markov chain  SYMBOL  is equivalent to the event that its corresponding state sequence  SYMBOL  has transition frequencies  SYMBOL  that independently take the particular values  SYMBOL  as prescribed in  SYMBOL
The claim is proved
It also follows that  SYMBOL  is the average of independent Bernoulli trials (success taken as a type-1 transition from state  SYMBOL )
It is distributed according to the Binomial distribution with parameters  SYMBOL  and  SYMBOL
We now summarize the problem setting under which the main result of the paper holds
Problem setting : Let  SYMBOL  and  SYMBOL  be positive integers
Let  SYMBOL  be the stationary probability distribution based on a finite, ergodic and reversible Markov chain with probability-transition matrix  SYMBOL  that has a second largest eigenvalue  SYMBOL
All probability values are measured according to  SYMBOL
Denote by  SYMBOL
After reaching stationarity the source generates a binary sequence  SYMBOL  by repeatedly drawing  SYMBOL  according to  SYMBOL
Denote by  SYMBOL
Let  SYMBOL  be a data-sequence obtained by randomly drawing according to  SYMBOL
Let the learner's model  SYMBOL  be Markov of order  SYMBOL , and denote by  SYMBOL  the probability of making a type-1 transition from state  SYMBOL  of  SYMBOL
The learner uses the first  SYMBOL  bits,  SYMBOL , to estimate  SYMBOL ) by  SYMBOL
Let  SYMBOL  denote the number of times that state  SYMBOL  appears in  SYMBOL ,  SYMBOL
After training, the learner's decision at state  SYMBOL  is to output  SYMBOL  if  SYMBOL  else output  SYMBOL
Denote by  SYMBOL  the probability that a Binomial random variable with parameters  SYMBOL ,  SYMBOL , is larger (or smaller) than  SYMBOL  given that  SYMBOL  is smaller (or larger) than  SYMBOL , respectively
Let  SYMBOL
Let  SYMBOL
Using  SYMBOL  the learner is tested incrementally on the remaining  SYMBOL  bits  SYMBOL  of the data and predicts an output bit  SYMBOL  for bit  SYMBOL  in  SYMBOL  to be  SYMBOL  if  SYMBOL , else  SYMBOL
Denote by  SYMBOL  the sequence of mistakes where  SYMBOL  if  SYMBOL , and  SYMBOL  otherwise,  SYMBOL
Denote by  SYMBOL ,  SYMBOL , the subsequence of  SYMBOL  with time instants  SYMBOL  corresponding to  SYMBOL -predictions,  SYMBOL ,  SYMBOL
Note that  SYMBOL  is also a subsequence of the input sequence  SYMBOL  hence effectively the learner acts as a selection rule which picks certain bits  SYMBOL  from  SYMBOL
Let    SYMBOL *}   and assume that the learner's model order  SYMBOL  satisfies,    SYMBOL  We now state the main result of the paper
Before presenting the proof we make the following remarks,   The effect of the training sequence length  SYMBOL  on  SYMBOL  is as  SYMBOL  which is  SYMBOL
As  SYMBOL  increases the class of possible learnt models (hypothesis class) decreases in size thereby decreasing the bound  SYMBOL  on the deviation of the error sequence
The effect of the learner's model order  SYMBOL  is opposite of that of  SYMBOL
We see that  SYMBOL  and as  SYMBOL  increases, the hypothesis class increases in size
The effect of the length  SYMBOL  of the error sequence on  SYMBOL  is as  SYMBOL
Clearly, the longer the subsequence the less chance that its frequency of 1s deviate from the mean  SYMBOL
The effect of the inter-dependence between the states of the source model  SYMBOL  on  SYMBOL  is as  SYMBOL
As the dependence increases,  SYMBOL  decreases which increases the possible deviation size  SYMBOL
As  SYMBOL  decreases, the bits of the sequence  SYMBOL  become less dependent and  SYMBOL  decreases
### abstract ###
We consider the problem of estimating the conditional probability of a label in time  SYMBOL , where  SYMBOL  is the number of possible labels
We analyze a natural reduction of this problem to a set of binary regression problems organized in a tree structure, proving a regret bound that scales with the depth of the tree
Motivated by this analysis, we propose the first online algorithm which provably constructs a logarithmic depth tree on the set of labels to solve this problem
We test the algorithm empirically, showing that it works succesfully on a dataset with roughly  SYMBOL  labels
### introduction ###
The central question in this paper is how to efficiently estimate the conditional probability of label  SYMBOL  given an observation  SYMBOL
Virtually all approaches for solving this problem require  SYMBOL  time
A commonly used one-against-all approach, which tries to predict the probability of label  SYMBOL  versus all other labels, for each  SYMBOL ,  requires  SYMBOL  time per training example
Another common  SYMBOL  approach is to learn a scoring function  SYMBOL  and convert it into a conditional probability estimate according to  SYMBOL , where  SYMBOL  is a normalization factor
The motivation for dealing with the computational difficulty is the usual one---we want the capability to solve otherwise unsolvable problems
For example, one of our experiments involves a probabilistic prediction problem with roughly  SYMBOL  labels and  SYMBOL  examples, where any  SYMBOL  solution is intractable
### abstract ###
For a variety of regularized optimization problems in machine learning,  algorithms computing the entire solution path have been developed recently
Most of these methods are quadratic programs that are parameterized by a single parameter, as for example the Support Vector Machine (SVM)
Solution path algorithms do not only compute the solution for one particular value of the regularization parameter but the entire path of solutions, making the selection of an optimal parameter much easier
It has been assumed that these piecewise linear solution paths have only linear complexity, ie \ linearly many bends
We prove that for the support vector machine this complexity can be exponential in the number of training points in the worst case
More strongly, we construct  a single instance of  SYMBOL  input points in  SYMBOL  dimensions for an SVM such that at least  SYMBOL  many distinct subsets of  support vectors % occur as the regularization parameter changes
### introduction ###
Regularization methods such as support vector machines (SVM) and  related kernel methods % have become very successful standard tools in many optimization, classification and regression tasks in a variety of areas, for example signal processing, statistics, biology, computer vision and computer graphics as well as data mining
These regularization methods have in common that they are convex, usually quadratic, optimization problems containing a special parameter in their objective function, called the regularization parameter, representing the tradeoff between two optimization objectives
In machine learning the two terms are usually the model complexity (regularization term) and the accuracy on the training data (loss term), or in other words the tradeoff between a good generalization performance and over-fitting
Such parameterized quadratic programming problems have been studied extensively in both optimization and machine learning, resulting in many algorithms that are able to not only compute solutions at a single value of  the parameter, but along the whole solution path as the parameter varies
For many variants, it is known that the solution paths are piecewise linear functions in the parameter, however, the complexity of these paths remained unknown
Here we prove that the complexity of the solution path for SVMs, which  are simple instances of parameterized quadratic programs, is indeed  exponential in the worst case
Furthermore, our example shows that  exponentially many distinct subsets of support vectors of the optimal  solution occur as the regularization parameter changes
Here  the ``exponentially many'' is valid both in terms of the number of input  points and also in the dimension of the space containing the points
### abstract ###
For a wide variety of regularization methods, algorithms computing the entire solution path have been developed recently
Solution path algorithms do not only compute the solution for one particular value of the regularization parameter but the entire path of solutions, making the selection of an optimal parameter much easier
Most of the currently used algorithms are not robust in the sense that they cannot deal with general or degenerate input
Here we present a new robust, generic method for parametric quadratic programming
Our algorithm directly applies to nearly all machine learning applications, where so far every application required its own different algorithm
We illustrate the usefulness of our method by applying it to a very low rank problem which could not be solved by existing path tracking methods, namely to compute part-worth values in choice based conjoint analysis, a popular technique from market research to estimate consumers preferences on a class of parameterized options
### introduction ###
We study a combinatorial algorithm to solve parameterized quadratic programs, i e , to compute the whole solution path
Unlike other methods employed in machine learning, our algorithm can deal with singular objective function matrices, without perturbing the input
Regularization methods resulting in parametrized quadratic programs have successfully been applied in many optimization, classification and regression tasks in a variety of areas as for example signal processing, statistics, biology, surface reconstruction and information retrieval
We will briefly review some applications here, and we will also study another application, namely choice based conjoint analysis in more detail
Conjoint analysis comprises a popular family of techniques mostly used in market research to assess consumers' preferences on a set of options that are specified by multiple parameters, see~ CITATION  for an overview and recent developments
We will show that a regularization approach to the analysis of preference data leads to a parameterized quadratic program with a sparse, low rank positive semi-definite matrix describing the quadratic term of the objective function
### abstract ###
In the context of inference with expectation constraints, we propose an approach based on the ``loopy belief propagation'' algorithm (\textsc{lpb}), as a surrogate to an exact Markov Random Field (\textsc{mrf}) modelling
A prior information composed of correlations among a large set of  SYMBOL  variables, is encoded into a graphical model; this encoding is optimized with respect to an approximate decoding procedure (\textsc{lbp}), which is used to infer hidden variables from an observed subset
We focus on the situation where the underlying data have many different statistical components, representing a variety of independent patterns
Considering a single parameter family of models we show how \textsc{lpb} may be used to encode and decode efficiently such information, without solving the NP hard inverse problem yielding the optimal \textsc{mrf}
Contrary to usual practice, we work in the non-convex Bethe free energy minimization framework, and manage to associate a belief propagation fixed point to each component of the underlying probabilistic mixture
The mean field limit is considered and yields an exact connection with the Hopfield model at finite temperature and steady state, when the number of mixture components is proportional to the number of variables
In addition, we provide an enhanced learning procedure, based on a straightforward multi-parameter extension of the model in conjunction with an effective continuous optimization procedure
This is performed using the stochastic search heuristic \textsc{cmaes} and yields a significant improvement with respect to the single parameter basic model
### introduction ###
Prediction or recognition methods on systems in a random environment have somehow to exploit regularities or correlations, possibly both spatial and temporal, to infer a global behavior from partial observations
For example, on a road-traffic network, one is interested to extract, from fixed sensors and floating car data, an estimation of the overall traffic situation and its evolution~ CITATION
For image recognition or visual event detection, it is in some sense the mutual information between different pixels or sets of pixels that one wishes to exploit
The natural probabilistic tool to encode mutual information is the Markov Random Field (\textsc{mrf}), which marginal conditional probabilities have to be computed for the prediction or recognition process
The inference problem (with expectation constraints~ CITATION ) that we want to address is stated as follows: the system is composed of discrete variables  SYMBOL  for which the only known statistical information is in the form of marginal probabilities,  SYMBOL  on a set  SYMBOL  of cliques  SYMBOL
Such marginals are typically the result of some empirical procedure producing historical data
Based on this historical information,  consider then a situation where some of the variables are observed, say a subset  SYMBOL , while  the other one, the complementary set  SYMBOL , remains hidden
What prediction can be made concerning this complementary set, and how fast can we make this prediction, if we think in terms of real time applications, like traffic prediction for example
Since the variables take their values over a finite set, the marginal probabilities are fully described by a finite set of correlations and, following the principle of maximum entropy distribution of Jaynes~ CITATION , we expect the historical data to be best encoded in a \textsc{mrf} with a joint probability distribution of  SYMBOL  of the form  SYMBOL } This representation corresponds to a factor graph~ CITATION , where by convenience we associate a function  SYMBOL  to each variable  SYMBOL  in addition to the subsets  SYMBOL , that we call ``factors''
SYMBOL  together with  SYMBOL  define the factor graph  SYMBOL , which will be assumed to be connected
There are two main issues:    inverse problem : how to set the parameters of () in order to fulfill the constraints imposed by the historical data
inference : how to decode (in the sense of computing marginals) in the most efficient manner---typically in real time---this information, in terms of conditional probabilities  SYMBOL
Exact procedures generally face an exponential complexity problem both for the encoding and decoding procedures and one has to resort to approximate procedures~ CITATION
The Bethe approximation~ CITATION , which is used in statistical physics consists in minimizing an approximate version of the variational free energy associated to~()
In computer science, the belief propagation \textsc{bp} algorithm~ CITATION  is a message passing procedure that allows to compute efficiently exact marginal probabilities when the underlying graph is a tree
When the graph has cycles, it is still possible to apply the procedure (then referred to as \textsc{lbp}, for ``loopy belief propagation''), which converges with a rather good accuracy on sufficiently sparse graphs
However, there may be several fixed points, either stable or unstable
It has been shown that these points coincide with stationary points of the Bethe free energy~ CITATION  which is defined as follows:  In addition, stable fixed points of \textsc{lbp} are local minima of the Bethe free energy~ CITATION
The question of convergence of \textsc{lbp} has been addressed in a series of works~ CITATION  establishing conditions and bounds on the \textsc{mrf} coefficients for having global convergence
In the present work, we reverse the viewpoint
Since the decoding procedure is performed with \textsc{lbp}, presumably the best encoding of the historical data is the one for which \textsc{lbp}'s output is  SYMBOL  in absence of ``real time'' information, that is when all the variables remain hidden ( SYMBOL )
This has actually been proposed in~ CITATION , where it is proved in a specific case, that working with the ``wrong'' model, i e \ the message passing approximate version, yields better results from the decoding viewpoint
We will come back on this later in Section~, when we will compare various possible approximate models within this framework
In this paper, we propose  a new  approach, based on multiple fixed points of \textsc{lbp} identification, able to deal both with the encoding and decoding  procedure in a consistent way, suitable for real time applications
The paper is organized as follows: our inference strategy is detailed in Section~; in Section~, we specify the problem to the inference of binary variables which distribution follows a mixture of product forms and present some numerical results; these are analyzed in Section~ in the light of some scaling limits where mean field equations become relevant, allowing for a direct connection with the Hopfield model
In Section~ we propose a multi-parameter extension of the model well suited to a continuous optimization, which allows to enhance the performance of the model
Finally we conclude in Section~ by comparing our approach with other variant of \textsc{lbp} and giving perspective for future developments
### abstract ###
Suppose we are given two probability measures on the set of one-way infinite finite-alphabet sequences and consider the question when one of the  measures predicts the other, that is, when conditional probabilities  converge (in a certain sense) when one of the measures is chosen to generate the sequence
This question may be considered a refinement of the problem of sequence prediction in its most general formulation: for a given  class of probability measures, does there exist a measure which predicts all of the measures in the class
To address this problem, we find some conditions on local absolute continuity which are sufficient for prediction and which generalize several different notions which are known to be sufficient for prediction
We also formulate some open questions to outline a direction for finding the conditions on classes of measures for which prediction is possible
### introduction ###
Let a sequence  SYMBOL ,  SYMBOL  of letters from some finite alphabet  SYMBOL  be generated by some probability measure  SYMBOL
Having observed the first  SYMBOL  letters  SYMBOL  we want to predict what is the probability of the next letter being  SYMBOL , for each  SYMBOL
This task is motivated by numerous applications --- from weather forecasting and stock market prediction to data compression
If the measure  SYMBOL  is known completely then the best forecasts one can make for the  SYMBOL st  outcome of a sequence  SYMBOL  is  SYMBOL -conditional probabilities of   SYMBOL  given  SYMBOL
On the other hand, it is immediately apparent that if nothing is known about the distribution  SYMBOL  generating the sequence then no prediction is possible, since for any predictor there is a measure on which it errs (gives inadequate probability forecasts) on every step
Thus one has to restrict the attention to some class of measures
Laplace was perhaps the first to address the question of sequence prediction, his motivation being as follows: Suppose that we know that the Sun has risen every day for 5000 years, what is the probability that it will rise tomorrow
He suggested to assume that the probability that the Sun rises is the same every day and the trials are independent of each other
Thus Laplace considered the task of sequence prediction when the true generating measure belongs to the family of Bernoulli  iid  \ measures  with binary alphabet  SYMBOL
The predicting measure suggested by Laplace was  SYMBOL  where  SYMBOL  is the number of 1s in  SYMBOL
The conditional probabilities of Laplace's measure  SYMBOL  converge to the true conditional probabilities  SYMBOL -almost surely under any Bernoulli  iid  measure  SYMBOL
This approach generalizes to the problem of predicting any finite-memory (e g \ Markovian) measure
Moreover, in  CITATION  a measure  SYMBOL  was constructed for predicting an arbitrary stationary measure
The conditional probabilities of  SYMBOL  converge to the true ones  on average , where average is taken over time steps (that is, in Cesaro sense),  SYMBOL -almost surely for any stationary measure  SYMBOL
However, as it was shown in the same work, there is no measure for which conditional probabilities converge to the true ones  SYMBOL -a s \ for every stationary  SYMBOL
Thus we can see that already for the problem of predicting outcomes of a stationary measure two criteria of prediction arise: prediction in the average (or in Cesaro sense) and prediction on each step, and the solution exists only for the former problem
But what if the measure generating the sequence is not stationary
A different assumption one can make is that the measure  SYMBOL  generating the sequence is computable
Solomonoff  CITATION  suggested a measure  SYMBOL  for predicting any computable probability measure
The key observation here is that the class of all computable probability measures is countable; let us denote it by  SYMBOL
A Bayesian predictor  SYMBOL  for a countable class of measures  SYMBOL   is constructed as follows:  SYMBOL  for any measurable set A, where the weights  SYMBOL  are positive  and sum to one
The best predictor for a measure  SYMBOL  is the measure  SYMBOL  itself
The Bayesian predictor simply takes the weighted average of the predictors for all measures in the class --- for countable classes this is possible
It was shown by Solomonoff  CITATION  that  SYMBOL -conditional probabilities converge to  SYMBOL -conditional probabilities almost surely for any computable measure  SYMBOL
In fact this is a special case of a more general (though without convergence rate) result of Blackwell and Dubins  CITATION  which states that if a measure  SYMBOL  is absolutely continuous with respect to a measure  SYMBOL  then  SYMBOL  converges to  SYMBOL  in total variation  SYMBOL -almost surely
Convergence in total variation means prediction in a very strong sense~--- convergence of conditional probabilities of arbitrary events (not just the next outcome), or prediction with arbitrary fast growing horizon
Since for  SYMBOL  we have  SYMBOL  for every measurable set  SYMBOL  and for every  SYMBOL , each  SYMBOL  is absolutely continuous with respect to  SYMBOL
Thus the problem of sequence prediction for certain  classes of measures (such as the class of all stationary measures or the class of all computable measures) was often addressed in the literature
Although the mentioned classes of measures are sufficiently interesting, it is often hard to decide in applications with which assumptions does a problem at hand comply; not to mention such practical issues as that a predicting measure for all computable measures is necessarily non-computable itself
Moreover, to be able to generalize the solutions of the sequence prediction problem to such problems as active learning, where outcomes of a sequence may depend on actions of the predictor, one has to understand better under which conditions  the problem of sequence prediction is solvable
In particular, in active learning, the stationarity assumption does not seem to be applicable (since the predictions are non-stationary), although, say, the Markov assumption is often applicable and is extensively studied
Thus, we formulate the following general questions which we start to address in the present work:   For which classes of measures is sequence prediction possible
Under which conditions does a measure  SYMBOL  predict a measure  SYMBOL
As we have seen, these questions have many facets, and in particular there are many criteria of prediction to be considered, such as almost sure convergence of conditional probabilities, convergence in average, etc
Extensive as the literature on sequence prediction is, these questions in their full generality have not received much attention
One line of research which exhibits this kind of generality consists in extending the result of Blackwell and Dubins mentioned above, which states that if  SYMBOL  is absolutely continuous with respect to  SYMBOL , then  SYMBOL  predicts  SYMBOL  in total variation distance
In  CITATION  a question of whether, given a class of measures  SYMBOL  and a prior (``meta''-measure)  SYMBOL  over this class of measures, the conditional probabilities of a Bayesian mixture of the class  SYMBOL  w r t
SYMBOL  converge to the true  SYMBOL -probabilities (weakly merge, in terminology of  CITATION ) for  SYMBOL --almost any measure  SYMBOL  in  SYMBOL
This question can be considered solved, since the authors provide necessary and sufficient conditions on the measure given by the mixture of the class  SYMBOL  w r t
SYMBOL  under which prediction is possible
The major difference from the general  questions we posed above is that we do not wish to assume that we have a measure on our class of measures
For large (non-parametric) classes of measures it may not be intuitive which measure over it is natural; rather, the question is  whether a ``natural'' measure which can be used for prediction exists
To address the general questions posed, we start with the following observation
As it was mentioned, for a Bayesian mixture  SYMBOL  of a countable class of measures  SYMBOL ,  SYMBOL , we have  SYMBOL  for any  SYMBOL  and any measurable set  SYMBOL , where  SYMBOL  is a constant
This condition is stronger than the assumption of absolute continuity and is sufficient for prediction in a very strong sense
Since we are willing to be satisfied with prediction in a weaker sense (e g \ convergence of conditional probabilities), let us make a weaker assumption: Say that  a measure  SYMBOL  dominates a measure  SYMBOL  with coefficients  SYMBOL   if \rho(x_1,\dots,x_n) \;\geq\; c_n \mu(x_1,\dots,x_n) for all  SYMBOL \paranodot{The first concrete question} we pose is, under what conditions on  SYMBOL  does () imply that  SYMBOL  predicts  SYMBOL
Observe that if  SYMBOL  for any  SYMBOL  then any measure  SYMBOL  is  locally  absolutely continuous with respect to  SYMBOL  (that is, the measure  SYMBOL  restricted to the first  SYMBOL  trials  SYMBOL  is absolutely continuous w r t
SYMBOL  for each  SYMBOL ), and moreover, for any measure  SYMBOL  some constants  SYMBOL  can be found that satisfy ()
For example, if  SYMBOL  is Bernoulli  iid  \ measure with parameter  SYMBOL  and  SYMBOL  is any other measure, then () is (trivially) satisfied with  SYMBOL
Thus we know that if  SYMBOL  then  SYMBOL  predicts  SYMBOL  in a very strong sense, whereas exponentially decreasing  SYMBOL  are not enough for prediction
Perhaps somewhat surprisingly, we will show that dominance with any subexponentially decreasing coefficients is sufficient for prediction, in a weak sense of convergence of expected averages
Dominance with any polynomially decreasing coefficients, and also with coefficients decreasing (for example) as  SYMBOL , is sufficient for (almost sure) prediction on average (i e \ in Cesaro sense)
However, for prediction on every step we have a negative result: for any dominance coefficients that go to zero there exists a pair of measures  SYMBOL  and  SYMBOL  which satisfy~() but  SYMBOL  does not predict  SYMBOL  in the sense of almost sure convergence of probabilities
Thus the situation is similar to that for predicting any stationary measure: prediction is possible in the average but not on every step
Note also that for Laplace's measure  SYMBOL  it can be shown that  SYMBOL  dominates any  iid  \ measure  SYMBOL  with linearly decreasing coefficients  SYMBOL ; a generalization of  SYMBOL  for predicting all measures with memory  SYMBOL  (for a given  SYMBOL ) dominates them with polynomially  decreasing coefficients
Thus dominance with decreasing coefficients generalizes (in a sense) predicting countable classes of measures (where we have dominance with a constant), absolute continuity (via local absolute continuity), and predicting  iid  \ and finite-memory measures
Another way to look for generalizations  is as follows
The Bayes mixture  SYMBOL , being a sum of countably many measures (predictors), possesses some of their predicting properties
In general, which predictive properties are preserved under summation
In particular, if we have two predictors  SYMBOL  and  SYMBOL  for two classes of measures, we are interested in the question whether  SYMBOL  is a predictor for the union of the two classes
An answer to this question would improve our understanding of how far a class of measures for which a predicting measure exists can be extended without losing this property \paranodot{{Thus,} the second question} we consider is the following: suppose that a measure  SYMBOL  predicts  SYMBOL  (in some weak sense), and let  SYMBOL  be some other measure (e g \ a predictor for a different class of measures)
Does the measure  SYMBOL  still predict  SYMBOL
That is, we ask to which prediction quality criteria does the idea of taking a Bayesian sum generalize
Absolute continuity is preserved under summation along with it's (strong) prediction ability
It was mentioned in  CITATION  that prediction in the (weak) sense of convergence of expected averages of conditional probabilities is preserved under summation
Here we find that several stronger notions of prediction are not preserved under summation
Thus we address the following two questions
Is dominance with decreasing coefficients sufficient for prediction in some sense, under some  conditions on the coefficients
And, if a measure  SYMBOL  predicts a measure  SYMBOL  in some sense, does the measure  SYMBOL  also predict  SYMBOL  in the same sense, where  SYMBOL  is an arbitrary measure
Considering different criteria of prediction (a s \ convergence of conditional probabilities, a s \ convergence of averages, etc ) in the above two questions we obtain not two but many different questions, some of which we answer in the positive and some in the negative,   yet some are left open
The paper is organized as follows
Section~ introduces necessary notation and measures of divergence of probability measures
Section~ addresses the question of whether dominance with decreasing coefficients is sufficient for prediction, while in Section~ we consider the question of summing a predictor with an arbitrary measure
Both sections~ and~ also propose some open questions and directions for future research
In Section~ we discuss some interesting special cases of the questions considered, and also some related problems
### abstract ###
We study the regret of optimal strategies for online convex optimization games
Using von Neumann's minimax theorem, we show that the optimal regret in this adversarial setting is closely related to the behavior of the empirical minimization algorithm in a stochastic process setting: it is equal to the maximum, over joint distributions of the adversary's action sequence, of the difference between a sum of minimal expected losses and the minimal empirical loss
We show that the optimal regret has a natural geometric interpretation, since it can be viewed as the gap in Jensen's inequality for a concave functional---the minimizer over the player's actions of expected loss---defined on a set of probability distributions
We use this expression to obtain upper and lower bounds on the regret of an optimal strategy for a variety of online learning problems
Our method provides upper bounds without the need to construct a learning algorithm; the lower bounds provide explicit optimal strategies for the adversary
### introduction ###
Within the Theory of Learning, two particular topics have gained significant popularity over the past 20 years: Statistical Learning and Online Adversarial Learning
Papers on the former typically study generalization bounds, convergence rates, complexity measures of function classes---all under the assumption that the examples are drawn, typically in an  iid 
manner, from some underlying distribution
Working under such an assumption, Statistical Learning finds its roots in statistics, probability theory, high-dimensional geometry, and one can argue that the main questions are by now relatively well-understood
Online Learning, while having its origins in the early 90's, recently became a popular area of research once again
One might argue that it is the assumptions, or lack thereof, that make online learning attractive
Indeed, it is often assumed that the observed data is generated maliciously rather than being drawn from some fixed distribution
Moreover, in contrast with the ``batch learning'' flavor of Statistical Learning, the sequential nature of the online problem lets the adversary change its strategy in the middle of the interaction
It is no surprise that this adversarial learning seems quite a bit more difficult than its statistical cousin
The worst case adversarial analysis does provide a realistic modeling in learning scenarios such as network security applications, email spam detection, network routing etc , which is largely responsible for the renewed interest in this area
Upon a review of the central results in adversarial online learning---most of which can be found in the recent book Cesa-Bianchi and Lugosi  CITATION ---one cannot help but notice frequent similarities between the guarantees on performance of online algorithms and the analogous guarantees under stochastic assumptions
However, discerning an explicit link has remained elusive
Vovk  CITATION  notices this phenomenon: ``for some important problems, the adversarial bounds of on-line competitive learning theory are only a tiny amount worse than the average-case bounds for some stochastic strategies of Nature
''   In this paper, we attempt to build a bridge between adversarial online learning and statistical learning
Using von Neumann's minimax theorem, we show that the optimal regret of an algorithm for online convex optimization is exactly the difference between a sum of minimal expected losses and the minimal empirical loss, under an adversarial choice of a stochastic process generating the data
This leads to upper and lower bounds for the optimal regret that exhibit several similarities to results from statistical learning
The online convex optimization game proceeds in rounds
At each of these  SYMBOL  rounds, the player (learner) predicts a vector in some convex set, and the adversary responds with a convex function which determines the player's loss at the chosen point
In order to emphasize the relationship with the stochastic setting, we denote the player's choice as  SYMBOL  and the adversary's choice as  SYMBOL
Note that this differs, for instance, from the notation in  CITATION
Suppose  SYMBOL  is a  convex compact  class of functions, which constitutes the set of Player's choices
The Adversary draws his choices from a  closed compact  set  SYMBOL
We also define a continuous bounded loss function  SYMBOL  and assume that  SYMBOL  is convex in the second argument
Denote by  SYMBOL  the associated loss class
Let  SYMBOL  be the set of all probability distributions on  SYMBOL
Denote a sequence  SYMBOL  by  SYMBOL
We denote a joint distribution on  SYMBOL  by a bold-face  SYMBOL  and its conditional  and marginal distributions by  SYMBOL  and  SYMBOL , respectively
The online convex optimization interaction is described as follows \frameitblack{ {Online Convex Optimization (OCO) Game }  \setlength{sep}{-1pt} []  At each time step  SYMBOL  to  SYMBOL ,  Player chooses  SYMBOL   Adversary chooses  SYMBOL   Player observes  SYMBOL  and suffers loss  SYMBOL    }  The objective of the player is to minimize the {regret}  SYMBOL $  It turns out that many online learning scenarios can be realized as instances of OCO, including prediction with expert advice, data compression,  sequential investment, and forecasting with side information (see, for example,~ CITATION )
### abstract ###
Given  iid  \ data from an unknown distribution, we consider the problem of predicting future items
An adaptive way to estimate the probability density is to recursively subdivide the domain to an appropriate data-dependent granularity
In Bayesian inference one assigns a data-independent prior probability to ``subdivide'', which leads to a prior over infinite(ly many) trees
We derive an exact, fast, and simple inference algorithm for such a prior, for the data evidence, the predictive distribution, the effective model dimension, moments, and other quantities
We prove asymptotic convergence and consistency results, and illustrate the behavior of our model on some prototypical functions
### introduction ###
We consider the problem of inference from  iid  \ data  SYMBOL , in particular of the unknown distribution  SYMBOL  the data is sampled from
In case of a continuous domain this means inferring a probability density from data
Without structural assumption on  SYMBOL , this is hard to impossible, since a finite amount of data is never sufficient to uniquely select a density (model) from an infinite-dimensional space of densities (model class)
In parametric estimation one assumes that  SYMBOL  belongs to a finite-dimensional family
The two-dimensional family of Gaussians characterized by mean and variance is prototypical (Figure )
The maximum likelihood (ML) estimate of  SYMBOL  is the distribution that maximizes the data likelihood
Maximum likelihood overfits if the family is too large and especially if it is infinite-dimensional
A remedy is to penalize complex distributions by assigning a prior (2nd order) probability to the densities  SYMBOL
Maximizing the model posterior (MAP), which is proportional to likelihood times the prior, prevents overfitting
A full Bayesian procedure keeps the complete posterior for inference
Typically, summaries like the mean and variance of the posterior are reported }  \paranodot{How to choose the prior } In finite or small compact low-dimensional spaces a uniform prior often works (MAP reduces to ML)
In the non-parametric case one typically devises a hierarchy of finite-dimensional model classes of increasing dimension
Selecting the dimension with maximal posterior often works well due to the Bayes factor phenomenon  CITATION : In case the true model is low-dimensional, higher-dimensional (complex) model classes are automatically penalized, since they contain fewer ``good'' models
In a full Bayesian treatment one would assign a prior probability (e g \  SYMBOL ) to the dimension  SYMBOL   and mix over the dimension
The probably simplest and oldest model for an interval domain is to divide the interval (uniformly) into bins, assume a constant distribution within each bin, and take a frequency estimate for the probability in each bin (Figure ), or a Dirichlet posterior in Bayesian inference
There are heuristics for choosing the number of bins as a function of the data size
The simplicity and easy computability of the bin model is very appealing to practitioners
Drawbacks are that distributions are discontinuous, its restriction to one dimension (or at most low dimension: curse of dimensionality), the uniform (or more generally fixed) discretization, and the heuristic choice of the number of bins
We present a full Bayesian solution to these problems, except for the non-continuity problem
Our model can be regarded as an extension of Polya trees  CITATION
There are plenty of alternative Bayesian models that overcome some or all of the limitations
Examples are % continuous Dirichlet process (mixtures)  CITATION , % Bernstein polynomials  CITATION , % Bayesian field theory  CITATION , % randomized Polya trees  CITATION , % Bayesian bins with boundary averaging  CITATION , % Bayesian kernel density estimation % or other mixture models  CITATION , and universal priors  CITATION , % but exact analytical solutions are infeasible
% Markov Chain Monte Carlo sampling  CITATION , % Expectation Maximization algorithms  CITATION , % variational methods  CITATION , % efficient MAP or M(D)L approximations  CITATION , % or kernel density estimation  CITATION  % can often be used to obtain approximate numerical solutions, but computation time and/or global convergence remain critical issues
There are of course also plenty of non-Bayesian density estimators; see (references in)  CITATION  in general, and  CITATION  for density tree estimation in particular
The idea of the model class discussed in this paper is very simple: With some (e g \ equal) probability, we chose  SYMBOL  either uniform or split the domain in two parts (of equal volume), and assign a prior to each part, recursively, i e \ in each part again either uniform or split
For finitely many splits,  SYMBOL  is a piecewise constant function, for infinitely many splits it is virtually  any  distribution
While the prior over  SYMBOL  is neutral about uniform versus split, we will see that the posterior favors a split if and only if the data clearly indicates non-uniformity
The method is a full Bayesian non-heuristic tree approach to adaptive binning for which we present a very simple and fast algorithm for computing all( ) quantities of interest
Note that we are not arguing that our model performs better in practice than the more advanced models above
The main distinguishing feature of our model is that it allows for a fast and exact analytical solution
It's likely use is as a building block in complex problems, where computation time and Bayesian integration are the major issues
In any case, if/since the Polya tree model deserves attention, also our model should
In Section  we introduce our model and compare it to Polya trees
We also discuss some example domains, like intervals, strings, volumes, and classification tasks
% Section  derives recursions for the posterior and the data evidence
% Section  proves convergence/consistency
% In Section  we introduce further quantities of interest, including the effective model dimension, the tree size and height, the cell volume, and moments, and present recursions for them
% The proper case of infinite trees is discussed in Section , where we analytically solve the infinite recursion at the data separation level
% Section  collects everything together and presents the algorithm
% In Section  we numerically illustrate the behavior of our model on some prototypical functions
% Section  contains a brief summary, conclusions, and outlook, including natural generalizations of our model
% See  CITATION  for program code
### abstract ###
Given a time series of multicomponent measurements  SYMBOL , the usual objective of nonlinear blind source separation (BSS) is to find a ``source" time series  SYMBOL , comprised of statistically independent combinations of the measured components
In this paper, the source time series is required to have a density function in  SYMBOL  that is equal to the product of density functions of individual components
This formulation of the BSS problem has a solution that is unique, up to permutations and component-wise transformations
Separability is shown to impose constraints on certain locally invariant (scalar) functions of  SYMBOL , which are derived from local higher-order correlations of the data's velocity  SYMBOL
The data are separable if and only if they satisfy these constraints, and, if the constraints are satisfied, the sources can be explicitly constructed from the data
The method is illustrated by using it to separate two speech-like sounds recorded with a single microphone
### introduction ###
Sensory devices often receive signals from multiple physical stimuli that evolve simultaneously but are unrelated to one another
In many of these situations, it is necessary to create separate representations of one or more of these stimuli by blindly processing the observed signals (i e , by processing them without prior knowledge of the nature of the stimuli)
In recent years, there has be considerable progress in the solution of this ``blind source separation" (BSS) problem for the special case in which the signals and source variables are linearly related
However, although nonlinear BSS is often performed effortlessly by humans, computational methods for doing this are quite limited~ CITATION
Consider a time series of data  SYMBOL , where  SYMBOL  is a multiplet of  SYMBOL  measurements ( SYMBOL )
The usual objectives of nonlinear BSS are: 1) determine if these data are instantaneous mixtures of  SYMBOL  statistically independent source components  SYMBOL   SYMBOL } where  SYMBOL  is a possibly nonlinear, invertible  SYMBOL  mixing function; 2) if this is the case, compute the mixing function
In other words, the problem is to find a coordinate transformation  SYMBOL  that transforms the observed data  SYMBOL  from the measurement-defined coordinate system ( SYMBOL ) on state space to a special source coordinate system ( SYMBOL ) in which the components of the transformed data are statistically independent
Let  SYMBOL  be the state space probability density function (PDF) in the source coordinate system, defined so that  SYMBOL  is the fraction of total time that the source trajectory  SYMBOL  is located within the volume element  SYMBOL  at location  SYMBOL
In the usual formulation of the BSS problem, the source components are required to be statistically independent in the sense that their state space PDF is the product of the density functions of the individual components  SYMBOL } In every formulation of BSS, multiple solutions can be created by permutations and component-wise transformations of any one solution
However, it is well known that the criterion in () is so weak that it suffers from a much worse non-uniqueness problem: namely, in this form of the BSS problem, multiple solutions can be created by transformations that mix the source variables (see~ CITATION  and references therein)
The issue of non-uniqueness can be circumvented by considering the data's trajectory in  SYMBOL  ( SYMBOL ) instead of  SYMBOL  (i e , state space)
First, let  SYMBOL  be the PDF in this space, defined so that  SYMBOL  is the fraction of total time that the location and velocity of the source trajectory are within the volume element  SYMBOL  at location  SYMBOL
An earlier paper~ CITATION  described a formulation of the BSS problem in which this PDF was required to be the product of the density functions of the individual components  SYMBOL } Separability in  SYMBOL  is a stronger requirement than separability in state space
To see this, note that () can be recovered by integrating both sides of () over all velocities, but the latter equation cannot be deduced from the former one
In fact, it can be shown that () is strong enough to guarantee that the BSS problem in  SYMBOL  has a unique solution, up to permutations and component-wise transformations~ CITATION
Furthermore, this type of statistical independence has the virtue of being satisfied by almost all classical physical systems that are composed of non-interacting subsystems, which are the generators of most signals of interest
The author previously demonstrated~ CITATION  that the  SYMBOL  PDF of a time series induces a Riemannian geometry on the state space, with the metric equal to the local second-order correlation matrix of the data's velocity
Nonlinear BSS can be performed by computing this metric in the  SYMBOL  coordinate system (i e , by computing the second-order correlation of  SYMBOL  at each point  SYMBOL ), as well as its first and second derivatives with respect to  SYMBOL
However, although this is a mathematically correct and complete method of solving the nonlinear BSS problem, it suffers from a practical difficulty: namely, if the dimensionality of state space is high, a great deal of data is required to cover it densely enough in order to calculate these derivatives accurately
The current paper~ CITATION  shows how to perform nonlinear BSS by computing higher-order local correlations of the data's velocity, instead of computing derivatives of its second-order correlation
This approach is advantageous because it requires much less data for an accurate computation
For example, in the synthetic speech separation experiment in Section III, the new method can separate two synthetic utterances recorded with a single microphone after minutes of observation, rather than the hours of observation required by the differential geometric method
The method described in this paper differs significantly from the methods proposed by other investigators because it uses a criterion of statistical independence in  SYMBOL , instead of state space
In addition, there are technical differences between the proposed method and conventional ones
First of all, the technique in this paper exploits statistical constraints on the data that are  locally  defined in state space, in contrast to the usual criteria for statistical independence that are  global  conditions on the data time series or its time derivatives~ CITATION
Furthermore, unlike many other methods~ CITATION , the mixing function is derived in a constructive, deterministic, and non-parametric manner, without employing iterative algorithms, without using probabilistic learning methods, and without parameterizing it with a neural network architecture or other means
In addition, the proposed method can handle any differentiable mixing function, unlike some other techniques that only apply to a restricted class of mixing functions~ CITATION
The next section describes how to separate two-dimensional data into two one-dimensional source variables
Section III illustrates the method by using it to separate two simultaneous speech-like sounds that are recorded with a single microphone
The implications of this work are discussed in the last section
The appendix describes how the method can be generalized to separate data of arbitrary dimensionality into possibly multidimensional source variables
### abstract ###
This paper uses the notion of algorithmic stability to derive novel generalization bounds for several families of transductive regression algorithms, both by using convexity and closed-form solutions
Our analysis helps compare the stability of these algorithms \ignore{It suggests that several existing algorithms might not be stable but prescribes a technique to make them stable }  It also shows that a number of widely used transductive regression algorithms are in fact unstable
Finally, it reports the results of experiments with local transductive regression demonstrating the benefit of our stability bounds for model selection, for one of the algorithms, in particular for determining the radius of the local neighborhood used by the algorithm
### introduction ###
The problem of  transductive inference  was originally introduced by  CITATION
Many learning problems in information extraction, computational biology, natural language processing and other domains can be formulated as a transductive inference problem
In the transductive setting, the learning algorithm receives both a labeled training set, as in the standard induction setting, and a set of unlabeled test points
The objective is to predict the labels of the test points
No other test points will ever be considered
This setting arises in a variety of applications
Often, there are orders of magnitude more unlabeled points than labeled ones and they have not been assigned a label due to the prohibitive cost of labeling
This motivates the use of transductive algorithms which leverage the unlabeled data during training to improve learning performance
This paper deals with transductive regression, which arises in problems such as predicting the real-valued labels of the nodes of a fixed (known) graph in computational biology, or the scores associated with known documents in information extraction or search engine tasks
Several algorithms have been devised for the specific setting of transductive regression  CITATION
Several other algorithms introduced for transductive classification can be viewed in fact as transductive regression ones as their objective function is based on the square loss, for example, in  CITATION
CITATION  gave explicit VC-dimension generalization bounds for transductive regression that hold for all bounded loss functions and coincide with the tight classification bounds of  CITATION  when applied to classification
We present novel algorithm-dependent generalization bounds for transductive regression
Since they are algorithm-specific, these bounds can often be tighter than bounds based on general complexity measures such as the VC-dimension
Our analysis is based on the notion of algorithmic stability and our learning bounds generalize to the transduction scenario the stability bounds given by  CITATION  for the inductive setting and extend to regression the stability-based transductive classification bounds of  CITATION
In Section~ we give a formal definition of the transductive inference learning set-up, including a precise description and discussion of two related transductive settings
We also introduce the notions of cost and score stability used in the following sections
Standard concentration bounds such as McDiarmid's bound  CITATION  cannot be readily applied to the transductive regression setting since the points are not drawn independently but uniformly without replacement from a finite set
Instead, Section~ proves a concentration bound generalizing McDiarmid's bound to the case of random variables sampled without replacement
This bound is slightly stronger than that of  CITATION  and the proof much simpler and more concise
This concentration bound is used to derive a general transductive regression stability bound in Section~
Figure~ shows the outline of the paper
Section~ introduces and examines a very general family of tranductive algorithms, that of local transductive regression (\LTR) algorithms, a generalization of the algorithm of  CITATION
It gives general bounds for the stability coefficients of \LTR\ algorithms and uses them to derive stability-based learning bounds for these algorithms
The stability analysis in this section is based on the notion of cost stability and based on convexity arguments
In Section~, we analyze a general class of unconstrained optimization algorithms that includes a number of recent algorithms  CITATION
The optimization problems for these algorithms admit a closed-form solution
We use that to give a score-based stability analysis of these algorithms
Our analysis shows that in general these algorithms may not be stable
In fact, in Section~ we prove a lower bound on the stability coefficient of these algorithms under some assumptions
Section~ examines a class of constrained regularization optimization algorithms for graphs that enjoy better stability properties than the unconstrained ones just mentioned
This includes the graph Laplacian algorithm of  CITATION
In Section~, we give a score stability analysis with novel generalization bounds for this algorithm, simpler and more general than those given by  CITATION
Section~ shows that algorithms based on constrained graph regularizations are in fact special instances of the \LTR\ algorithms by showing that the regularization term can be written in terms of a norm in a reproducing kernel Hilbert space
This is used to derive a cost stability analysis and novel learning bounds for the graph Laplacian algorithm of  CITATION  in terms of the second smallest eigenvalue of the Laplacian and the diameter of the graph
Much of the results of these sections generalize to other constrained regularization optimization algorithms
These generalizations are briefly discussed in Section~ where it is indicated, in particular, how similar constraints can be imposed to the algorithms of  CITATION  to derive new and stable versions of these algorithms
Finally, Section~ shows the results of experiments with local transductive regression demonstrating the benefit of our stability bounds for model selection, in particular for determining the radius of the local neighborhood used by the algorithm, which provides a partial validation of our bounds and analysis
### abstract ###
We show that learning a convex body in  SYMBOL , given random samples from the body, requires  SYMBOL  samples
By learning a convex body we mean finding a set having at most  SYMBOL  relative symmetric difference with the input body
To prove the lower bound we construct a hard to learn family of convex bodies
Our construction of this family is very simple and based on error correcting codes
### introduction ###
We consider the following problem: Given uniformly random points  from a convex body in  SYMBOL , we would like to approximately learn the body with as few samples as possible
In this question, and throughout this paper, we are  interested in the number of samples but not in the computational requirements for  constructing such an approximation
Our main result will show that this needs about  SYMBOL  samples
This problem is a special case of the statistical problem of inferring  information about a probability distribution from samples
For example, one can approximate the centroid of the body with a sample of size roughly linear in  SYMBOL
On the other hand, a sample of size polynomial in  SYMBOL  is not  enough to approximate the volume of a convex body within a constant factor ( CITATION ,  and see Section  here for a discussion)
Note that known approximation algorithms for the volume (e g ,  CITATION ) do not work in this setting as they need a membership oracle and random points from various carefully chosen subsets of the  input body
Our problem also relates to work in learning theory (e g ,  CITATION ), where one is  given samples generated according to (say) the Gaussian distribution and each sample is labeled  ``positive'' or ``negative'' depending on whether it belongs to the body
Aside from different distributions, another difference between the learning setting of   CITATION  and ours is that in ours one gets only positive examples
Klivans~et~al ~ CITATION  give an algorithm and a nearly matching lower bound for learning convex bodies  with labeled samples chosen according to the Gaussian distribution
Their algorithm takes time   SYMBOL  and they also show a lower bound of  SYMBOL
The problem of learning convex sets from uniformly random samples from them was raised by Frieze~et~al ~ CITATION
They gave a polynomial time algorithm for learning parallelopipeds
Another somewhat related direction is the work on the learnability of discrete distributions by Kearns~et~al ~ CITATION
Our lower bound result (like that of  CITATION ) also allows for membership oracle queries
Note that it is known that estimating the volume of convex bodies requires an exponential number of  membership  queries if the algorithm is  deterministic   CITATION , which implies that learning bodies requires an exponential number of membership queries because if an algorithm can learn the body then it can also estimate its volume
To formally define the notion of learning we need to specify a distance   SYMBOL  between bodies
A natural choice  in our setting is to consider the total variation distance of the uniform distribution on each body (see Section )
We will use the term  random oracle of a convex body  SYMBOL   for a black box that  when queried outputs a uniformly random point from  SYMBOL
Remarkably, the lower bound of Klivans~et~al ~ CITATION  is numerically essentially identical to  ours ( SYMBOL  for  SYMBOL  constant)
Constructions similar to theirs are possible for our particular scenario~ CITATION
We believe that our argument is considerably simpler, and elementary compared to that of  CITATION
Furthermore, our construction of the hard to learn family  is explicit
Our construction makes use of error correcting codes
To our knowledge, this connection with  error correcting codes is new in such contexts and may find further applications
See Section~ for some further comparison \paragraph{An informal outline of the proof } The idea of the proof is to find a large family of convex bodies in  SYMBOL  satisfying two conflicting goals: (1) Any two bodies in the family are almost disjoint; (2) and yet they look alike in the sense that a small sample of random points from any such body is insufficient for determining which one it is
Since any two bodies are almost disjoint, even approximating a body would allow one to determine it exactly
This will imply that it is also hard to approximate
We first construct a family of bodies that although not almost disjoint, have sufficiently large symmetric difference
We will then be able to construct a family with almost disjoint bodies by taking products of bodies in the first family
The first family is quite natural (it is described formally in Sec ~)
Consider the cross polytope  SYMBOL  in  SYMBOL  (generalization of the octahedron to  SYMBOL  dimensions: convex hull of the vectors  SYMBOL , where  SYMBOL  is the unit vector in  SYMBOL  with the   SYMBOL th coordinate  SYMBOL  and the rest  SYMBOL )
A  peak  attached to a facet  SYMBOL  of  SYMBOL  is a pyramid that has  SYMBOL  as its base and has its other vertex outside  SYMBOL  on the normal to  SYMBOL  going  through its centroid
If the height of the peak is sufficiently small then attaching peaks to any subset of the  SYMBOL  facets will result in a convex polytope
We will show later that we can choose the height so that the volume of all the  SYMBOL  peaks is  SYMBOL  fraction of the volume of  SYMBOL
We call this family of bodies  SYMBOL  [We remark that our construction of cross-polytopes with peaks has resemblance to a construction in  CITATION  with different parameters, but there does not  seem to be any connection between the problem studied there and the problem we are interested in ]  Intuitively, a random point in a body from this family tells one that if the point is in one of the peaks then that peak is present, otherwise one learns nothing
Therefore if the number of queries is at most a polynomial in  SYMBOL , then one learns nothing about most of the peaks and so the algorithm cannot tell which body it got
But these bodies do not have large symmetric difference (can be as small as a  SYMBOL  fraction of the cross polytope if the two bodies differ in just one peak) but we can pick a subfamily of them having pairwise symmetric difference at least  SYMBOL  by picking a large random subfamily
We will do it slightly differently which will be more convenient for the proof: Bodies in  SYMBOL  have one-to-one correspondence with binary strings of length  SYMBOL : each facet corresponds to a coordinate of the string which takes value  SYMBOL  if that facet has a peak attached, else it has value  SYMBOL
To ensure that any two bodies in  our family differ in many peaks it suffices to ensure that their corresponding strings have large Hamming distance
Large sets of such strings are of course furnished by good error correcting codes
From this family we can obtain another family of almost disjoint bodies by taking products, while preserving the property that polynomially many random samples do not tell the bodies apart
This product trick (also known as tensoring) has been used many times before, in particular for amplifying hardness, but we are not aware of its use in a setting similar to ours
Our construction of the product family also resembles the operation of concatenation in coding theory
Acknowledgments
We are grateful to Adam Kalai and Santosh Vempala for useful discussions
### abstract ###
In this paper we apply computer learning methods to diagnosing ovarian cancer using the level of the standard biomarker CA125 in conjunction with information provided by mass-spectrometry
We are working with a new data set collected over a period of 7 years
Using the level of CA125 and mass-spectrometry peaks, our algorithm gives probability predictions for the disease
To estimate classification accuracy we convert probability predictions into strict predictions
Our algorithm makes fewer errors than almost any linear combination of the CA125 level and one peak's intensity (taken on the log scale)
To check the power of our algorithm we use it to test the hypothesis that CA125 and the peaks do not contain useful information for the prediction of the disease at a particular time before the diagnosis
Our algorithm produces  SYMBOL -values that are better than those produced by the algorithm that has been previously applied to this data set
Our conclusion is that the proposed algorithm is more reliable for prediction on new data \keywords{Online prediction, aggregating algorithm, ovarian cancer, mass-spectrometry, proteomics}
### introduction ###
Early detection of ovarian cancer is important since clinical symptoms sometimes do not appear until the late stage of the disease
This leads to difficulties in treatment of the patient
Using the antigen CA125 significantly improves the quality of diagnosis
However, CA125 becomes less reliable at early stages and sometimes elevates too late to make use of it
Our goal is to investigate whether existing methods of online prediction can improve the quality of the detection of the disease and to demonstrate that the information contained in mass spectra is useful for ovarian cancer diagnosis in the early stages of the disease
We refer to the  combination  of CA125 and peak intensity meaning the decision rule in the form  SYMBOL *} where  SYMBOL  is the level of CA125,  SYMBOL  is the intensity of the  SYMBOL -th peak, and  SYMBOL  are taken from the sets described below
We consider prediction in  triplets : each case sample is accompanied by two samples from healthy individuals,  matched controls , which are chosen to be as close as possible to the case sample with respect to attributes such as age, storage conditions, and serum processing
In the given triplet of samples of different individuals we detect one sample which we predict as cancer
This framework was first described in  CITATION
The authors analyze an ovarian cancer data set and show that the information contained in mass-spectrometry peaks can help to provide more precise and reliable predictions of the diseased patient than the CA125 criteria by itself some months before the moment of the diagnosis
In this paper we use the same framework and set of decision rules (CA125 combined with peak intensity) to derive an algorithm which performs better in some sense than any of these rules
For our research we use a different more recent ovarian cancer data set  CITATION  processed by the authors of  CITATION  with a larger number of items than in  CITATION
We combine decision rules proposed in  CITATION  by using an online prediction algorithm\footnote[1]{A survey of online prediction can be found in  CITATION  } and thus get our own decision rule
In this paper we use a combining algorithm described in  CITATION , because it allows us to output a probability measure on a given triplet and has the best theoretical guarantees for this type of prediction
In order to estimate classification accuracy, we convert probability predictions into strict predictions by the  maximum rule : we assign weight 1 to the labels with maximum predicted probability, weight 0 to the labels of other samples, and then normalize the assigned weights
We show that our algorithm gives more reliable predictions than the vast majority of particular combinations (in fact, more thorough experiments, not described here, show that it outperforms all particular combinations)
It performs well on different stages of disease
And when testing the hypothesis that CA125 and peaks do not contain useful information for the prediction of the disease at its early stages, our algorithm gives better  SYMBOL -values in comparison to the algorithm which chooses the best combination; in addition, our algorithm requires fewer adjustments
Our paper is organized as follows
In Section~ we describe methods we use to give predictions
Section~ gives a short description of the data set on which we work
We show our experiments and results in Section~, separated into description of the probability prediction algorithm in Subsection~ and detection at different stages before diagnosis in Subsection~
Section~ concludes our paper
### abstract ###
Inferring the sequence of states from observations is one of the most fundamental problems in Hidden Markov Models
In statistical physics language, this problem is equivalent to computing the marginals of a one-dimensional model with a random external field
While this task can be accomplished through transfer matrix methods,  it becomes quickly intractable when the underlying state space is large
This paper develops several low-complexity approximate algorithms to  address this inference problem when the state space becomes large
The new algorithms are based on various mean-field approximations of the transfer matrix
Their performances are studied in detail on a simple realistic model for DNA pyrosequencing
### introduction ###
Hidden Markov Models (HMM's) are a workhorse of modern statistics and  machine learning, with applications ranging from speech recognition to biological sequence alignment, to pattern classification  CITATION
An HMM defines the joint distribution over a sequence of states  SYMBOL ,  SYMBOL , and observations   SYMBOL , whereby the states form a Markov chain and the observations  are conditionally independent given the sequence of states
In formulae we have  SYMBOL }  The most fundamental algorithmic task related to HMM's is arguably the problem of inferring the sequence of states   SYMBOL  from the observations
The conditional  distribution of the state sequence given the observations is, by Bayes theorem,  SYMBOL } where  SYMBOL  can be thought as a normalization constant
The state sequence can then be estimated by the sequence of most likely states (symbol maximum a posteriori probability -MAP- estimation)  SYMBOL } This reduces the inference problem to the problem of computing marginals of  SYMBOL
From a statistical physics point of view  CITATION , the  conditional distribution () can be regarded as the Boltzmann distribution of a one dimensional system with variables  SYMBOL  and energy function  SYMBOL } at temperature  SYMBOL
The sequence of observations thus act  as a quenched external field
As suggested by this analogy, the  marginals of  SYMBOL  can be computed efficiently using a transfer matrix algorithm
In the present context this is also known as the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm  CITATION
The BCJR algorithm has complexity that is linear in the sequence length and quadratic in the number of states  SYMBOL
More precisely, the complexity in  SYMBOL  is the same as  multiplying an  SYMBOL  matrix times an  SYMBOL  vector
While this is easy for simple models with a few states, it becomes intractable for complex models
A simple mechanism leading to state space explosion is the presence of memory in the underlying Markov chain, or the dependence of each observation on multiple states
In all of these cases, the model can be reduced to a standard HMM via state space augmentation, but the augmented  state space becomes exponential in the memory length
This leads to severe limitations on the tractable memory length
This paper proposes several new algorithms for addressing this problem
Our basic intuition is that, when the memory length gets large, the transfer matrix can be accurately approximated using mean field ideas
We study the proposed method on a concrete model used in DNA pyrosequencing
In this case, one is interested in inferring the  underlying DNA sequence from an absorption signal that carries  traces of the base type at several positions
The effective memory length scales roughly as the square root of the sequence length, thus making plain transfer matrix impractical
The paper is organized as follows
The next section will define the  concrete model we study, and Section  describes the connection with DNA pyrosequencing to motivate it
Section  describes the transfer matrix algorithm and several low complexity approximation schemes
After describing a few bounds in , numerical and analytical results are collected in Section  \\
### abstract ###
Boosting is of great interest recently in the machine learning community because  of the impressive performance for classification and regression problems
The success of boosting algorithms may be interpreted in terms of the margin theory   CITATION
Recently, it has been shown that generalization error of classifiers can be obtained by explicitly taking the margin distribution of the training data into account
Most of the current boosting algorithms in practice usually optimize a convex loss function and do not make use of the margin distribution
In this work we design a new boosting algorithm, termed margin-distribution boosting (MDBoost), which directly maximizes the average margin and minimizes the margin variance at the same time
This way the margin distribution is optimized
A totally-corrective optimization algorithm based on column generation is proposed to implement MDBoost
Experiments on various  datasets show that MDBoost outperforms AdaBoost and LPBoost in most cases
### introduction ###
Boosting offers a method for improving existing classification algorithms
Given a training dataset, boosting builds a   strong  classifier using only a  weak  learning algorithm   CITATION
Typically, a weak (or base) classifier generated by the weak learning algorithm has a misclassification error that is slightly better than random guess
A strong classifier has a much better test error
In this sense,  boosting algorithms can boost the weak learning algorithm to obtain a much stronger classifier
Boosting was originally proposed as an ensemble learning method, which depends on majority voting of multiple individual classifiers
Later, Breiman  CITATION  and Friedman  CITATION  observed that many boosting algorithms can be viewed as gradient descent optimization in functional space
Mason  CITATION  developed  AnyBoost for boosting arbitrary loss functions with a similar idea
Despite the large success in practice of these boosting algorithms, there are still open questions about why and how boosting works
Inspired by the large-margin theory in kernel methods,  Schapire   CITATION  presented a margin-based bound for AdaBoost, which tries to interpret AdaBoost's success with the margin theory
Although the margin theory provides a qualitative explanation of the effectiveness  of boosting, the bounds are quantitatively weak
A recent work  CITATION  has proffered new tighter margin bounds, which may be useful for quantitative predictions
Arc-Gv   CITATION , a variant of the AdaBoost algorithm, was designed  by Breiman to empirically test AdaBoost's convergence properties
It   is very similar to AdaBoost (only different  in calculating the coefficient associated with each weak classifier) such that  it increases margins even more aggressively than AdaBoost
Breiman's   experiments on Arc-Gv  show contrary results to the margin theory: Arc-Gv always has a minimum margin that is provably larger than AdaBoost but Arc-Gv performs worse in terms of test error  CITATION
Grove and Schuurmans  CITATION  observed the same phenomenon
In the literature, much work has focused on maximizing the minimum margin  CITATION
Recently, Reyzin and Schapire  CITATION  re-ran Breiman's experiments by controlling weak classifiers' complexity
They found that a better margin distribution is more important than the minimum margin
It is of importance to have a large minimum margin, but not at the expense of other factors
They thus conjectured that maximizing the average margin rather than the minimum margin may lead to improved boosting algorithms
We try to verify this conjecture in this work
Recently, Garg and Roth  CITATION   introduced margin distribution based complexity measure for learning classifiers and developed margin distribution based generalization bounds
Competitive classification results have been shown by optimizing this bound
Another relevant work is  CITATION
CITATION  applies a boosting method to optimize the margin distribution based generalization bound obtained by   CITATION
Experiments show that the new boosting methods achieve considerable improvements over AdaBoost
The optimization of this new boosting method is based on the AnyBoost framework  CITATION
Aligned with these attempts, we propose a new boosting algorithm through optimization of margin distribution (termed MDBoost)
Instead of minimizing a margin distribution based generalization bound, we directly optimize the margin distribution: maximizing the average margin and at the same time minimizing the variance of the margin distribution
The theoretical justification of the proposed MDBoost is that, approximately, AdaBoost actually maximizes the average margin and minimizes the margin variance
The main contributions of our work are as follows
We propose a new totally-corrective boosting algorithm, MDBoost, by optimizing the margin distribution directly
The optimization procedure of MDBoost is based on the idea of  column generation that has been widely used in large-scale linear programming
We empirically demonstrate that MDBoost outperforms AdaBoost and LPBoost on most UCI datasets used in our experiments
The success of MDBoost verifies the conjecture in    CITATION
Our results also show that MDBoost has achieved similar (or better) classification performance compared with AdaBoost-CG  CITATION
AdaBoost-CG  is also totally-corrective in the sense  that all the linear coefficients of the weak classifiers are updated during the training
An advantage of MDBoost is that,  at each iteration, MDBoost solves a quadratic program while AdaBoost-CG needs to solve a general convex program
Throughout the paper, a matrix is denoted by an upper-case letter ( SYMBOL ); a column vector is denoted by a bold low-case letter ( SYMBOL )
The  SYMBOL th row of  SYMBOL  is denoted by  SYMBOL  and the  SYMBOL th column  SYMBOL
We use  SYMBOL  to denote the identity matrix
SYMBOL  and    SYMBOL  are column vectors of  SYMBOL 's and  SYMBOL 's, respectively
Their sizes will be clear from the context
We use  SYMBOL  to denote component-wise inequalities
The rest of the paper is structured as follows
In Section  we present the main idea
In Section  the dual of the MDBoost's optimization problem is derived, which enables us to design an LPBoost-like column generation based boosting algorithm
We provide an experimental comparison of the algorithms on UCI data in Section , and conclude the paper in Section
### abstract ###
Experimental verification has been the method of choice for verifying the stability of a multi-agent reinforcement learning (MARL) algorithm as the number of agents grows and theoretical analysis becomes prohibitively complex
For cooperative  agents, where the ultimate goal is to optimize some global metric, the stability is usually verified by observing the evolution of the global performance metric over time
If the global metric improves and eventually stabilizes, it is considered a reasonable verification of the system's stability
The main contribution of this note is establishing the need for better experimental frameworks and measures to assess the stability of large-scale adaptive cooperative systems
We show an experimental case study where the stability of the global performance metric can be rather deceiving, hiding an underlying instability in the system that later leads to a significant drop in performance
We then propose an alternative metric that relies on  agents' local policies and show, experimentally, that our proposed metric is more effective (than the traditional global performance metric) in exposing the instability of MARL algorithms
### introduction ###
The term  convergence , in reinforcement learning context, refers to the stability of the learning process (and the underlying model) over time
Similar to single agent reinforcement learning algorithms (such as Q-learning  CITATION ), the convergence of a multi-agent reinforcement learning (MARL) algorithm is an important property that received considerable attention  CITATION
However, proving the convergence of a MARL algorithm via theoretical analysis is significantly more challenging than proving the convergence in the single agent case
The presence of other agents that are also learning deem the environment non-stationary, therefore violating a foundational assumption in single agent learning
In fact, proving the convergence of MARL algorithm even in 2-player-2-action single-stage games (arguably the simplest class of multi-agent systems domains) has been challenging  CITATION
As a consequence, experimental verification is usually the method of choice as the number of agents grows and theoretical analysis becomes prohibitively complex
For cooperative agents, researchers typically verified  the stability of a MARL algorithm by observing the evolution of some global performance metric overtime  CITATION
This is not surprising since the ultimate goal of a cooperative system is to optimize some global metric
Examples of global performance metrics include the percentage of total number of delivered packets in routing problems  CITATION , the average turn around time of tasks in task allocation problems   CITATION , or the average reward (received by agents) in general  CITATION
If the global metric improves over time and eventually  appears  to stabilize, it is usually considered a reasonable verification of convergence  CITATION
Even if the underlying agent policies are not stable, one could argue that at the end, global performance is all that matters in a cooperative system
This paper challenges the above (widely-used) practice and establishes the need for better experimental frameworks and measures for assessing the stability of large-scale cooperative systems
We show an experimental case study where the stability of the global performance metric can hide an underlying instability in the system
This hidden instability later leads to a significant drop in the global performance metric itself
We propose an alternative measure that relies on agents' local policies: the policy entropy
We experimentally show that the proposed metric is more effective than the traditional global performance metric in exposing the instability of MARL algorithms in large-scale multi-agent systems
The paper is organized as follows
Section  describes the case study we will be using throughout the paper
Section  reviews MARL algorithms (with particular focus on WPL and GIGA-WoLF, the two algorithms we use in our experimental evaluation)
Section  presents our initial experimental results, where the global performance metric leads to a (misleading) conclusion that a MARL algorithm converges
Section  presents our proposed measure and illustrates how it is used to expose the hidden instability of a MARL algorithm
We conclude in Section
### abstract ###
We describe a preliminary investigation into learning a Chess player's style from game records
The method is based on attempting to learn features of a player's individual evaluation function using the method of temporal differences, with the aid of a conventional Chess engine architecture
Some encouraging results were obtained in learning the styles of two recent Chess world champions, and we report on our attempt to use the learnt styles to discriminate between the players from game records by trying to detect who was playing white and who was playing black
We also discuss some limitations of our approach and propose possible directions for future research
The method we have presented may also be applicable to other strategic games, and may even be generalisable to other domains where sequences of agents' actions are recorded
### introduction ###
In Chess, as in other popular strategic board games, players have different styles
For example, in Chess some players are more ``positional'' and other more ``tactical'', and this difference in style will affect their move choice in any given board position, and more generally their overall plan
The problem we tackle in this paper is that of applying machine learning to teach a computer to discriminate between players based on their style
Before we explain our methodology, we briefly review the method of temporal difference learning, which is central to our approach
Temporal difference learning  CITATION  is a machine learning technique, originating from the seminal work of Samuel  CITATION , in which learning occurs by minimising the differences between predictions and actual outcomes of a temporal sequence of observations
Samuel  CITATION  used the game of Checkers as a vehicle to study the feasibility of a computer learning from experience
Although the program written by Samuel did not achieve master strength, it was the precursor of the Checkers program Chinook  CITATION , which was the first computer program to win a match against a human world champion (See  CITATION  for a detailed, but less technical, description of the machine learning in Samuel's Checkers program )  Tesauro  CITATION  demonstrated the power of this technique by showing that temporal difference learning, combined with using a neural network, can enable a program to learn to play Backgammon at an expert level through self-play
Following this approach, there have been similar efforts in applying this technique to the games of Chess  CITATION , Go  CITATION , Othello  CITATION  and Chinese Chess  CITATION
Self-play is time consuming, so it is natural to try to make use of existing game records of strong players to train the evaluation function, as in  CITATION  (in which, however, the temporal difference training did not employ minimax lookahead)
Learning from game records has also been used in the game of Go  CITATION  to extract patterns for move prediction, using methods other than temporal difference learning
Here our aim is not necessarily to train a computer to be a competent game player, but rather to teach it to play in the style of a particular player, learning this from records of games played by that player (In principle, the system could learn by interacting with the player but, when sufficient game records exist, learning can generally be accomplished faster and more conveniently off-line ) It is important to note that information available during learning should  not  include any meta-features such as the date when the game was played, the name of the opening variation played, or the result of the game
All the learning module observes is the sequence of moves played in each game
Looking at it from a different perspective, we can view the problem as one of classification
Assume that we train the computer to play in the styles of two Chess players, say Kasparov and Kramnik
The problem can then be reformulated as follows: by inspecting the record of a game played between Kasparov and Kramnik, can the computer detect, with some confidence, which player was playing with the white pieces and which with the black pieces
At an even higher level, the problem can be recast as a Turing test for Chess  CITATION , where a computer may fool a human that it is a human player
In some sense this may already be true for the strongest available computer Chess programs  CITATION , as computers have already surpassed humans in their playing strength, mainly due to increased computing power and relying on brute-force calculations
Moreover, there seems to be a high correlation between the choices made by top human chess Grandmasters and world class chess engines (see  CITATION )
We will not discuss the Turing test debate further and, from now on, we will concentrate on the classification problem within the domain of Chess
As far as we know, this is a new problem, and in this paper we suggest tackling it using temporal difference learning
All previous uses of temporal difference learning in games (some of which are cited above) attempt to learn the weights of an evaluation function in order to improve the play of a computer program
In our scenario we still attempt to learn the weights of an evaluation function, but the objective is to imitate the style of a given player rather than improve the program's play
Of course, if the player under consideration is very strong, for example Kasparov or Kramnik, then the resulting program is likely to improve; but the method could also be used to learn the evaluation functions of weaker players
The learning algorithm described in Section~, based on Sutton's TD(0)  CITATION , corresponds to the simplest rule, which updates only the current predictions
We note that a more general formulation proposed by Sutton is TD( SYMBOL ); this utilises a decay factor  SYMBOL  between 0 and 1, and forces the algorithm to also take into account earlier predictions
To accelerate the training, we utilise both an adaptive learning rate and a momentum term  CITATION , as we describe in Subsection~
In Section~ we present a proof of concept, where we attempt to learn the styles of two recent Chess world champions, Kasparov and Kramnik, and we make use of the learnt feature weights to guess, in a game played between the two players, who was white and who was black
Despite some encouraging results, there are also some fundamental limitations of our approach for defining a player's ``style''
In particular, as pointed out to us by Chess Grandmaster Pablo San Segundo  CITATION , our choice of features (described in Subsection~) is probably too low-level, since all strong players seek to optimise the  placement of their pieces and maintain a combination of pieces according to sound tactical and positional criteria
On a higher level, it is tempting to classify Kasparov as a more ``tactical'' player and Kramnik as a more ``positional'' player
However, these concepts are difficult to formulate in a precise manner and, moreover, it is not clear how to translate them into an algorithmic framework
We discuss these and other issues in Subsection~
In Section~ we give our concluding remarks
### abstract ###
Prediction is a complex notion, and different predictors (such as people, computer programs, and probabilistic theories) can pursue very different goals
In this paper I will review some popular kinds of prediction and argue that the theory of competitive on-line learning can benefit from the kinds of prediction that are now foreign to it
The standard goal for predictor in learning theory is to incur a small loss for a given loss function measuring the discrepancy between the predictions and the actual outcomes
Competitive on-line learning concentrates on a ``relative'' version of this goal: the predictor is to perform almost as well as the best strategies in a given benchmark class of prediction strategies
Such predictions can be interpreted as decisions made by a ``small'' decision maker (i e , one whose decisions do not affect the future outcomes)
Predictions, or  probability forecasts , considered in the foundations of probability are statements rather than decisions; the loss function is replaced by a procedure for testing the forecasts
The two main approaches to the foundations of probability are measure-theoretic (as formulated by Kolmogorov) and game-theoretic (as developed by von Mises and Ville); the former is now dominant in mathematical probability theory, but the latter appears to be better adapted for uses in learning theory discussed in this paper
An important achievement of Kolmogorov's school of the foundations of probability was construction of a universal testing procedure and realization (Levin, 1976) that there exists a forecasting strategy that produces ideal forecasts
Levin's ideal forecasting strategy, however, is not computable
Its more practical versions can be obtained from the results of game-theoretic probability theory
For a wide class of forecasting protocols, it can be shown that for any computable game-theoretic law of probability there exists a computable forecasting strategy that produces ideal forecasts, as far as this law of probability is concerned
Choosing suitable laws of probability we can ensure that the forecasts agree with reality in requisite ways
Probability forecasts that are known to agree with reality can be used for making good decisions: the most straightforward procedure is to select decisions that are optimal under the forecasts (the principle of minimum expected loss)
This gives,  inter alia , a powerful tool for competitive on-line learning; I will describe its use for designing prediction algorithms that satisfy the property of universal consistency and its more practical versions
In conclusion of the paper I will discuss some limitations of competitive on-line learning and possible directions of further research \thispagestyle{empty} \ifFULLThe changes I made to the abstract as compared to  CITATION : ``talk'' is replaced by ``paper'' throughout
This abstract still refers to ``outcomes'' (rather than the ``observations'' and ``data'' of the main part of the paper) \blueend
### introduction ###
This paper is based on my invited talk at the 19th Annual Conference on Learning Theory (Pittsburgh, PA, June 24, 2006)
In recent years COLT invited talks have tended to aim at establishing connections between the traditional concerns of the learning community and the work done by other communities (such as game theory, statistics, information theory, and optimization)
Following this tradition, I will argue that some ideas from the foundations of probability can be fruitfully applied in competitive on-line learning
In this paper I will use the following informal taxonomy of predictions (reminiscent of Shafer's  CITATION , Figure 2, taxonomy of probabilities):  [D-predictions] are mere Decisions
They can never be true or false but can be good or bad
Their quality is typically evaluated with a loss function [S-predictions] are Statements about reality
They can be tested and, if found inadequate, rejected as false [F-predictions] (or Frequentist predictions) are intermediate between D-pre\-dic\-tions and S-predictions
They are successful if they match the fre\-quen\-cies of various observed events
Traditionally, learning theory in general and competitive on-line learning in particular consider D-predictions
I will start, in Section , from a simple asymptotic result about D-predictions: there exists a universally consistent on-line prediction algorithm (randomized if the loss function is not required to be convex in the prediction)
Section  is devoted to S-prediction and Section  to F-prediction
We will see that S-prediction is more fundamental than, and can serve as a tool for, F-prediction
Section  explains how F-prediction (and so, indirectly, S-prediction) is relevant for D-prediction
In Section  I will prove the result of Section  about universal consistency, as well as its non-asymptotic version
### abstract ###
We present a method for learning max-weight matching predictors in bipartite graphs
The method consists of performing maximum a posteriori estimation in exponential families with sufficient statistics that encode permutations and data features
Although inference is in general hard, we show that for one very relevant application--web page ranking--exact inference is efficient
For general model instances, an appropriate sampler is readily available
Contrary to existing max-margin matching models, our approach is statistically consistent and, in addition, experiments with increasing sample sizes indicate superior improvement over such models
We apply the method to graph matching in computer vision as well as to a standard benchmark dataset for learning web page ranking, in which we obtain state-of-the-art results, in particular improving on max-margin variants
The drawback of this method with respect to max-margin alternatives is its runtime for large graphs, which is comparatively high
### introduction ###
The Maximum-Weight Bipartite Matching Problem (henceforth `matching problem') is a fundamental problem in combinatorial optimization  CITATION
This is the problem of finding the `heaviest' perfect match in a weighted bipartite graph
An exact optimal solution can be found in cubic time by standard methods such as the Hungarian algorithm
This problem is of practical interest because it can nicely model real-world applications
For example, in computer vision the crucial problem of finding a correspondence between sets of image features is often modeled as a matching problem  CITATION
Ranking algorithms can be based on a matching framework  CITATION , as can clustering algorithms  CITATION
When modeling a problem as one of matching, one central question is the choice of the weight matrix
The problem is that in real applications we typically observe edge  feature vectors , not edge weights
Consider a concrete example in computer vision: it is difficult to tell what the `similarity score' is between two image feature points, but it is straightforward to extract feature vectors (e g ~SIFT) associated with those points
In this setting, it is natural to ask whether we could parameterize the features, and use  labeled matches  in order to estimate the parameters such that, given graphs with `similar' features, their resulting max-weight matches are also `similar'
This idea of `parameterizing algorithms' and then optimizing for agreement with data is called  structured estimation   CITATION
CITATION  and  CITATION  describe max-margin structured estimation formalisms for this problem
Max-margin structured estimators are appealing in that they  try  to minimize the loss that one really cares about (`structured losses', of which the Hamming loss is an example)
However structured losses are typically piecewise constant in the parameters, which eliminates any hope of using smooth optimization directly
Max-margin estimators instead minimize a surrogate loss which is easier to optimize, namely a convex upper bound on the structured loss  CITATION
In practice the results are often good, but known convex relaxations produce estimators which are statistically inconsistent  CITATION , i e ,~the algorithm in general fails to obtain the best attainable model in the limit of infinite training data
The inconsistency of multiclass support vector machines is a well-known issue in the literature that has received careful examination recently  CITATION
Motivated by the inconsistency issues of max-margin structured estimators as well as by the well-known benefits of having a full probabilistic model, in this paper we present a maximum a posteriori (MAP) estimator for the matching problem
The observed data are the edge feature vectors and the labeled matches provided for training
We then maximize the conditional posterior likelihood of matches given the observed data
We build an exponential family model where the sufficient statistics are such that the mode of the distribution (the prediction) is the solution of a max-weight matching problem
The resulting partition function is  SYMBOL P-complete to compute exactly
However, we show that for  learning to rank  applications the model instance is tractable
We then compare the performance of our model instance against a large number of state-of-the-art ranking methods, including DORM  CITATION , an approach that only differs to our model instance by using max-margin instead of a MAP formulation
We show very competitive results on standard webpage ranking datasets, and in particular we show that our model performs better than or on par with DORM
For intractable model instances, we show that the problem can be approximately solved using sampling and we provide experiments from the computer vision domain
However the fastest suitable sampler is still quite slow for large models, in which case max-margin matching estimators like those of  CITATION  and  CITATION  are likely to be preferable even in spite of their potential inferior accuracy
### abstract ###
In this paper we propose an algorithm for polynomial-time reinforcement learning in factored Markov decision processes (FMDPs)
The factored optimistic initial model (FOIM) algorithm, maintains an empirical model of the FMDP in a conventional way, and always follows a greedy policy with respect to its model
The only trick of the algorithm is that the model is initialized optimistically
We prove that with suitable initialization (i) FOIM converges to the fixed point of approximate value iteration (AVI); (ii) the number of steps when the agent makes non-near-optimal decisions (with respect to the solution of AVI) is polynomial in all relevant quantities; (iii) the per-step costs of the algorithm are also polynomial
To our best knowledge, FOIM is the first algorithm with these properties
This extended version contains the rigorous proofs of the main theorem
A version of this paper appeared in ICML'09
### introduction ###
Factored Markov decision processes (FMDPs) are practical ways to compactly formulate sequential decision problems---provided that we have ways to solve them
When the environment is unknown, all effective reinforcement learning methods apply some form of the ``optimism in the face of uncertainty'' principle: whenever the learning agent faces the unknown, it should assume high rewards in order to encourage exploration
Factored optimistic initial model  (FOIM) takes this principle to the extreme: its model is initialized to be overly optimistic
For more often visited areas of the state space, the model gradually gets more realistic, inspiring the agent to head for unknown regions and explore them, in search of some imaginary ``Garden of Eden''
The working of the algorithm is simple to the extreme: it will not make any explicit effort to balance exploration and exploitation, but always follows the greedy optimal policy with respect to its model
We show in this paper that this simple (even simplistic) trick is sufficient for effective FMDP learning
The algorithm is an extension of OIM ( optimistic initial model )  CITATION , which is a sample-efficient learning algorithm for flat MDPs
There is an important difference, however, in the way the model is solved
Every time the model is updated, the corresponding value function needs to be re-calculated (or updated) For flat MDPs, this is not a problem: various dynamic programming-based algorithms (like value iteration) can solve the model to any required accuracy in polynomial time
The situation is less bright for generating near-optimal FMDP solutions: all currently known algorithms may take exponential time, eg the approximate policy iteration of  CITATION  using decision-tree representations of policies, or solving the exponential-size flattened version of the FMDP
If we require polynomial running time (as we do in this paper in search for a practical algorithm), then we have to accept sub-optimal solutions
The only known example of a polynomial-time FMDP planner is  factored value iteration  (FVI)  CITATION , which will serve as the base planner for our learning method
This planner is guaranteed to converge, and the error of its solution is bounded by a term depending only on the quality of function approximators
Our analysis of the algorithm will follow the established techniques for analyzing sample-efficient reinforcement learning (like the works of  CITATION  on flat MDPs and  CITATION  on FMDPs)
However, the listed proofs of convergence rely critically on access to a near-optimal planner, so they have to be generalized suitably
By doing so, we are able to show that FOIM converges to a bounded-error solution in polynomial time with high probability
We introduce basic concepts and notations in section , then in section  we review existing work, with special emphasis to the immediate ancestors of our method
In sections  and  we describe the blocks of FOIM and the FOIM algorithm, respectively
We finish the paper with a short analysis and discussion
### abstract ###
In this paper, we consider the coherent theory of (epistemic) uncertainty of Walley, in which beliefs are represented through sets of probability distributions, and we focus on the problem of modeling prior ignorance about a categorical random variable
In this setting, it is a known result that a state of prior ignorance is not compatible with learning
To overcome this problem, another state of beliefs, called  near-ignorance , has been proposed
Near-ignorance resembles ignorance very closely, by satisfying some principles that can arguably be regarded as necessary in a state of ignorance, and allows learning to take place
What this paper does, is to provide new and substantial evidence that also near-ignorance cannot be really regarded as a way out of the problem of starting statistical inference in conditions of very weak beliefs
The key to this result is focusing on a setting characterized by a variable of interest that is  latent
We argue that such a setting is by far the most common case in practice, and we provide, for the case of categorical latent variables (and general  manifest  variables) a condition that, if satisfied, prevents learning to take place under prior near-ignorance
This condition is shown to be easily satisfied even in the most common statistical problems
We regard these results as a strong form of evidence against the possibility to adopt a condition of prior near-ignorance in real statistical problems
### introduction ###
Epistemic theories of statistics are often confronted with the question of  prior ignorance
Prior ignorance means that a subject, who is about to perform a statistical analysis, is missing substantial beliefs about the underlying data-generating process
Yet, the subject would like to exploit the available sample to draw some statistical conclusion, i e , the subject would like to use the data to learn, moving away from the initial condition of ignorance
This situation is very important as it is often desirable to start a statistical analysis with weak assumptions about the problem of interest, thus trying to implement an objective-minded approach to statistics
A fundamental question is whether prior ignorance is compatible with learning or not
Walley gives a negative answer for the case of his self-consistent (or  coherent ) theory of statistics based on the modeling of beliefs through sets of probability distributions
He shows, in a very general sense, that  vacuous  prior beliefs, i e , beliefs that a priori are maximally imprecise, lead to vacuous posterior beliefs, irrespective of the type and amount of observed data  CITATION
At the same time, he proposes focusing on a slightly different state of beliefs, called  near-ignorance , that does enable learning to take place  CITATION
Loosely speaking, near-ignorant beliefs are beliefs that are vacuous for a proper subset of the functions of the random variables under consideration (see Section~)
In this way, a near-ignorance prior still gives one the possibility to express vacuous beliefs for some functions of interest, and at the same time it maintains the possibility to learn from data
The fact that learning is possible under prior near-ignorance is shown, for instance, in the special case of the  imprecise Dirichlet model  (IDM)  CITATION
This is a popular model, based on a near-ignorance set of priors, used in the case of inference from categorical data generated by a multinomial process
Our aim in this paper is to investigate whether near-ignorance can be really regarded as a possible way out of the problem of starting statistical inference in conditions of very weak beliefs
We carry out this investigation in a setting made of categorical data generated by a multinomial process, like in the IDM, but we consider near-ignorance sets of priors in general, not only that used in the IDM
The interest in this investigation is motivated by the fact that near-ignorance sets of priors appear to play a crucially important role in the question of modeling prior ignorance about a categorical random variable
The key point is that near-ignorance sets of priors can be made to satisfy two principles: the  symmetry  and the  embedding principles
The first is well known and is equivalent to Laplace's  indifference principle ; the second states, loosely speaking, that if we are ignorant a priori, our prior beliefs on an event of interest should not depend on the space of possibilities in which the event is embedded (see Section~ for a discussion about these two principles)
Walley  CITATION , and later de Cooman and Miranda  CITATION , have argued extensively on the necessity of both the symmetry and the embedding principles in order to characterize a condition of ignorance about a categorical random variable
This implies, if we agree that the symmetry and the embedding principles are necessary for ignorance, that near-ignorance sets of priors should be regarded as an especially important avenue for a subject who wishes to learn starting in a condition of ignorance
Our investigation starts by focusing on a setting where the categorical variable  SYMBOL  under consideration is  latent
This means that we cannot observe the realizations of  SYMBOL , so that we can learn about it only by means of another, not necessarily categorical, variable  SYMBOL , related to  SYMBOL  through a known conditional probability distribution  SYMBOL
Variable  SYMBOL  is assumed to be  manifest , in the sense that its realizations can be observed (see Section~)
The intuition behind the setup considered, made of  SYMBOL  and  SYMBOL , is that in many real cases it is not possible to directly observe the value of a random variable in which we are interested, for instance when this variable represents a patient's health and we are observing the result of a diagnostic test
In these cases, we need to use a manifest variable (the medical test) in order to obtain information about the original latent variable (the patient's health)
In this paper, we regard the passage from the latent to the manifest variable as made by a process that we call the  observational process
Using the introduced setup, we give a condition in Section~, related to the likelihood function, that is shown to be sufficient to prevent learning about  SYMBOL  under prior near-ignorance
The condition is very general as it is developed for any set of priors that models near-ignorance (thus including the case of the IDM), and for very general kinds of probabilistic relations between  SYMBOL  and  SYMBOL
We show then, by simple examples, that such a condition is easily satisfied, even in the most elementary and common statistical problems
In order to fully appreciate this result, it is important to realize that latent variables are ubiquitous in problems of uncertainty
The key point here is that the scope of observational processes greatly extends if we consider that even when we directly obtain the value of a variable of interest, what we actually obtain is the observation of the value rather than the value itself
Doing this distinction makes sense because in practice an observational process is usually imperfect, i e , there is very often (it could be argued that there is always) a positive probability of confounding the realized value of  SYMBOL  with another possible value committing thus an observation error
Of course, if the probability of an observation error is very small and we consider one of the common Bayesian model proposed to learn under prior ignorance, then there is little difference between the results provided by a latent variable model modeling correctly the observational process, and the results provided by a model where the observations are assumed to be perfect
For this reason, the observational process is often neglected in practice and the distinction between the latent variable and the manifest one is not enforced
But, on the other hand, if we consider sets of probability distributions to model our prior beliefs, instead of a single probability distribution, and in particular if we consider near-ignorance sets of priors, then there can be an extreme difference between a latent variable model and a model where the observations are considered to be perfect, so that learning may be impossible in the first model and possible in the second
As a consequence, when dealing with sets of probability distributions, neglecting the observational process may be no longer justified even if the probability of observation error is tiny
This is shown in a definite sense in Example~ of Section~, where we analyze the relevance of our results for the special case of the IDM
From the proofs in this paper, it follows that this kind of behavior is mainly determined by the presence, in the near-ignorance set of priors, of extreme, almost-deterministic, distributions
And the question is that these problematic distributions, which are usually not considered when dealing with Bayesian models with a single prior, cannot be ruled out without dropping near-ignorance
These considerations highlight the quite general applicability of the present results and raise hence serious doubts about the possibility to adopt a condition of prior near-ignorance in real, as opposed to idealized, applications of statistics
As a consequence, it may make sense to consider re-focusing the research about this subject on developing models of very weak states of belief that are, however, stronger than near-ignorance
This might also involve dropping the idea that both the symmetry and the embedding principles can be realistically met in practice
### abstract ###
Engine assembly is a complex and heavily automated distributed-control process, with large amounts of faults data logged everyday
We describe an application of temporal data mining for analyzing fault logs in an engine assembly plant
Frequent episode discovery framework is a model-free method that can be used to deduce (temporal) correlations among events from the logs in an efficient manner
In addition to being theoretically elegant and computationally efficient, frequent episodes are also easy to interpret in the form actionable recommendations
Incorporation of domain-specific information is critical to successful application of the method for analyzing fault logs in the manufacturing domain
We show how domain-specific knowledge can be incorporated using heuristic rules that act as pre-filters and post-filters to frequent episode discovery
The system described here is currently being used in one of the engine assembly plants of General Motors and is planned for adaptation in other plants
To the best of our knowledge, this paper presents the first real, large-scale application of temporal data mining in the manufacturing domain
We believe that the ideas presented in this paper can help practitioners engineer tools for analysis in other similar or related application domains as well
### introduction ###
Automotive engine assembly is a heavily automated and complex process that is  controlled in a distributed fashion
Each assembly plant consists of several machines (or operations/stations) that are extensively inter-connected and are programmed to automatically execute the various operations necessary to manufacture an automotive engine
The distributed control system maintains elaborate logs regarding the time-evolving conditions of all machines in the plant, the status of different operations performed on a particular engine, the throughput statistics of the plant, etc
In this paper, we present an application that uses temporal data mining techniques for analyzing these time-stamped logs to help in  fault analysis and root-cause diagnosis
The application presented here is currently being used on a regular basis in engine assembly plants of General Motors }
### abstract ###
The problem of multi--agent learning and adaptation has attracted a great deal of attention in recent years
It has been suggested that the dynamics of multi agent learning can be studied using replicator equations from population biology
Most existing studies so far have been limited to discrete strategy spaces with a small number of available actions
In many cases, however, the choices available to agents are better characterized by continuous spectra
This paper suggests a generalization of the replicator framework that allows to study the adaptive dynamics of  SYMBOL --learning agents with continuous strategy spaces
Instead of probability vectors, agents' strategies are now characterized by probability measures over  continuous variables
As a result, the ordinary differential equations for the discrete case are replaced by a system of coupled integral--differential replicator equations that describe the mutual evolution of individual agent strategies
We derive a set of functional equations describing  the steady state  of the replicator dynamics, examine their solutions for several two--player games, and confirm our analytical results using simulations
### introduction ###
The notion of autonomous agents that learn by interacting with the environment, and possibly with other agents, is a central concept in modern distributed AI~ CITATION
Of particular interests are systems where multiple agents learn concurrently and independently by interacting with each other
This multi--agent learning problem has attracted a great deal of attention due to a number of important applications
Among existing approaches,  multi--agent reinforcement learning (MARL) algorithms have become increasingly popular due to their generality~ CITATION
Although MARL does not hold the same convergence guarantees as in single--agent case,  it has been shown to work well in practice (for a  recent survey, see~ CITATION )
From the analysis standpoint, MARL represents a complex  dynamical system, where the learning trajectories of individual agents are coupled with each other via  a collective reward  mechanism
Thus, it is desirable to know what are the possible long--term behaviors of those trajectories
Specifically, one is usually interested whether, for a particular game structure, those trajectories converge to a    desirable steady state (called fixed points),    or oscillate indefinitely between many (possibly infinite) meta--stable states
While answering this question has proven to be very difficult in the most general settings, there has been some limited progress  for specific scenarios
In particular, it has been established that for  simple, stateless Q--learning with a finite number of actions, the learning dynamics can be examined using the so called  replicator equations  from population biology~ CITATION
Namely, if one associates a particular biological trait with each pure strategy, then the adaptive learning of (possibly mixed) strategies in multi--agent settings is analogous to   competitive dynamics of mixed population, where the species evolve according to their relative fitness in the population
This framework has been used successfully to study various interesting features of adaptive dynamics of learning agents~ CITATION
With a few exceptions (e g , see ~ CITATION ), most existing studies so far have focused on discrete action spaces, which has limited the full analysis of the learning dynamics to games with very few actions
On the other hand, in many practical scenarios, strategic interactions between agents are better characterized by continuous spectra of possible choices
For instance, modeling an agent's bid in an auction with a continuous rather than discrete variable is more natural
In such situations, agents' strategies are represented as  probability density functions defined over a continuous set of actions
Of course, in reality all  the decisions are made over a discretized subset
However, the rationale for using the continuous approximation is that it makes the dynamics more amenable to mathematical analysis
In this paper we consider simple  SYMBOL --learning agents  that play repeated continuous--strategy games
The agents use Boltzmann action--selection mechanism that controls the exploration/exploitation tradeoff through a single temperature--like parameter
The reward functions for the agents are assumed to be functions of continuous variables instead of tensors, and the agent strategies are represented as probability distribution over those variables
In contrast to the finite strategy spaces where the learning dynamics is captured by a set of coupled ordinary differential equations, the replicator dynamics for  the continuous--strategy games are described by functional--differential equations for each agent, with coupling across different agents/equations
The long--term behavior of those equations define the steady state, or equilibrium, profiles of the agent strategies
It is shown that, in general, the steady state strategy profiles of the replicator dynamics  do not correspond to the Nash equilibria of the  game
This discrepancy can be attributed to the limited rationality of the agents due to exploration
In particular, for the Boltzmann action-selection mechanism studied here, exploration results in adding an entropic term to the agents' payoff function, with a coefficient  governed by the exploration rate (temperature)
Thus, when one  decreases the exploration rate, the relative importance of this term diminishes and one is able to gradually recover the correspondence with the Nash equilibria
Furthermore, for games that allow  uniformly  mixed Nash equilibrium, the steady state solution of the replicator equation  is identical with this uniform Nash equilibrium for any  exploration rate
This is because the uniform distribution already maximizes the entropic  term
And example of such a game if provided in Section~
The rest of this paper is organized as follows: In the next section we provide a brief overview of relevant literature
In Section~ we introduce our model,  derive the replicator equations for the continuous strategy spaces, and a set of coupled non--linear functional equations that describe the steady state strategy profile
In Section~ we illustrate the framework on several examples of two--agent games, and  provide some detailed results for  general bi--linear and quadratic payoffs
Finally, we conclude the paper with a discussion of our results and possible future directions in Section~
### abstract ###
This article treats the problem of learning a dictionary providing sparse representations for a given signal class, via  SYMBOL -minimisation
The problem can also be seen as factorising a  SYMBOL  matrix  SYMBOL  of training signals into a  SYMBOL  dictionary matrix  SYMBOL  and a  SYMBOL  coefficient matrix   SYMBOL , which is sparse
The exact question studied here is when a dictionary coefficient pair  SYMBOL  can be recovered as local minimum of a (nonconvex)  SYMBOL -criterion with input  SYMBOL
First, for general dictionaries and coefficient matrices, algebraic conditions ensuring local identifiability  are derived, which are then specialised to the case when the dictionary is a basis
Finally, assuming a random Bernoulli-Gaussian sparse model on the coefficient matrix, it is shown that sufficiently incoherent bases are locally identifiable with high probability
The perhaps surprising result is that the typically sufficient number of training samples  SYMBOL  grows up to a logarithmic factor only linearly with the signal dimension, ie SYMBOL , in contrast to previous approaches requiring combinatorially many samples
### introduction ###
Many signal processing tasks, such as denoising and compression, can be efficiently performed if one knows a sparse representation of the signals of interest
Moreover, a huge body of recent results on sparse representations has highlighted their impact on inverse linear problems such as (blind) source separation and localisation as well as compressed sampling, for a starting point see eg CITATION \\ In any of these publications, one will - more likely than not - find a statement starting with 'given a dictionary  SYMBOL  and a signal  SYMBOL  having an  SYMBOL -sparse approximation/representation  SYMBOL  \ldots', which points exactly to the remaining problem: all applications of sparse representations rely on a signal dictionary  SYMBOL  from which sparse linear expansions can be built that efficiently approximate the signals from a class of interest; success heavily depends on the good fit between the data class and the dictionary \\ For many signal classes, good dictionaries -- such as time-frequency or time-scale dictionaries -- are known, but new data classes may require the construction of new dictionaries to fit new types of data features
The analytic construction of dictionaries such as wavelets and curvelets stems from deep  mathematical tools from Harmonic Analysis
It may, however, be difficult and time consuming to develop complex mathematical theory each time a new class of data, which requires a different type of dictionary,  is met
An alternative approach is dictionary learning, which aims at infering the dictionary  SYMBOL  from a set of training data  SYMBOL
Dictionary learning, also known as  sparse coding , has the potential of 'industrialising' sparse representation techniques for new data classes \\ This article treats the theoretical dictionary learning problem, expressed as a factorisation problem which consists of identifying a  SYMBOL  matrix  SYMBOL  from a set of  SYMBOL  observed training vectors  SYMBOL ,  knowing that  SYMBOL ,  SYMBOL  for some unknown collection of coefficient vectors  SYMBOL  with certain statistical properties \\ Considering the extensive literature available for the sparse decomposition problem after the early work in ~ CITATION , surprisingly little work has been dedicated to theoretical dictionary learning so far
There exist several dictionary learning algorithms (see eg CITATION ), but only recently people have started to consider also the theoretical aspects of the problem
The origins of research into what is now called dictionary learning can be found in the field of Independent Component Analysis (ICA)~ CITATION
There, many identifiability results are available, which, however, rely on  asymptotic  statistical properties under  statistical independence  and  non-Gaussianity  assumptions \\ In contrast, Georgiev, Theis and Cichocki,  CITATION , as well as Aharon, Elad and Bruckstein,  CITATION , described more geometric identifiability conditions on the sparse coefficients of training data in an ideal (overcomplete) dictionary
Yet, for these conditions to hold, the size  SYMBOL  of the training set seems to be required to grow exponentially fast with the number of atoms  SYMBOL , and the provably good identification algorithms are combinatorial
Moreover, the algorithms and the identifiability analysis are not robust to 'outliers', i e , training samples  SYMBOL  where  SYMBOL  fails to be sufficiently sparse
For applications, on the other hand, we are concerned with relatively large-dimensional data (e g SYMBOL , or even  SYMBOL ) but limited availability of training data ( SYMBOL  is not much larger than say  SYMBOL ) as well as limited computational resources \\ In this article, we study the possibility of designing provably good, non-combinatorial dictionary learning algorithms that are robust to outliers and to the limited availability of training samples
Inspired by recent proofs of good properties of  SYMBOL -minimisation for sparse signal decomposition with a given dictionary, we investigate the properties of  SYMBOL -based dictionary learning,  CITATION
Our ultimate goal, described in details in Section~, is to characterise properties that a set of training samples  SYMBOL  should satisfy to guarantee that an ideal dictionary is the only local minimum of the  SYMBOL -criterion, opening up the possibility of replacing combinatorial learning algorithms with efficient numerical descent techniques
As a first step, we investigate conditions under which an ideal dictionary is a local minimum of the  SYMBOL -criterion \\ {Main results }  First,  we describe the proposed setting in Section~ and characterise the local minima of the  SYMBOL -cost function in Section~
We discuss the geometrical interpretation of this characterisation in Section~
Then, using concentration of measure, we prove in Section~ the perhaps surprising result that when    SYMBOL  if the samples  SYMBOL , are a typical draw from a Bernoulli-Gaussian random distribution (which can generate a large proportion of  outliers ), then any sufficiently incoherent basis matrix  SYMBOL ,  SYMBOL , is a local minimum of the cost function and is therefore 'locally identifiable'
The constant  SYMBOL  depends on a parameter of the Bernoulli-Gaussian distribution which drives the sparsity of the training set \\ This number of training samples is surprisingly small considering that  SYMBOL  training samples provide  SYMBOL  real parameters, while the basis matrix  SYMBOL  is essentially parameterised by  SYMBOL  independent real parameters \\ In the considered matrix identification setting, it should be noted that  SYMBOL  is  not  a convex cost function
It admits  several local minima  hence local identifiability only implies that, upon good initial conditions, numerical optimisation schemes performing the  SYMBOL -optimisation will recover the desired matrix  SYMBOL
However, empirical experiments in low dimension ( SYMBOL ), shown in Section~, indicate that for typical draws of Bernoulli-Gaussian training samples  SYMBOL , the matrix  SYMBOL  is in fact the  only  local minimum of the criterion (up to natural indeterminacies of the problem such as column permutation)
If this empirical observation could be turned into a theorem for general dimension  SYMBOL  under the Bernoulli-Gaussian sparse model, this would imply that typically: a)  SYMBOL -minimisation is a good  identification principle ; b) any decent  SYMBOL -descent algorithm is a good  identification algorithm
                                                                                                                                                                                                                                                                                                                                                                                                                                                 makros
tex                                                                                          0000644 0000000 0000000 00000005040 11311243514 011564  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   % \newcommand\dico{\mathbf{\Phi}} \newcommand\atom{\varphi} \newcommand\inn[2]{\langle\atom_{#1}, \atom_{#2}\rangle} \newcommand\ip[2]{#1, #2\rangle} \newcommand\natoms{K} \newcommand\sparsity{S} \newcommand\ddim{d} \newcommand\good{\Lambda} \newcommand\bad{{\overline{\good}}} \newcommand\sensing{\mathbf{\Psi}} \newcommand\satom{\psi} \newcommand\ident{\mathbf{I}} \newcommand\Id{\mathbf{I}} \newcommand\Proj{\mathbf{P}} \newcommand\Q{\mathbf{Q}} \newcommand\Gram{\mathbf{G}} \newcommand\DX{\Sigma} %diagonal matrix with norms of coefficients \newcommand\coeff{\sigma} \newcommand\Dynamic{\operatorname{R}} \newcommand\PSNR{\operatorname{PSNR}} \newcommand\samesim{\beta} \newcommand\gwJ{{\goodJ}} \newcommand\noise{{\eta}} \newcommand\ie{{i e }} \newcommand\iid{{ iid  }} \newcommand\Y{Y} \newcommand\X{X} \newcommand\rownormX[1]{\mathcal{X}^{#1}} \newcommand\eps{\varepsilon} \newcommand\manifold{\mathcal{D}} \newcommand\tangentspace[2]{T_{#2}#1} \newcommand\Sph{\mathcal{S}} \newcommand\pnorm{{q}} \newcommand\randsign[0]{\xi} \def\radius{R} {\mathbf{\Psi}} {\psi} {\mathbf{M}_0} {\mathbf{D}_0} {\mathbf{V}} {\mathbf{Z}} {\mathbf{\Delta}} {\mathbf{A}} \newcommand\Ogroup[1]{\mathcal{O}(#1)} \newcommand\Uclass[1]{\mathcal{B}(#1)} \newcommand\nsig[0]{N} \newcommand\Xbar[0]{\bar{\X}} \newcommand\Cost[1]{\mathcal{C}_{#1}} \newcommand\Null{\mathcal{N}} \newcommand\Nvec{\mathbf{N}} \newcommand\epscover{\mathcal{X}}  \newcommand\U{U} \newcommand\Err{E} \newcommand\diag{\operatorname{diag}} \newcommand\signop{\operatorname{sign}} \newcommand\sign{\operatorname{sign}} \newcommand\trace{\operatorname{trace}} \newcommand\B{\mathbf{B}} \newcommand{\N}{{\mathbb{N}}} \newcommand{\R}{{\mathbb{R}}} \newcommand{\Z}{{\mathbb{Z}}} \newcommand{\C}{{\mathbb{C}}} \renewcommand{\P}{{\mathbb{P}}} \newcommand{\E}{{\mathbb{E}}} \newcommand\opnorm[1]{|\ |\ | #1|\ |\ |}  \newcommand{\rec}{{\operatorname{recovery}}} \newcommand{\nrec}{{\operatorname{not~recovery}}}  \newtheorem{Theorem}{Theorem}[section] \newtheorem{lemma}[Theorem]{Lemma} \newtheorem{corollary}[Theorem]{Corollary} \newtheorem{example}[Theorem]{Example} \newtheorem{proposition}[Theorem]{Proposition} \newtheorem{definition}{Definition}[section] \newtheorem{conj}[Theorem]{Conjecture}  \newtheorem{remark}{Remark}[section]  \newenvironment{Proof}{ {\bf\underline{Proof:} }} {\hspace*{\fill} SYMBOL \vskip1em}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 phasetrans
eps                                                                                      0000644 0000000 0000000 00000031605 11325617152 012445  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   %
PS-Adobe-3 0 EPSF-3 0  /MathWorks 160 dict begin /bdef {bind def} bind def /ldef {load def} bind def /xdef {exch def} bdef /xstore {exch store} bdef /c  /clip ldef /cc /concat ldef /cp /closepath ldef /gr /grestore ldef /gs /gsave ldef /mt /moveto ldef /np /newpath ldef /cm /currentmatrix ldef /sm /setmatrix ldef /rm /rmoveto ldef /rl /rlineto ldef /s {show newpath} bdef /sc {setcmykcolor} bdef /sr /setrgbcolor ldef /sg /setgray ldef /w /setlinewidth ldef /j /setlinejoin ldef /cap /setlinecap ldef /rc {rectclip} bdef /rf {rectfill} bdef /pgsv () def /bpage {/pgsv save def} bdef /epage {pgsv restore} bdef /bplot /gsave ldef /eplot {stroke grestore} bdef /portraitMode 0 def /landscapeMode 1 def /rotateMode 2 def /dpi2point 0 def /FontSize 0 def /FMS {/FontSize xstore findfont [FontSize 0 0 FontSize neg 0 0] makefont setfont} bdef /reencode {exch dup where {pop load} {pop StandardEncoding} ifelse exch dup 3 1 roll findfont dup length dict begin { 1 index /FID ne {def}{pop pop} ifelse } forall /Encoding exch def currentdict end definefont pop} bdef /isroman {findfont /CharStrings get /Agrave known} bdef /FMSR {3 1 roll 1 index dup isroman {reencode} {pop pop} ifelse exch FMS} bdef /csm {1 dpi2point div -1 dpi2point div scale neg translate dup landscapeMode eq {pop -90 rotate} {rotateMode eq {90 rotate} if} ifelse} bdef /SO { [] 0 setdash } bdef /DO { [ 5 dpi2point mul 4 dpi2point mul] 0 setdash } bdef /DA { [6 dpi2point mul] 0 setdash } bdef /DD { [ 5 dpi2point mul 4 dpi2point mul 6 dpi2point mul 4 dpi2point mul] 0 setdash } bdef /L {lineto stroke} bdef /MP {3 1 roll moveto 1 sub {rlineto} repeat} bdef /AP {{rlineto} repeat} bdef /PDlw -1 def /W {/PDlw currentlinewidth def setlinewidth} def /PP {closepath eofill} bdef /DP {closepath stroke} bdef /MR {4 -2 roll moveto dup  0 exch rlineto exch 0 rlineto neg 0 exch rlineto closepath} bdef /FR {MR stroke} bdef /PR {MR fill} bdef /L1i {{currentfile picstr readhexstring pop} image} bdef /tMatrix matrix def /MakeOval {newpath tMatrix currentmatrix pop translate scale 0 0 1 0 360 arc tMatrix setmatrix} bdef /FO {MakeOval stroke} bdef /PO {MakeOval fill} bdef /PD {currentlinewidth 2 div 0 360 arc fill PDlw -1 eq not {PDlw w /PDlw -1 def} if} def /FA {newpath tMatrix currentmatrix pop translate scale 0 0 1 5 -2 roll arc tMatrix setmatrix stroke} bdef /PA {newpath tMatrix currentmatrix pop	translate 0 0 moveto scale 0 0 1 5 -2 roll arc closepath tMatrix setmatrix fill} bdef /FAn {newpath tMatrix currentmatrix pop translate scale 0 0 1 5 -2 roll arcn tMatrix setmatrix stroke} bdef /PAn {newpath tMatrix currentmatrix pop translate 0 0 moveto scale 0 0 1 5 -2 roll arcn closepath tMatrix setmatrix fill} bdef /vradius 0 def /hradius 0 def /lry 0 def /lrx 0 def /uly 0 def /ulx 0 def /rad 0 def /MRR {/vradius xdef /hradius xdef /lry xdef /lrx xdef /uly xdef /ulx xdef newpath tMatrix currentmatrix pop ulx hradius add uly vradius add translate hradius vradius scale 0 0 1 180 270 arc  tMatrix setmatrix lrx hradius sub uly vradius add translate hradius vradius scale 0 0 1 270 360 arc tMatrix setmatrix lrx hradius sub lry vradius sub translate hradius vradius scale 0 0 1 0 90 arc tMatrix setmatrix ulx hradius add lry vradius sub translate hradius vradius scale 0 0 1 90 180 arc tMatrix setmatrix closepath} bdef /FRR {MRR stroke } bdef /PRR {MRR fill } bdef /MlrRR {/lry xdef /lrx xdef /uly xdef /ulx xdef /rad lry uly sub 2 div def newpath tMatrix currentmatrix pop ulx rad add uly rad add translate rad rad scale 0 0 1 90 270 arc tMatrix setmatrix lrx rad sub lry rad sub translate rad rad scale 0 0 1 270 90 arc tMatrix setmatrix closepath} bdef /FlrRR {MlrRR stroke } bdef /PlrRR {MlrRR fill } bdef /MtbRR {/lry xdef /lrx xdef /uly xdef /ulx xdef /rad lrx ulx sub 2 div def newpath tMatrix currentmatrix pop ulx rad add uly rad add translate rad rad scale 0 0 1 180 360 arc tMatrix setmatrix lrx rad sub lry rad sub translate rad rad scale 0 0 1 0 180 arc tMatrix setmatrix closepath} bdef /FtbRR {MtbRR stroke } bdef /PtbRR {MtbRR fill } bdef /stri 6 array def /dtri 6 array def /smat 6 array def /dmat 6 array def /tmat1 6 array def /tmat2 6 array def /dif 3 array def /asub {/ind2 exch def /ind1 exch def dup dup ind1 get exch ind2 get sub exch } bdef /tri_to_matrix { 2 0 asub 3 1 asub 4 0 asub 5 1 asub dup 0 get exch 1 get 7 -1 roll astore } bdef /compute_transform { dmat dtri tri_to_matrix tmat1 invertmatrix  smat stri tri_to_matrix tmat2 concatmatrix } bdef /ds {stri astore pop} bdef /dt {dtri astore pop} bdef /db {2 copy /cols xdef /rows xdef mul dup 3 mul string currentfile  3 index 0 eq {/ASCIIHexDecode filter} {/ASCII85Decode filter 3 index 2 eq {/RunLengthDecode filter} if } ifelse exch readstring pop dup 0 3 index getinterval /rbmap xdef dup 2 index dup getinterval /gbmap xdef 1 index dup 2 mul exch getinterval /bbmap xdef pop pop}bdef /it {gs np dtri aload pop moveto lineto lineto cp c cols rows 8 compute_transform  rbmap gbmap bbmap true 3 colorimage gr}bdef /il {newpath moveto lineto stroke}bdef currentdict end def  MathWorks begin  0 cap  end  MathWorks begin bpage  bplot  /dpi2point 12 def portraitMode 1164 5808 csm  0     0  4800  1536 rc 85 dict begin %Colortable dictionary /c0 { 0 000000 0 000000 0 000000 sr} bdef /c1 { 1 000000 1 000000 1 000000 sr} bdef /c2 { 0 900000 0 000000 0 000000 sr} bdef /c3 { 0 000000 0 820000 0 000000 sr} bdef /c4 { 0 000000 0 000000 0 800000 sr} bdef /c5 { 0 910000 0 820000 0 320000 sr} bdef /c6 { 1 000000 0 260000 0 820000 sr} bdef /c7 { 0 000000 0 820000 0 820000 sr} bdef c0 1 j 1 sg 0    0 4801 1537 rf 6 w 0 897 898 0 0 -897 750 1189 4 MP PP -898 0 0 897 898 0 0 -897 750 1189 5 MP stroke gs 750 292 899 898 rc /mwscm { [/Indexed /DeviceRGB 63 < 000000 040404 080808 0c0c0c 101010 141414 181818 1c1c1c 202020 242424  282828 2c2c2c 303030 343434 383838 3c3c3c 404040 444444 484848 4c4c4c  505050 555555 595959 5d5d5d 616161 656565 696969 6d6d6d 717171 757575  797979 7d7d7d 818181 858585 898989 8d8d8d 919191 959595 999999 9d9d9d  a1a1a1 a5a5a5 aaaaaa aeaeae b2b2b2 b6b6b6 bababa bebebe c2c2c2 c6c6c6  cacaca cecece d2d2d2 d6d6d6 dadada dedede e2e2e2 e6e6e6 eaeaea eeeeee  f2f2f2 f6f6f6 fafafa ffffff  > ] setcolorspace } bdef mwscm gs np 751 292 mt 0 898 rl 897 0 rl 0 -898 rl cp c np [897 0 0 898 751 292] cc << % Image dictionary /ImageType 1 /Width 9 /Height 9 /BitsPerComponent 8 /Decode [0 255] /ImageMatrix [9 000000 0 0 9 000000 0 0] /DataSource currentfile /ASCII85Decode filter /RunLengthDecode filter >> image ,7+oG SYMBOL n*,10,GWA
*KI)`8]c+8u6D&/R&A0c0cg":Q\/0,=Bb
spA&)uBU:  SYMBOL Oe=;55mbk) SYMBOL kNar3^3`I
XoYB SYMBOL XJ, ~> gr gr  0 sg 1910  197 mt  (Spurious local minimum) s /Symbol /ISOLatin1Encoding 120 FMSR  2511 1472 mt  (m) s /Helvetica /ISOLatin1Encoding 120 FMSR  1816  775 mt  -90 rotate (p) s 90 rotate 4 w DO SO 6 w 2099 1189 mt 2996 1189 L 2099  292 mt 2996  292 L 2099 1189 mt 2099  292 L 2996 1189 mt 2996  292 L 2099 1189 mt 2996 1189 L 2099 1189 mt 2099  292 L 2248 1189 mt 2248 1180 L 2248  292 mt 2248  301 L 2165 1335 mt  (0 2) s 2447 1189 mt 2447 1180 L 2447  292 mt 2447  301 L 2364 1335 mt  (0 4) s 2647 1189 mt 2647 1180 L 2647  292 mt 2647  301 L 2564 1335 mt  (0 6) s 2846 1189 mt 2846 1180 L 2846  292 mt 2846  301 L 2763 1335 mt  (0 8) s 2099 1040 mt 2107 1040 L 2996 1040 mt 2987 1040 L 1898 1084 mt  (0 2) s 2099  840 mt 2107  840 L 2996  840 mt 2987  840 L 1898  884 mt  (0 4) s 2099  641 mt 2107  641 L 2996  641 mt 2987  641 L 1898  685 mt  (0 6) s 2099  442 mt 2107  442 L 2996  442 mt 2987  442 L 1898  486 mt  (0 8) s 2099 1189 mt 2996 1189 L 2099  292 mt 2996  292 L 2099 1189 mt 2099  292 L 2996 1189 mt 2996  292 L 1 sg 0 897 897 0 0 -897 3447 1189 4 MP PP -897 0 0 897 897 0 0 -897 3447 1189 5 MP stroke gs 3447 292 898 898 rc /mwscm { [/Indexed /DeviceRGB 63 < 000000 040404 080808 0c0c0c 101010 141414 181818 1c1c1c 202020 242424  282828 2c2c2c 303030 343434 383838 3c3c3c 404040 444444 484848 4c4c4c  505050 555555 595959 5d5d5d 616161 656565 696969 6d6d6d 717171 757575  797979 7d7d7d 818181 858585 898989 8d8d8d 919191 959595 999999 9d9d9d  a1a1a1 a5a5a5 aaaaaa aeaeae b2b2b2 b6b6b6 bababa bebebe c2c2c2 c6c6c6  cacaca cecece d2d2d2 d6d6d6 dadada dedede e2e2e2 e6e6e6 eaeaea eeeeee  f2f2f2 f6f6f6 fafafa ffffff  > ] setcolorspace } bdef mwscm gs np 3447 292 mt 0 898 rl 897 0 rl 0 -898 rl cp c np [897 0 0 898 3447 292] cc << % Image dictionary /ImageType 1 /Width 9 /Height 9 /BitsPerComponent 8 /Decode [0 255] /ImageMatrix [9 000000 0 0 9 000000 0 0] /DataSource currentfile /ASCII85Decode filter /RunLengthDecode filter >> image "Z\_14Y/Ji57T%q4=q[55
M7L)_3Td55mbk'bD'#+[%qP56_Au SYMBOL [(+
B8u <F<n ~> gr gr  0 sg 3266  197 mt  (Wrong global mimimum) s /Symbol /ISOLatin1Encoding 120 FMSR  3859 1472 mt  (m) s /Helvetica /ISOLatin1Encoding 120 FMSR  3164  775 mt  -90 rotate (p) s 90 rotate 4 w DO SO 6 w 3447 1189 mt 4344 1189 L 3447  292 mt 4344  292 L 3447 1189 mt 3447  292 L 4344 1189 mt 4344  292 L 3447 1189 mt 4344 1189 L 3447 1189 mt 3447  292 L 3596 1189 mt 3596 1180 L 3596  292 mt 3596  301 L 3513 1335 mt  (0 2) s 3795 1189 mt 3795 1180 L 3795  292 mt 3795  301 L 3712 1335 mt  (0 4) s 3995 1189 mt 3995 1180 L 3995  292 mt 3995  301 L 3912 1335 mt  (0 6) s 4194 1189 mt 4194 1180 L 4194  292 mt 4194  301 L 4111 1335 mt  (0 8) s 3447 1040 mt 3455 1040 L 4344 1040 mt 4335 1040 L 3246 1084 mt  (0 2) s 3447  840 mt 3455  840 L 4344  840 mt 4335  840 L 3246  884 mt  (0 4) s 3447  641 mt 3455  641 L 4344  641 mt 4335  641 L 3246  685 mt  (0 6) s 3447  442 mt 3455  442 L 4344  442 mt 4335  442 L 3246  486 mt  (0 8) s 3447 1189 mt 4344 1189 L 3447  292 mt 4344  292 L 3447 1189 mt 3447  292 L 4344 1189 mt 4344  292 L  end %%Color Dict  eplot  epage end  showpage                                                                                                                             phasetrans
pdf                                                                                      0000644 0000000 0000000 00000044057 11325617224 012434  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   %PDF-1 3 4 0 obj << /Length 5 0 R /Filter /FlateDecode >> stream xXr#7+p SYMBOL N&Dj	T0 8 0`(sKF=moS	)+&EvIqVY N@M&&z[%TAa>:oXh=Ht/+s*8P|Fk0`sOqQ
Wf\g\;XN SYMBOL l	#<@	 SYMBOL AY5ZpA()9:q[pZ ;f\=mkLFOQ~{t}\o )L5XS^@sC*]5Mt3&|EH"F#qF%54eAh%,8MWikrk&FWUCVF'-~s/[CQX/--r-pBAU /=OFk'k3;fWS[k_x:;k-y7bCanjM=x]H(&9
h\&NCwWaxj\2NP_55}0IJ &s2%&>+H| kg>uqD 5z[dSR)/^_<TlxkF`]%XQB, V;0h"a L  {"w8BLgP'z26iS:iMb"F:%<YetfF=vu1#~ endstream endobj 5 0 obj 1347 endobj 2 0 obj << /Type /Page /Parent 3 0 R /Resources 6 0 R /Contents 4 0 R /MediaBox [0 0 400 128] >> endobj 6 0 obj << /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ] /ExtGState << /Gs2 15 0 R /Gs1 16 0 R >> /Font << /F2 0 10 0 R /F1 0 9 0 R >> /XObject << /Im2 11 0 R /Im1 7 0 R /Im3 13 0 R >> >> endobj 11 0 obj << /Length 12 0 R /Type /XObject /Subtype /Image /Width 9 /Height 9 /ColorSpace 17 0 R /BitsPerComponent 8 /Filter /FlateDecode >> stream xS+(CKTDyT,INEUK{{>&&
m+{&A&E{Nf6nF3  endstream endobj 12 0 obj 67 endobj 7 0 obj << /Length 8 0 R /Type /XObject /Subtype /Image /Width 9 /Height 9 /ColorSpace 17 0 R /BitsPerComponent 8 /Filter /FlateDecode >> stream xb`2ddb`6g``752 4%a02J : endstream endobj 8 0 obj 77 endobj 13 0 obj << /Length 14 0 R /Type /XObject /Subtype /Image /Width 9 /Height 9 /ColorSpace 17 0 R /BitsPerComponent 8 /Filter /FlateDecode >> stream x1W7U06P"r6l\@=3#=p*XB   6 endstream endobj 14 0 obj 78 endobj 15 0 obj << /Type /ExtGState /OPM 1 >> endobj 16 0 obj << /Type /ExtGState /SM 0 02 >> endobj 17 0 obj [ /Indexed 18 0 R 63 <0000000404040808080c0c0c1010101414141818181c1c1c2020202424242828282c2c2c3030303434343838383c3c3c4040404444444848484c4c4c5050505555555959595d5d5d6161616565656969696d6d6d7171717575757979797d7d7d8181818585858989898d8d8d9191919595959999999d9d9da1a1a1a5a5a5aaaaaaaeaeaeb2b2b2b6b6b6babababebebec2c2c2c6c6c6cacacacececed2d2d2d6d6d6dadadadededee2e2e2e6e6e6eaeaeaeeeeeef2f2f2f6f6f6fafafaffffff> ] endobj 19 0 obj << /Length 20 0 R /N 3 /Alternate /DeviceRGB /Filter /FlateDecode >> stream xwTl/]"e
H& KYe7D"V SYMBOL &&3DFubq8CR SYMBOL %Zh`EJO SYMBOL 4(SXrdy"%*PZHTK"m"hHrz8=|u7]hI" sk+#j4} ]5n^mH :-XQvjhMUEeHGjU ^u-X87
][<<>
}JZ9boT)u/
PlF>bG}<|vTmWGw:bo<Zo];ZsgnAYU"	Mt]-IA~F^'A~JF *pM\g2
'>y=;o6ew SYMBOL wOsF'c"-aDmc>]VyYC}9/L1&zK>17>\f#"E"v" SYMBOL  ]o{h:gK]R
W_
Da/N(5iOR|)_I5H<in)Q:Wmzu)8
p 18'9cNVLi`D%hWnDc
l5ZjY(7(s<j49zE,QnyS"8n`U SYMBOL 
+-_TDaOERGQ )m6Olyk**0jdH`~s[ FH:tdx4AZ2nIPd SYMBOL TMtRRSQ/4h1eRy	]Y3u[j;9pMW{bqNLT}k1d-&M/-:mE/ B endstream endobj 23 0 obj 2205 endobj 24 0 obj << /Type /FontDescriptor /Ascent 701 /CapHeight 623 /Descent -299 /Flags 32 /FontBBox [-167 -299 1094 827] /FontName /LFTVVQ+Symbol /ItalicAngle 0 /StemV 103 /AvgWidth 572 /MaxWidth 1042 /StemH 38 /XHeight 467 /FontFile2 22 0 R >> endobj 25 0 obj [ 576 ] endobj 10 0 obj << /Type /Font /Subtype /TrueType /BaseFont /LFTVVQ+Symbol /FontDescriptor 24 0 R /Widths 25 0 R /FirstChar 181 /LastChar 181 /Encoding /MacRomanEncoding >> endobj 26 0 obj << /Length 27 0 R /Length1 12028 /Filter /FlateDecode >> stream xzy\GpUut}33\ (#r)B+AF]LT7>qDFuMLhc6nTf{EG~;=OU=UO=\U 9D6	"Dds7Eqs:Q"D-6oqCHbh:#B-MvtV8FqQ[-3M>}-/-H
(u@;C-Ab \JV~ 5'*);^-7<GB|
|aB2GZ 1PmRM (HJgD= Jn>Nh
pDf<1 mSt&Q"O>1~u `~M}r SYMBOL W{|0DF SYMBOL 8J\>,8z+UN{Z4X#r~@|#CM7t[V~};5i,V8xu#h &+BH\]w-
BRfBs2/j SYMBOL 4e "n: rw=j5:cV	2-H ;r[O2vG,7['{hmobiiqW+	(Cz7_W}aM"fXG)X@T<M<]Ym-
}2=36]MM;M2
s)+CV'3q ;YNr
x\[B]njVY0%3;okb(yLdI /h8/Y
m~
a-SvH`gQxVFwv3@bcs"/l|s7=~%o
xOYo/z0z-6>' SYMBOL R(Bu1U]L4OOCeK1vl zs^<63gk9)W\|uIAO# 2_T8{ fvgW)V SYMBOL l2:	= SYMBOL q4@"J50afo=Tf ;+7Q 2l}:	nqlkm3*&=w77c
w]m7s/wS_^S}3ffRg=: yl{Zj|W_h)/
6NeWv4S+H1UNWrEnK &N:mvF[8NmcwI^EvT	ou SYMBOL '
e8'`	`_Jc}{cc}JOiW8D
[yj c
9\8G@XF2[w@
CCcaf, ]P7G(3oGibYkzwH2{trKNLv7 SYMBOL 1"k SYMBOL Y
 ALOC)r}E6ZQiU:-cp2`u8Tpciv@	g0z('1)q^6"{XG(A >	 8}3^br;;^r\
aMxp^;wN^4_k)_mQaG5&c&6o*st	:^I/vu7D<aLOq^&*QYP1XbJM&WxN\yv75I
v#T@JL'(8
aKhvjG9V9Aj)LV-hy;qgT5/c SYMBOL 6VU(/LD^p [w<_yxQ
c
26S/8aozVyq^i/U*9O-\qmt;&N}bQ[z
gT<yS &,3EDD]et23c"Q*1f3f}&dEtfW
| M|^N>nM[MM= 3kdfyLQ p (3=z8z<Ez/>VN6YXIO<Js7a,8h =a22nVJM5@CIVA6,zz4_#-iN}>
wnB]a@et :w
N=BdJj+hN@D+M
%vX	6)2s5|]3~>>1:j'y}a]o&-qTz[&x(d Yq>c(p{(|UF NEbXx1TK84
[;U8y6cB/,dVUj*'rvE-P ex']n~g8Je	e	<sWVW*:	vwod-
IZd,F}UJsnW:Ik|b+I*TGf1zcn5+lX4SAn^*g>&%mS[e@bD(Y5P3:]@xHK`:
S[93zDz
~kf6 ={sxV+_`q\==mJ On[( &~ygO~/@_3
:"r:VP,l5
K|2}1&&7`O5,jG		]83kkS :u &q' SYMBOL <gsc8hW
r>& p473vR
 SYMBOL k=le0|/lYX/y*-e[H^
v%dBx,S-QA`IaBb3YOG>Sb9xI;+W2 u\7H`;lh4NcKH1bB
nGy-wSUs[ }XXPYAExC(zK9'-g+F jtj6`<h%N=B be0whsD"-lG`_6+;nFX3Y`ucK(T}T<-i|"+=kB"A~ Wcdy/b5b0 s [CgDu'a/]llD8mQVK 1kDVo_]
WE; E/=1kzf"dL_JZ m8uh SYMBOL e(`&B51-tl*)Dc0FUO)+Z2{"UjL&:Yol@`N%d/Z<m{\aX	blJDd*D3\yXfO8C)PzTEn(@	`hcXU[fB cW|Nlf&O {"bl
BbC-2Y5@E3+Q	)NpHk-jLR9J x(	6R*HN=cb[v)1w1SOmx&]/e%9LTB\I LB SYMBOL 29Y(d fn>d1l&,5%z-UXxcc~zb[h-"<iX` H0`kIdl	3d~h2[4l-0[A[=<tKxu%y M@,O
YsgDtiV	,nrQ1b"+<)&osdD8A>yZsOB8KinGg&u SYMBOL abTGU4X@l19`|VIy^YT,@ Sp
d8c 
'll"@c{H
yk5[A43tk`6K(Y:B>r+&6f 2ncI\'Pn2aB*KZ=XP)Bai*&[aUj
XK avk6uT&-
SQ)3zQ0
O& KJ,w
K	 	Sy S({3S7N :w7rp74L@Z{LQ[aWk SYMBOL Uj`8}D l^emJd[
^X;Y SYMBOL _*	1F[6;mPfKn_-	
kz_NDve1H18isKig IQ&q)%Dk\&9q[RW;qXzsYP@HI `,gS'<bztq@z(kIj}b+pz6Vy0dD 	|Vz R3 SYMBOL kqcFiCESPd<#,4_,t%'E7Kh>XDZx@ a w,
CN*3Q;(c4(E<&,"@A[F|FEcZE
@ Yc%k9`:5}@elsC/V%'
l=t+j{nIa SYMBOL A"d@|5{%aZsmHj{%4LFu)27Xo^(w[xBr5=\t;6Bl  SYMBOL ~tkPw&R TuT67X_\|7X^zS^7WM{xWz\g{5QuB{ C+CKo\HMC`\'V1Z7MxWEn|M[@fJ>IAI~7oEqjg62ogp;jcV7E&: B
6Dy{}>i=HuC-}qIT'Q'onfc9K9- 5')H6u6Usj7dDA(^S3Qn-t8Cnw}
xTI5+dNb7("Vn:'3W_Ed:M<OP@fLw^

-enD7u:nM=E	4MgX{f7`uq0q_q,s-8o5+Y 1fw Gn,ynzt|zf7"* }finsCZm(:Lk{)70^UuSi=~>GJr1VVn:YoCL@nov#NRK}mjs[n3z^ |^>V 1b#&Y;@	szb)j#G+
{'ovCixn
inAEHu|mKODjY1msz@Wf%`VG7 SYMBOL HeL*qt3B-u(TK}DwdP b\]8@)`:nQ`34rBPAS79%L'/ef7{[lbZ~7b SYMBOL Fx7mRSoNJNLCSCS
}2c"=kSXOn2*/} z>9ZY>)Ll\h}pqe)A7de|]]Re[\	@sW SYMBOL EH)LrR) b%Vg
mm^&s2>AJq `wL"
HMx-vF7 (_(AkA]ehOa)j BR<}3EYr@
bW0f#}^wO_yd\_Ww	K;2
 ta{2 SYMBOL V z SYMBOL 98gVLZ~3R-}=p,Z'i[KVVA20+6  G}=XeK^,iQ'>23XU
SUwWMDD(g*' ,X{( [m cW,AB&Kk%eeE{+)GGpIS+*s<f
,<Hj,}Kxr%0HyB#ZQ@}i-ZzJ-<e|+v :uyM /r1GXW8 >sBjdO-iG-
ibB}{ JG(#,vz+ SYMBOL wPc)Mxm(J]2>W 8d
aEhkb_nj`Y*5)y6;Ell(ENeIRQ"%1k:Lv=zl SYMBOL V fPo+'(pCa{#')(SD*_hGUc<*6f]cZ IVA@`>c# 0&H0:jL-S~@9io~jNSc,
vVptHdZ}\Q- SYMBOL "b8V:DHFz
CnT
-7e"V8G:cl SYMBOL lMK >u{}BP)HOu2W_TeA SYMBOL (bh(+X	"JF;'Nw>}w (
a @P"f'0 D6 p(h@_63u_-Z [3C+K  ;
r
YLD)c#c1 2N|bO<Gq||o%ez6 "%|n:(Sl@})__	 ;GD,HK0&Lgg3H,9Ldd8% |fYP-d2A//ZN- )6[h);h[/> h{yIHD
VV>RV:|{<KykrY+pLUZ_aOBt4B@"2*~khu=(k I@B=iQFa21e2;2d	t08W	|A ,\`(%`^P@8Ip\W5pC`<5 Q
iCd w "x(JZJr5@C'seC;)0a+{p4NKBx3\GV|	) d a#aHH1R"MH\G	-a+& 3,b10
u0fKj`
@l6-Vb-Qkpx\n;xs|~'~ 
C 	
BAHXK SYMBOL HRttL&dy5||<L~KQRDrrrJR=	T	u3zF&g)([%W#*7 \(o %H~|q>	[RF"MF1L1[Te'Jx%C%_%RJ#4Gcu:(G73%Ie%e{SCadd1T4UT*TTTUzUUUoScemUkS{Q7UPW~A}b}95L5"5ii<9:5MvhWh~Tfz1U
NTgN|Hz,T NI}mPw,tF-5j4oL50^l\k|g24mr6u0M713fBZAEE%2res+}VV(k[c{jg=~mCNNb&q'}d]N,:+Uuv^|o]5[7wMm}CQSY9eu{^>*}7l 6 8`k`f 7
p2)hEPW0%8*:Qi8# z<0-AQ#p5#m"GvGG
7xt~g|LbLCtOlyPU|BLB}&: SYMBOL O&&N~	rRSvLrg<O^o/>IsK6^> `/22fLgej&d'g*	3]9Z99"3Qhh'\(wanLHyy5yoc(z
dloaqu
Yf WB+SVv[UjtCkHk2zmWbuj
YHH\4u6W|})76T}39usoc---zl=TX|d[ fEqI/WWA
1TRSox4in={j-n`[kk+x\S-zEjpjh8qn6I<r;,73KOOcY~0aWj]:6"DgkG
<sg,=3uVtv\{|E\rtWXW:^mqi^>k:8w7w[nn
u3V/~M~nr:53(_ry
ZrL{~
x:LlfW_w=7~oLM_uNO=|zfCoYo_Cggg  endstream endobj 22 0 obj 2615 endobj 11 0 obj [ /ICCBased 21 0 R ] endobj 23 0 obj << /Length 24 0 R /N 1 /Alternate /DeviceGray /Filter /FlateDecode >> stream xV	TS%
A@0P a  JLBaP'X"HQ HQ( 8(X	_BZ_s9o(  U)c,1CBq0M ^_7@L HQg2U8"1 628 P0sTs/@t0V8 g
 ,R,y`(`3*^PA#8 ZIp\ W5A0qL"BFdeDEa 7 1H<, SYMBOL b		1a5PN 4]AF1f9c~X SYMBOL &:qybqD"LH SYMBOL uZcID	p)9RJ-r2BV6vN^']
(}^K}GPZ #2edQTOj5zNM})++k,
+)I^rrr,9*fr)FL%)P< N((L(*+(+*(RDdU*PtNiXlQ^\|^yDbRIV)VAGe\UIuj *Sj5c5@TZYx6ju}<"&>4o--51MsP{4kV<3hwP-s0Z&u}E;i SYMBOL F]FoM7 1Q7a435u3M71iF2c6f'W_@---z-B+*jZ::9snGkwmlmml5V+;gs_g-;ev:>;Gv90T
EG2:l||]]

4x}nznl\:L3f20Cq*v/WWww}Dq_;~D -~,mUw_@xh(l[
_u  aPK0fobs()4 SYMBOL %<ItI8T4W_ SYMBOL LvHY EN SYMBOL l{
%]dcd0`eAE
rd(VVEi(w&+{wuw{v[tHGFCMr>xh5@s46d:xqsYz-rW;ziZ\z|hdr]GRNvh(+"	d"}d3/RjzOg}2/ApVW@4 ~
Tj`P]A HQl' 	H-l;ml<RAX=l{BrxOy%el9,]y`d4J==FR6R]k0BqS<C	4NbJ%yq+nSNA'C q\9Zg	g
jM+m{2+>
N(_MWNs+S\(y
qW ^V
Ttf*c]sf@NCl}	<TL`U_1F=Uy2/[g'	v=>p\p8{*QNTZw9l`O)dG,: SYMBOL paP SYMBOL ^di4Z+UMt@JHYBy;5mm-ak;:/a>%@
gE(_o7sn+hg	;eo SYMBOL gOzV@/	H:3T SYMBOL M~k=KDsQrh]|Q=i" ='X~<-BVZYWw}ksN|qmo<xy/7[b`arMrwu gwZV\{X~xl xzdzHzdH0t~mjlfeg~wo}~-hqyrsqu~wqgaNy	XtkY-e%krpy_~]` {<u
a	 7r_	   A endstream endobj 38 0 obj 701 endobj 39 0 obj << /Type /FontDescriptor /Ascent 750 /CapHeight 666 /Descent -250 /Flags 32 /FontBBox [-64 -282 1080 782] /FontName /RUHJNR+CMMI10 /ItalicAngle 0 /StemV 72 /MaxWidth 1080 /StemH 31 /XHeight 500 /FontFile3 37 0 R >> endobj 40 0 obj [ 791 0 0 0 0 0 0 828 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 485 ] endobj 13 0 obj << /Type /Font /Subtype /Type1 /BaseFont /RUHJNR+CMMI10 /FontDescriptor 39 0 R /Widths 40 0 R /FirstChar 81 /LastChar 118 /Encoding /MacRomanEncoding >> endobj 41 0 obj << /Length 42 0 R /Subtype /Type1C /Filter /FlateDecode >> stream xcd`ad`ddpv22g5B`)9R~s-~}aL1/)}qKj~}hQL@[]w%fi
YN)b>(s=-yxn"  ^M endstream endobj 42 0 obj 205 endobj 43 0 obj << /Type /FontDescriptor /Ascent 750 /CapHeight 666 /Descent -250 /Flags 32 /FontBBox [-59 -282 1154 782] /FontName /HCLLIJ+CMR7 /ItalicAngle 0 /StemV 79 /MaxWidth 1149 /StemH 36 /XHeight 500 /FontFile3 41 0 R >> endobj 44 0 obj [ 877 ] endobj 15 0 obj << /Type /Font /Subtype /Type1 /BaseFont /HCLLIJ+CMR7 /FontDescriptor 43 0 R /Widths 44 0 R /FirstChar 43 /LastChar 43 /Encoding /MacRomanEncoding >> endobj 45 0 obj << /Length 46 0 R /Subtype /Type1C /Filter /FlateDecode >> stream xcd`ad`ddpv4	ge+-"V~Gw2B I
se{3`YLtKJkc- *^=CdO%lspq1OSg{t<k - endstream endobj 46 0 obj 162 endobj 47 0 obj << /Type /FontDescriptor /Ascent 782 /CapHeight 695 /Descent -951 /Flags 4 /FontBBox [-47 -983 1284 814] /FontName /HCLLIJ+CMSY7 /ItalicAngle 0 /StemV 93 /MaxWidth 1267 /StemH 49 /XHeight 521 /FontFile3 45 0 R >> endobj 48 0 obj [ 893 ] endobj 49 0 obj << /Type /Encoding /Differences [ 33 /minus ] >> endobj 50 0 obj << /Length 51 0 R /Filter /FlateDecode >> stream x]j0D= gc(): EAkzAz3gHJ`	Xgux%mU&*a[@mWF SYMBOL j~O=
c endstream endobj 51 0 obj 207 endobj 17 0 obj << /Type /Font /Subtype /Type1 /BaseFont /HCLLIJ+CMSY7 /FontDescriptor 47 0 R /Widths 48 0 R /FirstChar 33 /LastChar 33 /ToUnicode 50 0 R /Encoding 49 0 R >> endobj 52 0 obj << /Length 53 0 R /Subtype /Type1C /Filter /FlateDecode >> stream xU{Ta*#V0y G+]ewCeG{4%5S "I%'s#	_ SYMBOL bga3@Y }dr6
DD&Il 6QDKV@n%("O'}fbe~&_%oQD)T	U;Gj/2t4LH_m	NQx^p 
BjTYh@"+yF0 9od>2jD"oa\x,laW>/EqC0-T{O(:=RfK<*`u;^KmsxM%=}m"eX3hk
#3)6-F3qx(2rq"eN@ SYMBOL / ;aw5re_=C^l\|mU SYMBOL 09s:H+ /j7CM8KSRxM;	wde0JY[M'uxZeR=7[rSiCvoY)6 ]
oG{ SYMBOL L23I&s&yECF"A"IHbDRQ0 \-B)P L KV^"T]L SYMBOL X 0}z
>
PNV}Qh+y dT>D)
I&8m~eWdDu;ETA{K`"26}+R-FYlV5	Y7	CY,Pl&
 SYMBOL r:dXXVrM:*\
g[M99z^h^< SYMBOL c
s<'>"|l01:/ 9tT+q9E<w SYMBOL ZJ1(S07+
i53K`A
'1aZu5PZ1m#=]|v_n 6B I hgcv)ojt[v#n=vo
no[=bi _0fc--*:[*,7Vnjjj:F|
P}~,
v)pd Rm3ODTA aF={ SYMBOL Q2UaCSzn=G/ab
ETJdl]0ng2 SYMBOL #)\X*2nj;uzzw

07>z+\ SYMBOL 3LHyl
tJfzD:J+=*}aT2dvy`~73l/J/`)V+)_(aq:KxI3x4AzWxu;@+p/znXyXwAx=e1vO3`arF1-=r:R)6C~Rbd5u(,CS2}F
l0N{UU SYMBOL ZJ2]A2zB`HkdAAfQ*z|Lr\D8TYR
J8 SVa)R_ vQG;|M-[}DeX4%%(Bs5M (qgkou hj[\Il(M[j>@
-	B@i/-lDpaf@  E,de7
gM,%6H#oJi16s " `F;y;[ SYMBOL AZ;3%W(debA	B\
'U	B;:sTz	nE(O~~	VcGz\
J9[*s~;j)Z4bsH/xv
}}Ruv[`/Oz"rq R	 m64/aZ }-'2E
7Bd1%
 |aqn4r2Z+@O7o1W>	Uc~FNCkOg7Z:Zf	[sp#|h,V
snB
j~	Fp}vOJbp
H@D:3`^T3W3<>r6v_#Nmp4DQ[(w_e<'Mt2}ic1X94/A# 9 SYMBOL 86
n#U gsYND=cNQ6LBbqCe=]<aRg_II~6gp
Ao SYMBOL cdg*HJ<+Kqe7N`Vi_lCQO<y
7bzz< I1JJGW00Uz`52z1
>ap@Ri36R],Zrh2uqDI9d[MS0
VDLxsdWD[-X`w
O 2yL\,eKIuWbo(/U:t
I~c'D%M
Z4BokX=cgDpb\o &%Wl
GrD5E%FUJ5Ue`WNylHB SYMBOL /JDXlQvAeuaK	1'}BcbvG`X)7`tCL:&\&ux0_)@w+vT,H=;6=up'vKwY|+hq

av=Aw6egyZ };+I1:v	f6uW)vvySe\
Jey,I<kR 9ogQ1&(S'jxuJe A9S4=6BF0
:3%g"jPtJO>_0I[
J5/8K~N

wM;5z]8<OIXaY%	J2yTe)dc(8,:<;tHo/lU;)(Tz0(w)SRO SYMBOL [{BqW3O)7/ SYMBOL xjzD@D:1
HBx07	q2c'KW~<8p\4N14N1N endstream endobj 57 0 obj 5041 endobj 58 0 obj << /Type /FontDescriptor /Ascent 770 /CapHeight 684 /Descent -230 /Flags 4 /FontBBox [-951 -481 1445 1122] /FontName /FLULVR+Helvetica /ItalicAngle 0 /StemV 0 /AvgWidth -441 /MaxWidth 1500 /XHeight 513 /FontFile2 56 0 R >> endobj 59 0 obj [ 556 556 556 556 556 556 556 722 278 584 278 556 278 556 ] endobj 60 0 obj << /Length 61 0 R /Filter /FlateDecode >> stream x]j0E -E8/0li,de%M8B3sl{tKQ@t	dOgD^HcuY:cEp*
e"#C|:xM#(kihu/FY OwB SYMBOL n*8x5EL[o]-9w SYMBOL HI:*{PaxyIm#ve'Ur[Yr/%N\v%B=+ SYMBOL &6{&6aXj,D	U+(eSA[fs&
efL"=RUZ SYMBOL gcxoD09B@H%R
+ue>'iV5'|EuKjy3y%5b+j`:HT2hB#MLxmRk:xD8[D8q 
AA sNAy SYMBOL 1% n# ": SYMBOL 3e[FnQTdv--_%2+cxpl}FT=&w -M
 SYMBOL L8nA@<kcAFmnA Z5' )I cl;^=Q"`;v~D;  5|l;r`;{
/` BOnZOh 3)wvg'D	GnQk
#Atj;Wl~]qZ
Ym	vB	v*@RhksD`jQ
Hq cN}qaydCx:HN-w7<zy=y%rBWp/i5BQPCt
dGABa@%av]3q9\2bAUw{tpsl_"F5~_ha,<CVM+P*Z]Hk@F
p&5pq40sr:&H\P@7mHSods3@
&26E%Z
L2- A7
giO`lBuaF]q``1CMv3eo	d\F=^6|5}^Y|{+gu|f]q]:_GI{XCG}o\g|=:
Zx<{u}r4Yi;-kT^~f/Y]m"OxUn;hj{  w Z%kfK>	/]}hdVdv31UF;B9_]=M_n0nk@u{
s_}u+5O"~w'c:;pp,9	4 #A
} _
p5^UsB\qlXyOiE/_PL1*Q;aFZ^<&^9p#zz& =u+({*&5uBe<Y{~9ruIsR/9t
l[[Y/Hmlc[<1zCaWPy@Y1wOzbq6L=Isb \q]g_BkY5FIH SYMBOL  d+,B*6(+ SYMBOL Y#eH%R# "'%
{RQT5Fb4MGstZf,zCgdj=A SYMBOL X	VN6cD-"
SYMBOL
R)TBMj"zI	2A lr&|||<B~+%#+e+#+%*: SYMBOL l93{F)M	hN^^^~~~}iA6qC]yw(F SYMBOL *QMX^XWrC#<"J#FFfEvDGEG
\8gWb4c1E/+_lxKK4Z*X<1>:Pv0=lq'g;s' SYMBOL %M~r  Z*zB SYMBOL cqFk s2&k(5*V(18'J<uyCW#Xc`ZIKYK>=,mkPP\8yoolqOE%|WM	zJKl&mn`bYn[m{}Kc"u;
T&UUyT5qix}}}kkgTU=:w
umj=w^
6Z5V75G<1G;15d':lz'N*=-}3g&Ecgw,{n=_s\E'/9]:qqnrkzvnn^570x{mwL]{xZj~5i~Pw9~H#Gu
}rrgEOGM#//>YRW^uLL<xzM[1u~xrf>|9edA3y+g(GOL1kK- `j/O94_1;NMelmi

L>]W 5K~Syp{oQ \bh eLV& |vs<\`S
8
1JIc|e>IA_0WHH a/
g
\HN`pE5i z@=
}S+H0~aJ\h<Yl
L3G%Kbfr< LX4a_\
07u0%s%juM)g,xU97j [|=S\3ucFa)%a)4E4*K%'
M
4pN/
JNfu4A3Y/yr{7+M'dJ{axMu_=Wg	`89Jv23{o	@%}N</`/ wzzuTKvX>5+ofHT)n/^\-

5 uQ~ endstream endobj 22 0 obj 2905 endobj 18 0 obj [ /ICCBased 21 0 R ] endobj 23 0 obj << /Length 24 0 R /N 3 /Alternate /DeviceRGB /Filter /FlateDecode >> stream xwTl/]"e
H& KYe7D"V SYMBOL &&3DFubq8CR SYMBOL %Zh`EJO SYMBOL \h '}kwD:rAO>S/[F8<*Dc
'it4&U SYMBOL El 6o"#
JPDq#ODRV)v8KS'^2+Ut4LH_mzqr'dXCa#=V)&xk l<[pE{paU  o_< 'f
kR-;EY_	udw4N<7hx)/%-v}dSEld7	L^CZYLh1rgpW
A`
#7'RHHlR(yWVXtTMv-e
wLfcOAJ(cA	LTW"sdpevakjw; IznCU#9>AXj2_- TgAf
J,b mY|t9hXw{x
+a*'	WA7R87hM{;aWOjEqvaOGSx , v fxCA
AoV[q7_[byY8+#_Eg<m=u]==PeTj3uj{A';;LJ*##W'8S}iKXP[='~j_~H`5F\:wqon[ ~(}d	2X[G\Cd;17~bE*N>WIt7~R&LN~9/wlvXO_p&n3-Zn
DMiFLE/So'h-}4A/)#Ps8~t9~k=8%-hS t	 ]mTkM'g4,F
Ul}&s6k;:4mQQ*CJx>
uw}F+(xiud5-yUX:-@%9<	Jj*l6 SYMBOL O#
QzeVJul:\-She-LK/K`%=lv&gdiA>cOcuoY0/W9Y]}O_C"9_
Z_k({[@VM"Nyy4 `) k]M	_h endstream endobj 38 0 obj 1843 endobj 39 0 obj << /Type /FontDescriptor /Ascent 969 /CapHeight 861 /Descent -250 /Flags 32 /FontBBox [-283 -282 1041 1001] /FontName /TSFEXJ+CMR10 /ItalicAngle 0 /StemV 69 /AvgWidth 500 /MaxWidth 1260 /StemH 31 /XHeight 646 /FontFile3 37 0 R >> endobj 40 0 obj [ 722 0 0 0 0 0 0 0 0 0 0 0 0 681 0 0 0 0 0 750 0 0 0 0 0 0 0 0 0 0 0 0 444 0 444 306 500 0 0 0 0 278 833 556 500 0 0 392 394 389 556 0 0 0 528 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 500 ] endobj 12 0 obj << /Type /Font /Subtype /Type1 /BaseFont /TSFEXJ+CMR10 /FontDescriptor 39 0 R /Widths 40 0 R /FirstChar 67 /LastChar 248 /Encoding /MacRomanEncoding >> endobj 41 0 obj << /Length 42 0 R /Subtype /Type1C /Filter /FlateDecode >> stream xM  WMTATL+CMMI10  Mk = D      2 9 W    9MUVxVJ/'FU5
 )lpw}:& SYMBOL @HB< 1|@Q| H,TEZZtZo;NGlZ"jutcgvNL*]'A*|_{c^gsv-@8t/m
Y5:
K_-Y1^- H;=M =<B2<:yj#	Q6~Lyf K8@w LjE=^KEWAoznb
I'=>	DTLF*Fr NB'
AlH~pP:F1pX2Ec3t,H<iH{A|At} (#{S<XJ(;y8yUK6"i`aBC^1=+e"}7l>P"'3B:RO'>/>meCkr)+ P [3eC)Y
V3bAio7L@Uet' L1G{xrr~<|eB^'fIf SYMBOL '(FX%<#/c
s|gx>@89d^9<*:(c %` )^O]1bR%A4/-{{Vxl	ko1
/G SYMBOL _\(^^oEl SYMBOL d +=d i Ox rPT5HRS)\
7h[Vf'{>Ol{7[f;Vz{PFM'FqK:o SYMBOL UB4;n)fEhDQWF7dTHj#
8/DWkq(aA	qiRTc{rSX9*<Dq8a=n'C`n7hECX)37SZU3 N7oU=ZY#[6gY)	
[lwwu[H[ @"B#U3)
&	rK(|gqF 
w;BpQ"w|= GX AK~"'	;B5b(Kfpp('8SFF#SO+{F,p|qgFBkg <N##Bx
7p
y`r|SbUPBsGe py	RE0	jl7O8~ SYMBOL ~W| SYMBOL "TRm~XB^qZ((F'r

J,Vv) SYMBOL X`6MzmtrbviEMf1j[:QxSNt_{eiyYs3W+ SYMBOL @	C&;WaIDDx:1fAJE00RvOa}	m9W

O('8ikkM
%0axFeHx#[Z:,Vehh4nS]D[%;TVHg|~G3rrnXPa<):"&=r;xt)=&q;D`vB1-9b"fxYnxae6tb]{MZGSpZ9_j%-tVm0lp-m_,'sPhs>r,Kj
t^p	qF	RZSVVCC16 1Ko0t/o )KCO%G4FHr|d	,1`QhQweb9^% ,|-dCPQ%d`+*
B8qL#uo
+'
<EM`O>y<O
	wv
mx\"%r}|XicdL:sF[\T{5 SYMBOL ':l mVLK
qy_s#+Y{DUsMc5g#a8I* SYMBOL J|9/o]K-d( ;@ G@{(nYP -XPX@"un  Y5(uH E+;wQ_B vyk~  endstream endobj 54 0 obj 302 endobj 10 0 obj << /Type /Font /Subtype /TrueType /BaseFont /ZEEYGY+Helvetica /FontDescriptor 51 0 R /Widths 52 0 R /FirstChar 33 /LastChar 45 /ToUnicode 53 0 R >> endobj 57 0 obj << /Length 58 0 R /Length1 5028 /Filter /FlateDecode >> stream xX{pTI  SYMBOL `HcTPGCP::jQ/:*MVT&03{~sws{s(SD<L5nT]j5'mD#\0u[dB=cxm;xH{h;E,<%cPF CFwZJ"FHBq7W_7"e:,{Z<U^C/Hh SYMBOL krd8p8{:QNTZw;l`)dG,: SYMBOL ojqU=
N 74:;_o
f9 SYMBOL 6`5fq066q7,
aA1#s4hx &y&j7Uss;ftVf#v,VVIa]UWp[OY*oAhHWdzT&Pgb5+~M5EA_vpU^%:FKcD69<#hAGL"Mz`vkqcIG6iM/5YHH"}m9v\OU SYMBOL M
TT\c\a}zvn(R < )]b">[sFW:x `:Es5pkn qNbK(_)h}n1<1<s8)C|w<3MJZsXRH0\
\y) Y,_#b
-E0\upR]b11|pP s3|[aoN+](E>iZu* SYMBOL apAhAzQO
)I;*
CZp	X_KkUgT$@_O
cc
@"2=
sE5]aqCwtvC/fX endstream endobj 58 0 obj 2718 endobj 56 0 obj << /Type /FontDescriptor /Ascent 770 /CapHeight 684 /Descent -230 /Flags 32 /FontBBox [-951 -481 1445 1122] /FontName /XWAAQD+Helvetica /ItalicAngle 0 /StemV 0 /AvgWidth -441 /MaxWidth 1500 /XHeight 513 /FontFile2 57 0 R >> endobj 59 0 obj [ 239 239 584 ] endobj 60 0 obj << /Length 61 0 R /Filter /FlateDecode >> stream xc`8  endstream endobj 61 0 obj 15 endobj 55 0 obj << /Type /Font /Subtype /CIDFontType2 /BaseFont /XWAAQD+Helvetica /CIDSystemInfo << /Registry (Adobe) /Ordering (Identity) /Supplement 0 >> /FontDescriptor 56 0 R /W 59 0 R /DW 1000 /CIDToGIDMap 60 0 R >> endobj 7 0 obj << /Type /Font /Subtype /Type0 /Encoding /Identity-H /BaseFont /XWAAQD+Helvetica /DescendantFonts [ 55 0 R ] >> endobj 62 0 obj (Mac OS X 10 6 2 Quartz PDFContext) endobj 63 0 obj (D:20091212140402Z00'00') endobj 1 0 obj << /Producer 62 0 R /CreationDate 63 0 R /ModDate 63 0 R >> endobj xref 0 64 0000000000 65535 f  0000026459 00000 n  0000003827 00000 n  0000010098 00000 n  0000000022 00000 n  0000003807 00000 n  0000003931 00000 n  0000026238 00000 n  0000000000 00000 n  0000000000 00000 n  0000022642 00000 n  0000010061 00000 n  0000014795 00000 n  0000016110 00000 n  0000010935 00000 n  0000016850 00000 n  0000000000 00000 n  0000012000 00000 n  0000007285 00000 n  0000004161 00000 n  0000004207 00000 n  0000004255 00000 n  0000007264 00000 n  0000007322 00000 n  0000010040 00000 n  0000010181 00000 n  0000010231 00000 n  0000010661 00000 n  0000010681 00000 n  0000010911 00000 n  0000011104 00000 n  0000011359 00000 n  0000011379 00000 n  0000011608 00000 n  0000011632 00000 n  0000011697 00000 n  0000011980 00000 n  0000012174 00000 n  0000014110 00000 n  0000014131 00000 n  0000014377 00000 n  0000014963 00000 n  0000015757 00000 n  0000015777 00000 n  0000016008 00000 n  0000016279 00000 n  0000016577 00000 n  0000016597 00000 n  0000016826 00000 n  0000017016 00000 n  0000021912 00000 n  0000021933 00000 n  0000022172 00000 n  0000022244 00000 n  0000022622 00000 n  0000026017 00000 n  0000025635 00000 n  0000022806 00000 n  0000025614 00000 n  0000025875 00000 n  0000025907 00000 n  0000025998 00000 n  0000026365 00000 n  0000026417 00000 n  trailer << /Size 64 /Root 25 0 R /Info 1 0 R /ID [ <f214c56415d9a190bc694849b2f8384a> <f214c56415d9a190bc694849b2f8384a> ] >> startxref 26534                                                                                                                                                                                             section234
### abstract ###
Motivated by the philosophy and phenomenal success of compressed sensing, the problem of reconstructing a matrix from a sampling of its entries has attracted much attention recently
Such a problem can be viewed as an information--theoretic variant of the well--studied matrix completion problem, and the main objective is to design an  efficient  algorithm that can reconstruct a matrix by inspecting only a  small  number of its entries
Although this is an impossible task in general, Cand\`{e}s and co--authors have recently shown that under a so--called  incoherence  assumption, a rank  SYMBOL   SYMBOL  matrix can be reconstructed using semidefinite programming (SDP) after one inspects  SYMBOL  of its entries
In this paper we propose an alternative approach that is much more efficient and can reconstruct a larger class of matrices by inspecting a significantly smaller number of the entries
Specifically, we first introduce a class of so--called  stable  matrices and show that it includes all those that satisfy the incoherence assumption
Then, we propose a randomized basis pursuit (RBP) algorithm and show that it can reconstruct a stable rank  SYMBOL   SYMBOL  matrix after inspecting  SYMBOL  of its entries
Our sampling bound is only a logarithmic factor away from the information--theoretic limit and is essentially optimal
Moreover, the runtime of the RBP algorithm is bounded by  SYMBOL , which compares very favorably with the  SYMBOL  runtime of the SDP--based algorithm
Perhaps more importantly, our algorithm will provide an  exact  reconstruction of the input matrix in polynomial time
By contrast, the SDP--based algorithm can only provide an  approximate  one in polynomial time
### introduction ###
A fundamental problem that arises frequently in many disciplines is that of reconstructing a matrix with certain properties from some partial information
Typically, such a problem is motivated by the desire to deduce global structure from a (small) number of local observations
For instance, consider the following applications:   {Covariance Estimation } In areas such as statistics, machine learning and wireless communications, it is often of interest to find the  maximum likelihood estimate  of the covariance matrix  SYMBOL  of a random vector  SYMBOL
Such an estimate can be used to study the relationship among the variables in  SYMBOL , or to give some indication on the performance of certain systems
Usually, extra information is available to facilitate the estimation
For instance, we may have a number of independent samples that are drawn according to the distribution of  SYMBOL , as well as some structural constraints on  SYMBOL  (e g , certain entries of  SYMBOL  have prescribed values  CITATION , the matrix  SYMBOL  has a Toeplitz structure and some of its entries have prescribed values  CITATION , etc )
Thus, the estimation problem becomes that of completing a partially specified matrix so that the completion satisfies the structural constraints and maximizes certain likelihood function {Graph Realization } It is a trivial matter to see that given the coordinates of  SYMBOL  points in  SYMBOL , the distance between any two points can be computed efficiently
However, the inverse problem --- given a subset of interpoint distances, find the coordinates of points (called a  realization ) in  SYMBOL  (where  SYMBOL  is fixed) that fit those distances --- turns out to be anything but trivial (see, eg ,  CITATION )
Such a problem arises in many different contexts, such as sensor network localization (see, eg ,  CITATION ) and molecular conformation (see, e
g,  CITATION ), and is equivalent to the problem of completing a partially specified matrix to an  Euclidean distance matrix  that has a certain rank (cf ~ CITATION ) {Recovering Structure from Motion } A fundamental problem in computer vision is to reconstruct the structure of an object by analyzing its motion over time
This problem, which is known as the  Structure from Motion (SfM) Problem  in the literature, can be formulated as that of finding a low--rank approximation to certain measurement matrix (see, eg ,  CITATION )
However, due to the presence of occlusion or tracking failures, the measurement matrix often has missing entries
When one takes into account such difficulties, the reconstruction problem becomes that of completing a partially specified matrix to one that has a certain rank (see, eg ,  CITATION ) {Recommendation Systems } Although electronic commerce has offered great convenience to customers and merchants alike, it has complicated the task of tracking and predicting customers' preferences
To cope with this problem, various  recommendation systems  have been developed over the years (see, eg ,  CITATION )
Roughly speaking, those systems maintain a matrix of preferences, where the rows correspond to users and columns correspond to items
When an user purchases or browses a subset of the items, she can specify her preferences for those items, and those preferences will then be recorded in the corresponding entries of the matrix
Naturally, if an user has not considered a particular item, then the corresponding entry of the matrix will remain unspecified
Now, in order to predict users' preferences for the unseen items, one will have to complete a partially specified matrix so that the completion maximizes certain performance measure (such as each individual's utility  CITATION )
Note that in all the examples above, we are forced to take whatever information is given to us
In particular, we cannot, for instance, specify which entries of the unknown matrix to examine
As a result, the reconstruction problem can be ill--posed (e g , there may not be a unique or even any solution that satisfies the given criteria)
This is indeed an important issue
However, we shall not address it in this paper (see, eg ,  CITATION  for related work)
Instead, we take a different approach and consider the information--theoretic aspects of the reconstruction problem
Specifically, let  SYMBOL  be the rank  SYMBOL  matrix that we wish to reconstruct
For the sake of simplicity, suppose that  SYMBOL  is known
Initially,  no  information about  SYMBOL  (other than its rank) is available
However, we are allowed to inspect  any  entry of  SYMBOL  and inspect as many entries as we desire in order to complete the reconstruction
Of course, if we inspect all  SYMBOL  entries of  SYMBOL , then we will be able to reconstruct  SYMBOL  exactly
Thus, it is natural to ask whether we can inspect only a  small  number of entries and still be able to reconstruct  SYMBOL  in an  efficient  manner
Besides being a theoretical curiosity, such a problem does arise in practical applications
For instance, in the sensor network localization setting  CITATION , the aforementioned problem is tantamount to asking which of the pairwise distances are needed in order to guarantee a successful reconstruction of the network topology
It turns out that if the number of required pairwise distances is small, then we will be able to efficiently reconstruct the network topology by performing just a few distance measurements and solving a small semidefinite program (SDP)  CITATION
To get an idea of what we should aim for, let us first determine the degrees of freedom available in specifying the rank  SYMBOL  matrix  SYMBOL
This will give us a lower bound on the number of entries of  SYMBOL  we need to inspect in order to guarantee an exact reconstruction
Towards that end, consider the singular value decomposition (SVD)  SYMBOL , where  SYMBOL  and  SYMBOL  have orthonormal columns, and  SYMBOL  is a diagonal matrix
Clearly, there are  SYMBOL  degrees of freedom in specifying  SYMBOL
Now, observe that for  SYMBOL , the  SYMBOL --th column of  SYMBOL  must be orthogonal to all of the previous  SYMBOL  columns, and that it must have unit length
Thus, there are  SYMBOL  degrees of freedom in specifying the  SYMBOL --th column of  SYMBOL , which implies that there are  SYMBOL  degrees of freedom in specifying  SYMBOL
By the same argument, there are  SYMBOL  degrees of freedom in specifying  SYMBOL
Hence, we have:  SYMBOL  SYMBOL A SYMBOL SYMBOL A SYMBOL A SYMBOL A SYMBOL \Theta(\Delta) SYMBOL A SYMBOL nn SYMBOL A=e_1e_1^T SYMBOL e_1=(1,0,\ldots,0)\in\R^n SYMBOL A SYMBOL A SYMBOL A SYMBOL \Theta(\Delta) SYMBOL A SYMBOL A$
### abstract ###
Information distance is a parameter-free similarity measure based on compression, used in pattern recognition, data mining, phylogeny, clustering, and classification
The notion of information distance is extended from pairs to multiples (finite lists)
We study maximal overlap, metricity, universality,  minimal overlap, additivity, and normalized information distance in multiples
We use the theoretical notion of Kolmogorov complexity which for practical purposes is approximated by the length of the compressed version of the file involved, using a real-world compression program
### introduction ###
In pattern recognition, learning, and data mining one obtains information from objects containing information
This involves an objective definition of the information in a single object, the information to go from one object to another object in a pair of objects, the information to go from one object to any other object in a multiple of objects, and the shared information between objects,   CITATION
The classical notion of Kolmogorov complexity  CITATION  is an objective measure  for the information in an  a  single  object, and information distance measures the information  between a  pair  of objects  CITATION
This last notion has spawned research in the theoretical direction, among others   CITATION
Research in the practical direction has focused on  the  normalized  information distance, the similarity metric, which arises by normalizing the information distance in a proper manner and  approximating the Kolmogorov complexity through real-world compressors  CITATION , This normalized information distance is a parameter-free, feature-free, and alignment-free similarity measure  that has had great impact in applications
A variant of this compression distance has been tested on all time sequence databases used in the last decade in the major data mining conferences (sigkdd, sigmod, icdm, icde, ssdb, vldb, pkdd, pakdd)  CITATION
The conclusion is that the method is competitive with all 51  other methods used and superior in  heterogenous data clustering and anomaly detection
In  CITATION  it was shown that the method is resistant to noise
This theory  has found many applications in pattern recognition, phylogeny, clustering, and classification
For objects that are represented as computer files such applications range from weather forecasting, software, earthquake prediction, music, literature, ocr, bioinformatics, to internet  CITATION
For objects that are only represented by name,  or objects that are abstract like `red,' `Einstein,'  `three,' the normalized information distance uses background information provided by Google, or any search engine that produces aggregate page  counts
It discovers the `meaning' of words and phrases in the sense of producing a relative semantics
Applications run from ontology, semantics, tourism on the web, taxonomy, multilingual questions, to question-answer systems   CITATION
For more references on either subject see the textbook  CITATION  or Google Scholar for references to  CITATION
However, in many applications we are interested in  shared information between many objects instead of just a pair of objects
For example, in customer reviews of gadgets, in blogs about public happenings, in newspaper articles about the same occurrence, we are interested in the most comprehensive one or the most specialized one
Thus, we want to extend the information distance  measure from pairs to multiples
### abstract ###
We present a novel approach for learning nonlinear dynamic models, which leads to a new set of tools capable of solving problems that are otherwise difficult
We provide theory showing this new approach is consistent for models with long range structure, and apply the approach to motion capture and  high-dimensional video data, yielding results superior to standard alternatives
### introduction ###
The notion of hidden states appears in many nonstationary models of the world such as Hidden Markov Models (HMMs), which have discrete states, and Kalman filters, which have continuous states
Figure~ shows a general dynamic model with observation  SYMBOL  and unobserved hidden state  SYMBOL
The system is characterized by a state transition probability  SYMBOL , and a state to observation probability  SYMBOL
The method for predicting future events under such a dynamic model is to maintain a posterior distribution over the hidden state  SYMBOL , based on all observations  SYMBOL  up to time  SYMBOL
The posterior can be updated using the formula:   The prediction of future events  SYMBOL ,  SYMBOL , conditioned on  SYMBOL  is through the posterior over  SYMBOL :  Hidden state based dynamic models have a wide range of applications, such as time series forecasting, finance, control, robotics, video and speech processing
Some detailed dynamic models and application examples can be found in  CITATION
From \Eqref{eq:predict}, it is clear that the benefit of using a hidden state  dynamic model is that the information contained in the observation  SYMBOL  can be captured by a relatively small hidden state  SYMBOL
Therefore in order to predict the future, we do not have to use all previous observations  SYMBOL  but only its state representation  SYMBOL
In principle,  SYMBOL  may contain a finite history of length  SYMBOL , such as  SYMBOL
Although the notation only considers first order dependency, it incorporates higher order dependency by considering a representation of the form  SYMBOL , which is a standard trick }  In an HMM or Kalman filter,  both transition and observation functions are linear maps
There are reasonable algorithms that can learn these linear dynamic models
For example, in addition to the classical EM approach, it was recently shown that global learning of certain hidden Markov models can be achieved in polynomial time  CITATION
Moreover, for linear models, the posterior update rule is quite  simple
Therefore, once the model parameters are estimated, such models can be readily applied for prediction
However in many real problems, the system dynamics cannot be approximated linearly
For such problems, it is often necessary to  incorporate nonlinearity into the dynamic model
The standard approach to this problem is through nonlinear probability modeling, where prior knowledge is required to define a sensible state representation, together with parametric forms of transition and observation probabilities
The model parameters are learned by using probabilistic methods such as the EM  CITATION
When the learned model is applied for prediction purposes, it is necessary to maintain the posterior  SYMBOL  using the update formula in \Eqref{eq:post-update}
Unfortunately, for nonlinear systems, maintaining  SYMBOL  is generally difficult because the posterior can become exponentially more complex (e g , exponentially many mixture components in a mixture model) as  SYMBOL  increases
This computational difficulty is a significant obstacle to applying nonlinear dynamic systems to practical problems
The traditional approach to address the computational difficulty is through approximation methods
For example, in the particle filtering approach  CITATION , one uses a finite number of samples to represent the posterior distribution and the samples are then updated as observations arrive
Another approach is to maintain a mixture of Gaussians to approximate the posterior,  SYMBOL , which may also be regarded as a mixture of Kalman filters  CITATION
Although an exponential in  SYMBOL  number of mixture components are needed to accurately represent the posterior, in practice, one has to use a fixed number of mixture components to approximate the distribution
This leads to the following question: even if the posterior can be well-approximated by a computationally tractable approximation family (such as finite mixtures of Gaussians), how can one design a good approximate inference method that is guaranteed to find a good quality approximation
The use of complex techniques required to design  reasonable approximation schemes makes it non-trivial to  apply nonlinear dynamic models for many practical problems
This paper introduces an alternative approach, where we start with a different representation of a linear dynamic model which we call the  sufficient posterior representation
It is shown that one can recover the underlying state representation by using prediction methods that are not necessarily probabilistic
This allows us to model nonlinear dynamic behaviors with many available nonlinear supervised learning algorithms such as neural networks, boosting, and support vector machines in a simple and unified fashion
Compared to the traditional approach, it has several distinct advantages:   It does not require us to design any explicit state representation and probability model using prior knowledge
Instead, the representation is implicitly embedded in the representational choice of the underlying supervised learning algorithm, which may be regarded as a black box with the power to learn an arbitrary representation
The prior knowledge can be simply encoded as input features to the learning algorithms, which significantly simplifies the modeling aspect
It does not require us to come up with any specific representation of the posterior and the corresponding approximate Bayesian inference schemes for posterior updates
Instead, this issue is addressed by incorporating the posterior update as part of the learning process
Again, the posterior representation is implicitly embedded in the representational choice of the underlying supervised learning algorithm
In this sense, our scheme learns the optimal representation for posterior approximation and the corresponding update rules within the representational power of the underlying supervised algorithm
It is possible to obtain performance guarantees for our algorithm in terms of the learning performance of the underlying supervised algorithm
The performance of the latter has been heavily investigated in the statistical and learning theory literature
Such results can thus be applied to obtain theoretical results on our methods for learning nonlinear dynamic models
### abstract ###
Catalogs of periodic variable stars contain large numbers of periodic light-curves (photometric time series data from the astrophysics domain)
Separating anomalous objects from well-known classes is an important step towards the discovery of new classes of astronomical objects
Most anomaly detection methods for time series data assume either a single continuous time series or a set of time series whose periods are aligned
Light-curve data precludes the use of these methods as the periods of any given pair of light-curves may be out of sync
One may use an existing anomaly detection method if, prior to similarity calculation, one performs the costly act of aligning two light-curves, an operation that scales poorly to massive data sets
This paper presents PCAD, an unsupervised anomaly detection method for large sets of unsynchronized periodic time-series data, that outputs a ranked list of both global and local anomalies
It calculates its anomaly score for each light-curve in relation to a set of centroids produced by a modified k-means clustering algorithm
Our method is able to scale to large data sets through the use of sampling
We validate our method on both light-curve data and other time series data sets
We demonstrate its effectiveness at finding known anomalies, and discuss the effect of sample size and number of centroids on our results
We compare our method to naive solutions and existing time series anomaly detection methods for unphased data, and show that PCAD's reported anomalies are comparable to or better than all other methods
Finally, astrophysicists on our team have verified that PCAD finds true anomalies that might be indicative of novel astrophysical phenomena \keywords{Anomaly detection Time Series Data}
### introduction ###
Quasars  CITATION , radio pulsars  CITATION , and cosmic gamma-ray bursts  CITATION  were all discovered by alert scientists who, while examining data for a primary purpose, encountered aberrant phenomena whose further study led to these legendary discoveries
Such discoveries were possible in an era when scientists had a close connection with their data
The advent of massive data sets renders unexpected discoveries through manual inspection improbable if not impossible
Fortunately, automated anomaly detection programs may resurrect this mode of discovery and identify atypical phenomena indicative of novel astronomical objects *}  Our research applies anomaly detection to photometric time series data, called  light-curve  data
Our specific application is to find anomalies in sets of light-curves of periodic variable stars
Most stars, like our own Sun, are of almost constant luminosity, whereas variable stars undergo significant variations
There are over 350,000 cataloged variable stars with more being discovered
The 2003 General Catalogue of Variable Stars  CITATION  lists known and suspected variable stars in our own galaxy, as well as 10,000 in other galaxies
For  periodic  variable stars, the period of the star can be established
Common types of periodic variable stars include Cepheid, Eclipsing Binaries and RR Lyrae, details of which can be found in  CITATION
The study of periodic variable stars is of great importance to astronomy
For example, the study of Cepheids yielded the most valuable method for determining the Hubble constant, and the study of binary stars enabled the discovery of a star's true mass
Finding a new class or subclass of variable stars will be of tremendous value
Figure  shows a typical light-curve from each star class before and after we perform our pre-processing techniques (described in Section )
The y-axis measures the magnitude of brightness of the star
Magnitude is inversely proportional to the brightness of the observation, thus, the y-axis is plotted with descending values
The x-axis measures folded time
A folded light-curve is a light-curve where all periods are mapped onto a single period, which is why there may be multiple points on the y-axis for a single time point
We describe light-curves and the process of folding in more detail in Section  }  Our research is motivated by the challenges inherent to performing anomaly detection on large sets of periodic variable light-curves
Several of these challenges are common to many time series data sets
There are a large number of time-points in each light-curve (high dimensionality), low signal-to-noise ratio, and voluminous amounts of data
Indeed, new surveys, such as the Panoramic Survey Telescope and Rapid Response System (Pan-STARRS), have the capacity to produce light-curves for billions of stars  CITATION
Any technique developed for light-curves must scale to very large data sets
A unique challenge of working with light-curve data is that the periods of the light-curves are not synchronized because each is generated by a different source (star)
To understand why phasing poses such a challenge for anomaly detection in this domain, consider Figure , which illustrates how two similar light-curves may appear dissimilar under a similarity measure like Euclidean distance if a phase adjustment is not performed
The top panel shows two similar light-curves whose phases are not synchronized
The middle panel shows the square of the correlation plotted as a function of the phase adjustment
The maximum similarity occurs at a phase shift of approximately 0 3
The bottom panel shows the two light-curves after the dotted light-curve is shifted by this amount
We define the optimal phase shift between two light-curves as the shift that yields the maximum similarity value
This phasing problem presents a challenge to both general anomaly detection techniques, and those developed specifically for time series
A general anomaly detection method, even with a metric that works for unphased data, may not work out of the box
With regard to time series anomaly detection techniques, our task of finding anomalies in  SYMBOL  distinct time series differs from most work which assumes a single contiguous time series (not necessarily periodic) in which anomalous sub-regions are sought
PCAD is our solution to the problem of anomaly detection on large sets of unsynchronized periodic time series
The heart of PCAD is a modified k-means clustering algorithm, called Phased K-means (Pk-means), that runs on a sampling of the data
Pk-means differs from k-means in that it re-phases each time series prior to similarity calculation and updates centroids from these rephased curves
Because Pk-means is a modification of k-means, we provide a proof that Pk-means does not break k-means's convergence properties
The Pk-means subroutine runs offline on a sampling of the data
The use of sampling enables PCAD to scale to large data sets
The online portion of PCAD is the calculation of the anomaly score for each time series from the set of centroids produced offline by Pk-means
This operation is linear in the size of the data set
Another advantage of PCAD is its flexibility to discover two types of anomalies: local and global
We define the terms local and global anomaly and provide scoring methods for both
Once each time series is assigned an anomaly score, PCAD ranks the time series accordingly and outputs the top  SYMBOL  for review
To our knowledge, PCAD is the only anomaly detection method developed specifically for unsynchronized time series data that can output both global and local outliers
Our paper presents empirical evidence on four data sets that PCAD effectively finds known anomalies and produces a better ranking of anomalies when compared to naive solutions and other state-of-the-art anomaly detection methods for time series
We discuss the effect of sample size and the parameter  SYMBOL  (used by Pk-means) on the anomaly detection results, and show experimental results on light-curve data with an unknown number of anomalies
Our paper concludes with an astrophysicists's discussion of the significance of the anomalies found by PCAD
### abstract ###
We derive an exact and efficient Bayesian regression algorithm for piecewise constant functions of unknown segment number, boundary location, and levels
It works for any noise and segment level prior, eg \ Cauchy which can handle outliers
We derive simple but good estimates for the in-segment variance
We also propose a Bayesian regression curve as a better way of smoothing data without blurring boundaries
The Bayesian approach also allows straightforward determination of the evidence, break probabilities and error estimates, useful for model selection and significance and robustness studies
We discuss the performance on synthetic and real-world examples
Many possible extensions will be discussed
### introduction ###
We consider the problem of fitting a piecewise constant function through noisy one-dimensional data, as eg \ in Figure , where the segment number, boundaries and levels are unknown
Regression with piecewise constant (PC) functions, also known as change point detection, has many applications
For instance, determining DNA copy numbers in cancer cells from micro-array data, to mention just one recent
We provide a full Bayesian analysis of PC-regression
For a fixed number of segments we choose a uniform prior over all possible segment boundary locations
Some prior on the segment levels and data noise within each segment is assumed
Finally a prior over the number of segments is chosen
From this we obtain the posterior segmentation probability distribution (Section )
In practice we need summaries of this complicated distribution
A simple maximum (MAP) approximation or mean does not work here
The right way is to proceed in stages from determining the most critical segment number, to the boundary location, and finally to the then trivial segment levels
We also extract the evidence, the boundary probability distribution, and an interesting non-PC regression curve including error estimate (Section )
We derive an exact polynomial-time dynamic-programming-type algorithm for all quantities of interest (Sections  and )
Our algorithm works for any noise and level prior
We consider more closely the Gaussian ``standard'' prior and heavy-tailed robust-to-outliers distributions like the Cauchy, and briefly discuss the non-parametric case (Sections  and )
Finally, some hyper-parameters like the global data average and variability and local within-level noise have to be determined
We introduce and discuss efficient semi-principled estimators, thereby avoiding problematic or expensive numerical EM or Monte-Carlo estimates (Section )
We test our method on some synthetic examples (Section ) and some real-world data sets (Section )
The simulations show that our method handles difficult data with high noise and outliers well
Our basic algorithm can (easily) be modified in a variety of ways: For discrete segment levels, segment dependent variance, piecewise linear and non-linear regression, non-parametric noise prior, etc (Section )
Sen and Srivastava  CITATION  developed a frequentist solution to the problem of detecting a single (the most prominent) segment boundary (called change or break point)
Olshen et al \  CITATION  generalize this method to detect pairs of break points, which improves recognition of short segments
Both methods are then (heuristically) used to recursively determine further change points
Another approach is penalized Maximum Likelihood (ML)
For a fixed number of segments, ML chooses the boundary locations that maximize the data likelihood (minimize the mean square data deviation)
Jong et al \  CITATION  use a population based algorithm as minimizer, while Picard et al \  CITATION  use dynamic programming, which is structurally very close to our core recursion, to find the exact solution in polynomial time
An additional penalty term has to be added to the likelihood in order to determine the correct number of segments
The most principled penalty is the Bayesian Information Criterion  CITATION
Since it can be biased towards too simple  CITATION  or too complex  CITATION  models, in practice often a heuristic penalty is used
An interesting heuristic, based on the curvature of the log-likelihood as a function of the number of segments, has been used in  CITATION
Our Bayesian regressor is a natural response to penalized ML
Many other regressors exist; too numerous to list them all
Another closely related work to ours is Bayesian bin density estimation by Endres and F\"oldi\'ak  CITATION , who also average over all boundary locations, but in the context of density estimation
A full Bayesian approach (when computationally feasible) has various advantages over others: A generic advantage is that it is more principled and hence involves fewer heuristic design choices
This is particularly important for estimating the number of segments
Another generic advantage is that it can be easily embedded in a larger framework
For instance, one can decide among competing models solely based on the (Bayesian) evidence
Finally, Bayes often works well in practice, and provably so if the model assumptions are valid
We can also extract other information (nearly for free), like probability estimates and variances for the various quantities of interest
Particularly interesting is the expected level (and variance) of each data point
This leads to a regression curve, which is very flat, i e \ smoothes the data, in long and clear segments, wiggles in less clear segments, follows trends, and jumps at the segment boundaries
It thus behaves somewhat between local smoothing (which wiggles more and blurs jumps) and rigid PC-segmentation
### abstract ###
This paper presents studies on a deterministic annealing algorithm based on quantum annealing for variational Bayes (QAVB) inference, which can be seen as an extension of the simulated annealing for variational Bayes (SAVB) inference
QAVB	is as easy as SAVB to implement
Experiments revealed QAVB finds a better local optimum than SAVB in terms of the variational free energy in latent Dirichlet allocation (LDA)
### introduction ###
Several studies that are related to machine learning with quantum mechanics have recently been conducted
The main idea behind these has been based on a generalization of the probability distribution obtained by using a density matrix, which is a self-adjoint positive-semidefinite matrix of trace one
CITATION  connects the basic probability rule of quantum mechanics, called the ``Born Rule'', which formulates a generalized probability by using a density matrix, to spectral clustering and other machine learning algorithms based on spectral theory
CITATION  combined a margin maximization scheme with a probabilistic modeling approach by incorporating the concepts of quantum detection and estimation theory  CITATION
CITATION  proposed a quantum Markov random field using a density matrix and quantum mechanics and applied to image restoration
Generalizing a Bayesian framework based on a density matrix has also been proposed
CITATION  proposed a ``quantum Bayes rule'' for conditional density between two probability spaces
Warmuth et al generalized the Bayes rule to treat a case where the prior was a density matrix  CITATION  and unified Bayesian probability calculus for density matrices with rules for translation between joints and conditionals  CITATION
Typically, the formulas derived by quantum mechanics generalization have retained the conventional theory as a special case when the density matrices have been diagonal
Computing the full posterior distributions over model parameters for probabilistic graphical models, eg latent Dirichlet allocation  CITATION , remains difficult in these quantum Bayesian frameworks, as well as classical Bayesian frameworks
In this paper, we generalize the variational Bayes inference  CITATION , which is widely used framework for probabilistic graphical models, based on ideas that have been used in quantum mechanics
Variational Bayes (VB) inference has been widely used as an approximation of Bayesian inference for probabilistic models that have discrete latent variables
For example, in a probabilistic mixture model, such as a mixture of Gaussians, each data point is assigned to a latent class, and a latent variable corresponding to a data point indicates the latent class
VB is an optimization algorithm that minimizes the cost function
The cost function, called the negative variational free energy, is a function of latent variables
We have called the cost function ``energy'' in this paper
Since VB is a gradient algorithm similar to the Expectation Maximization (EM) algorithm, it suffers from a local optimal problem in practice
Deterministic annealing (DA) algorithms have been proposed for the EM algorithm  CITATION  and VB  CITATION  based on simulated annealing (SA)  CITATION  to overcome issue with local optima
We called simulated annealing based VB SAVB
SA is one of the most well known physics based approaches to machine learning
SA is based on the concept of statistical mechanics, called ``temperature''
We decrease the parameter of ``temperature'' gradually in SA
Because the energy landscape becomes flat at high temperature, it is easy to change the state (see Fig (a))
However, the state is trapped at low temperature because of the valley in the energy barrier and the transition probability becomes very low
Therefore, SA does not necessarily find a global optimum in the practical cooling schedule of temperature  SYMBOL
In physics, quantum annealing (QA) has attracted attention as an alternative annealing method of optimization problems by a process that is analogous to quantum fluctuations  CITATION
QA is expected to help states avoid being trapped by poor local optima at low temperatures
The main point of this paper is to explain the novel DA algorithm for VB based on the QA (QAVB) we derived and present the effects of QAVB we obtained through experiments
QAVB is a generalization of VB and SAVB attained by using a density matrix
We describe our motivation for deriving QAVB in terms of a density matrix in Section
Here, we overview the QAVB that we derived
Interestingly, although QAVB is generalized and formulated by a density matrix, the algorithm for QAVB we finally derived does not need operations for a density matrix such as eigenvalue decomposition and only has simple changes from the SAVB algorithm
Since SAVB does not necessarily find a global optimum, we still need to run multiple SAVBs independently with different random initializations where  SYMBOL  denote the number of SAVBs
Here, let us consider running dependently, not independently, multiple SAVBs where ``dependently'' means that we run multiple SAVBs introducing interaction  SYMBOL  among neighboring SAVBs that are randomly numbered such as  SYMBOL ,  SYMBOL  and  SYMBOL  (see Fig (b))
In Fig ,  SYMBOL  indicates the latent class states of  SYMBOL  data points in the  SYMBOL -th SAVB
The independent SAVBs have a very low transition probability among states, i e , they have been trapped, at high temperature as shown in Fig (c), while the dependent QAVBs can changes the state in that situation
This is because interaction  SYMBOL  starts from zero (i e , ``independent''), gradually increases,	 and makes  SYMBOL  and  SYMBOL  approach each other, the state will then be moved into  SYMBOL
If there is a better state around sub-optimal states that the independent SAVBs find, the dependent SAVBs are expected to work well
The dependent SAVBs are just QAVB where interaction  SYMBOL  and the above scheme are derived from QA mechanisms as will be explained in the following section
This paper is organized as follows
In Section , we introduce the notations used in this paper
In Section , we motivate QAVB in terms of a density matrix
Section  and  explain how we derive QAVB and present the experimental results in latent Dirichlet allocation (LDA)
Section  concludes this paper *}
### abstract ###
Many learning machines that have hierarchical structure or hidden variables are now being used in information science, artificial intelligence, and bioinformatics
However, several learning machines used in such fields are not regular but  singular statistical models,  hence their generalization performance is still left unknown
To overcome these problems,  in the previous papers, we proved new equations in statistical learning,   by which we can estimate the Bayes generalization loss from the Bayes training loss and the functional variance, on the condition that the true distribution is a singularity contained in a learning machine
In this paper, we prove that the same equations hold even if a  true distribution is not contained in a parametric model
Also we prove that, the proposed equations in  a regular case are asymptotically equivalent to the Takeuchi information criterion
Therefore, the proposed equations are always applicable without any condition  on the unknown true distribution
### introduction ###
Nowadays, a lot of learning machines are being used in information science, artificial intelligence, and bioinformatics
However, several learning machines used in such fields, for example,  three-layer neural networks, hidden Markov models, normal mixtures, binomial mixtures, Boltzmann machines, and reduced rank regressions have hierarchical structure or hidden variables, with the result that the mapping from the parameter to the probability distribution is not one-to-one
In such learning machines, it was pointed out that  the maximum likelihood estimator is not subject to the normal distribution  CITATION ,  and that the  a posteriori  distribution can not be approximated by any gaussian distribution  CITATION
Hence the conventional statistical  methods for model selection, hypothesis test, and hyperparameter optimization  are not applicable to such learning machines
In other words, we have not yet established the theoretical foundation for learning machines which extract hidden structures from random samples
In statistical learning theory, we study the problem of learning and generalization based on several assumptions
Let  SYMBOL  be a true probability density function and   SYMBOL  be a learning machine, which is represented by  a probability density function of  SYMBOL  for a parameter  SYMBOL
In this paper, we examine the following two assumptions \\ (1) The first is the parametrizability condition
A true distribution  SYMBOL  is said to be  parametrizable  by a learning machine  SYMBOL ,  if there is a parameter  SYMBOL  which satisfies  SYMBOL
If  otherwise, it is called  nonparametrizable  \\ (2) The second is the regularity condition
A true distribution  SYMBOL  is said to be  regular  for a learning machine  SYMBOL ,  if the parameter  SYMBOL  that minimizes the log loss function  SYMBOL } is unique and if the Hessian matrix  SYMBOL  is positive definite
If a true distribution is not regular for a learning machine, then it is said to be   singular
In study of layered neural networks and normal mixtures,  both conditions are important
In fact,  if a learning machine is redundant compared to a true distribution, then the true distribution is parametrizable and singular
Or if a learning machine is too simple to approximate a  true distribution, then the true distribution is nonparametrizable and  regular
In practical applications, we need a method  to determine the optimal learning machine,  therefore, a general formula is desirable by which the generalization loss can be estimated from the training loss without regard to such conditions
In the previous papers  CITATION ,  we studied a case when a true distribution is parametrizable and singular,  and proved new formulas which enable us  to estimate the generalization loss from the training loss and the functional variance
Since the new formulas hold for an arbitrary  set of a true distribution,  a learning machine, and an  a priori  distribution, they are called   equations of states in statistical estimation
However, it has not been clarified whether they hold or not  in a nonparametrizable case
In this paper, we study the case when a true distribution is nonparametrizable and regular, and  prove that the same equations of states also hold
Moreover, we show that, in  a nonparametrizable and regular case, the equations of states are asymptotically  equivalent to the Takeuchi information criterion (TIC)  for the maximum likelihood method
Here TIC was  derived for the model selection criterion in the case when the true distribution  is not contained in a statistical model  CITATION
The network information criterion  CITATION  was devised by generalizing it to an arbitrary loss function in the regular case
If a true distribution is singular for a learning machine,  TIC is ill-defined, whereas the equations of states are well-defined and equal to the average generalization losses
Therefore, equations of states can be understood as the generalized version of TIC from the maximum likelihood method in a regular case to Bayes method for regular and singular cases
This paper consists of six sections
In Section 2, we summarized the framework of Bayes learning and the results of previous papers
In Section 3,  we show the main results of this paper
In Section 4, some lemmas are prepared  which are used in the proofs of the main results
The proofs of lemmas are given in the Appendix
In Section 5, we prove the main theorems
In Section 5 and 6, we discuss and conclude this paper
### abstract ###
The problem of classifying sonar signals from rocks and mines first studied by Gorman and Sejnowski has become a benchmark against which many learning algorithms have been tested
We discovered that both the training set and the test set of this benchmark are linearly separable, although with different hyperplanes
Moreover, the complete set of learning and test patterns together, is also linearly separable
We give the weights that separate these sets, which may be used to compare results found by other algorithms
### introduction ###
It has become a current practice to test the performance of learning algorithms on \textsl{realistic} benchmark problems
The underlying difficulty of such tests is that in general these problems are not well caracterized, making it thus impossible to decide whether a better solution that the one already found exists
The Sonar signals classification benchmark, introduced by Gorman et al CITATION  is widely used to test machine learning algorithms
In this problem the classifier has to discriminate if a given sonar return was produced by a metal cylinder or by a cylindrically shaped rock in the same environment
The benchmark contains 208 preprocessed sonar spectra, defined by  SYMBOL  real values, with their corresponding class
Among these,  SYMBOL  patterns are usually used to determine the classifier parameters through a procedure called learning
Then, the classifier is used to class the  SYMBOL  remaining patterns and the fraction of misclassified patterns is used to estimate the generalization error produced by the learning algorithm
We applied Monoplane, a neural incremental learning algorithm, to this benchmark
In this algorithm, the hidden units are included one after the other until the number of training errors vanishes
Each hidden unit is a simple binary perceptron, trained with the learning algorithm Minimerror  CITATION
### abstract ###
An approach to the acceleration of parametric weak classifier boosting is proposed
Weak classifier is called parametric if it has fixed number of parameters and, so, can be represented as a point into multidimensional space
Genetic algorithm is used instead of exhaustive search to learn parameters of such classifier
Proposed approach also takes cases when effective algorithm for learning some of the classifier parameters exists into account
Experiments confirm that such an approach can dramatically decrease classifier training time while keeping both training and test errors small
### introduction ###
Boosting is one of the commonly used classifier learning approaches
It is machine learning meta-algorithm that iteratively learns additive model consisting of weighed \term{weak} classifiers that belong to some classifier family  SYMBOL
In case of two-class classification problem (which we will consider in this paper) boosted classifier usually has form  SYMBOL } There  SYMBOL  is a sample to classify,  SYMBOL  are weak classifiers learned during boosting procedure,  SYMBOL  are weak classifier weights,  SYMBOL ,  SYMBOL
Set  SYMBOL  is referred to as \term{weak} classifier family
That is because it elements should have error rate only slightly better than random guessing
It expresses the key idea of boosting: strong classifier can be built on top of many weak
There are many boosting procedures that differ by the type of loss being optimized for the final classifier
But no matter what kind of boosting procedure is used, on each iteration it should select (learn) a weak classifier with minimal weighed loss from  SYMBOL  family using special algorithm called \term{weak learner}
Fast and accurate optimization methods are often not applicable there (especially in the case of discrete classifier parameters), so exhaustive search over weak classifier parameter space is used as a weak learner
Unfortunately, exhaustive search can take a lot of time
For example, learning cascade of boosted classifiers based on haar features with \term{AdaBoost} and exhaustive search over classifier parameter space took several weeks in the famous work  CITATION
That's why it is often very important to decrease weak classifier learning time using some appropriate numerical optimization approach
One of the widely used approaches to the numerical optimization is genetic algorithm  CITATION
It is based on biological evolution ideas
Optimization problem solution is coded as \term{chromosome} vector \term{Initial population} of solutions is created using random number generator \term{Fitness function} is then used to assign fitness value to every population member
Solutions with the biggest fitness values are selected for the next step
In the next step, \term{genetic operators} (crossover and mutation usually) are applied to selected chromosomes to produce new solutions and to modify existing ones slightly
That modified solutions form up a new generation
Then described process repeats
That's how evolution is modeled
It continues until global or suboptimal solution is found or time allowed for evolution is over
Genetic algorithms are often used for global extremum search in big and complicated search spaces
It makes genetic algorithm good candidate for weak classifier learner
### abstract ###
General-purpose, intelligent, learning agents cycle through sequences of observations, actions, and rewards that are complex, uncertain, unknown, and non-Markovian
On the other hand, reinforcement learning is well-developed for small finite state Markov decision processes (MDPs)
Up to now, extracting the right state representations out of bare observations, that is, reducing the general agent setup to the MDP framework, is an art that involves significant effort by designers
The primary goal of this work is to automate the reduction process and thereby significantly expand the scope of many existing reinforcement learning algorithms and the agents that employ them
Before we can think of mechanizing this search for suitable MDPs, we need a formal objective criterion
The main contribution of this article is to develop such a criterion
I also integrate the various parts into one learning algorithm
Extensions to more realistic dynamic Bayesian networks are developed in Part II  CITATION
The role of POMDPs is also considered there
### introduction ###
Artificial General Intelligence (AGI) is concerned with designing agents that perform well in a wide range of environments  CITATION
Among the well-established ``narrow'' Artificial Intelligence (AI) approaches  CITATION , arguably Reinforcement Learning (RL)  CITATION  pursues most directly the same goal
RL considers the general agent-environment setup in which an agent interacts with an environment (acts and observes in cycles) and receives (occasional) rewards
The agent's objective is to collect as much reward as possible
Most if not all AI problems can be formulated in this framework
Since the future is generally unknown and uncertain, the agent needs to learn a model of the environment based on past experience, which allows to predict future rewards and use this to maximize expected long-term reward
The simplest interesting environmental class consists of finite state fully observable Markov Decision Processes (MDPs)  CITATION , which is reasonably well understood
Extensions to continuous states with (non)linear function approximation  CITATION , partial observability (POMDP)  CITATION , structured MDPs (DBNs)  CITATION , and others have been considered, but the algorithms are much more brittle
A way to tackle complex real-world problems is to reduce them to finite MDPs which we know how to deal with efficiently
This approach leaves a lot of work to the designer, namely to extract the right state representation (``features'') out of the bare observations in the initial (formal or informal) problem description
Even if  potentially  useful representations have been found, it is usually not clear which ones will turn out to be better, except in situations where we already know a perfect model
Think of a mobile robot equipped with a camera plunged into an unknown environment
While we can imagine which image features will potentially be useful, we cannot know in advance which ones will actually be useful
The primary goal of this paper is to develop and investigate a method that  automatically  selects those features that are necessary and sufficient for  reducing  a complex real-world problem to a computationally tractable MDP
Formally, we consider maps  SYMBOL  from the past observation-reward-action history  SYMBOL  of the agent to an MDP state
Histories not worth being distinguished are mapped to the same state, i e \  SYMBOL  induces a partition on the set of histories
We call this model  SYMBOL MDP
A state may be simply an abstract label of the partition, but more often is itself a structured object like a discrete vector
Each vector component describes one feature of the history  CITATION
For example, the state may be a 3-vector containing (shape,color,size) of the object a robot tracks
For this reason, we call the  reduction ,  Feature RL , although in this Part I only the simpler unstructured case is considered
SYMBOL  maps the agent's experience over time into a sequence of MDP states
Rather than informally constructing  SYMBOL  by hand, our goal is to develop a formal objective criterion  SYMBOL  for  evaluating  different reductions  SYMBOL
Obviously, at any point in time, if we want the criterion to be effective it can only depend on the agent's past experience  SYMBOL  and possibly generic background knowledge
The ``Cost'' of  SYMBOL  shall be small iff it leads to a ``good'' MDP representation
The establishment of such a criterion transforms the, in general, ill-defined RL problem to a formal optimization problem (minimizing Cost) for which efficient algorithms need to be developed
Another important question is which problems  can  profitably be reduced to MDPs  CITATION
The real world does not conform itself to nice models: Reality is a non-ergodic partially observable uncertain unknown environment in which acquiring experience can be expensive
So we should exploit the data (past experience) at hand as well as possible, cannot generate virtual samples since the model is not given (need to be learned itself), and there is no reset-option
No criterion for this general setup exists
Of course, there is previous work which is in one or another way related to  SYMBOL MDP
As partly detailed later, the suggested  SYMBOL MDP model has interesting connections to many important ideas and approaches in RL and beyond: \parskip=0ex\parsep=0exsep=0ex   SYMBOL MDP side-steps the open problem of learning POMDPs  CITATION , %  Unlike Bayesian RL algorithms  CITATION ,  SYMBOL MDP avoids learning a (complete stochastic) observation model, %   SYMBOL MDP is a scaled-down practical instantiation of AIXI  CITATION , %   SYMBOL MDP extends the idea of state-aggregation from planning (based on bi-simulation metrics  CITATION ) to RL (based on information), %   SYMBOL MDP generalizes U-Tree  CITATION  to arbitrary features, %   SYMBOL MDP extends model selection criteria to general RL problems  CITATION , %   SYMBOL MDP is an alternative to PSRs  CITATION  for which proper learning algorithms have yet to be developed, %   SYMBOL MDP extends feature selection from supervised learning to RL  CITATION
Learning in agents via rewards is a much more demanding task than ``classical'' machine learning on independently and identically distributed ( iid  ) data, largely due to the temporal credit assignment and exploration problem
Nevertheless, RL (and the closely related adaptive control theory in engineering) has been applied (often unrivaled) to a variety of real-world problems, occasionally with stunning success (Backgammon, Checkers,  CITATION , helicopter control  CITATION )
SYMBOL MDP overcomes several of the limitations of the approaches in the items above and thus broadens the applicability of RL
SYMBOL MDP owes its general-purpose  learning  and  planning  ability to its  information  and  complexity  theoretical foundations
The implementation of  SYMBOL MDP is based on (specialized and general)  search  and  optimization  algorithms used for finding good reductions  SYMBOL
Given that  SYMBOL MDP aims at general AI problems, one may wonder about the role of other aspects traditionally considered in AI  CITATION :  knowledge representation  (KR) and  logic  may be useful for representing complex reductions  SYMBOL
Agent interface fields like  robotics , computer  vision , and natural  language  processing can speedup learning by pre\&post-processing the raw observations and actions into more structured formats
These representational and interface aspects will only barely be discussed in this paper
The following diagram illustrates  SYMBOL MDP in perspective \end{center}   Section  formalizes our  SYMBOL MDP setup, which consists of the agent model with a map  SYMBOL  from observation-reward-action histories to MDP states
Section  develops our core  SYMBOL  selection principle, which is illustrated in Section  on a tiny example
Section  discusses general search algorithms for finding (approximations of) the optimal  SYMBOL , concretized for context tree MDPs
In Section  I find the optimal action for  SYMBOL MDP, and present the overall algorithm
Section  improves the  SYMBOL  selection criterion by ``integrating'' out the states
Section  contains a brief discussion of  SYMBOL MDP, including relations to prior work, incremental algorithms, and an outlook to more realistic  structured  MDPs (dynamic Bayesian networks,  SYMBOL DBN) treated in Part II
Rather than leaving parts of  SYMBOL MDP vague and unspecified, I decided to give at the very least a simplistic concrete algorithm for each building block, which may be assembled to one sound system on which one can build on
Throughout this article,  SYMBOL  denotes the binary logarithm, %  SYMBOL  the empty string, % and  SYMBOL  if  SYMBOL  and  SYMBOL  else is the Kronecker symbol
% I generally omit separating commas if no confusion arises, in particular in indices
For any  SYMBOL  of suitable type (string,vector,set), I define string  SYMBOL , % sum  SYMBOL , union  SYMBOL , and vector  SYMBOL , % where  SYMBOL  ranges over the full range  SYMBOL  and  SYMBOL  is the length or dimension or size of  SYMBOL
%  SYMBOL  denotes an estimate of  SYMBOL
%  SYMBOL  denotes a probability over states and rewards or parts thereof
I do not distinguish between random variables  SYMBOL  and realizations  SYMBOL , and abbreviation  SYMBOL  never leads to confusion
More specifically,  SYMBOL  denotes the number of states, %  SYMBOL  any state index, %  SYMBOL  the current time, % and  SYMBOL  any time in history
% Further, in order not to get distracted at several places I gloss over initial conditions or special cases where inessential
Also 0 SYMBOL undefined=0 SYMBOL infinity:=0
### abstract ###
KNN is one of the most popular classification methods, but it often fails to work well with inappropriate choice of distance metric or due to the presence of numerous class-irrelevant features
Linear feature transformation methods have been widely applied to extract class-relevant information to improve kNN classification, which is very limited in many applications
Kernels have been used to learn powerful non-linear feature transformations, but these methods fail to scale to large datasets
In this paper, we present a scalable non-linear feature mapping method based on a deep neural network pretrained with restricted boltzmann machines for improving kNN classification in a large-margin framework, which we call DNet-kNN
DNet-kNN can be used for both classification and for supervised dimensionality reduction
The  experimental results on two benchmark handwritten digit datasets show that DNet-kNN has much better performance than large-margin kNN using a linear mapping and kNN based on a deep autoencoder pretrained with retricted boltzmann machines
### introduction ###
kNN is one of the most popular classification methods due to its simplicity and reasonable effectiveness: it doesn't require fitting a model and it has been shown to have good performance for classifying many types of data
However, the good classification performance of kNN is highly dependent on the metric used  for computing pairwise distances between data points
In practice, we often use Euclidean distances as similarity metric to calculate k nearest  neighbors of data points of interest
To classify high-dimensional data in real applications, we often need to learn or choose a good distance metric
Previous work on metric learning in  CITATION  and  CITATION  learns a global linear transformation matrix in the original feature space of data points to make similar data points stay closer while making dissimilar data points move farther apart using additional similarity or label information
In  CITATION , a global linear transformation is applied to the original feature space of data points to learn Mahalanobis metrics, which requires all data points in the same class collapse to one point
Making data points in the same class collapse to one point is unnecessary for kNN classification
It may produce poor performance when data points cannot be essentially collapsed to points,  which is often true for some class containing multiple patterns
An information-theoretic based approach is used to learn linear transformations in  CITATION
In  CITATION , a global linear transformation is learned to directly improve kNN classification to achieve the goal of a large margin
This method has been shown to yield significant improvement over kNN classification, but the linear transformation often fails to give good performance in high-dimensional space and a pre-processing dimensionality reduction step by PCA is often required for success
In many situations, a linear transformation is not powerful enough to capture the underlying class-specific data manifold; thus we need to resort to more powerful non-linear transformations, so that each data point will stay closer to its nearest neighbors having the same class as itself than to any other data in the non-linearly transformed feature space
Kernel tricks have been used to kernelize some of the above methods in order to improve kNN classification  CITATION
The method in  CITATION  extends the work in  CITATION  to perform linear dimensionality reduction to improve large-margin kNN classification and kernelized the method in  CITATION
However, the kernel-based approaches behave almost like template-based approaches
If the chosen kernel cannot well reflect the true class-related structure of the data, the resulting performance will be bad
Besides, kernel-based approaches often have difficulty in handling large datasets
We might want to achieve non-linear mappings by learning a directed multi-layer belief net or a deep autoencoder, and then perform kNN classification using the hidden distributed representations of the original input data
However, a multi-layer belief net often suffers from the "explaining away" effect, that is, the top hidden units become dependent conditional on the bottom visible units, which makes inference intractable; and learning a deep autoencoder with backpropagation is amost impossible because the gradient backpropagated to the lower layers from the output often becomes very noisy and meaningless
Fortunately, recent research has shown that training a deep generative model called Deep Belief Net is feasible by pretraining the deep net using a type of undirected graphical model called Restricted Boltzmann Machine (RBM)  CITATION
RBMs produce "complementary priors" to make the inference process in a deep belief net much easier, and the deep net can be trained greedily layer by layer using the simple and efficient learning rule of RBM
The greedy layerwise pretraining strategy has made learning models with deep architures possible  CITATION
Moreover, the greedy pretraining idea has also been successfully applied to initialize the weights of a deep autoencoder to learn a very powerful non-linear mapping for dimensionality reduction, which is illustrated in Fig 1a) and 1b)
Besides, the idea of deep learning has motivated researchers to use powerful generative models with deep architectures to learn better discriminative models  CITATION
In this paper, by combining the idea of deep learning and large-margin discriminative learning, we propose a new kNN classification and supervised dimensionality reduction method called DNet-kNN
It learns a non-linear feature transformation to directly achieve the goal of large-margin kNN classification, which is based on a Deep Encoder Network pretrained with RBMs as shown in Fig 2
Our approach is mainly inspired by the work in  CITATION ,  CITATION  and  CITATION
Given the labels of some or all training data, it allows us to learn a non-linear feature mapping to minimize the invasions to each data point's genuine neighborhood by other impostor nearest neighbors, which favours kNN classification directly
Previous researchers once used an autoencoder or a deep autoencoder for non-linear dimensionality reduction to improve kNN  CITATION
None of these approaches used an objective function as direct as what we use here for improving kNN classification
The approach discussed in  CITATION  uses a convolution net to learn a similarity metric discriminatively, but it was handcrafted
Our approach based on general deep neural networks is more flexible and the connection weight matrices between layers are automatically learned from data
We applied DNet-kNN on the USPS and MNIST handwritten digit datasets for classification
The test error we obtained on the MNIST benchmark dataset is  SYMBOL , which is better than that obtained by deep belief net, deep autoencoder and SVM  CITATION
In addition, our fine-tuning process is very fast and converges to a good local minimum within several iterations of conjugate-gradient update
Our experimental results show that: (1) a good generative model can be used as a pretraining stage to improve discriminative learning; (2) pretraining with generative models in a layerwise greedy way makes it possible to learn a good discriminative model with deep architecture;  (3) pretraining with RBMs makes discriminative learning process much faster than that without pretraining; (4) pretraining helps to find a much better local minimum than without pretraining
These conclusions are consistent with the results of previous research trials on deep networks  CITATION
We organize this paper as follows: in section 2, we introduce kNN classification using linear transformations in a large-margin framework
In section 3, we describe previous work on RBM and training models with deep architectures
In section 4, we present DNet-kNN, which trains a Deep Encoder Network for improving large-margin kNN classification
In section 5, we present our experimental results on the USPS and MNIST  CITATION  handwritten digit datasets
In section 6, we conclude the paper with some discussions and propose possible extensions of our current method
### abstract ###
% Given a matrix  SYMBOL  of low-rank, we consider the problem of reconstructing it from noisy observations of a small, random subset of its entries
The problem arises in a variety of applications, from collaborative filtering (the `Netflix problem') to structure-from-motion and positioning
We study a low complexity algorithm introduced by  CITATION , based on a combination of spectral techniques and manifold optimization, that we call  here {OptSpace}
We prove performance guarantees that are  order-optimal in a number of circumstances
### introduction ###
Spectral techniques are an authentic workhorse in machine learning, statistics, numerical analysis, and signal processing
Given  a matrix  SYMBOL , its largest singular values---and the associated singular vectors---`explain' the most significant correlations in the  underlying data source
A low-rank approximation of  SYMBOL  can further be used for low-complexity implementations of a number of linear algebra algorithms  CITATION
In many practical circumstances we have access only to a sparse subset of the entries of an  SYMBOL  matrix  SYMBOL
It has   recently been discovered that, if the matrix  SYMBOL  has rank  SYMBOL , and unless it is too `structured', a small random subset of its  entries allow to reconstruct it  exactly
This result was first proved by  CITATION  by analyzing a convex relaxation introduced by  CITATION
A tighter analysis of the same convex relaxation was  carried out by  CITATION
A number of iterative schemes to solve the convex optimization problem appeared soon thereafter  CITATION
In an alternative line  of work,  CITATION  attacked the same problem using a combination of spectral techniques and manifold optimization: We will refer to their algorithm as \optspace \optspace\, is intrinsically of low complexity,   the most complex operation being computing  SYMBOL  singular values (and the corresponding singular vectors)   of a sparse  SYMBOL  matrix
The performance guarantees proved by  CITATION  are comparable  with the information theoretic lower bound: roughly   SYMBOL  random entries are needed to reconstruct  SYMBOL  exactly (here we assume  SYMBOL  of order  SYMBOL )
A related approach was also developed by  CITATION , although without performance guarantees for matrix  completion
The above results crucially rely on the assumption that   SYMBOL  is  exactly  a rank  SYMBOL  matrix
For many applications of interest, this assumption is unrealistic and it is therefore important to investigate their robustness
Can the above approaches be generalized when the underlying data is `well approximated' by a rank  SYMBOL  matrix
This question was addressed by  CITATION  within the convex relaxation approach of  CITATION
The present paper proves a similar robustness result for \optspace
Remarkably the guarantees we obtain are order-optimal in a variety of circumstances, and improve over the analogous results of  CITATION
### abstract ###
Clusters of genes that have evolved by repeated segmental duplication present difficult challenges throughout genomic analysis, from sequence assembly to functional analysis
Improved understanding of these clusters is of utmost importance, since they have been shown to be the source of evolutionary innovation, and have been linked to multiple diseases, including HIV and a variety of cancers
Previously, Zhang \etal~(2008)  developed an algorithm for reconstructing parsimonious evolutionary histories of such gene clusters, using only human genomic sequence data
In this paper, we propose a probabilistic model for the evolution of gene clusters on a phylogeny, and an MCMC algorithm for reconstruction of duplication histories from genomic sequences in multiple species
Several projects are underway to obtain high quality BAC-based assemblies of  duplicated clusters in multiple species, and we anticipate that our method  will be useful in analyzing these valuable new data sets
### introduction ###
Segmental duplications cover about 5\% of the human genome  CITATION
When multiple segmental duplications occur at a particular genomic locus they give rise to complex gene clusters
Many important gene families  linked to various diseases, including cancers, Alzheimer's disease, and HIV, reside  in such clusters
Gene duplication is often followed by functional diversification  CITATION , and, indeed, genes overlapping segmental duplications have been shown to be enriched for positive selection  CITATION
In this paper, we describe a probabilistic model of evolution of such gene clusters on a phylogeny, and devise a Markov-chain Monte Carlo sampling algorithm for inference of highly probable duplication histories and ancestral sequences
To demonstrate the usefulness of our approach, we apply our algorithm to simulated sequences on human-chimp-macaque phylogeny, as well as to real clusters assembled from available BAC sequencing data
Previously,   CITATION  studied the reconstruction of gene family histories by considering tandem duplications and inversions as the only possible events
They also assume that  genes are always copied as a whole unit
CITATION  demonstrated that  more complex models are needed to address evolution of gene clusters in the human genome
In more recent work, genes have been replaced by generic  atomic segments   CITATION  as the substrates of reconstruction algorithms
Briefly, a self-alignment is constructed by a local alignment program (e g , blastz  CITATION ), and only alignments above certain threshold (e g , 93\% for human-macaque split) are kept
The boundaries of alignments mark  breakpoints , and the sequences between neighboring breakpoints  are considered atomic segments (Fig )
Due to the  transitivity  of sequence similarity between atomic segments, the set of atomic segments can be decomposed into equivalence classes, or  atom types
Thus, the nucleotide sequence is transformed into a simpler sequence of atoms
The task of  duplication history reconstruction  is to find a sequence of evolutionary events (e g , duplications, deletions,  and speciations) that starts with an ancestral sequence of atoms,  in which no atom type occurs twice, and ends with atomic sequences of extant species
Such a history also directly implies ``gene trees'' of individual atomic types, which we call  segment trees
These trees are implicitly rooted and reconciled with the species tree, and this information can be easily used to reconstruct ancestral sequences at speciation points segment by segment (see eg CITATION )
A common way of looking at these histories is from the most recent events back in time
In this context, we can start from extant sequences, and  unwind  events one-by-one, until the ancestral sequence is reached
CITATION  sought solutions of this problems  with small number of events,  given the sequence from a single species
In particular, they proved a necessary condition to identify candidates for the latest duplication operation, assuming no reuse of breakpoints
After unwinding the latest duplication, the same step is repeated to identify the second latest duplication, etc
Zhang \etal{} showed that following any sequence of  candidate duplications leads to a history with the same number of duplication events under no-breakpoint-reuse assumption
As a result, there may be an exponential number of most parsimonious solutions to the problem, and it may be impossible to reconstruct a unique history
A similar parsimony problem has also been recently explored by   CITATION  in the context of much larger sequences (whole genomes) and a broader set of operations (including inversions, translocations, etc )
In their algorithm, Ma \etal{} reconstruct phylogenetic trees for every atomic segment, and reconcile these segment trees with the species tree to infer deletions and rooting
The authors give a polynomial-time algorithm for the history reconstruction, assuming no-breakpoint-reuse and correct atomic segment trees
Both methods make use of fairly extensive heuristics to overcome violations of their assumptions and  allow their algorithms to be applied to real data
The no-breakpoint-reuse assumption is often justified by the argument that in long sequences, it is unlikely that the same breakpoint is used twice  CITATION
However, there is evidence that breakpoints do not occur uniformly throughout the sequence, and that breakpoint reuse is frequent  CITATION
Moreover, breakpoints located close to each other may lead to short atoms that  can't be reliably identified by sequence similarity algorithms and categorized into atom types
For example, in our simulated data (Section ),  approximately 2\% of atoms are shorter than 20bp and may appear  as additional breakpoint reuses instead
Thus, no-breakpoint-reuse can be a useful guide, but cannot be entirely relied on in application to real data sets
We have also examined the assumption of correctness of segment trees  inferred from sequences of individual segments  (Fig )
For segments shorter than 500bp (39\% of all segments in our simulations)  69\% of the trees were incorrectly reconstructed, and even for segments 500-1,000bp long, a substantial fraction is incorrect (46\%) }  In this paper, we present a simple probabilistic model for sequence evolution by duplication, and we design a sampling algorithm that explicitly accounts for uncertainty in the estimation of segment trees and allows for breakpoint reuse
The results of  CITATION  suggest that, in spite of an improved model, there may still be many solutions of similar likelihood
The stochastic sampling approach allows us to examine such multiple solutions in the same framework and extract expectations for quantities of particular interest (e g , the expected number of events on individual branches of the phylogeny, or local properties of the ancestral sequences)
In addition, by using data from multiple species, our approach obtains additional information about ancestral configurations
Our problem is closely related to the problem of reconstruction of gene trees and their reconciliation with species trees
Recent algorithms for gene tree reconstruction (e g ,  CITATION ) also consider genomic context of individual genes
However, our algorithms for reconstruction of duplication histories not only use such context as an additional piece of information, but the derived evolutionary histories also explain how similarities in the genomic context of individual genes evolved
Our current approach uses a simple HKY nucleotide substitution model  CITATION ,  with variance in rates allowed between individual atomic segments
However, in future work it will be possible to employ more complex models of sequence evolution, such as variable rate site models and models of codon evolution, within the same framework
Such extensions will allow us to  identify sites and branches under selection in gene clusters in a principled way, and contribute towards better functional characterization of these important genomic regions }                                             main
bbl                                                                                            0000644 0000000 0000000 00000014062 11215404221 011154  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  main
tex                                                                                            0000644 0000000 0000000 00000004513 11213761545 011232  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   \documentclass[11pt]{article} \usepackage[dvips]{graphicx} \usepackage{amssymb} \usepackage{natbib} \usepackage[headings]{fullpage} \pagestyle{headings} \setlength\textfloatsep{3mm minus 4 pt}    \def\etal{ et al }    intro
tex methods
tex experiments
tex discussion
tex  \paragraph{Acknowledgements } We would like to thank Devin Locke and LaDeana Hillier at Washington University, St
Louis for providing us with the BAC sequences from chimp, orangutan, and macaque
We would also like to thank Webb Miller and Yu Zhang for helpful discussions on this problem \bibliographystyle{apalike}  \bibliography{dups}  \end{document}                                                                                                                                                                                      methods
### abstract ###
The paper proposes a new message passing algorithm for cycle-free factor graphs
The proposed "entropy message passing" ( EMP ) algorithm may be viewed as sum-product message passing over the entropy semiring, which has previously appeared in automata theory
The primary use of  EMP  is to compute the entropy of a model
However,  EMP  can also be used to compute expressions that appear in expectation maximization and in gradient descent algorithms
### introduction ###
The efficient marginalization of a multivariate function is important in many areas including signal processing, artificial intelligence, and digital communications
When a cycle-free factor graph representation of the function is available, then exact marginals can be computed by sum-product message passing in the factor graph  CITATION - CITATION
In fact, a number of well-known algorithms are special cases of sum-product message passing
The "sum" and the "product" in sum-product message passing may belong to an arbitrary commutative semiring  CITATION , CITATION
In this paper, we propose to use it with the entropy semiring and the resulting algorithm will be called "entropy message passing" ( EMP )
The entropy semiring was introduced by Cortes et al CITATION  to compute the relative entropy between probabilistic automata
In this paper, we translate the ideas of  CITATION  into the language of factor graphs and message passing algorithms
The primary use of  EMP  is to compute the entropy of a model with a cycle-free factor graph for fixed observations
The main prior work on this subject is by Hernando et al CITATION ; again, a main point of the present paper is to clarify and to generalize this prior work by reformulating it in terms of sum-product message passing
However,  EMP  can also be used to compute expressions that appear in expectation maximization and in gradient ascent algorithms  CITATION - CITATION ; this connection appears to be new
The paper is structured as follows
In Section II, we review sum-product message passing over a commutative semiring
In Section III, we introduce the entropy semiring
The  EMP  algorithm is described in Section IV and the mentioned applications are described in Section V
### abstract ###
A standard approach in pattern classification is to estimate the distributions of the label classes, and then to apply the Bayes classifier to the estimates of the distributions in order to classify unlabeled examples
As one might expect, the better our estimates of the label class distributions, the better the resulting classifier will be
In this paper we make this observation precise by identifying risk bounds of a classifier in terms of the quality of the estimates of the label class distributions
We show how PAC learnability relates to estimates of the distributions that have a PAC guarantee on their  SYMBOL  distance from the true distribution, and we bound the increase in negative log likelihood risk in terms of PAC bounds on the KL-divergence
We give an inefficient but general-purpose smoothing method for converting an estimated distribution that is good under the  SYMBOL  metric into a distribution that is good under the KL-divergence
### introduction ###
We consider a general approach to pattern classification in which elements of each class are first used to train a probabilistic model via some unsupervised learning method
The resulting models for each class are then used to assign discriminant scores to an unlabeled instance, and a label is chosen to be the one associated with the model giving the highest score
For example~ CITATION  uses this approach to classify protein sequences, via training a well-known probabilistic suffix tree model of Ron et al ~ CITATION  on each sequence class
Indeed, even where an unsupervised technique is mainly being used to gain insight into the process that generated two or more data sets, it is still sometimes instructive to try out the associated classifier, since the misclassification rate provides a quantitative measure of the accuracy of the estimated distributions
The work of~ CITATION  has led to further related algorithms for learning classes of probabilistic finite state automata (PDFAs) in which the objective of learning has been formalized as the estimation of a true underlying distribution (over strings output by the  target PDFA ) with a distribution represented by a hypothesis PDFA
The natural discriminant score to assign to a string, is the probability that the hypothesis would generate that string at random
As one might expect, the better one's estimates of label class distributions (the class-conditional densities), the better should be the associated classifier
The contribution of this paper is to make precise that observation
We give bounds on the risk of the associated Bayes classifier in terms of the quality of the estimated distributions
These results are partly motivated by our interest in the relative merits of estimating a class-conditional distribution using the variation distance, as opposed to the KL-divergence (defined in the next section)
In~ CITATION  it has been shown how to learn a class of PDFAs using KL-divergence, in time polynomial in a set of parameters that includes the expected length of strings output by the automaton
In~ CITATION  we show how to learn this class with respect to variation distance, with a polynomial sample-size bound that is independent of the length of output strings
Furthermore, it can be shown that it is necessary to switch to the weaker criterion of variation distance, in order to achieve this
We show here that this leads to a different---but still useful---performance guarantee for the Bayes classifier
Abe and Warmuth~ CITATION  study the problem of learning probability distributions using the KL-divergence, via classes of probabilistic automata
Their criterion for learnability is that---for an unrestricted input distribution  SYMBOL ---the hypothesis PDFA should be almost (i e ~within  SYMBOL ) as close as possible to  SYMBOL
Abe, Takeuchi and Warmuth~ CITATION  study the negative log-likelihood loss function in the context of learning  stochastic rules , i e ~rules that associate an element of the domain  SYMBOL  to a probability distribution over the range  SYMBOL
We show here that if two or more label class distributions are learnable in the sense of~ CITATION , then the resulting stochastic rule (the conditional distribution over  SYMBOL  given  SYMBOL ) is learnable in the sense of~ CITATION
We show that if instead the label class distributions are well estimated using the variation distance, then the associated classifier may not have a good negative log likelihood risk, but will have a  misclassification rate  that is close to optimal
This result is for general  SYMBOL -class classification, where distributions may overlap (i e the optimum misclassification rate may be positive)
We also incorporate variable misclassification penalties (sometimes one might wish a false positive to cost more than a false negative), and show that this more general loss function is still approximately minimized provided that discriminant likelihood scores are rescaled appropriately
As a result we show that PAC-learnability and more generally p-concept learnability~ CITATION , follows from the ability to learn class distributions in the setting of Kearns et al ~ CITATION
Papers such as~ CITATION  study the problem of learning various classes of probability distributions with respect to KL-divergence and variation distance, in this setting
It is well-known (noted in~ CITATION ) that learnability with respect to KL-divergence is stronger than learnability with respect to variation distance
Furthermore, the KL-divergence is usually used (for example in~ CITATION ) due to the property that when minimized with respect to an sample, the empirical likelihood of that sample is maximized
An algorithm that learns with respect to variation distance can sometimes be converted to one that learns with respect to KL-divergence by a smoothing technique~ CITATION , when the domain is  SYMBOL , and  SYMBOL  is a parameter of the learning problem
In this paper we give a related smoothing rule that applies to the version of the PDFA learning problem where we seem to ``need'' to use the variation distance
However, the smoothed distribution does not have an efficient representation, and requires the probabilities used in the target PDFA to have limited precision
### abstract ###
%%%% Replace with your abstract
Traffic forecasting from past observed traffic data with small calculation complexity is one of important problems for planning of servers and networks
Focusing on World Wide Web (WWW) traffic as fundamental investigation, this paper would deal with Bayesian forecasting of network traffic on the time varying Poisson model from a viewpoint from statistical decision theory
Under this model, we would show that the estimated forecasting value is obtained by simple arithmetic calculation and expresses real WWW traffic well from both theoretical and empirical points of view
### introduction ###
Under network environment such as Internet, planning of servers and networks is one of important problems for stable operation
It is often typical situation that administrators analyze logs on their servers and networks
They may frequently look into result of log analysis software where these tools usually have some functions to periodically summarize logs
For example, webalizer  CITATION  and analog  CITATION  etc \, have been widely used among World Wide Web (WWW) server administrators or users for long years
These tools usually summarize the logs by counting hourly, daily, and monthly numbers of hits, files, and pages etc
Administrators would often make their operation plans with combination of their experience and intuition from these logs
In this case, traffic forecasting rule is not clearly formulated and those summarized logs remain in the field of  descriptive statistics  from the statistical point of view
On the other hand, researchers in the field of traffic engineering have been suggesting a lot of analysis models
Probabilistic approach is one of viewpoints in this field
It is wide-spread fact that the stationary Poisson distribution is not always suitable for Internet traffic because of its nature of non-stationality  CITATION   CITATION  and long-range dependence (LRD)  CITATION   CITATION  etc
Therefore desirable conditions of good traffic models are to have structures to express such nature at least
Furthermore, another requirement of models is to have a structure of traffic forecasting
For this point, parameter estimation is often performed at first under assumption of the stationarity  CITATION , then the estimated parameter is substituted for the parameter of model
This approach has been wide-spread in the field of  inferential statistics  from the statistical point of view
However, substituting the estimated parameter as a constant for the model's parameter is not always suitable especially on forecasting problems
This is because there is often no guarantee that the assumptions under the parameter estimation of the model always hold for future unknown data set
Bayesian approach  CITATION  CITATION  is one of alternatives for this point
In Bayesian approach, a probability distribution of parameter is assumed as the prior distribution
If new data is observed, then the Bayes theorem updates the prior distribution of parameter to the posterior distribution and then forecasts the posterior distribution of data
Recently, this approach has been widely applied to many forecasting problems especially in the field of information technologies and bioinformatics etc
In order to take Bayesian approach,  statistical decision theory  is an important theoretical framework from the statistical point of view
Taking the above factors into account, this paper would deal with Bayesian forecasting of WWW traffic on the non-stationary i e time varying Poisson model
Bayesian forecasting on time varying parameter model has been proposed in  CITATION  by defining certain class of parameter transformation function
However, it has not yet been discussed about any predictive estimator nor definite transformation function of parameter  CITATION
This paper would clearly define a random-walking type of transformation function of parameter to obtain the Bayes optimal prediction for WWW traffic
Then its effectiveness would be evaluated with real WWW traffic data
In this model, time varying degree is caught by a real valued constant  SYMBOL  and this constant would play an important role throughout this paper
Another feature is that the traffic forecasting value is obtained by simple arithmetic calculations under known  SYMBOL
In general, the Bayes theorem often results in large calculation costs
However, certain combination of parameter distribution and its transformation function solves this problem
We believe that this point can be helpful not only for theoretical calculation cost but also for real implementation on WWW log analysis tools  CITATION   CITATION
The rest of this paper is organized as the followings
Section  gives some definitions and explanations of the forecasting model with time varying Poisson distribution
Section  shows some analysis examples of real WWW traffic data  to validate this paper's approach and Section  gives{} their discussions
Finally, Section  concludes this paper
                                                                                                                                                                                                                                       chap02-20091120a
### abstract ###
In this paper, we present two classes of Bayesian approaches to the two-sample problem
Our first class of methods extends the Bayesian t-test to include all parametric models in the exponential family and their conjugate priors
Our second class of methods uses Dirichlet process mixtures (DPM) of such conjugate-exponential distributions as flexible nonparametric priors over the unknown distributions
%On synthetic examples and real medical datasets, we show that our tests are competitive with the best state-of-the-art methods for this task, even outperforming them on average on the medical datasets
### introduction ###
In this paper, we tackle the so-called two-sample problem:  An associated test is called a two-sample test
Such tests are encountered in various disciplines from the life sciences to the social sciences:   In medical studies, one may want to find out if two classes of patients show different behaviour, response to a drug or susceptibility to a disease
In microarray analysis, one may compare measurements from different weeks, labs or platforms to find out if they follow the same distribution, before integrating them into one dataset, in order to increase sample size
In the neurosciences, one may want to compare measurements of brain signals under different external stimuli, to check whether brain activity is affected by these stimuli
In the social sciences, one may want to compare whether the behavior of a group of people, eg when they graduate, marry, or die, is different across countries or generations
In the financial sciences, one could for example compare the set of transactions performed at a stock exchange during different weeks, to find out if there is a change in activity in the financial markets
While this question has been studied in detail by classic statistics for univariate data, there is less work on multivariate data (which we review in Section )
The only machine learning approach to this problem is a kernel method by  CITATION , using the means of the two samples  SYMBOL  and  SYMBOL  in a universal reproducing kernel Hilbert Space as its test statistics, but it has created lots of interest in that subject and follow-on studies~ CITATION
Here, we approach this two-sample problem from a Bayesian perspective
The classic Bayesian formulation of this problem would be in terms of a Bayes factor~ CITATION  which represents the likelihood ratio that the data were generated according to hypothesis  SYMBOL  (that is from the same distribution) or hypothesis  SYMBOL  (that is from different distributions)
However, how to exactly define these two hypotheses is a crucial question, and many answers have been given in the Bayesian literature with hypotheses that are tailored to a specific problem or application domain; one example are the Bayesian t-tests used in microarray data analysis~ CITATION
Our goal in this paper is to define two general classes of two-sample tests that represent a precise formulation of the two-sample problem, but are not tailored to a specific application
They are designed to offer an attractive middle ground between the general idea of using Bayes factors and the specialised hypotheses testing problems studied in the literature
In detail, we define a class of nonparametric Bayesian two sample tests based on Dirichlet process mixture models
The use of Dirichlet process mixtures for flexible nonparametric modelling of general unknown distributions has a long history in Statistics
However, although the two-sample problem depends crucially on testing whether data come from one or two unknown distributions, Bayesian approaches based on nonparametric density models have not been explored to date
Here we propose and explore such a non-parametric method using the classic Dirichlet process mixture
To the best of our knowledge, the only work that is remotely related is that on a Bayesian test for a parametric versus a nonparametric model of the data by Berger and Guglielmi~ CITATION
This addresses a different but related question since it assumes a parametric null hypothesis
We also define a parametric Bayesian two-sample test where the model of the data is a member of the exponential family
This test generalizes the Bayesian t-test by~ CITATION  and~ CITATION , who assume that the samples are Gaussian
This paper is structured as follows
In Section~ we will review existing approaches to the two-sample problem on multivariate data, and highlight some differences between frequentist and Bayesian hypothesis testing
In Section~ we outline the common core of our two Bayesian two-sample test, before providing the details on the parametric test in Section~ and on the non-parametric  test in Section~
%In Section~ we will evaluate the performance of our tests, comparing it to the state-of-the-art methods in this field
### abstract ###
Two ubiquitous aspects of large-scale data analysis are that the data often have heavy-tailed properties and that diffusion-based or spectral-based methods are often used to identify and extract structure of interest
Perhaps surprisingly, popular distribution-independent methods such as those based on the VC dimension fail to provide nontrivial results for even simple learning problems such as binary classification in these two settings
In this paper, we develop distribution-dependent learning methods that can be used to provide dimension-independent sample complexity bounds for the binary classification problem in these two popular settings
In particular, we provide bounds on the sample complexity of maximum margin  classifiers when the magnitude of the entries in the feature vector decays according to a power law and also when learning is performed with the so-called Diffusion Maps kernel
Both of these results rely on bounding the annealed entropy of gap-tolerant classifiers in a Hilbert space
We provide such a bound, and we demonstrate that our proof technique generalizes to the case when the margin is measured with respect to more general Banach space norms
The latter result is of potential interest in cases where modeling the relationship between data elements as a dot product in a Hilbert space is too restrictive
### introduction ###
Two ubiquitous aspects of large-scale data analysis are that the data often have heavy-tailed properties and that diffusion-based or spectral-based methods are often used to identify and extract structure of interest
In the absence of strong assumptions on the data,  popular distribution-independent methods such as those based on the VC dimension fail to provide nontrivial results for even simple learning problems such as binary classification in these two settings
At root, the reason is that in both of these situations the data are formally very high dimensional and that (without additional regularity assumptions on the data) there may be a small number of ``very outlying'' data points
In this paper, we develop distribution-dependent learning methods that can be used to provide dimension-independent sample complexity bounds for the maximum margin version of the binary classification problem in these  two popular settings
In both cases,  we are able to obtain nearly optimal linear classification hyperplanes since the distribution-dependent tools we employ are able to control the aggregate effect of the ``outlying'' data points
In particular, our results will hold even though the data may be  infinite-dimensional and unbounded
### abstract ###
{dimension reduction; kernel methods; low-rank approximation; machine learning; Nystr\"om extension}% In recent years, the spectral analysis of appropriately defined kernel matrices has emerged as a principled way to extract the low-dimensional structure often prevalent in high-dimensional data
Here we provide an introduction to spectral methods for linear and nonlinear dimension reduction, emphasizing ways to overcome the computational limitations currently faced by practitioners with massive datasets
In particular, a data subsampling or landmark selection process is often employed to construct a kernel based on partial information, followed by an approximate spectral analysis termed the Nystr\"om extension
We provide a quantitative framework to analyse this procedure, and use it to demonstrate algorithmic performance bounds on a range of practical approaches designed to optimize the landmark selection process
We compare the practical implications of these bounds by way of real-world examples drawn from the field of computer vision, whereby low-dimensional manifold structure is shown to emerge from high-dimensional video data streams
### introduction ###
In recent years, dramatic increases in available computational power and data storage capabilities have spurred a renewed interest in dimension reduction methods
This trend is illustrated by the development over the past decade of several new algorithms designed to treat nonlinear structure in data, such as isomap (Tenenbaum  et al ~2000), spectral clustering (Shi \&~Malik~2000), Laplacian eigenmaps (Belkin \&~Niyogi~2003), Hessian eigenmaps (Donoho \&~Grimes~2003) and diffusion maps (Coifman  et al ~2005)
Despite their different origins, each of these algorithms requires computation of the principal eigenvectors and eigenvalues of a positive semi-definite kernel matrix
In fact, spectral methods and their brethren have long held a central place in statistical data analysis
The spectral decomposition of a positive semi-definite kernel matrix underlies a variety of classical approaches such as principal components analysis, in which a low-dimensional subspace that explains most of the variance in the data is sought, Fisher discriminant analysis, which aims to determine a separating hyperplane for data classification, and multidimensional scaling, used to realize metric embeddings of the data
As a result of their reliance on the exact eigendecomposition of an appropriate kernel matrix, the computational complexity of these methods scales in turn as the cube of either the dataset  dimensionality  or  cardinality  (Belabbas \&~Wolfe~2009)
Accordingly, if we write  SYMBOL  for the requisite complexity of an exact eigendecomposition, large and/or high-dimensional datasets can pose severe computational problems for both classical and modern methods alike
One alternative is to construct a kernel based on partial information; that is, to analyse directly a set of `landmark' dimensions or examples that have been selected from the dataset as a kind of summary statistic
Landmark selection thus reduces the overall computational burden by enabling practitioners to apply the aforementioned algorithms directly to a subset of their original data---one consisting solely of the chosen landmarks---and subsequently to extrapolate their results at a computational cost of  SYMBOL
While practitioners often select landmarks simply by sampling from their data uniformly at random, we show in this article how one may improve upon this approach in a data-adaptive manner, at only a slightly higher computational cost
We begin with a review of linear and nonlinear dimension-reduction methods in~\S, and formally introduce the optimal landmark selection problem in~\S
We then provide an analysis framework for landmark selection in~\S, which in turn yields a clear set of trade-offs between computational complexity and quality of approximation
Finally, we conclude in~with a case study demonstrating applications to the field of computer vision
### abstract ###
We describe an adaptation and application of a search-based structured prediction algorithm ``\searn'' to unsupervised learning problems
We show that it is possible to reduce unsupervised learning to supervised learning and demonstrate a high-quality unsupervised shift-reduce parsing model
We additionally show a close connection between unsupervised \searn\ and expectation maximization
Finally, we demonstrate the efficacy of a semi-supervised extension
The key idea that enables this is an application of the  predict-self  idea for unsupervised learning
### introduction ###
A prevalent and useful version of unsupervised learning arises when both the observed data and the latent variables are structured
Examples range from hidden alignment variables in speech recognition  CITATION  and machine translation  CITATION , to latent trees in unsupervised parsing  CITATION , and to pose estimation in computer vision  CITATION
These techniques are all based on probabilistic models
Their applicability hinges on the tractability of (approximately) computing latent variable expectations, thus enabling the use of EM  CITATION
In this paper we show that a recently-developed  search-based  algorithm, \searn\  CITATION  (see Section~), can be utilized for unsupervised structured prediction (Section~)
We show: (1) that under an appropriate construction, \searn\ can imitate the expectation maximization (Section~); (2) that unsupervised \searn\ can be used to obtain competitive performance on an unsupervised dependency parsing task (Section~); and (3) that unsupervised \searn\ naturally extends to a semi-supervised setting (Section~)
The key insight that enables this work is that we can consider the prediction of the (observed) input to be, itself, a structured prediction problem
### abstract ###
We learn multiple hypotheses for related tasks under a latent hierarchical relationship between tasks
We exploit the intuition that for  domain adaptation , we wish to share classifier structure, but for  multitask learning , we wish to share covariance structure
Our hierarchical model is seen to subsume several previously proposed multitask learning models and performs well on three distinct real-world data sets
### introduction ###
We consider two related, but distinct tasks: domain adaptation (DA)  CITATION  and multitask learning (MTL)  CITATION
Both involve learning related hypotheses on multiple data sets
In DA, we learn multiple classifiers for solving the  same problem  over data from  different distributions
In MTL, we learn multiple classifiers for solving  different problems  over data from the  same distribution
Seen from a Bayesian perspective, a natural solution is a hierarchical model, with hypotheses as leaves  CITATION
However, when there are more than two hypotheses to be learned (i e , more than two domains or more than two tasks), an immediate question is: are all hypotheses equally related
If not, what is their relationship
We address these issues by proposing two hierarchical models with  latent  hierarchies, one for DA and one for MTL (the models are nearly identical)
We treat the hierarchy nonparametrically, employing Kingman's coalescent  CITATION
We derive an EM algorithm that makes use of recently developed efficient inference algorithms for the coalescent  CITATION
On several DA and MTL problems, we show the efficacy of our model
Our models for DA and MTL share a common structure based on an unknown hierarchy
The key difference between the DA model and the MTL model is in what information is shared across the hierarchy
For simplicity, we consider the case of linear classifiers (logistic regression and linear regression)
This can be extended to non-linear classifiers by moving to Gaussian processes  CITATION
In domain adaption, a useful model is to assume that there is a single classifier that ``does well'' on all domains  CITATION
In the context of hierarchical Bayesian modeling, we interpret this as saying that the weight vector associated with the linear classifier is generated according to the hierarchical structure
On the other hand, in MTL, one does  not  expect the same weight vector to do well for all problems
Instead, a common assumption is that features co-vary in similar ways between tasks  CITATION
In a hierarchical Bayesian model, we interpret this as saying that the covariance structure associated with the linear classifiers is generated according to the hierarchical structure
In brief: for DA, we share weights; for MTL, we share covariance
### abstract ###
We present an algorithmic framework for learning multiple related tasks
Our framework exploits a form of prior knowledge that relates the output spaces of these tasks
We present PAC learning results that analyze the conditions under which such learning is possible
We present results on learning a shallow parser and named-entity recognition system that exploits our framework, showing consistent improvements over baseline methods
### introduction ###
When two NLP systems are run on the same data, we expect certain constraints to hold between their outputs
This is a form of prior knowledge
We propose a self-training framework that uses such information to significantly boost the performance of one of the systems
The key idea is to perform self-training  only  on outputs that obey the constraints
Our motivating example in this paper is the task pair: named entity recognition (NER) and shallow parsing (aka syntactic chunking)
Consider a hidden sentence with known POS and syntactic structure below
Further consider four potential NER sequences for this sentence \end{small}   Without ever seeing the actual sentence, can we guess which NER sequence is correct
NER1 seems wrong because we feel like named entities should not be part of verb phrases
NER2 seems wrong because there is an NNP, we also include \mytag{NNPS} } (proper noun) that is not part of a named entity (word 5)
NER3 is amiss because we feel it is unlikely that a  single  name should span more than one NP (last two words)
NER4 has none of these problems and seems quite reasonable
In fact, for the hidden sentence, NER4 is correct
The remainder of this paper deals with the problem of formulating such prior knowledge into a workable system
There are similarities between our proposed model and both self-training and co-training; background is given in Section~
We present a formal model for our approach and perform a simple, yet informative, analysis (Section~)
This analysis allows us to define what good and bad constraints are
Throughout, we use a running example of NER using hidden Markov models to show the efficacy of the method and the relationship between the theory and the implementation
Finally, we present full-blown results on seven different NER data sets (one from CoNLL, six from ACE), comparing our method to several competitive baselines (Section~)
We see that for many of these data sets, less than one hundred labeled NER sentences are required to get state-of-the-art performance, using a discriminative sequence labeling algorithm  CITATION
### abstract ###
We present \searn, an algorithm for integrating \textsc{sear}ch and l\textsc{earn}ing to solve complex structured prediction problems such as those that occur in natural language, speech, computational biology, and vision \searn\ is a meta-algorithm that transforms these complex problems into simple classification problems to which any binary classifier may be applied
Unlike current algorithms for structured learning that require  decomposition  of both the loss function and the feature functions over the predicted structure, \searn\ is able to learn prediction functions for  any  loss function and  any  class of features
Moreover, \searn\ comes with a strong, natural theoretical guarantee: good performance on the derived classification problems implies good performance on the structured prediction problem
### introduction ###
Prediction is the task of learning a function  SYMBOL  that maps inputs  SYMBOL  in an input domain  SYMBOL  to outputs  SYMBOL  in an output domain  SYMBOL
Standard algorithms---support vector machines, decision trees, neural networks, etc
---focus on ``simple'' output domains such as  SYMBOL  (in the case of binary classification) or  SYMBOL  (in the case of univariate regression)
We are interested in problems for which elements  SYMBOL  have complex internal structure
The simplest and best studied such output domain is that of labeled sequences
However, we are interested in even more complex domains, such as the space of English sentences (for instance in a machine translation application), the space of short documents (perhaps in an automatic document summarization application), or the space of possible assignments of elements in a database (in an information extraction/data mining application)
The structured complexity of features and loss functions in these problems significantly exceeds that of sequence labeling problems
From a high level, there are four dimensions along which structured prediction algorithms vary: structure (varieties of structure for which efficient learning is possible), loss (different loss functions for which learning is possible), features (generality of feature functions for which learning is possible) and data (ability of algorithm to cope with imperfect data sources such as missing data, etc )
An in-depth discussion of alternative structured prediction algorithms is given in Section~
However, to give a flavor, the popular conditional random field algorithm  CITATION  is viewed along these dimensions as follows
Structure: inference for a CRF is tractable for any graphical model with bounded tree width; Loss: the CRF typically optimizes a log-loss approximation to 0/1 loss over the entire structure; Features: any feature of the input is possible but only output features that obey the graphical model structure are allowed; Data: EM can cope with hidden variables
We prefer a structured prediction algorithm that is not limited to models with bounded treewidth, is applicable to any loss function, can handle arbitrary features and can cope with imperfect data
Somewhat surprisingly, \searn\ meets nearly all of these requirements by transforming structured prediction problems into binary prediction problems to which a vanilla binary classifier can be applied \searn\ comes with a strong theoretical guarantee: good binary classification performance implies good structured prediction performance
Simple applications of \searn\ to standard structured prediction problems yield tractable state-of-the-art performance
Moreover, we can apply \searn\ to more complex, non-standard structured prediction problems and achieve excellent empirical performance
This paper has the following outline:   Introduction
Core Definitions
The \searn\ Algorithm
Theoretical Analysis
A Comparison to Alternative Techniques
Experimental results
Discussion
### abstract ###
%   <- trailing '%' for backward compatibility of
sty file We develop a Bayesian framework for tackling the supervised clustering problem, the generic problem encountered in tasks such as reference matching, coreference resolution, identity uncertainty and record linkage
Our clustering model is based on the Dirichlet process prior, which enables us to define distributions over the countably infinite sets that naturally arise in this problem
We add  supervision  to our model by positing the existence of a set of unobserved random variables (we call these ``reference types'') that are generic across all clusters
Inference in our framework, which requires integrating over infinitely many parameters, is solved using Markov chain Monte Carlo techniques
We present algorithms for both conjugate and non-conjugate priors
We present a simple---but general---parameterization of our model based on a Gaussian assumption
We evaluate this model on one artificial task and three real-world tasks, comparing it against both unsupervised and state-of-the-art supervised algorithms
Our results show that our model is able to outperform other models across a variety of tasks and performance metrics
### introduction ###
Supervised clustering is the general characterization of a problem that occurs frequently in strikingly different communities
Like standard clustering, the problem involves breaking a finite set  SYMBOL  into a  SYMBOL -way partition  SYMBOL  (with  SYMBOL  unknown)
The distinction between supervised clustering and standard clustering is that in the supervised form we are given training examples
These training examples enable a learning algorithm to determine what aspects of  SYMBOL  are relevant to creating an appropriate clustering
The  SYMBOL  training examples  SYMBOL  are subsets of  SYMBOL  paired with their correct partitioning
In the end, the supervised clustering task is a prediction problem: a new  SYMBOL  is presented and a system must produce a partition of it
The supervised clustering problem goes under many names, depending on the goals of the interested community
In the relational learning community, it is typically referred to as  identity uncertainty  and the primary task is to augment a reasoning system so that it does not implicitly (or even explicitly) assume that there is a one-to-one correspondence between elements in an knowledge base and entities in the real world  CITATION
In the database community, the task arises in the context of merging databases with overlapping fields, and is known as  record linkage   CITATION
In information extraction, particularly in the context of extracting citations from scholarly publications, the task is to identify which citations are to the same publication
Here, the task is known as  reference matching   CITATION
In natural language processing, the problem arises in the context of  coreference resolution , wherein one wishes to identify which entities mentioned in a document are the same person (or organization) in real life  CITATION
In the machine learning community, it has additionally been referred to as  learning under equivalence constraints   CITATION  and  learning from cluster examples   CITATION
In this paper, we propose a generative model for solving the supervised clustering problem
Our model takes advantage of the  Dirichlet process prior , which is a non-parametric Bayesian prior over discrete distributions
This prior plays two crucial roles: first, it allows us to estimate the number of clusters  SYMBOL  in a principled manner; second, it allows us to control the complexity of the solutions that are learned
We present inference methods for our model based on Markov chain Monte Carlo methods
We compare our model against other methods on large, real-world data sets, where we show that it is able to outperform most other systems according to several metrics of performance
The remainder of this paper is structured as follows
In Section~, we describe prior efforts to tackle the supervised clustering problem
In Section~, we develop our framework for this problem, starting from very basic assumptions about the task
We follow this discussion with a general scheme for inference in this framework (Section~)
Next, in Section~, we present three generic parameterizations of our framework and describe the appropriate adaptation of the inference scheme to these parameterizations
We then discuss performance metrics for the supervised clustering problem in Section~ and present experimental results of our models' performance on artificial and real-world problems in Section~
We conclude in Section~ with a discussion of the advantages and disadvantages of our model, our generic parameterization, and our learning techniques
### abstract ###
%   <- trailing '%' for backward compatibility of
sty file   In recent years analysis of complexity of learning Gaussian mixture models from sampled data has received significant attention in computational machine learning and theory communities
In this paper we present the first result showing that polynomial time learning of multidimensional Gaussian Mixture distributions is possible when the separation between the component means is arbitrarily small
Specifically, we present an algorithm for learning the parameters of a mixture of  SYMBOL  identical spherical Gaussians in  SYMBOL -dimensional space with an arbitrarily small separation between the components, which is polynomial in dimension, inverse component separation and other input parameters for a  fixed  number of components  SYMBOL
The algorithm uses a projection to  SYMBOL  dimensions and then a reduction to the  SYMBOL -dimensional case
It relies on a theoretical analysis showing that two  SYMBOL -dimensional mixtures whose densities are close in  the  SYMBOL  norm must have similar means and mixing coefficients
To produce the necessary lower bound  for the  SYMBOL  norm in terms of the distances between the corresponding means, we analyze the behavior of the Fourier transform of a mixture of Gaussians  in one dimension around the origin, which turns out to be closely related to the properties of the Vandermonde matrix obtained from the component means
Analysis of  minors of the Vandermonde matrix  together with basic function approximation results allows us to provide a  lower bound for the norm  of the mixture in the  Fourier domain and hence a bound in the original space
Additionally, we present a separate argument for reconstructing variance
### introduction ###
Mixture models, particularly Gaussian mixture models, are a widely used tool for many problems of statistical inference  CITATION
The basic problem  is to estimate the parameters of a mixture distribution, such as the mixing coefficients, means and variances within some pre-specified precision from a number of sampled data points
While the history of Gaussian mixture models goes back to~ CITATION , in recent years the theoretical aspects  of mixture learning have attracted considerable attention  in the theoretical computer science, starting with the pioneering work of~ CITATION , who showed that a mixture of  SYMBOL  spherical Gaussians in  SYMBOL  dimensions can be learned in time polynomial in  SYMBOL , provided certain separation conditions between the component means (separation of order  SYMBOL ) are satisfied
This work has been refined and extended in a number of recent papers
The first result from~ CITATION  was later improved to the order of  SYMBOL  in~ CITATION  for spherical Gaussians and in~ CITATION  for general Gaussians
The separation requirement was further reduced and made independent of  SYMBOL  to the order of  SYMBOL  in  CITATION  for spherical Gaussians and to the order of  SYMBOL  in~ CITATION  for Logconcave distributions
In a related work~ CITATION  the separation requirement was reduced to  SYMBOL
An extension of PCA called isotropic PCA  was introduced in  CITATION   to learn mixtures of Gaussians when any pair of Gaussian components is separated by a hyperplane having very small overlap along the hyperplane direction (so-called "pancake layering problem")
In a slightly different direction the recent work~ CITATION  made an important contribution to the subject by providing a polynomial time algorithm  for PAC-style learning of mixture of Gaussian distributions with arbitrary separation between the means
The authors used a grid search over the space of parameters to a construct a hypothesis mixture of Gaussians that has density close to the actual mixture generating the data
We note that the problem analyzed in~ CITATION  can be viewed as density estimation within a certain family of distributions and is different from most other work on the subject, including our paper, which address parameter learning
We also note several recent papers dealing with the related problems of learning mixture of product distributions and heavy tailed distributions
See for example,  CITATION
In the statistics literature,  CITATION  showed that optimal convergence rate of MLE estimator for finite mixture of normal distributions is  SYMBOL , where  SYMBOL  is the sample size, if number of mixing components  SYMBOL  is known in advance and is  SYMBOL  when the number of mixing components is known up to an upper bound
However, this result does not address the computational aspects, especially in high dimension
In this paper we develop a polynomial time (for a fixed  SYMBOL ) algorithm to identify the parameters of the  mixture of  SYMBOL  identical spherical Gaussians with potentially unknown variance for an arbitrarily small separation  between the components
To the best of our knowledge this is the first result of this  kind except for the simultaneous and independent work~ CITATION ,  which analyzes the case of a mixture of  two Gaussians with arbitrary covariance matrices using the method of moments
We note that the results in~ CITATION   and in our paper are somewhat orthogonal
Each paper deals with a special case of the  ultimate goal (two arbitrary Gaussians in~ CITATION   and  SYMBOL  identical spherical Gaussians with unknown variance in our case), which is to show polynomial learnability for  a mixture with an arbitrary number of components and arbitrary variance
All other existing algorithms for parameter estimation require minimum separation between the components to be   an increasing function of at least one of  SYMBOL  or  SYMBOL
Our result also implies a density estimate bound along the lines of~ CITATION
We note, however, that we do have to pay  a price as our procedure (similarly to that in~ CITATION ) is super-exponential in  SYMBOL
Despite these limitations we believe that our paper makes a step towards understanding the fundamental problem of polynomial learnability of Gaussian mixture distributions
We also think that the technique used  in the paper to obtain the lower bound may be of independent interest
The main algorithm in our paper involves a grid search over a certain space of parameters, specifically means and mixing coefficients of the mixture (a completely separate argument is given to estimate the variance)
By giving appropriate lower and upper bounds for the norm of the difference of two mixture distributions in terms of their means, we show that such a grid search is guaranteed to find a mixture with nearly correct values of the parameters
To prove that, we need to provide a lower and upper bounds on the norm of the mixture
A key point of our paper is the lower bound showing that two mixtures with different means cannot produce similar density functions
This bound is obtained by  reducing the problem to a 1-dimensional mixture distribution and  analyzing the behavior of the Fourier transform (closely related to the characteristic function, whose coefficients are moments of a random variable up to multiplication by a power of the imaginary unit  SYMBOL ) of the difference between densities near zero
We use certain properties of minors of Vandermonde matrices to show that the norm of the mixture in the Fourier domain is bounded from below
Since the  SYMBOL  norm is invariant under the Fourier transform this provides a lower bound on the norm of the mixture in the original space
We also note the work~ CITATION , where Vandermonde matrices appear in the analysis of mixture distributions in the context of proving consistency of the method of moments (in fact, we rely on a result from~ CITATION  to  provide an estimate for the variance)
Finally, our lower bound, together with an upper bound and some results from the non-parametric density estimation and spectral projections of mixture distributions allows us to set up a grid search algorithm over the space of parameters with the desired guarantees
### abstract ###
In this paper we introduce the class of stationary prediction strategies and construct a prediction algorithm that asymptotically performs as well as the best continuous stationary strategy
We make mild compactness assumptions but no stochastic assumptions about the environment
In particular, no assumption of stationarity is made about the environment, and the stationarity of the considered strategies only means that they do not depend explicitly on time; we argue that it is natural to consider only stationary strategies even for highly non-stationary environments
### introduction ###
This paper belongs to the area of learning theory that has been variously referred to as prediction with expert advice, competitive on-line prediction, prediction of individual sequences, and universal on-line learning; see  CITATION  for a review
There are many proof techniques known in this field; this paper is based on Kalnishkan and Vyugin's Weak Aggregating Algorithm  CITATION , but it is possible that some of the numerous other techniques could be used instead
In Section  we give the main definitions and state our main results, Theorems --; their proofs are given in Sections --
In Section  we informally discuss the notion of stationarity, and Section  concludes
### abstract ###
Dirichlet process (DP) mixture models provide a flexible Bayesian framework for density estimation
Unfortunately, their flexibility comes at a cost: inference in DP mixture models is computationally expensive, even when conjugate distributions are used
In the common case when one seeks only a maximum a posteriori assignment of data points to clusters, we show that search algorithms provide a practical alternative to expensive MCMC and variational techniques
When a true posterior sample is desired, the solution found by search can serve as a good initializer for MCMC
Experimental results show that using these techniques is it possible to apply DP mixture models to very large data sets
### introduction ###
Dirichlet process (DP) mixture models provide a flexible Bayesian solution to nonparametric density estimation
Their flexibility derives from the fact that one need not specify a number of mixture components a priori
In practice, DP mixture models have been used for problems in genomics  CITATION , relational learning  CITATION , data mining  CITATION  and vision  CITATION
Despite these successes, the flexibility of DP mixture models comes at a high computational cost
Standard algorithms based on MCMC, such as those described by \namecite{neal98dpmm}, are computationally expensive and can take a long time to converge to the stationary distribution
Variational techniques  CITATION  are an attractive alternative, but are difficult to implement and can remain slow
In this paper, we show that standard search algorithms, such as A*, and beam search, provide an attractive alternative to these expensive techniques
Our algorithms allows one to apply DP mixture models to very large data sets
Like variational approaches to DP mixture models, we focus on conjugate distributions from the exponential family
Unlike MCMC techniques, which can produce samples of cluster assignments from the corresponding posterior, our search-based techniques will only find an approximate MAP cluster assignment
We do not believe this to be a strong limitation: in practice, the applications cited above all use MCMC techniques to draw a sample and then simply choose from this sample the single assignment with the highest posterior probability
If one needs samples from the posterior, then the solution found by our methods could initialize MCMC
### abstract ###
We present \bayesum\ (for ``Bayesian summarization''), a model for sentence extraction in query-focused summarization \bayesum\ leverages the common case in which multiple documents are relevant to a single query
Using these documents as reinforcement for query terms, \bayesum\ is not afflicted by the paucity of information in short queries
We show that approximate inference in \bayesum\ is possible on large data sets and results in a state-of-the-art summarization system
Furthermore, we show how \bayesum\ can be understood as a justified query expansion technique in the language modeling for IR framework
### introduction ###
We describe \bayesum, an algorithm for performing query-focused summarization in the common case that there are many relevant documents for a given query
Given a query and a collection of relevant documents, our algorithm functions by asking itself the following question: what is it about these relevant documents that differentiates them from the  non- relevant documents \bayesum\ can be seen as providing a statistical formulation of this exact question
The key requirement of \bayesum\ is that multiple relevant documents are known for the query in question
This is not a severe limitation
In two well-studied problems, it is the de-facto standard
In standard multidocument summarization (with or without a query), we have access to known relevant documents for some user need
Similarly, in the case of a web-search application, an underlying IR engine will retrieve multiple (presumably) relevant documents for a given query
For both of these tasks, \bayesum\ performs well, even when the underlying retrieval model is noisy
The idea of leveraging known relevant documents is known as query expansion in the information retrieval community, where it has been shown to be successful in ad hoc retrieval tasks
Viewed from the perspective of IR, our work can be interpreted in two ways
First, it can be seen as an  application  of query expansion to the summarization task (or, in IR terminology, passage retrieval); see  CITATION
Second, and more importantly, it can be seen as a method for query expansion in a non-ad-hoc manner
That is, \bayesum\ is a statistically justified query expansion method in the language modeling for IR framework  CITATION
### abstract ###
We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough ``target'' data to do slightly better than just using only ``source'' data
Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl ) and outperforms state-of-the-art approaches on a range of datasets
Moreover, it is trivially extended to a multi-domain adaptation problem, where one has data from a variety of different domains
### introduction ###
The task of domain adaptation is to develop learning algorithms that can be easily ported from one domain to another---say, from newswire to biomedical documents
This problem is particularly interesting in NLP because we are often in the situation that we have a large collection of labeled data in one ``source'' domain (say, newswire) but truly desire a model that performs well in a second ``target'' domain
The approach we present in this paper is based on the idea of transforming the domain adaptation learning problem into a standard supervised learning problem to which any standard algorithm may be applied (eg , maxent, SVMs, etc )
Our transformation is incredibly simple: we augment the feature space of both the source and target data and use the result as input to a standard learning algorithm
There are roughly two varieties of the domain adaptation problem that have been addressed in the literature: the fully supervised case and the semi-supervised case
The fully supervised case models the following scenario
We have access to a large, annotated corpus of data from a source domain
In addition, we spend a little money to annotate a small corpus in the target domain
We want to leverage both annotated datasets to obtain a model that performs well on the target domain
The semi-supervised case is similar, but instead of having a small annotated target corpus, we have a large but  unannotated  target corpus
In this paper, we focus exclusively on the fully supervised case
One particularly nice property of our approach is that it is incredibly easy to implement: the Appendix provides a  SYMBOL  line,  SYMBOL  character Perl script for performing the complete transformation (available at \url{http://hal3
name/easyadapt
pl
gz})
In addition to this simplicity, our algorithm performs as well as (or, in some cases, better than) current state of the art techniques
### abstract ###
We consider a class of fully stochastic and fully distributed algorithms, that we prove to learn equilibria in games
Indeed, we consider a family of stochastic distributed dynamics that we prove to converge weakly (in the sense of weak convergence for probabilistic processes) towards their mean-field limit, i
e an ordinary differential equation (ODE) in the general case
We focus then on a class of stochastic dynamics where this ODE turns out to be related to multipopulation replicator dynamics
% , well-known and studied in evolutionary game theory
Using facts known about convergence of this ODE, we discuss the convergence of the initial stochastic dynamics: For general games, there might be non-convergence, but when convergence of the ODE holds, considered stochastic algorithms converge towards Nash equilibria
For games admitting Lyapunov functions, that we call Lyapunov games, the stochastic dynamics converge
We prove that any ordinal potential game, and hence any potential game is a Lyapunov game, with a multiaffine Lyapunov function
For Lyapunov games with a multiaffine Lyapunov function, we prove that this Lyapunov function is a super-martingale over the stochastic dynamics
This leads a way to provide bounds on their time of convergence by martingale arguments
This applies in particular for many classes of games that have been considered in literature, including several load balancing game scenarios and congestion games
### introduction ###
Consider a scenario where agents learn from their experiments, by small adjustments
This might  be  for example about choosing their telephone companies, or about their portfolio investments
%, that we will assume to be rational
% Assume that agents are rational
We are interested in understanding when the whole market can converge towards rational situations, i e Nash equilibria in the sense of game theory
This is natural to expect dynamics of adjustments to be stochastic, and fully distributed, since we expect agents to adapt their strategies based on their local knowledge of the market, and since agents are often involved in games where a global, and hence local, deterministic description of the whole global market is not possible
% We also want to avoid dynamics that would suppose a global knowledge of the market, that is to say we   Several such dynamics of adjustments have been considered recently in the algorithmic game theory literature
Up to our knowledge, this has been done mainly for deterministic dynamics or best-response based dynamics: Computing a best response requires a global description of the market
Stochastic variations, avoiding a global description, have been considered
However, considered dynamics are somehow rather ad-hoc, in order to get efficient convergence time bounds, and still mainly best-response based
We want to consider here more general dynamics, and discuss when one may expect convergence
This could lead to consider any dynamics  which is monotone with respect to the utility of players, in relation with evolutionary game theory literature  CITATION
We propose to restrict here to dynamics that lead to dynamics related to (possibly perturbed) replicator dynamics
Somehow, as algorithmic game theory can be seen as an algorithmic version of classical game theory, our long term aim is to better understand algorithmic evolutionary game theory
Somehow, we could also say, that as best-response dynamics can be seen as strategies that visit corners of the simplex of (mixed) strategies, we are interested in a long term objective in learning methods that could be seen as interior point methods to find equilibria
Basic game theory framework
Let  SYMBOL  be the set of players
Every player  SYMBOL  has a set  SYMBOL  of  pure strategies
Let  SYMBOL  be the cardinal of  SYMBOL
A  mixed strategy   SYMBOL  corresponds to a probability distribution over pure strategies: pure strategy  SYMBOL  is chosen with probability  SYMBOL , with  SYMBOL
Let  SYMBOL  be the simplex of mixed strategies for player  SYMBOL
Any pure strategy  SYMBOL  can be considered as mixed strategy  SYMBOL , where vector  SYMBOL  denotes the unit probability vector  with  SYMBOL  component unity, hence as a corner of  SYMBOL
Let  SYMBOL  be the space of all mixed strategies
A  strategy profile   SYMBOL  specifies the (mixed or pure) strategies of all players:  SYMBOL  corresponds to the mixed strategy played by player  SYMBOL
Following classical convention, we write often write abusively  SYMBOL , where  SYMBOL  denotes the vector of the strategies played by all other players
We allow games whose payoffs may be random: we only assume that whenever the strategy profile  SYMBOL  is known, each player  SYMBOL  gets a random  cost  of expected value  SYMBOL
In particular, the expected cost for player  SYMBOL   for playing pure strategy  SYMBOL   is denoted by  SYMBOL
Some classes of games
Several classes of % (deterministic) games where players' costs are based on the shared usage of a common set of resources  SYMBOL  where each resource  SYMBOL  has an associated nondecreasing cost function denoted by  SYMBOL , have been considered in algorithmic game theory literature
In  load balancing games   CITATION , resources are called machines, and players compete for elements (i e singleton subsets) of  SYMBOL
Hence, the pure strategy space  SYMBOL  of player  SYMBOL  having a weight  SYMBOL  corresponds to  SYMBOL  or a subset of  SYMBOL , and a pure strategy  SYMBOL  for player  SYMBOL  is some element  SYMBOL
The cost for player (task)  SYMBOL   under profile of pure strategies (assignment)  SYMBOL   corresponds to  SYMBOL , where  SYMBOL  is the load of machine  SYMBOL :   SYMBOL , that is to say %  defined as  the sum of the weights of the tasks running on it
In  congestion games   CITATION , resources are called edges, and players compete for subsets of  SYMBOL
Hence, the pure strategy space  SYMBOL  of player  SYMBOL  is a subset of  SYMBOL  and a pure strategy  SYMBOL  for player  SYMBOL  is a subset of  SYMBOL
The cost of player  SYMBOL  under  profile of pure strategies  SYMBOL  corresponds to  SYMBOL  where  SYMBOL  is the number of % players  that use resource  SYMBOL  in  SYMBOL , that is to say the number of  SYMBOL  with  SYMBOL
In  weighted congestion games , weights  SYMBOL  are associated to players, and one takes instead  SYMBOL
In  task allocation games   CITATION ,  as in load balancing games, resources are called machines, and players compete for elements (i e singleton subsets) of  SYMBOL
Each resource (machine)  SYMBOL  is  assumed to have a function   SYMBOL  that takes as input a set of tasks  SYMBOL  assigned to it, and outputs a cost  SYMBOL  for each participating player  SYMBOL
The cost of player  SYMBOL  under  profile of pure strategies  SYMBOL  is then given by  SYMBOL
Functions  SYMBOL  can be considered as speed and scheduling policies, and associated costs as corresponding completion time for player (task)  SYMBOL
For example, SPT and LPT are policies that schedule the jobs without preemption respectively in order of increasing or decreasing weights (processing times)  CITATION
Clearly, load balancing games are particular task allocation games, and load balancing games are particular weighted congestion games
A load balancing game whose weights are unitary is a particular congestion game
Ordinal and potential games
All these classes of games can be related to ordinal and potential games introduced by  CITATION :  A game is an  ordinal potential game  if there exists some function  SYMBOL  from  pure  strategies to  SYMBOL  such that for all pure strategies  SYMBOL ,  SYMBOL , and  SYMBOL , one has   SYMBOL
### abstract ###
Principal component analysis (PCA) is a widely used technique for data  analysis and dimension reduction with numerous applications in science  and engineering
However, the standard PCA suffers from the fact  that the principal components (PCs) are usually linear combinations  of all the original variables, and it is thus often difficult to  interpret the PCs
To alleviate this drawback, various sparse  PCA approaches were proposed in literature  CITATION
Despite success in achieving sparsity, some important properties  enjoyed by the standard PCA are lost in these methods such as  uncorrelation of PCs and orthogonality of loading vectors
Also,  the total explained variance that they attempt to maximize  can be too optimistic
In this paper we propose a new formulation  for sparse PCA, aiming at finding sparse and nearly uncorrelated PCs  with orthogonal loading vectors while explaining as much of the total  variance as possible
We also develop a novel augmented  Lagrangian method for solving a class of nonsmooth constrained  optimization problems, which is well suited for our formulation of sparse  PCA
We show that it converges to a  feasible  point, and moreover under  some regularity assumptions, it converges to a stationary point
Additionally, we propose two nonmonotone gradient methods for solving  the augmented Lagrangian subproblems, and establish their global and  local convergence
Finally, we compare our sparse PCA approach with  several existing methods on synthetic, random, and real data, respectively
The computational results demonstrate that the sparse PCs produced by our approach  substantially outperform those by other methods in terms of total  explained variance, correlation of PCs, and orthogonality of loading vectors \vskip14pt   {Key words:} sparse PCA, augmented Lagrangian method,  nonmonotone gradient methods, nonsmooth minimization  \vskip14pt   {AMS 2000 subject classification:} 62H20, 62H25, 62H30, 90C30, 65K05
### introduction ###
Principal component analysis (PCA) is a popular tool for data  processing and dimension reduction
It has been widely used in  numerous applications in science and engineering such as biology,  chemistry, image processing, machine learning and so on
For  example, PCA has recently been applied to human face recognition,  handwritten zip code classification and gene expression data  analysis (see  CITATION )
In essence, PCA aims at finding a few linear combinations of the  original variables, called  principal components  (PCs), which  point in orthogonal directions capturing as much of the variance  of the variables as possible
It is well known that PCs can be found  via the eigenvalue decomposition of the covariance matrix  SYMBOL
However,  SYMBOL  is typically unknown in practice
Instead, the PCs  can be approximately computed via the singular value decomposition (SVD)  of the data matrix or the eigenvalue decomposition of the sample  covariance matrix
In detail, let  SYMBOL   be a  SYMBOL -dimensional random vector, and  SYMBOL  be an  SYMBOL  data  matrix, which records the  SYMBOL  observations of  SYMBOL
Without loss of  generality, assume  SYMBOL  is centered, that is, the column means of  SYMBOL   are all  SYMBOL
Then the commonly used sample covariance matrix is   SYMBOL
Suppose the eigenvalue decomposition of   SYMBOL  is   SYMBOL  Then  SYMBOL  gives the PCs, and the columns of  SYMBOL  are the   corresponding loading vectors
It is worth noting that  SYMBOL   can also be obtained by performing the SVD of  SYMBOL  (see, for  example,  CITATION )
Clearly, the columns of  SYMBOL  are orthonormal  vectors, and moreover  SYMBOL  is diagonal
We thus immediately see  that if  SYMBOL , the corresponding PCs are uncorrelated;  otherwise, they can be correlated with each other (see Section   for details)
We now describe several important  properties of the PCs obtained by the standard PCA when  SYMBOL   is well estimated by  SYMBOL  (see also  CITATION ):  [1 ] The PCs sequentially capture the maximum variance of the variables  approximately, thus encouraging minimal information loss as much as possible; [2 ] The PCs are nearly uncorrelated, so the explained variance by  different PCs has small overlap;   [3 ] The PCs point in orthogonal directions, that is, their loading  vectors are orthogonal to each other
In practice, typically the first few PCs are enough to represent the data,  thus a great dimensionality reduction is achieved
In spite of the popularity  and success of PCA due to these nice features, PCA has an obvious drawback,  that is, PCs are usually linear combinations of all  SYMBOL  variables and the  loadings are typically nonzero
This makes it often difficult to interpret  the PCs, especially when  SYMBOL  is large
Indeed, in many applications, the original  variables have concrete physical meaning
For example in biology, each  variable might represent the expression level of a gene
In these cases,  the interpretation of PCs would be facilitated if they were composed only  from a small number of the original variables, namely, each PC involved a  small number of nonzero loadings
It is thus imperative to develop sparse  PCA techniques for finding the PCs with sparse loadings while enjoying the  above three nice properties as much as possible
Sparse PCA has been an active research topic for more than a decade
The first  class of approaches are based on ad-hoc methods by post-processing the PCs  obtained from the standard PCA mentioned above
For example, Jolliffe  CITATION   applied various rotation techniques to the standard PCs for obtaining sparse loading  vectors
Cadima and Jolliffe  CITATION  proposed a simple thresholding approach  by artificially setting to zero the standard PCs' loadings with absolute values  smaller than a threshold
In recent years, optimization approaches have been  proposed for finding sparse PCs
They usually formulate sparse PCA into an optimization  problem, aiming at achieving the sparsity of loadings while maximizing the explained  variance as much as possible
For instance, Jolliffe et al \  CITATION  proposed  an interesting algorithm, called SCoTLASS, for finding sparse orthogonal loading  vectors by sequentially maximizing the approximate variance explained by each PC  under the  SYMBOL -norm penalty on loading vectors
Zou et al \  CITATION   formulated sparse PCA as a regression-type optimization problem and imposed a  combination of  SYMBOL - and  SYMBOL -norm penalties on the regression coefficients
d'Aspremont et al \  CITATION  proposed a method, called DSPCA, for  finding sparse PCs by solving a sequence of semidefinite program relaxations  of sparse PCA
Shen and Huang  CITATION  recently developed an approach  for computing sparse PCs by solving a sequence of rank-one matrix approximation  problems under several sparsity-inducing penalties
Very recently, Journ\'ee et al \   CITATION  formulated sparse PCA as nonconcave maximization problems with   SYMBOL - or  SYMBOL -norm sparsity-inducing penalties
They showed that these problems  can be reduced into maximization of a convex function on a compact set, and they  also proposed a simple but computationally efficient gradient method for finding  a stationary point of the latter problems
Additionally, greedy methods were  investigated for sparse PCA by Moghaddam et al \  CITATION  and d'Aspremont  et al \  CITATION
The PCs obtained by the above methods  CITATION  are usually sparse
However, the aforementioned  nice properties of the standard PCs are lost to some extent in these sparse PCs
Indeed, the likely correlation among the sparse PCs are not considered in these  methods
Therefore, their sparse PCs can be quite correlated with each other
Also,  the total explained variance that these methods attempt to maximize can be too  optimistic as there may be some overlap among the individual variances of  sparse PCs
Finally, the loading vectors of the sparse PCs given by these  methods lack orthogonality except SCoTLASS  CITATION
In this paper we propose a new formulation for sparse PCA by taking into  account the three nice properties of the standard PCA, that is, maximal  total explained variance, uncorrelation of PCs, and orthogonality of loading  vectors
We also explore the connection of this formulation with the standard  PCA and show that it can be viewed as a certain perturbation of the standard  PCA
We further propose a novel augmented Lagrangian method for solving a  class of nonsmooth constrained optimization problems, which is well suited  for our formulation of sparse PCA
This method differs from the classical augmented  Lagrangian method in that: i) the values of the augmented Lagrangian functions  at their approximate minimizers given by the method are bounded from above; and  ii) the magnitude of penalty parameters outgrows that of Lagrangian multipliers  (see Section  for details)
We show that this method converges to  a  feasible  point, and moreover it converges to a first-order stationary  point under some regularity assumptions
We also propose two nonmonotone gradient  methods for minimizing a class of nonsmooth functions over a closed convex set,  which can be suitably applied to the subproblems arising in our augmented  Lagrangian method
We further establish global convergence and, under a local  Lipschitzian error bounds assumption  CITATION , local linear rate of convergence  for these gradient methods
Finally, we compare the sparse PCA approach proposed  in this paper with several existing methods  CITATION  on synthetic, random, and real data, respectively
The computational  results demonstrate that the sparse PCs obtained by our approach substantially  outperform those by the other methods in terms of total explained variance,  correlation of PCs, and orthogonality of loading vectors
The rest of paper is organized as follows
In Section , we propose a new formulation for sparse PCA and  explore the connection of this formulation with the standard PCA
In Section  , we then develop a novel augmented Lagrangian method for  a class of nonsmooth constrained problems, and propose two nonmonotone gradient  methods for minimizing a class of nonsmooth functions over a closed convex set
In Section , we discuss the applicability and implementation details  of our augmented Lagrangian method for sparse PCA
The sparse PCA approach proposed  in this paper is then compared with  several existing methods on synthetic, random,  and real data in Section
Finally, we present some concluding  remarks in Section
### abstract ###
In a multi-armed bandit (MAB) problem, an online algorithm makes a sequence of choices
In each round it chooses from a time-invariant set of alternatives and receives the payoff associated with this alternative
While the case of small strategy sets is by now well-understood, a lot of recent work has focused on MAB problems with exponentially or infinitely large  strategy sets, where one needs to assume extra structure in order to make the problem tractable
In particular, recent literature considered information on similarity between arms
We consider similarity information in the setting of  contextual bandits , a natural extension of the basic MAB problem where before each round an algorithm is given the  context  -- a hint about the payoffs in this round
Contextual bandits are directly motivated by placing advertisements on webpages, one of the crucial problems in sponsored search
A particularly simple way to represent similarity information in the contextual bandit setting is via a  similarity distance  between the context-arm pairs which bounds from above the difference between the respective expected payoffs
Prior work on contextual bandits with similarity uses ``uniform" partitions of the similarity space, so that each context-arm pair is approximated by the closest pair in the partition
Algorithms based on ``uniform" partitions disregard the structure of the payoffs and the context arrivals, which is potentially wasteful
We present algorithms that are based on  adaptive  partitions, and take advantage of "benign" payoffs and context arrivals without sacrificing the worst-case performance
The central idea is to maintain a finer partition in high-payoff regions of the similarity space and in popular regions of the context space
Our results apply to several other settings, eg MAB with constrained temporal change~ CITATION  and sleeping bandits~ CITATION
### introduction ###
In a multi-armed bandit problem (henceforth, ``multi-armed bandit" will be abbreviated as MAB), an algorithm is presented with a sequence of trials
In each round, the algorithm chooses one alternative from a set of alternatives ( arms ) based on the past history, and receives the payoff associated with this alternative
The goal is to maximize the total payoff of the chosen arms
The MAB setting has been introduced in 1952 in~ CITATION  and studied intensively since then in Operations Research, Economics and Computer Science
This setting is a clean model for the exploration-exploitation trade-off, a crucial issue in sequential decision-making under uncertainty
One standard way to evaluate the performance of a bandit algorithm is  regret , defined as the difference between the expected payoff of an optimal arm and that of the algorithm
By now the MAB problem with a small finite set of arms is quite well understood, eg see~ CITATION
However, if the arms set is exponentially or infinitely large, the problem becomes intractable unless we make further assumptions about the problem instance
Essentially, a bandit algorithm needs to find a needle in a haystack; for each algorithm there are inputs on which it performs as badly as random guessing
Bandit problems with large sets of arms have been an active area of investigation in the past decade (see Section~ for a discussion of related literature)
A common theme in these works is to assume a certain  structure  on payoff functions
Assumptions of this type are natural in many applications, and often lead to efficient learning algorithms  CITATION
In particular, a line of work started in~ CITATION  assumes that some information on similarity between arms is available
In this paper we consider similarity information in the setting of  contextual bandits ~ CITATION , a natural extension of the basic MAB problem where before each round an algorithm is given the  context  -- a hint about the payoffs in this round
Contextual bandits are directly motivated by the problem of placing advertisements on webpages, one of the crucial problems in sponsored search
One can cast it as a bandit problem so that arms correspond to the possible ads, and payoffs correspond to the user clicks
Then the context consists of information about the page, and perhaps the user this page is served to
Furthermore, we assume that similarity information is available on both the context and the arms
Following the work in~ CITATION  on the (non-contextual) bandits, a particularly simple way to represent similarity information in the contextual bandit setting is via a  similarity distance  between the context-arm pairs, which gives an upper bound on the difference between the corresponding payoffs \xhdr{Our model: contextual bandits with similarity information }  The contextual bandits framework is defined as follows
Let  SYMBOL  be the  context set  and  SYMBOL  be the  arms set , and let  SYMBOL  be the set of feasible context-arms pairs
In each round  SYMBOL , the following events happen in succession:   a context  SYMBOL  is revealed to the algorithm,  the algorithm chooses an arm  SYMBOL  such that  SYMBOL ,  payoff (reward)  SYMBOL  is revealed
The sequence of context arrivals  SYMBOL  is fixed before the first round, and does not depend on the subsequent choices of the algorithm
With  stochastic payoffs , for each pair  SYMBOL  there is a distribution  SYMBOL  with expectation  SYMBOL , so that  SYMBOL  is an independent sample from  SYMBOL
With  adversarial payoffs , this distribution can change from round to round
For simplicity, we present the subsequent definitions for the stochastic setting only, whereas the adversarial setting is fleshed out later in the paper (Section~) \OMIT{Here  SYMBOL  is the  payoff function  defined as an independent random sample from some fixed distribution  SYMBOL  over functions  SYMBOL }  In general, the goal of a bandit algorithm is to maximize the total payoff  SYMBOL , where  SYMBOL  is the  time horizon
In the contextual MAB setting, we benchmark the algorithm's performance in terms of the context-specific ``best arm"
Specifically, the goal is to minimize the  contextual regret :   The context-specific best arm is a more demanding benchmark than the best arm used in the ``standard" (context-free) definition of regret
The similarity information is given to an algorithm as a metric space  SYMBOL  which we call the  similarity space , such that the following Lipschitz condition holds:  Without loss of generality,  SYMBOL
The absence of similarity information is modeled as  SYMBOL
An instructive special case is the  product similarity space   SYMBOL , where  SYMBOL  is a metric space on contexts ( context space ), and  SYMBOL  is a metric space on arms ( arms space ), and    \xhdr{Prior work: uniform partitions }  CITATION  consider contextual MAB with similarity information on contexts
They suggest an algorithm that chooses a ``uniform" partition  SYMBOL  of the context space and approximates  SYMBOL  by the closest point in  SYMBOL , call it  SYMBOL
Specifically, the algorithm creates an instance  SYMBOL  of some bandit algorithm  SYMBOL  for each point  SYMBOL , and invokes  SYMBOL  in each round  SYMBOL
The granularity of the partition is adjusted to the time horizon, the context space, and the black-box regret guarantee for  SYMBOL
Furthermore,  CITATION  provides a bandit algorithm  SYMBOL  for the adversarial MAB problem on a metric space that has a similar flavor: pick a ``uniform" partition  SYMBOL  of the arms space, and run a  SYMBOL -arm bandit algorithm such as \EXP~ CITATION  on the points in  SYMBOL
Again, the granularity of the partition is adjusted to the time horizon, the arms space, and the black-box regret guarantee for \EXP
Applying these two ideas to our setting (with the product similarity space) gives a simple algorithm which we call the
Its contextual regret, even for adversarial payoffs, is  where  SYMBOL  is the covering dimension of the context space and  SYMBOL  is that of the arms space \xhdr{Our contributions } Using ``uniform" partitions disregards the potentially benign structure of expected payoffs and context arrivals
The central topic in this paper is {\bfadaptive partitions} of the similarity space which are adjusted to frequently occurring contexts and high-paying arms, so that the algorithms can take advantage of the problem instances in which the expected payoffs or the context arrivals are ``benign" (``low-dimensional"), in a sense that we make precise later
We present two main results, one for stochastic payoffs and one for adversarial payoffs
For stochastic payoffs, we provide an algorithm called  contextual zooming  which ``zooms in" on the regions of the context space that correspond to frequently occurring contexts, and the regions of the arms space that correspond to high-paying arms
Unlike the algorithms in prior work, this algorithm considers the context space and the arms space  jointly  -- it maintains a partition of the similarity space, rather than one partition for contexts and another for arms
We develop provable guarantees that capture the ``benign-ness" of the context arrivals and the expected payoffs
In the worst case, we match the guarantee~\refeq{eq:regret-naive} for the \naiveAlg
We obtain nearly matching lower bounds using the KL-divergence techniques from~ CITATION
The lower bound is very general as it holds for every given (product) similarity space  and  for every fixed value of the upper bound
Our stochastic contextual MAB setting, and specifically the \ZoomAlg, can be fruitfully applied beyond the ad placement scenario described above and beyond MAB with similarity information per se
First, writing  SYMBOL  one can incorporate ``temporal constraints" (across time, for each arm), and combine them with ``spatial constraints" (across arms, for each time)
The analysis of contextual zooming yields concrete, meaningful bounds this scenario
In particular, we recover one of the main results in~ CITATION
Second, our setting subsumes the stochastic  sleeping bandits  problem~ CITATION , where in each round some arms are ``asleep", i e not available in this round
Here contexts correspond to subsets of arms that are ``awake"
Contextual zooming recovers and generalizes the corresponding result in~ CITATION
Third, following the publication of a preliminary version of this paper, contextual zooming has been applied to bandit learning-to-rank in~ CITATION  \OMIT{ it applies to a version of the adversarial MAB problem in which an adversary is constrained to change the expected payoffs of each arm  gradually , eg by a small amount in each round
In fact, we can combine significant constraints across time (for each arm) and across arms (for each time) }  \OMIT{For the context-free setting, our guarantees match those in~ CITATION
Our algorithm and analysis extends to a more general setting where some context-arms pairs may be unfeasible, and moreover the right-hand side of~\refeq{eq:LipschitzD} is replaced by an arbitrary metric on the feasible context-arms pairs }  \OMIT{We apply the \ZoomAlg{} to a (context-free) adversarial MAB problem in which an adversary is constrained to change the expected payoffs of each arm  gradually , eg by a small amount in each round
This setting is naturally modeled as a contextual MAB problem in which the  SYMBOL -th context arrival is simply  SYMBOL
Then  SYMBOL  corresponds to the expected payoff of arm  SYMBOL  at time  SYMBOL , and the context metric  SYMBOL  provides an upper bound on the temporal change  SYMBOL
We term it the {\bf\driftProblem}
Interestingly, this problem incorporates significant constraints both across time (for each arm) and across arms (for each time); to the best of our knowledge, such MAB models are quite rare in the literature
Notable special cases of  SYMBOL  include  SYMBOL  and 	 SYMBOL , which corresponds to, respectively, the bounded change per round and the high-probability behavior of a random walk
We derive provable guarantees for these two examples, and show that they are essentially optimal
Interestingly, the \problem{} subsumes the stochastic  sleeping bandits  problem~ CITATION , where in each round some arms are ``asleep", i e not available in this round
Each context arrival  SYMBOL  corresponds to the set of arms that are ``awake" in this round
More precisely, contexts  SYMBOL  correspond to subsets  SYMBOL  of arms, so that only the context-arm pairs  SYMBOL ,  SYMBOL  are feasible, and the context distance is  SYMBOL
Moreover, the \problem{} extends the sleeping bandits setting by incorporating similarity information on arms
The \ZoomAlg{} (and its analysis) applies, and is geared to exploit this additional similarity information
In the absence of such information the algorithms essentially reduces to the ``highest awake index" algorithm in~ CITATION  } %%%%%%%  \OMIT{ %%%%%%% The analysis of \ZoomAlg{} carries over to the \driftProblem; contextual regret becomes  dynamic regret  -- regret with respect to a benchmark which in each round plays the best arm for this round
In this setting, the quantity of interest is average dynamic regret, which is typically independent of the time horizon } %%%%%%%%%%%%%%  \OMIT{ %%%%%%%%%%% Furthermore, we consider the  Dynamic MAB problem ~ CITATION  in which the  state  (the current expected payoff) of each arm undergoes an independent Brownian motion on a  SYMBOL  interval with reflecting boundaries
We treat this problem as (essentially) a special case of the \driftProblem{} such that  SYMBOL , where  SYMBOL  is the  volatility  (speed of change) of the Brownian motion
We improve the analysis of \ZoomAlg{} to obtain guarantees that are superior to those for the algorithms in~ CITATION , and provide a nearly matching lower bound } %%%%%%%%  For the adversarial setting, we provide an algorithm which maintains an adaptive partition of the context space and thus takes advantage of ``benign" context arrivals
We develop provable guarantees that capture this ``benign-ness"
In the worst case, the contextual regret is bounded in terms of the covering dimension of the context space, matching~\refeq{eq:regret-naive}
Our algorithm is in fact a  meta-algorithm : given an adversarial bandit algorithm \bandit, we present a contextual bandit algorithm which calls \bandit{} as a subroutine
Our setup is flexible: depending on what additional constraints are known about the adversarial payoffs, one can plug in a bandit algorithm from the prior work on the corresponding version of adversarial MAB, so that the regret bound for \bandit{} plugs into the overall regret bound \OMIT{Our setup allows us to leverage prior work on other adversarial MAB formulations, such as the basic  SYMBOL -arm version~ CITATION , linear payoffs~ CITATION  and convex payoffs~ CITATION }  \xhdr{Discussion } Adaptive partitions (of the arms space) for context-free MAB with similarity information have been introduced in~ CITATION
This paper further explores the potential of the zooming technique in~ CITATION
Specifically, contextual zooming extends this technique to adaptive partitions of the entire similarity space, which necessitates a technically different algorithm and a more delicate analysis
We obtain a clean algorithm for contextual MAB with improved (and nearly optimal) bounds
Moreover, this algorithm applies to several other, seemingly unrelated problems and unifies some results from prior work
One alternative approach is to maintain a partition of the context space, and run a separate instance of the zooming algorithm from~ CITATION  on each set in this partition
Fleshing out this idea leads to the meta-algorithm that we present for adversarial payoffs (with \bandit{} being the zooming algorithm)
This meta-algorithm is parameterized (and constrained) by a specific a priori regret bound for \bandit
Unfortunately, any a priori regret bound for zooming algorithm would be a pessimistic one, which negates its main strength -- the ability to adapt to ``benign" expected payoffs \xhdr{Map of the paper } Section~ is related work, and Section~ is Preliminaries
Contextual zooming is  presented in Section~
Lower bounds are in Section~
Some applications of contextual zooming are discussed in Section~
The adversarial setting is treated in Section~
### abstract ###
% Sparse coding---that is, modelling data vectors as sparse linear combinations of basis elements---is widely used in machine learning, neuroscience, signal processing, and statistics
This paper focuses on the large-scale matrix factorization problem that consists of  learning  the basis set in order to adapt it to specific data
Variations of this problem include dictionary learning in signal processing, non-negative matrix factorization and sparse principal component analysis
In this paper, we propose to address these tasks with a new online optimization algorithm, based on stochastic approximations, which scales up gracefully to large data sets with millions of training samples, and extends naturally to various  matrix factorization formulations, making it suitable for a wide range of learning problems
A proof of convergence is presented, along with experiments with natural images and genomic data demonstrating that it leads to state-of-the-art performance in terms of speed and optimization for both small and large data sets
### introduction ###
The linear decomposition of a signal using a few atoms of a  learned  dictionary instead of a predefined one---based on wavelets  CITATION  for example---has recently led to state-of-the-art results in numerous low-level signal processing tasks such as image denoising  CITATION , texture synthesis  CITATION  and audio processing  CITATION , as well as higher-level tasks such as image classification  CITATION , showing that sparse learned models are well adapted to natural signals
Unlike decompositions based on principal component analysis and its variants, these models do not impose that the basis vectors be orthogonal, allowing more flexibility to adapt the representation to the data
In machine learning and statistics, slightly different matrix factorization problems are formulated  in order to obtain a few  interpretable  basis elements from a set of data vectors
This includes non-negative matrix factorization and its variants  CITATION , and sparse principal component analysis  CITATION
As shown in this paper, these problems have strong similarities; even though we first focus on the problem of dictionary learning, the algorithm we propose is able to address all of them
While learning the dictionary has proven to be critical to achieve (or improve upon) state-of-the-art results in signal and image processing, effectively solving the corresponding optimization problem is a significant computational challenge, particularly in the context of large-scale data sets that may include millions of training samples
Addressing this challenge and designing a generic algorithm which is  capable of efficiently handling various matrix factorization problems, is the topic of this paper
Concretely, consider a signal  SYMBOL  in  SYMBOL
We say that it admits a sparse approximation over a \mbox{ dictionary }  SYMBOL  in  SYMBOL , with  SYMBOL  columns referred to as  atoms , when one can find a linear combination of a ``few'' atoms from  SYMBOL  that is ``close'' to the signal  SYMBOL
Experiments have shown that modelling a signal with such a sparse decomposition ( sparse coding ) is very effective in many signal processing applications  CITATION
For natural images, predefined dictionaries based on various types of wavelets  CITATION  have also been used for this task
However, learning the dictionary instead of using off-the-shelf bases has been shown to dramatically improve signal reconstruction  CITATION
Although some of the learned dictionary elements may sometimes ``look like'' wavelets (or Gabor filters), they are tuned to the input images or signals, leading to much better results in practice
Most recent algorithms for dictionary learning  CITATION  are iterative  batch  procedures, accessing the whole training set at each iteration in order to minimize a cost function under some constraints, and cannot efficiently deal with very large training sets  CITATION , or dynamic training data changing over time, such as video sequences
To address these issues, we propose an  online  approach that processes the signals, one at a time, or in mini-batches
This is particularly important in the context of image and video processing  CITATION , where it is common to learn dictionaries adapted to small patches, with training data that may include several millions of these patches (roughly one per pixel and per frame)
In this setting, online techniques based on stochastic approximations are an attractive alternative to batch methods~(see, eg ,  CITATION )
For example, first-order stochastic gradient descent with projections on the constraint set  CITATION  is sometimes used for dictionary learning (see  CITATION  for instance)
We show in this paper that it is possible to go further and exploit the specific structure of sparse coding in the design of an optimization procedure tuned to this problem, with low memory consumption and lower computational cost than classical batch algorithms
As demonstrated by our experiments, it scales up gracefully to large data sets with millions of training samples, is easy to use, and is faster than competitive methods
The paper is structured as follows: Section~ presents the dictionary learning problem
The proposed method is introduced in Section , with a proof of convergence in Section~
Section~ extends our algorithm to various matrix factorization problems that generalize dictionary learning, and Section  is devoted to experimental results, demonstrating that our algorithm is suited to a wide class of learning problems
### abstract ###
We consider the task of opportunistic channel access in a primary system composed of independent Gilbert-Elliot channels where the secondary (or opportunistic) user does not dispose of a priori information regarding the statistical characteristics of the system
It is shown that this problem may be cast into the framework of model-based learning in a specific class of Partially Observed Markov Decision Processes (POMDPs) for which we introduce an algorithm aimed at striking an optimal tradeoff between the exploration (or estimation) and exploitation requirements
We provide finite horizon regret bounds for this algorithm as well as a numerical evaluation of its performance in the single channel model as well as in the case of stochastically identical channels
### introduction ###
In recent years, opportunistic spectrum access for cognitive radio has been the focus of significant research efforts  CITATION
These works propose to improve spectral efficiency by making smarter use of the large portion of the frequency bands that remains unused
In Licensed Band Cognitive Radio, the goal is to share the bands licensed to primary users with non primary users called secondary users or cognitive users
These secondary users must carefully %sense the primary users's presence and adapt their own transmission identify available spectrum resources and communicate avoiding to disturb the primary network
Opportunistic spectrum access thus has the potential for significantly increasing the spectral efficiency of wireless networks
In this paper, we focus on the opportunistic communication model previously considered by  CITATION , which consists of  SYMBOL  channels in which a single secondary user searches for idle channels temporarily unused by primary users
The  SYMBOL  channels are modeled as Gilbert-Elliot channels: at each time slot, a channel is either idle or occupied and the availability of the channel evolves in a Markovian way
Assuming that the secondary user can only sense  SYMBOL  channels simultaneously  CITATION , his main task is to choose which channel to sense at each time aiming to maximise its expected long-term transmission efficiency
Under this model, channel allocation may be interpreted as a planning task in a particular class of Partially Observed Markov Decision Process (POMDP) also called restless bandits  CITATION
In the works of  CITATION , it is assumed that the statistical information about the primary users' traffic is fully available to the secondary user
In practice however, the statistical characteristics of the traffic %(i e the transition probabilities of the availabilty of each channel)  are not fixed a priori and must be somehow estimated by the secondary user
As the secondary user selects channels to sense, we are not faced with a simple parameter estimation problem but with a task which is closer to reinforcement learning  CITATION
We consider scenarios in which the secondary user first carries out an  exploration phase  in which the statistical information regarding the model is gathered and then follows by the  exploitation phase , where the optimal sensing policy, based on the estimated parameters, is applied
The key issue is to reach the proper balance between exploration and exploitation
This issue has been considered before by  CITATION  who proposed an asymptotic rule to set the length of the exploration phase but without a precise evaluation of the performance of this approach
Lai et al  CITATION  also considered this problem in the multiple secondary users case but in a simpler model where each channel is modeled as an independent and identically distributed source
In the field of reinforcement learning, this class of problems is known as  model-based reinforcement learning  for which several approaches have been proposed recently  CITATION
However, none of these directly applies to the channel allocation model in which the state of the channels is only partially observed
Our contribution consists in proposing a strategy, termed  Tiling Algorithm , for adaptively setting the length of the exploration phase
Under this strategy, the length of the exploration phase is not fixed beforehand and the exploration phase is terminated as soon as we have accumulated enough statistical evidence to determine the optimal sensing policy
The distinctive feature of this approach is that it comes with strong performance guarantees in the form of finite-horizon regret bounds
For the sake of clarity, this strategy is described in the general abstract framework of parametric POMDPs
Remark that the channel access model corresponds to a specific example of POMDP parameterized by the transition probabilities of the availability of each channel
As the approach relies on the restrictive assumption that for each possible parameter value the solution of the planning problem be fully known, it is not applicable to POMDPs at large but is well suited to the case of the channel allocation model
We provide a detailed account of the use of the approach for two simple instances of the opportunistic channel access model, including the case of stochastically identical channels considered by  CITATION
The article is organized as follows
The channel allocation model is formally described in Section
In Section , the tiling algorithm is presented and its performance in terms of finite-horizon regret bounds are obtained
The application to opportunistic channel access is detailed in Section , both in the one channel model and in the case of stochastically identical channels
### abstract ###
We present a streaming model for large-scale classification (in the context of  SYMBOL -SVM)  by leveraging connections between learning and computational geometry
The streaming model imposes the constraint that only a single pass over the data is allowed
The  SYMBOL -SVM is known to have an equivalent formulation in terms of the minimum enclosing ball (MEB) problem, and an efficient algorithm based on the idea of  core sets  exists (CVM)  CITATION
CVM learns a  SYMBOL -approximate MEB for a set of points and yields an approximate solution to corresponding SVM instance
However CVM works in batch mode requiring multiple passes over the data
This paper presents a single-pass SVM which is based on the minimum enclosing ball of streaming data
We show that the MEB updates for the streaming case can be easily adapted to learn the SVM weight vector in a way similar to using online stochastic gradient updates
Our algorithm performs polylogarithmic computation at each example, and requires very small and constant storage
Experimental results show that, even in such restrictive settings, we can learn efficiently in just one pass and get accuracies comparable to other state-of-the-art SVM solvers (batch and online)
We also give an analysis of the algorithm, and discuss some open issues and possible extensions
### introduction ###
Learning in a streaming model poses the restriction that we are constrained both in terms of time, as well as storage
Such scenarios are quite common, for example, in cases such as analyzing network traffic data, when the data arrives in a streamed fashion at a very high rate
Streaming model also applies to cases such as disk-resident large datasets which cannot be stored in memory
Unfortunately, standard learning algorithms do not scale well for such cases
To address such scenarios, we propose applying the  stream model  of computation  CITATION  to supervised learning problems
In the stream model, we are allowed only one pass (or a small number of passes) over an ordered data set, and polylogarithmic storage and polylogarithmic computation per element
In spite of the severe limitations imposed by the streaming framework, streaming algorithms have been successfully employed in many different domains  CITATION
Many of the problems in geometry can be adapted to the streaming setting and since many learning problems have equivalent geometric formulations, streaming algorithms naturally motivate the development of efficient techniques for solving (or approximating) large-scale batch learning problems
In this paper, we study the application of the stream model to the problem of maximum-margin classification, in the context of  SYMBOL -SVMs  CITATION
Since the support vector machine is a widely used classification framework, we believe success here will encourage further research into other frameworks
SVMs are known to have a natural formulation in terms of the minimum enclosing ball problem in a high dimensional space  CITATION
This latter problem has been extensively studied in the computational geometry literature and admits natural streaming algorithms  CITATION
We adapt these algorithms to the classification setting, provide some extensions, and outline some open issues
Our experiments show that we can learn efficiently in just one pass and get competetive classification accuracies on synthetic and real datasets
### abstract ###
In probabilistic grammatical inference, a usual goal is to infer a good approximation of an unknown distribution  SYMBOL  called a  stochastic language
The estimate of  SYMBOL  stands in some class of probabilistic models such as probabilistic automata (PA)
In this paper, we focus on probabilistic models based on multiplicity automata (MA)
The stochastic languages generated by MA are called  rational stochastic languages ; they strictly include stochastic languages generated by PA; they also admit a very concise canonical representation
Despite the fact that this class is not recursively enumerable, it is efficiently identifiable in the limit by using the algorithm DEES, introduced by the authors in a previous paper
However, the identification is not proper and before the convergence of the algorithm, DEES can produce MA that do not define stochastic languages
Nevertheless,  it is possible to use these MA to define stochastic languages
We show that they belong to a broader class of rational series, that we call  pseudo-stochastic rational languages
The aim of this paper is twofold
First we provide a theoretical study of pseudo-stochastic rational languages, the languages output by DEES, showing for example that this class is decidable within polynomial time
Second, we have carried out a lot of experiments in order to compare DEES to classical inference algorithms such as ALERGIA and MDI
They show that DEES outperforms them in most cases {Keywords } pseudo-stochastic rational languages, multiplicity automata, probabilistic grammatical inference
### introduction ###
In probabilistic grammatical inference, we often consider stochastic languages which define distributions over  SYMBOL , the set of all the possible words over an alphabet  SYMBOL
In general, we consider an unknown distribution  SYMBOL   and the goal is to find a good approximation given a finite sample of words independently drawn from  SYMBOL
The class of probabilistic automata (PA) is often used for modeling such distributions
This class has the same expressiveness as Hidden Markov Models and is identifiable in the limit~ CITATION
However, there exists no efficient algorithm for identifying PA
This can be explained by the fact that there exists no canonical representation of these automata which makes it difficult to correctly identify the structure of the target
One solution is to focus on subclasses of PA such as probabilistic deterministic automata~ CITATION  but with an important lack of expressiveness
Another solution consists in considering the class of multiplicity automata (MA)
These models admit a canonical representation which offers good opportunities from a machine learning point of view
MA define functions that compute rational series with values in  SYMBOL ~ CITATION
MA are a strict generalization of PA and the stochastic languages generated by PA are special cases of rational stochastic languages
Let us denote by  SYMBOL  the class of rational stochastic languages computed by MA with parameters in  SYMBOL  where  SYMBOL
With  SYMBOL  or  SYMBOL ,  SYMBOL  is exactly the class of stochastic languages generated by PA with parameters in  SYMBOL
But, when  SYMBOL  or  SYMBOL , we obtain strictly greater classes
This provides several advantages: Elements of  SYMBOL  have a minimal normal representation, thus elements of  SYMBOL  may have significantly smaller representation in  SYMBOL ; parameters of these minimal representations are directly related to probabilities of some natural events of the form  SYMBOL , which can be efficiently estimated from stochastic samples; lastly when  SYMBOL  is a field, rational series over  SYMBOL  form a vector space and efficient linear algebra techniques can be used to deal with rational stochastic languages
However, the class  SYMBOL  presents a serious drawback: There exists no recursively enumerable subset class of MA which exactly generates it~ CITATION
As a consequence, no proper identification algorithm can exist: indeed, applying a proper identification algorithm to an enumeration of samples of  SYMBOL  would provide an enumeration of the class of rational stochastic languages over  SYMBOL
In spite of this result, there exists an efficient algorithm, DEES, which is able to identify  SYMBOL  in the limit
But before reaching the target, DEES can produce MA that do not define stochastic languages
However, it has been shown in~ CITATION  that with probability one, for any rational stochastic language  SYMBOL , if DEES is given as input a sufficiently large sample  SYMBOL  drawn according to  SYMBOL , DEES outputs a rational series such that  SYMBOL  converges absolutely to 1
Moreover,  SYMBOL  converges to 0 as the size of  SYMBOL  increases
We show that these MA belong to a broader class of rational series, that we call  pseudo-stochastic rational languages
A pseudo-stochastic rational language  SYMBOL  has the property that  SYMBOL  is defined for any word  SYMBOL  and that  SYMBOL
A stochastic language  SYMBOL  can be associated with  SYMBOL  in such a way that  SYMBOL  when the sum  SYMBOL  is absolutely convergent
As a first consequence,  SYMBOL  when  SYMBOL  is a stochastic language
As a second consequence, for any rational stochastic language  SYMBOL , if DEES is given as input increasing samples drawn according to  SYMBOL , DEES outputs pseudo-stochastic rational languages  SYMBOL  such that  SYMBOL  converges to 0 as the size of  SYMBOL  increases
The aim of this paper is twofold: To provide a theoretical study of the class of pseudo-stochastic rational languages and a series of experiments in order to compare the performance of DEES to two classical inference algorithms: ALERGIA~ CITATION  and MDI~ CITATION
We show that the class of pseudo-stochastic rational languages is decidable within polynomial time
We provide an algorithm that can be used to compute  SYMBOL  from any MA that computes  SYMBOL
We also show how it is possible to simulate  SYMBOL  using such an automaton
We show that there exist pseudo-stochastic rational languages  SYMBOL  such that  SYMBOL  is not rational
Finally, we show that it is undecidable whether two pseudo-stochastic rational languages define the same stochastic language
We have carried out a lot of experiments which show that DEES outperforms ALERGIA and MDI in most cases
These results were expected since ALERGIA and MDI have not the same theoretical expressiveness and since DEES aims at producing a minimal representation of the target in the set of MA, which can be significantly smaller than the smaller equivalent PDA (if it exists)
The paper is organized as follows
In section 2, we introduce some background about multiplicity automata, rational series and stochastic languages and present the algorithm DEES
Section 3 deals with our study of pseudo-rational stochastic languages
Our experiments are detailed in Section 4
### abstract ###
This work describes a method of approximating matrix permanents efficiently using belief propagation
We formulate a probability distribution whose partition function is exactly the permanent, then use Bethe free energy to approximate this partition function
After deriving some speedups to standard belief propagation, the resulting algorithm requires  SYMBOL  time per iteration
Finally, we demonstrate the advantages of using this approximation
### introduction ###
The permanent is a scalar quantity computed from a matrix and has been an active topic of research for well over a century
It plays a role in cryptography and statistical physics where it is fundamental to Ising and dimer models
While the determinant of an  SYMBOL  matrix can be evaluated exactly in sub-cubic time, efficient methods for computing the permanent have remained elusive
Since the permanent is  SYMBOL P-complete, efficient exact evaluations cannot be found in general
The best exact methods improve over brute force ( SYMBOL ) and include Ryser's algorithm  CITATION  which requires as many as  SYMBOL  arithmetic operations
Recently, promising fully-polynomial randomized approximate schemes (FPRAS) have emerged which provide arbitrarily close approximations
Many of these methods build on initial results by Broder  CITATION  who applied Markov chain Monte Carlo (a popular tool in machine learning and statistics) for sampling perfect matchings to approximate the permanent
Recently, significant progress has produced an FPRAS that can handle arbitrary  SYMBOL  matrices with non-negative entries  CITATION
The method uses Markov chain Monte Carlo and only requires a polynomial order of samples
However, while these methods have tight theoretical guarantees, they carry expensive constant factors, not to mention relatively high polynomial running times that discourage their usage in practical applications
In particular, we have experienced that the prominent algorithm in  CITATION  is slower than Ryser's exact algorithm for any feasible matrix size, and project that it only becomes faster around  SYMBOL
It remains to be seen if other approximate inference methods can be brought to bear on the permanent
For instance, loopy belief propagation has also recently gained prominence in the machine learning community
The method is exact for singly-connected networks such as trees
In certain special loopy graph cases, including graphs with a single loop, bipartite matching graphs  CITATION  and bipartite multi-matching graphs  CITATION , the convergence of BP has been proven
In more general loopy graphs, loopy BP still maintains some surprising empirical success
Theoretical understanding of the convergence of loopy BP has recently been improved by noting certain general conditions for its fixed points and relating them to minima of Bethe free energy
This article proposes belief propagation for computing the permanent and investigates some theoretical and experimental properties
In Section , we describe a probability distribution parameterized by a matrix similar to those described in  CITATION  for which the partition function is exactly the permanent
In Section , we discuss Bethe free energy and introduce belief propagation as a method of finding a suitable set of pseudo-marginals for the Bethe approximation
In Section , we report results from experiments
We then conclude with a brief discussion
### abstract ###
We study the problem of estimating the time delay between two signals representing delayed, irregularly sampled and noisy versions of the same underlying pattern
We propose and demonstrate an evolutionary algorithm for the (hyper)parameter estimation of a kernel-based technique in the context of an astronomical problem, namely estimating the time delay between two gravitationally lensed signals from a distant quasar
Mixed types (integer and real) are used to represent variables within the evolutionary algorithm
We test the algorithm on several artificial data sets, and also on real astronomical observations of quasar Q0957+561
By carrying out a statistical analysis of the results we present a detailed comparison of our method with the most popular methods for time delay estimation in astrophysics
Our method yields more accurate and more stable time delay estimates: for Q0957+561, we obtain 419 6 days between images A and B
Our methodology can be readily applied to current state-of-the-art optical monitoring data in astronomy, but can also be applied in other disciplines involving similar time series data
### introduction ###
The  estimation of  time delay , the delay between arrival times of two signals that originate from the same source but travel along different paths to the observer, is a real-world problem in Astronomy
A time series to be analysed could, for instance, represent the repeated measurement, over many months or years, of the flux of radiation (optical light or radio waves) from a very distant quasar, a very bright source of light usually a few billion light-years away
Some of these quasars appear as a set of multiple nearby images on the sky, due to the fact that the trajectory of light coming from the source gets bent as it passes a massive galaxy on the way (the ``lens''), and, as a result, the observer receives the light from various directions, resulting in the detection of several images  CITATION
This phenomenon is called gravitational lensing, and is a natural consequence of a prediction of the General theory of Relativity, which postulates that massive objects distort space-time and thus cause the bending of trajectories of light rays passing near them
Quasars are variable sources, and the same sequence of variations is detected at different times in the different images, according to the travel time along the various paths
The time delay between the signals depends on the  mass of the lens, and thus it is the most direct method to measure the distribution of matter in the Universe, which is often dark  CITATION
In this scenario, the underlying pattern in time of emitted flux intensities from a quasar gets delayed and corrupted by all kinds of noise processes
For example, astronomical time series are not only corrupted by observational noise, but they are also typically irregularly sampled with possibly large observational gaps (missing data)  CITATION
This is due to practical limitations of observation such as equipment availability, weather conditions, the brightness of the moon, among many other factors  CITATION
Over a hundred systems of lensed quasars are currently known, and about 10 of these have been monitored for long periods, and in some of these cases, the measurement of a time delay has been claimed
Here we focus on Q0957+561, the first multiply-imaged quasar to be discovered  CITATION
This source, which has a pair of images (here referred to as A and B), has been monitored for over twenty years, and despite numerous claims, a universally agreed value for the time delay in this system has not emerged  CITATION
In an earlier paper, we presented an analysis of repeated radio observations, along with simulated data generated according to the properties of these observations  CITATION , to show that a kernel-based approach can improve upon the currently popular methods of estimating time delays from real astronomical data
The more common form of observations, however, employs optical telescopes for monitoring known multiply-imaged sources, and these observations have inherent problems that require the modification of our previous approach
Here we present a largely modified approach that outperforms  on optical datasets our previous appraoch, as well as alternative approaches in use in astrophysics
Here we introduce a novel  evolutionary algorithm (EA) to estimate the parameters of a model-based method for time delay estimation
The EA uses, as a fitness function, the mean squared error (MSE SYMBOL ) given by cross-validation on observed data, and also performs a novel regularisation procedure based on singular value decomposition (SVD)
Our population is also represented by mixed types, integers and reals
The contribution of this paper is in several directions: i) an evolutionary algorithm has been introduced to form a novel hybridisation with our kernel method, ii) a principled automatic method has been proposed to estimate the time delay, kernel width, and SVD regularisation parameters, iii) the application of EA driven by a model based formulation to a real-world problem, and iv) we carefully study statistical significance of the results on different data
Our EA is an evolutionary optimisation technique in presence of uncertainties  CITATION   and missing data with mixed representation -- through two linked populations, each devoted to one particular data type
The parameters to optimise come from a kernel machine
We do  parameter optimisation and  model selection at the same time
This approach can be applied to other problems, not only time series from gravitational lensing
For instance, the missing data problems cover those cases where instrumental equipment fails, observations are  incorrectly recorded, sociological factors are involved, etc
Therefore, the data are unevenly sampled, which restricts the use of Fourier analysis  CITATION (\S13 8)
Problems with noisy and missing data occur in almost all sciences, where the data availability is influenced by what is easy or feasible to collect (e g , see  CITATION )
We compare the performance of our EA in several ways:    The performance of our method is assessed against that of two of the most popular methods in the astrophysical literature  CITATION , i e ,  {(a)} the Dispersion spectra method  CITATION  and {(b)} a scheme based on the structure function of the intrinsic variability of the source, here referred to as the PRH method  CITATION
Because the true time delay of observed fluxes from quasars is not known, we assess the performance of algorithms in a controlled series of experiments, where artificially generated data with known delays are used
We employ three kinds of artificial data sets: large scale data  CITATION , PRH data  CITATION  and Wiener data (as outlined in  CITATION )
To justify our EA, an analogous non-evolutionary model-based approach (K-V) is also employed in this paper
Our statistical analysis shows that the results from our EA are  more accurate and significant than state-of-the-art methods
We use our EA as well as a (1+1)-ES algorithm  CITATION  on actual astronomical observations, where the twin images were observed over several years with optical telescopes  CITATION
The remainder of this paper is organised as follows: the data under analysis is described in \S
The kernel approach is outlined in \S, and the EA is presented in
The results and our conclusions are in and respectively
Finally, our future work is presented in
### abstract ###
We develop  abc-logitboost , based on the prior work on  abc-boost  CITATION  and  robust logitboost  CITATION
Our extensive experiments on a variety of datasets demonstrate the considerable  improvement of  abc-logitboost  over  logitboost  and  abc-mart
### introduction ###
Boosting algorithms  CITATION  have become very successful in machine learning
This study revisits  logitboost  CITATION  under the framework of  adaptive base class boost (abc-boost)  in  CITATION , for multi-class classification
We denote a training dataset by  SYMBOL , where  SYMBOL  is the number of feature vectors (samples),  SYMBOL  is the  SYMBOL th feature vector, and   SYMBOL  is the  SYMBOL th class label, where  SYMBOL  in multi-class classification
Both  logitboost  CITATION  and  mart  (multiple additive regression trees) CITATION  algorithms can be viewed as generalizations to the  logistic regression model, which assumes the class probabilities  SYMBOL   to be  While traditional logistic regression assumes  SYMBOL ,  logitboost  and  mart  adopt the flexible ``additive model,''  which is a function of  SYMBOL  terms:  where   SYMBOL , the base learner, is typically a regression tree
The parameters,  SYMBOL  and  SYMBOL , are learned from the data, by maximum likelihood, which is equivalent to minimizing the  negative log-likelihood loss   where  SYMBOL  if  SYMBOL  and  SYMBOL  otherwise
For identifiability, the ``sum-to-zero'' constraint,  SYMBOL , is usually adopted  CITATION
### abstract ###
The selection of features that are relevant for a prediction or classification problem is an important problem in many domains involving high-dimensional data
Selecting features helps fighting the curse of dimensionality, improving the performances of prediction or classification methods, and interpreting the application
In a nonlinear context, the mutual information is widely used as relevance criterion for features and sets of features
Nevertheless, it suffers from at least three major limitations: mutual information estimators depend on smoothing parameters, there is no theoretically justified stopping criterion in the feature selection greedy procedure, and the estimation itself suffers from the curse of dimensionality
This chapter shows how to deal with these problems
The two first ones are addressed by using resampling techniques that provide a statistical basis to select the estimator parameters and to stop the search procedure
The third one is addressed by modifying the mutual information criterion into a measure of how features are complementary (and not only informative) for the problem at hand
### introduction ###
High-dimensional data are nowadays found in many applications areas: image and signal processing, chemometrics, biological and medical data analysis, and many others
The availability of low cost sensors and other ways to measure information, and the increased capacity and lower cost of storage equipments, facilitate the simultaneous measurement of many features, the idea being that adding features can only increase the information at disposal for further analysis
The problem is that high-dimensional data are in general more difficult to analyse
Standard data analysis tools either fail when applied to high-dimensional data, or provide meaningless results
Difficulties related to handling high-dimensional data are usually gathered under the  curse of dimensionality  terms, which gather many phenomena usually having counter-intuitive mathematical or geometrical interpretation
The curse of dimensionality already concerns simple phenomena, like colinearity
In many real-world high-dimensional problems, some features are highly correlated
But if the number of features exceeds the number of measured data, even a simple linear model will lead to an undetermined problem (more parameters to fit than equations)
Other difficulties related to the curse of dimensionality arise  in more common situations, when the dimension of the data space is high even if many data are available for fitting or learning
For example, data analysis tools which use Euclidean distances between data or representatives, or any kind of Minkowski or fractional distance (i e most tools) suffer from the fact that distances concentrate in high-dimensional spaces (distances between two random close points and between two random far ones tend to converge to the same value, in average)
Facing these difficulties, data analysis tools must address two ways to counteract them
One is to develop tools that are able to model high-dimensional data with a number of (effective) parameters which is lower than the dimension of the space
As an example, Support-Vector Machines enter into this category
The other way is to decrease in some way the dimension of the data space, without significant loss of information
The two ways are complementary, as the first one addresses the algorithms while the second preprocesses the data themselves
Two possibilities also exist to reduce the dimensionality of the data space: features (dimensions) can be selected, or combined
Feature combination means to  project  data, either linearly (Principal Component Analysis, Linear Discriminant Analysis, etc ) or nonlinearly
Selecting features, i e keeping some of the original features as such, and discarding others, is a priori less powerful than projection (it is a particular case)
However, it has a number of advantages, mainly when interpretation is sought
Indeed after selection the resulting features are among the original ones, which allows the data analyst to interact with the application provider
For example, discarding features may help avoiding to collect useless (possibly costly) features in a further measument campaign
Obtaining relevances for the original features may also help the application specialist to interpret the data analysis results, etc
Another reason to prefer selection to projection in some circumstances, is when the dimension of the data is really high, and the relations between features known or identified to be strongly nonlinear
In this case indeed linear projection tools cannot be used; and while nonlinear dimensionality reduction is nowadays widely used for data visualization, its use in quantitative data preprocessing remains limited because of the lack of commonly accepted standard method, the need for expertise to use most existing tools and the computational cost of some of the methods
This chapter deals with feature selection, based on mutual information between features
The following of this chapter is organized as follows
Section  introduces the problem of feature selection and the main ingredients of a selection procedure
Section  details the Mutual Information relevance criterion, and the difficulties related to its estimation
Section  shows how to solve these issues, in particular how to choose the smoothing parameter in the Mutual Information estimator, how to stop the greedy search procedure, and how to extend the mutual information concept by using nearest neighbor ranks when the dimension of the search space increases
### abstract ###
Median clustering extends popular neural data analysis methods such as the self-organizing map or neural gas to general data structures given by a dissimilarity matrix only
This offers flexible and robust global data inspection methods which are particularly suited for a variety of data as occurs in biomedical domains
In this chapter, we give an overview about median clustering and its properties and extensions, with a particular focus on efficient implementations adapted to large scale data analysis
### introduction ###
The tremendous growth of electronic information in biological and medical domains has turned automatic data analysis and data inspection tools towards a key technology for many application scenarios
Clustering and data visualization constitute one fundamental problem to arrange data in a way understandable by humans
In biomedical domains, prototype based methods are particularly  well suited since they represent data in terms of typical values which can be directly inspected by humans and visualized in the plane  if an additional low-dimensional neighborhood or embedding is present
Popular methodologies include K-means clustering, the self-organizing map, neural gas, affinity propagation, etc
which have successfully been applied to various problems in the biomedical domain such as gene expression analysis, inspection of mass spectrometric data, health-care, analysis of microarray  data, protein sequences, medical image analysis, etc \  CITATION
Many popular prototype-based clustering algorithms, however, have been derived for Euclidean data embedded in a real-vector space
In biomedical applications, data are diverse including temporal signals such as EEG and EKG signals,  functional data such as mass spectra, sequential data such as DNA sequences, complex graph structures such as biological networks, etc
Often, the Euclidean metric is not appropriate to compare such data, rather, a problem dependent similarity or dissimilarity measure should be used such as  alignment, correlation, graph distances, functional metrics,  or general kernels
Various extensions of prototype-based methods towards more general data structures exist such as extensions for recurrent and recursive data structures, functional versions, or kernelized formulations, see eg \  CITATION  for an overview
A very general approach relies on  a matrix which characterizes the pairwise similarities or dissimilarities of data
This way, any  distance measure or kernel (or generalization thereof which might violate symmetry, triangle inequality, or positive definiteness) can be dealt with including discrete settings which cannot be embedded in Euclidean space such as alignment of sequences  or empirical measurements of pairwise similarities without explicit underlying metric
Several approaches extend popular clustering algorithms such as K-means or the self-organizing map towards this setting by means of the relational dual formulation or kernelization of the approaches  CITATION
These methods have the drawback that they partially require specific properties of the dissimilarity matrix (such as positive definiteness), and they represent data in terms of prototypes which are given by (possibly implicit) mixtures of training points, thus they cannot easily be interpreted directly
Another general approach leverages mean field annealing techniques  CITATION  as a way to optimize a modified criterion that does not rely anymore on the use of prototypes
As for the relational and kernel approaches, the main drawback of those solutions is the reduced interpretability
An alternative is offered by a representation of classes by the median or centroid, i e \ prototype locations are restricted to the discrete set given by the training data
This way, the distance of data points from prototypes is well-defined
The resulting learning problem is connected to a  well-studied optimization problem, the K-median problem: given a set of data points and pairwise dissimilarities, find  SYMBOL  points forming centroids and an assignment of the data into k classes such that the average dissimilarities of points to their respective closest centroid is minimized
This problem is NP hard in general unless the dissimilarities have a special form (e g \ tree metrics),  and there exist constant factor approximations for specific settings (e g \ metrics)  CITATION
The popular K-medoid clustering extends the batch optimization scheme of K-means to this restricted setting of prototypes:  it in turn assigns data points to the respective closest prototypes and determines optimum prototypes for these assignments  CITATION
Unlike K-means, there does not exist a closed form of the optimum prototypes given fixed assignments such that exhaustive search is used
This results in a complexity  SYMBOL  for one epoch for K-centers clustering instead of  SYMBOL  for K-means,  SYMBOL  being the number of data points
Like K-means, K-centers clustering is highly sensitive to initialization
Various approaches optimize the cost function of K-means or K-median by different methods to avoid local optima as much as possible, such as Lagrange relaxations of the corresponding integer linear program, vertex substitution heuristics, or affinity propagation  CITATION
In the past years, simple, but powerful  extensions of neural based clustering to general dissimilarities have been proposed which can be seen as generalizations of K-centers clustering to include neighborhood cooperation, such that the topology of data is taken into account
More precisely, the median clustering has been integrated into the popular self-organizing map (SOM)  CITATION  and its applicability has been demonstrated in a large scale experiment from bioinformatics  CITATION
Later, the same idea has been integrated into neural gas (NG) clustering together with a proof of the convergence of median SOM and median NG clustering  CITATION
Like K-centers clustering, the methods require an exhaustive search to obtain optimum prototypes given fixed assignments such that the complexity of a standard implementation for one epoch is  SYMBOL  (this can be reduced to  SYMBOL  for median SOM, see Section  and  CITATION )
Unlike K-means, local optima and overfitting can widely be avoided due to the neighborhood cooperation such that fast and reliable methods result which are robust with respect to noise in the data
Apart from this numerical stability, the methods have further benefits: they are given by simple formulas and they are very easy to implement, they rely on underlying cost functions which can be extended towards the setting of partial supervision, and in many  situations a considerable speed-up of the algorithm can be obtained, as demonstrated in  CITATION , for example
In this chapter, we present an overview about neural based median clustering
We present the principle methods based on the cost functions of NG and SOM, respectively, and  discuss applications, extensions and properties
Afterwards, we discuss several possibilities to speed-up the clustering algorithms, including exact methods, as well as single pass approximations for large data sets
### abstract ###
This paper introduces a principled approach for the design of a scalable general reinforcement learning agent
Our approach is based on a direct approximation of AIXI, a Bayesian optimality notion for general reinforcement learning agents
Previously, it has been unclear whether the theory of AIXI could motivate the design of practical algorithms
We answer this hitherto open question in the affirmative, by providing the first computationally feasible approximation to the AIXI agent
To develop our approximation, we introduce a new Monte-Carlo Tree Search algorithm along with an agent-specific extension to the Context Tree Weighting algorithm
Empirically, we present a set of encouraging results on a variety of stochastic and partially observable domains
We conclude by proposing a number of directions for future research
### introduction ###
Reinforcement Learning  CITATION  is a popular and influential paradigm for agents that learn from experience
AIXI  CITATION  is a Bayesian optimality notion for reinforcement learning agents in unknown environments
This paper introduces and evaluates a practical reinforcement learning agent that is directly inspired by the AIXI theory
Consider an agent that exists within some unknown environment
The agent interacts with the environment in cycles
In each cycle, the agent executes an action and in turn receives an observation and a reward
The only information available to the agent is its history of previous interactions
The  general reinforcement learning problem  is to construct an agent that, over time, collects as much reward as possible from the (unknown) environment
The AIXI agent is a mathematical solution to the general reinforcement learning problem
To achieve generality, the environment is assumed to be an unknown but computable function; i e \ the observations and rewards received by the agent, given its past actions, can be computed by some program running on a Turing machine
The AIXI agent results from a synthesis of two ideas: sep1mm\parskip0mm  the use of a finite-horizon expectimax operation from sequential decision theory for action selection; and  an extension of Solomonoff's universal induction scheme  CITATION  for future prediction in the agent context
More formally, let  SYMBOL  denote the output of a universal Turing machine  SYMBOL  supplied with program  SYMBOL  and input  SYMBOL ,  SYMBOL  a finite lookahead horizon, and  SYMBOL  the length in bits of program  SYMBOL
The action picked by AIXI at time  SYMBOL , having executed actions  SYMBOL  and having received the sequence of observation-reward pairs  SYMBOL  from the environment, is given by:  SYMBOL } Intuitively, the agent considers the sum of the total reward over all possible futures up to  SYMBOL  steps ahead, weighs each of them by the complexity of programs consistent with the agent's past that can generate that future, and then picks the action that maximises expected future rewards
Equation () embodies in one line the major ideas of Bayes, Ockham, Epicurus, Turing, von Neumann, Bellman, Kolmogorov, and Solomonoff
The AIXI agent is rigorously shown by  CITATION  to be optimal in many different senses of the word
In particular, the AIXI agent will rapidly learn an accurate model of the environment and proceed to act optimally to achieve its goal
Accessible overviews of the AIXI agent have been given by both  CITATION  and  CITATION
A complete description of the agent can be found in  CITATION
As the AIXI agent is only asymptotically computable, it is by no means an algorithmic solution to the general reinforcement learning problem
Rather it is best understood as a Bayesian  optimality notion  for decision making in general unknown environments
As such, its role in general AI research should be viewed in, for example, the same way the minimax and empirical risk minimisation principles are viewed in decision theory and statistical machine learning research
These principles define what is optimal behaviour if computational complexity is not an issue, and can provide important theoretical guidance in the design of practical algorithms
This paper demonstrates, for the first time, how a practical agent can be built from the AIXI theory
As can be seen in Equation~(), there are two parts to AIXI
The first is the expectimax search into the future which we will call  planning
The second is the use of a Bayesian mixture over Turing machines to predict future observations and rewards based on past experience; we will call that  learning
Both parts need to be approximated for computational tractability
There are many different approaches one can try
In this paper, we opted to use a generalised version of the UCT algorithm  CITATION  for planning and a generalised version of the Context Tree Weighting algorithm  CITATION  for learning
This combination of ideas, together with the attendant theoretical and experimental results, form the main contribution of this paper
The paper is organised as follows
Section  introduces the notation and definitions we use to describe environments and accumulated agent experience, including the familiar notions of reward, policy and value functions for our setting
Section  describes a general Bayesian approach for learning a model of the environment
Section  then presents a Monte-Carlo Tree Search procedure that we will use to approximate the expectimax operation in AIXI
This is followed by a description of the Context Tree Weighting algorithm and how it can be generalised for use in the agent setting in Section
We put the two ideas together in Section  to form our AIXI approximation algorithm
Experimental results are then presented in Sections
Section  provides a discussion of related work and the limitations of our current approach
Section  highlights a number of areas for future investigation
### abstract ###
We consider the problem of high-dimensional non-linear variable selection for supervised learning
Our approach is based on performing linear selection among exponentially many  appropriately defined  positive definite kernels that characterize non-linear interactions between the original variables
To select efficiently from these many kernels, we use the natural hierarchical structure of the problem to extend the multiple kernel learning framework to kernels that can  be embedded in a directed acyclic graph; we show that it is then possible to perform kernel selection through a graph-adapted sparsity-inducing norm,  in polynomial time in the number of selected kernels
Moreover, we study the consistency of variable selection  in high-dimensional settings, showing that under certain assumptions, our regularization framework allows a number of irrelevant variables which is  exponential in the number of observations
Our simulations on synthetic datasets and datasets from the UCI repository show state-of-the-art predictive performance for non-linear regression problems
### introduction ###
High-dimensional problems represent a recent and important topic in machine learning, statistics and signal processing
In such settings, some notion of sparsity is a fruitful way of avoiding overfitting, for example through variable or feature selection
This has led to many  algorithmic and theoretical advances
In particular, regularization by sparsity-inducing norms such as the  SYMBOL -norm has  attracted a lot of interest in recent years
While early work has focused on efficient algorithms to solve the convex optimization problems, recent research has looked at the model selection properties and predictive performance of such methods, in the linear case~ CITATION  or within constrained non-linear settings such as the multiple kernel learning framework~ CITATION  or generalized additive models~ CITATION
However, most of the recent work dealt with  linear high-dimensional  variable selection, while the focus of much of the earlier work in machine learning and statistics was  on  non-linear low-dimensional  problems: indeed, in the last two decades,  kernel methods have been a prolific  theoretical and algorithmic machine learning framework
By using appropriate regularization by Hilbertian norms, representer theorems enable to consider large and potentially infinite-dimensional feature spaces while working within an implicit feature space no larger than the number of observations
This has led to numerous works on kernel design adapted to specific data types and generic kernel-based algorithms for many learning tasks  CITATION
However, while non-linearity is required in many domains such as computer vision or bioinformatics, most theoretical results related to non-parametric methods do not scale well with input dimensions
In this paper, our goal is to bridge the gap between linear and non-linear methods, by tackling  high-dimensional non-linear  problems
The task of non-linear variable section is a hard problem with few approaches that have both good theoretical and algorithmic properties, in particular in high-dimensional settings
Among classical  methods, some are implicitly or explicitly based on sparsity and model selection, such as boosting~ CITATION , multivariate additive regression splines~ CITATION ,  decision trees~ CITATION , random forests~ CITATION , Cosso~ CITATION  or Gaussian process based methods~ CITATION , while some others do not rely on sparsity, such as nearest neighbors or kernel methods~ CITATION
First attempts were made to combine non-linearity and sparsity-inducing norms by considering  generalized additive models , where the predictor function is assumed to be a sparse linear combination of non-linear functions of each variable~ CITATION
However, as shown in \mysec{universal}, higher orders of interactions are needed for universal consistency, i e , to adapt to the potential high complexity of the interactions between the relevant variables; we need to potentially allow  SYMBOL  of them for  SYMBOL  variables (for all possible subsets of the  SYMBOL  variables)
Theoretical results suggest that with appropriate assumptions,  sparse methods such as greedy methods and methods based on the  SYMBOL -norm would be able to deal correctly with  SYMBOL  features if  SYMBOL  is of the order of the number of observations  SYMBOL ~ CITATION
However, in presence of more than a few dozen variables, in order to deal with that many features, or even to simply enumerate those, a certain form of factorization or recursivity is needed
In this paper, we propose to use a hierarchical structure based on directed acyclic graphs, which is natural in our context of non-linear variable selection
We consider a positive definite kernel that can be expressed as a large sum of positive definite  basis  or  local kernels
This exactly corresponds to the situation where a large feature space is the concatenation of  smaller feature spaces, and we aim to do selection among these many kernels (or equivalently feature spaces), which may be done through  multiple kernel learning~ CITATION
One major difficulty however is that the number of these smaller kernels is usually exponential in the dimension of the input space and applying multiple kernel learning directly to this decomposition would be intractable
As shown in \mysec{decompositions}, for non-linear variable selection, we consider a sum of kernels which are indexed by the set of subsets of all considered variables, or more generally by  SYMBOL , for  SYMBOL
In order to perform selection efficiently, we make the extra assumption that these small kernels can be embedded in a  directed acyclic graph  (DAG)
Following~ CITATION , we consider in \mysec{mkl} a specific combination of  SYMBOL -norms that is adapted to the DAG, and that will restrict the authorized sparsity patterns to certain configurations; in our specific kernel-based framework, we are able to use the DAG to design an optimization algorithm which has polynomial complexity in the number of selected kernels (\mysec{optimization})
In simulations (\mysec{simulations}), we focus on   directed grids , where our framework allows to perform non-linear variable selection
We provide some experimental validation of our novel regularization framework; in particular, we compare it to the regular  SYMBOL -regularization, greedy forward selection and non-kernel-based methods, and shows that it is always competitive and often leads to better performance, both on synthetic examples, and standard regression datasets from the UCI repository
Finally, we extend in \mysec{consistency} some of the known consistency results of the Lasso and multiple kernel learning~ CITATION , and give a partial answer to the model selection capabilities of our regularization framework by giving necessary and sufficient conditions for model consistency
In particular, we show that our framework is adapted to estimating consistently only the  hull   of the relevant variables
Hence, by restricting the statistical power of our method, we gain computational efficiency
Moreover, we show that we can obtain scalings between the number of variables and the number of observations which are similar to the linear case~ CITATION : indeed, we show that our regularization framework may achieve non-linear variable selection consistency even with a number of variables  SYMBOL  which is exponential in the number of observations  SYMBOL
Since we deal with  SYMBOL  kernels, we achieve consistency with a number of kernels which is  doubly  exponential in  SYMBOL
Moreover, for general directed acyclic graphs, we show that the total number of vertices may grow unbounded as long as the maximal out-degree (number of children) in the DAG is less than exponential in the number of observations
This paper extends previous work~ CITATION , by providing more background on multiple kernel learning, detailing all proofs, providing new consistency results in high dimension, and comparing our non-linear predictors with non-kernel-based methods \paragraph{Notation } Throughout the paper we consider Hilbertian norms  SYMBOL  for elements  SYMBOL  of Hilbert spaces, where the specific Hilbert space can always be inferred from the context (unless otherwise stated)
For rectangular matrices  SYMBOL , we denote by  SYMBOL  its largest singular value
We   denote by  SYMBOL  and  SYMBOL  the largest and smallest eigenvalue of a symmetric matrix  SYMBOL
These are naturally extended to compact self-adjoint operators~ CITATION
Moreover, given a vector  SYMBOL  in the product space  SYMBOL  and a subset  SYMBOL  of  SYMBOL ,  SYMBOL  denotes the vector in  SYMBOL  of elements of  SYMBOL  indexed by  SYMBOL
Similarly, for a matrix  SYMBOL  defined with  SYMBOL  blocks adapted to  SYMBOL ,  SYMBOL   denotes the submatrix of   SYMBOL  composed of blocks of  SYMBOL  whose rows are in  SYMBOL  and columns are in  SYMBOL
Moreover,  SYMBOL  denotes the cardinal of the set  SYMBOL  and  SYMBOL  denotes the dimension of the Hilbert space  SYMBOL
We denote by  SYMBOL    the  SYMBOL -dimensional vector of ones
We denote by  SYMBOL  the positive part of a real number  SYMBOL
Besides, given matrices  SYMBOL , and a subset  SYMBOL  of  SYMBOL ,  SYMBOL  denotes the block-diagonal matrix composed of the blocks indexed by   SYMBOL
Finally, we let denote  SYMBOL  and  SYMBOL  general probability measures and expectations
### abstract ###
Given  SYMBOL  points in a  SYMBOL  dimensional Euclidean space, the Minimum Enclosing Ball (MEB) problem is to find the ball with the smallest radius which contains all  SYMBOL  points
We give a  SYMBOL  approximation algorithm for producing an enclosing ball whose radius is at most  SYMBOL  away from the optimum (where  SYMBOL  is an upper bound on the norm of the points)
This improves existing results using  coresets , which yield a  SYMBOL  greedy algorithm
Finding the Minimum Enclosing Convex Polytope (MECP) is a related problem wherein a convex polytope of a fixed shape is given and the aim is to find the smallest magnification of the polytope which encloses the given points
For this problem we present a  SYMBOL  approximation algorithm, where  SYMBOL  is the number of faces of the polytope
Our algorithms borrow heavily from convex duality and recently developed techniques in non-smooth optimization, and are in contrast with existing methods which rely on geometric arguments
In particular, we specialize the excessive gap framework of  CITATION  to obtain our results
### introduction ###
Given a set  SYMBOL  of  SYMBOL  points in  SYMBOL , the minimum enclosing ball (MEB) is the ball with the smallest radius which contains all the points in  SYMBOL
The problem of finding a MEB arises in application areas as diverse as data mining, learning, statistics, computer graphics, and computational geometry  CITATION
Therefore efficient algorithms for this problem are not only of theoretical interest, but also have wide practical applicability
Exact algorithms for finding the MEB typically have an exponential dependence on  SYMBOL   CITATION
For example, the  CITATION  algorithm runs in  SYMBOL  time which makes it inadmissible for many practical applications; in the case of linear SVMs data may have a million or more dimensions
Therefore, there has been a significant interest in finding approximation algorithms for this problem
State of the art approximation algorithms for the MEB problem extensively use the concept of coresets  CITATION
Given an  SYMBOL , an  SYMBOL -coreset  SYMBOL  has the property that if the smallest enclosing ball containing  SYMBOL  is expanded by a factor of  SYMBOL , then the resulting ball also contains  SYMBOL
Therefore, locating an  SYMBOL -coreset is equivalent to finding an  SYMBOL  approximation algorithm to the MEB problem
The approximation guarantees of such algorithms are  multiplicative
Briefly, a coreset is built incrementally in a greedy fashion  CITATION
At every iteration, the MEB of the current candidate coreset is built
If every point in  SYMBOL  lies in an  SYMBOL  ball of the current solution then the algorithm stops, otherwise the most  violated  point, that is, the point which is furthest away from the current MEB is included in the candidate coreset and the iterations continue
The best known algorithms in this family have a running time of  SYMBOL   CITATION
In contrast, we present a new algorithm which is derived by casting the problem of finding the MEB as a convex but non-smooth optimization problem
By specializing a general framework of  CITATION , our algorithm is able to achieve a running time of  SYMBOL  where  SYMBOL  is an upper bound on the norm of the points
Also, the approximation guarantees of our algorithm are  additive , that is, given a tolerance  SYMBOL  and denoting the optimal radius by  SYMBOL , our algorithm produces a function whose value lies between  SYMBOL  and  SYMBOL
Although these two types of approximation guarantees seem different, by a simple argument in section , we show that our algorithm also yields a traditional scale-invariant  SYMBOL  multiplicative approximation with  SYMBOL  effort
We extend our analysis to the closely related minimum enclosing convex polytope (MECP) problem, and present a new algorithm
As before, given a set  SYMBOL  of  SYMBOL  points in  SYMBOL , the task here is to find the smallest polytope of a given fixed shape which encloses these points
In our setting translations and magnifications are allowed but rotations are not allowed
We present a  SYMBOL  approximation algorithm, where  SYMBOL  denotes the number of faces of the polytope
We apply our algorithms to two problems of interest in machine learning namely finding the maximum margin hyperplane and computing the distance of a polytope from the origin
A coreset algorithm for the first problem was proposed by  CITATION  while the second one was studied by  CITATION
In both cases our algorithms require fewer number of iterations and yield better computational complexity bounds
Our paper is structured as follows: In Section  we introduce notation, briefly review some results from convex duality, and present the general framework of  CITATION
In Section  we address the MEB problem and in Section  the MECP problem, and present our algorithms and their analysis
We discuss some applications of our results to machine learning problems in Section
The paper then concludes with a discussion and outlook for the future in Section
Technical proofs can be found in Appendix  and , while preliminary experimental evaluation can be found in Appendix~
### abstract ###
Conditional Random Fields (CRFs) constitute a popular and efficient approach for supervised sequence labelling
CRFs can cope with large description spaces and can integrate some form of structural dependency between labels
In this contribution, we address the issue of efficient feature selection for CRFs based on imposing sparsity through an  SYMBOL  penalty
We first show how sparsity of the parameter set can be exploited to significantly speed up training and labelling
We then introduce coordinate descent parameter update schemes for CRFs with  SYMBOL  regularization
We finally provide some empirical comparisons of the proposed approach with state-of-the-art CRF training strategies
In particular, it is shown that the proposed approach is able to take profit of the sparsity to speed up processing and handle larger dimensional models
### introduction ###
Conditional Random Fields (CRFs), originally introduced in  CITATION , constitute a popular and effective approach for supervised structure learning tasks involving the mapping between complex objects such as strings and trees
An important property of CRFs is their ability to cope with large and redundant feature sets and to integrate some form of structural dependency between output labels
Directly modeling the conditional probability of the label sequence given the observation stream allows to explicitly integrate complex dependencies that can not directly be accounted for in generative models such as Hidden Markov Models (HMMs)
Results presented in section~ will illustrate this ability to use large sets of redundant and non-causal features
Training a CRF amounts to solving a convex optimization problem: the maximization of the penalized conditional log-likelihood function
For lack of an analytical solution however, the CRF training task requires numerical optimization and implies to  repeatedly perform inference over the entire training set during the computation of the gradient of the objective function
This is where the modeling of structure takes its toll: for general dependencies, exact inference is intractable and approximations have to be considered
In the simpler case of linear-chain CRFs, modeling the interaction between pairs of adjacent labels makes the complexity of inference grow quadratically with the size of label set: even in this restricted setting, training a CRF remains a computational burden, especially when the number of output labels is large
Introducing structure has another, less studied, impact on the number of potential features that can be considered
It is possible, in a linear-chain CRF, to introduce features that simultaneously test the values of adjacent labels and some property of the observation
In fact, these features often contain valuable information  CITATION
However, their number scales quadratically with the number of labels, yielding both a computational (feature functions have to be computed, parameter vectors have to be stored in memory) and an estimation problem
The estimation problem stems from the need to estimate large parameter vectors based on sparse training data
Penalizing the objective function with the  SYMBOL  norm of the parameter vector is an effective remedy to overfitting; yet, it does not decrease the number of feature computations that are needed
In this paper, we consider the use of an alternative penalty function, the  SYMBOL  norm, which yields much sparser parameter vectors  CITATION
As we will show, inducing a sparse vector not only reduces the number of feature functions that need to be computed, but it can also reduce the time needed to perform parameter estimation and decoding
The main shortcoming of the  SYMBOL  regularizer is that the objective function is no longer differentiable everywhere, challenging the use of gradient-based optimization algorithms
Proposals have been made to overcome this difficulty: for instance, the orthant-wise limited-memory quasi-Newton algorithm  CITATION  uses the fact that the  SYMBOL  norm remains differentiable when restricted to regions in which the sign of each coordinate is fixed (an ``orthant'')
Using this technique,  CITATION  reports test performance that are on par with those obtained with a  SYMBOL  penalty, albeit with more compact models
Our first contribution is to show that even in this situation (equivalent test performance), the   SYMBOL  regularization may be preferable as sparsity in the parameter set can be exploited to reduce the computational cost associated with parameter training and label inference
For parameter estimation, we consider an alternative optimization approach, which generalizes to CRFs the proposal of  CITATION  (see also  CITATION )
In a nutshell, optimization is performed in a coordinate-wise fashion, based on an analytic solution to the unidimensional optimization problem
In order to tackle realistic problems, we propose an efficient blocking scheme in which the coordinate-wise updates are applied simultaneously to a properly selected group (or block) of parameters
Our main methodological contributions are thus twofold: (i) a fast implementation of the training and decoding algorithms that uses the sparsity of parameter vectors and (ii) a novel optimization algorithm for using  SYMBOL  penalty with CRFs
These two ideas combined together offer the opportunity of using very large ``virtual'' feature sets for which only a very small number of features are effectively selected
As will be seen (in Section~), this situation is frequent in typical natural language processing applications, particularly when the number of possible labels is large
Finally, the proposed algorithm has been implemented as C code and validated through experiments on artificial and real-world data
In particular, we provide detailed comparisons, in terms of numerical efficiency, with solutions traditionally used for  SYMBOL  and  SYMBOL  penalized training of CRFs in publicly available software such as CRF++  CITATION ,  CRFsuite  CITATION  and crfsgd  CITATION
The rest of this paper is organized as follows
In Section , we introduce our notations and restate more precisely the issues we wish to address, based on the example of a simple natural language processing task
Section~ discusses the algorithmic gains that are achievable when working with sparse parameter vectors
We then study, in Section , the training algorithm used to achieve sparsity, which implements a coordinate-wise descent procedure
Section~ discusses our contributions with respect to related work
And finally, Section  presents our experimental results, obtained both on simulated data, a phonetization task, and a named entity recognition problem
### abstract ###
We start from a simple asymptotic result for the problem of on-line regression with the quadratic loss function: the class of continuous limited-memory prediction strategies admits a ``leading prediction strategy'', which not only asymptotically performs at least as well as any continuous limited-memory strategy but also satisfies the property that the excess loss of any continuous limited-memory strategy is determined by how closely it imitates the leading strategy
More specifically, for any class of prediction strategies constituting a reproducing kernel Hilbert space we construct a leading strategy, in the sense that the loss of any prediction strategy whose norm is not too large is determined by how closely it imitates the leading strategy
This result is extended to the loss functions given by Bregman divergences and by strictly proper scoring rules
### introduction ###
Suppose  SYMBOL  is a normed function class of prediction strategies (the ``benchmark class'')
It is well known that, under some restrictions on  SYMBOL , there exists a ``master prediction strategy'' (sometimes also called a ``universal strategy'') that performs almost as well as the best strategies in  SYMBOL  whose norm is not too large (see, eg ,  CITATION )
The ``leading prediction strategies'' constructed in this paper satisfy a stronger property: the loss of any prediction strategy in  SYMBOL  whose norm is not too large exceeds the loss of a leading strategy by the divergence between the predictions output by the two prediction strategies
Therefore, the leading strategy implicitly serves as a standard for prediction strategies  SYMBOL  in  SYMBOL  whose norm is not too large: such a prediction strategy  SYMBOL  suffers a small loss to the degree that its predictions resemble the leading strategy's predictions, and the only way to compete with the leading strategy is to imitate it \ifFULLFrom the practical point of view, master strategies are much more interesting than leading strategies, although the existence of leading strategies is a very curious fact \blueend We start the formal exposition with a simple asymptotic result (Proposition  in \S) asserting the existence of leading strategies in the problem of on-line regression with the quadratic loss function for the class of continuous limited-memory prediction strategies
To state a non-asymptotic version of this result (Proposition ) we introduce several general definitions that are used throughout the paper
In the following two sections Proposition  is generalized in two directions, to the loss functions given by Bregman divergences (\S) and by strictly proper scoring rules (\S)
Competitive on-line prediction typically avoids making any stochastic assumptions about the way the observations are generated, but in we consider, mostly for comparison purposes, the case where observations are generated stochastically
That section contains most of the references to the related literature, although there are bibliographical remarks scattered throughout the paper
Some proofs and proof sketches are given in \S, and the rest can be found in the full version of this paper,  CITATION
The proofs are gathered in \S
The final section, \S, discusses % the general picture and  possible directions of further research
There are many techniques for constructing master strategies, such as gradient descent, strong and weak aggregating algorithms, following the perturbed leader, defensive forecasting, to mention just a few
In this paper we will use defensive forecasting (proposed in  CITATION  and based on  CITATION  and much earlier work by Levin, Foster, and Vohra)
The master strategies constructed using defensive forecasting automatically satisfy the stronger properties required of leading strategies; on the other hand, it is not clear whether leading strategies can be constructed using other techniques
### abstract ###
This paper addresses the problem of finding the nearest neighbor (or one of the R-nearest neighbors) of a query object  SYMBOL  in a database of  SYMBOL  objects
In contrast with most existing approaches, we can only access the ``hidden'' space in which the objects live through a similarity oracle
The oracle, given two reference objects and a query object, returns the reference object closest to the query object
The oracle attempts to model the behavior of human users, capable of making statements about similarity, but not of assigning meaningful numerical values to distances between objects
Using such an oracle, the best we can hope for is to obtain, for every object  SYMBOL  in the database, a sorted list of the other objects according to their distance to  SYMBOL
We call the position of object  SYMBOL  in this list the  rank  of  SYMBOL  with respect to  SYMBOL
The difficulty of searching using such an oracle depends on the non-homogeneities of the underlying space
We use two different characterizations of the underlying space to capture this property
The first one,  rank distortion , relates pairwise ranks to the average difference in ranks w r t
other objects (a more precise definition is given in Section )
The second one, the combinatorial framework (a notion from  CITATION ), defines approximate triangle inequalities on ranks (a more precise definition is given in Section )
Roughly speaking, it defines a multiplicative factor  SYMBOL  by which the triangle inequality on ranks can be violated
Utilizing the insights from these ideas, we develop a hierarchical search algorithm that builds a data structure, which allows us to retrieve the nearest neighbor with high probability in  SYMBOL  questions
The learning requires asking  SYMBOL  questions in total and we need to store  SYMBOL  bits in total
We also provide an approximate nearest neighbor search algorithm
Finally, we show a lower bound of  SYMBOL  average number of questions in the search phase for randomized algorithms when the answers to all possible questions in the learning phase are given
We also introduce  rank-sensitive  hash functions which gives same hash value for ``similar'' objects based on the rank-value of the objects obtained from the similarity oracle
As one application of RSH, we demonstrate that, we can retrieve one of the  SYMBOL -nearest neighbor of a query point in  SYMBOL  evaluations of the hash function, where  SYMBOL  only depends on  SYMBOL  and the rank distortion
### introduction ###
Consider the situation where we want to search and navigate a database, but we do not know the underlying relationships between the objects
In particular, distances may be difficult to discern, or may not be well-defined
Such situations are common with  objects where human perception may be involved
A collection of pictures of faces, taken from different angles and distances is an illustration of such a dataset
Indeed, the distances between feature vectors might be far from the similarity perceived by humans
Notwithstanding, either with human-assistance or approximate classification, we may be able to determine the relative proximity of an object with respect to a small number of other objects
Humans have the ability to compare objects and make statements about which are the most similar ones, though they can probably not assign a meaningful numerical value to similarity
This led to the question of how to design search algorithms based on binary similarity decisions of the type ``A looks more like B than C''
More formally, we aim to design an algorithm that given a query object ( eg ,  a face), efficiently returns an object that is similar to that object among the objects in a database
To do so, we have access to a similarity oracle which, given two reference objects and a query object, can tell which of the two reference objects is most similar to the query object
We measure the performance of all our algorithms in terms of the number of questions that we need to ask the oracle
We can pre-process the database during a learning phase, and use the resulting answers to facilitate the search process
We do  not  make the assumption that the ``hidden'' space in which the database objects live needs to be a metric space
Using this oracle one can retrieve for every object  SYMBOL  in the database, a sorted list of the other objects according to their distance to  SYMBOL
We call the position of object  SYMBOL  in this list the  rank  of  SYMBOL  with respect to  SYMBOL , and denote it by  SYMBOL
Clearly, this relationship can be asymmetric  i e ,    SYMBOL  in general
This setup raises several new questions and issues, as any space can be described by its ranks relationships
How much does the fact that the rank of some object  SYMBOL  w r t
some other object  SYMBOL  is  SYMBOL , and the rank of  SYMBOL  w r t
SYMBOL  is  SYMBOL  tell us about the rank of  SYMBOL  w r t
SYMBOL
In this paper, we introduce the notion of  rank distortion  (see Section  for a rigorous definition)
The rank distortion captures how closely  SYMBOL  is related to the average  SYMBOL
The framework introduced in  CITATION , defines approximate triangle inequalities on the ranks, another way to capture these relationships
Those inequalities roughly tell us how ``transitive'' the similarity relationship is and give us a notion of  combinatorial disorder
If we have this information, we can use partial rank information to estimate, or infer the other ranks
In this paper, we will first investigate the case where we can use such a characterization of the hidden space as an input to our algorithms
We develop a randomized hierarchical scheme that improves the existing bounds for nearest neighbor search based on a similarity oracle (see Section )
We also prove, as far as we know, the first lower bound on the average number of questions to be asked for randomized nearest-neighbor search in this setup (see Section )
Then, in Section , we ask what can be done if no characterization of the hidden space is known and therefore cannot be used as an input to the algorithms
In that case, we cannot estimate, or limit, ranks anymore if we have partial rank information
Nevertheless, we develop algorithms that can decompose the space such that dissimilar objects are likely to get separated, and similar objects have the tendency to stay together
This generalizes the notion of randomized  SYMBOL - SYMBOL -trees ( CITATION ) to our setup
Building on this intuition, we introduce the notion of  rank-sensitive hashing  (RSH) in Section
Similarly to locality-sensitive hashing, we can retrieve one of the  SYMBOL  nearest neighbors of a query point very efficiently
The hash function itself does not require any characterization of the subjacent space as an input
However, the smallest value of  SYMBOL  we can choose depends on the rank distortion
In general, both the criteria (combinatorial disorder and rank distortion) we use to characterize the hidden space seem to capture how ``homogeneous'' that space is
It appears that the less homogeneous it is, the more difficult it becomes to search
In particular, if the rank relationship is very asymmetric, and some objects are far from every other object, the information contained about those objects in the ranks matrix is very sparse and hard to capture
We apply this idea of RSH to NN search, but we believe that this might be useful in other scenarios as well
### abstract ###
We describe the Median  SYMBOL -flats (MKF) algorithm, a simple online method for hybrid linear modeling, ie , for approximating data by a mixture of flats
This algorithm simultaneously partitions the data into clusters while finding their corresponding best approximating  SYMBOL   SYMBOL -flats, so that the cumulative  SYMBOL  error is minimized
The current implementation restricts  SYMBOL -flats to be  SYMBOL -dimensional linear subspaces
It requires a negligible amount of storage, and its complexity, when modeling data consisting of  SYMBOL  points in  SYMBOL  with  SYMBOL   SYMBOL -dimensional linear subspaces, is of order  SYMBOL , where  SYMBOL  is the number of iterations required for convergence (empirically on the order of  SYMBOL )
Since it is an online algorithm, data can be supplied to it incrementally and it can incrementally produce the corresponding output
The performance of the algorithm is carefully evaluated using synthetic and real data
### introduction ###
Many common data sets can be modeled by mixtures of flats (i e , affine subspaces)
For example, feature vectors of different moving objects in a video sequence lie on different affine subspaces (see eg ,  CITATION ), and similarly, images of different faces under different illuminating conditions are on different linear subspaces with each such subspace corresponding to a distinct face~ CITATION
Such data give rise to the problem of hybrid linear modeling, i e , modeling data by a mixture of flats
Different kinds of algorithms have been suggested for this problem utilizing different mathematical theories
For example, Generalized Principal Component Analysis (GPCA)~ CITATION  is based on algebraic geometry, Agglomerative Lossy Compression (ALC)~ CITATION  uses information theory, and Spectral Curvature Clustering (SCC)~ CITATION  uses multi-way clustering methods as well as multiscale geometric analysis
On the other hand, there are also some heuristic approaches, eg , Subspace Separation~ CITATION  and Local Subspace Affinity (LSA)~ CITATION
Probably, the most straightforward method of all is the  SYMBOL -flats (KF) algorithm or any of its variants~ CITATION
The  SYMBOL -flats algorithm aims to partition a given data set  SYMBOL  into  SYMBOL  subsets  SYMBOL , each of which is well approximated by its best fit  SYMBOL -flat
More formally, given parameters  SYMBOL  and  SYMBOL , the algorithm tries to minimize the objective function  \sum_{i=1}^K \min_{d-\text{flats } L_i} \sum_{\bx_j \cX_i} \dist^2(\bx_j,L_i)\,
In practice, the minimization of this function is performed iteratively as in the  SYMBOL -means algorithm~ CITATION
That is, after an initialization of  SYMBOL   SYMBOL -flats (for example, they may be chosen randomly), one repeats the following two steps until convergence: 1) Assign clusters according to minimal distances to the flats determined at the previous stage 2) Compute least squares  SYMBOL -flats for these newly obtained clusters by Principal Component Analysis (PCA)
This procedure is very fast and is guaranteed to converge to at least a local minimum
However, in practice, the local minimum it converges to is often significantly worse than the global minimum
As a result, the  SYMBOL -flats algorithm is not as accurate as more recent hybrid linear modeling algorithms, and even in the case of underlying linear subspaces (as opposed to general affine subspaces) it often fails when either  SYMBOL  is sufficiently large (e g ,  SYMBOL ) or there is a large component of outliers
This paper has two goals
The first one is to show that in order to significantly improve the robustness to outliers and noise of the  SYMBOL -flats algorithm, it is sufficient to replace its objective function (Eq ~\eqref{eq:objective_kflats}) with  \sum_{i=1}^K \min_{d-\text{flats } L_i} \sum_{\bx_j \cX_i} \dist(\bx_j,L_i)\,, that is, replacing the  SYMBOL  average with an  SYMBOL  average
The second goal is to establish an online algorithm for this purpose, so that data can be supplied to it incrementally, one point at a time, and it can incrementally produce the corresponding output
We believe that an online procedure, which has to be very different than  SYMBOL -flats, can also be beneficial for standard settings of moderate-size data which is not streaming
Indeed, it is possible that such a strategy will converge more often to the global minimum of the  SYMBOL  error than the straightforward  SYMBOL  generalization of  SYMBOL -flats (assuming an accurate algorithm for computing best  SYMBOL  flats)
In order to address those goals we propose the Median  SYMBOL -flats (MKF) algorithm
We chose this name since in the special case where  SYMBOL  the well-known  SYMBOL -medians algorithm (see eg ,  CITATION ) approximates the minimum of the same energy function
The MKF algorithm employs a stochastic gradient descent strategy~ CITATION  in order to provide an online approximation for the best  SYMBOL   SYMBOL -flats
Its current implementation only applies to the setting of underlying linear subspaces (and not general affine ones)
Numerical experiments with synthetic and real data indicate superior performance of the MKF algorithm in various instances
In particular, it outperforms some standard algorithms in the cases of large outlier component or relatively large intrinsic dimension of flats
Even on the Hopkins 155 Database for motion segmentation~ CITATION , which requires small intrinsic dimensions, has little noise, and few outliers, the MKF performs very well and in particular better than  SYMBOL -flats
We speculate that this is because the iterative process of MKF converges more often to a global minimum than that of the  SYMBOL -flats
The rest of this paper is organized as follows
In Section~ we introduce the MKF algorithm
Section~ carefully tests the algorithm on both artificial data of synthetic hybrid linear models and real data of motion segmentation in video sequences
Section~ concludes with a brief discussion and mentions possibilities for future work
### abstract ###
Ensemble learning aims to improve generalization ability by using multiple base learners
It is well-known that to construct a good ensemble, the base learners should be  accurate  as well as  diverse
In this paper, unlabeled data is exploited to facilitate ensemble learning by helping augment the diversity among the base learners
Specifically, a semi-supervised ensemble method named {\udeed} is proposed
Unlike existing semi-supervised ensemble methods where error-prone  pseudo-labels  are estimated for unlabeled data to enlarge the labeled data to improve accuracy, {\udeed} works by maximizing accuracies of base learners on labeled data while maximizing diversity among them on unlabeled data
Experiments show that {\udeed} can effectively utilize unlabeled data for ensemble learning and is highly competitive to well-established semi-supervised ensemble methods
### introduction ###
In  ensemble learning   CITATION , a number of base learners are trained and then combined for prediction to achieve strong generalization ability
Numerous effective ensemble methods have been proposed, such as \textsc{Boosting}  CITATION , \textsc{Bagging}  CITATION , \textsc{Stacking}  CITATION , etc , and most of these methods work under the supervised setting where the labels of training examples are known
In many real-world tasks, however, unlabeled training examples are readily available while obtaining their labels would be fairly expensive
Semi-supervised learning   CITATION  is a major paradigm to exploit unlabeled data together with labeled training data to improve learning performance automatically, without human intervention
This paper deals with semi-supervised ensembles, that is, ensemble learning with labeled and unlabeled data
In contrast to the huge volume of literatures on ensemble learning and on semi-supervised learning, only a few work has been devoted to the study of semi-supervised ensembles
As indicated by Zhou  CITATION , this was caused by the different philosophies of the ensemble learning community and the semi-supervised learning community
The ensemble learning community believes that it is able to boost the performance of weak learners to strong learners by using multiple learners, and so there is no need to use unlabeled data; while the semi-supervised learning community believes that it is able to boost the performance of weak learners to strong learners by exploiting unlabeled data, and so there is no need to use multiple learners
However, as Zhou indicated  CITATION , there are several important reasons why ensemble learning and semi-supervised learning are actually mutually beneficial, among which an important one is that by considering unlabeled data it is possible to help augment the  diversity  among the base learners, as explained in the following paragraph
It is well-known that the generalization error of an ensemble is related to the average generalization error of the base learners and the diversity among the base learners
Generally, the lower the average generalization error (or, the higher the average accuracy) of the base learners and the higher the diversity among the base learners, the better the ensemble  CITATION
Previous ensemble methods work under supervised setting, trying to achieve a high average accuracy and a high diversity by using the labeled training set
It is noteworthy, however, pursuing a high accuracy and a high diversity may suffer from a dilemma
For example, for two classifiers which have perfect performance on the labeled training set, they would not have diversity since there is no difference between their predictions on the training examples
Thus, to increase the diversity needs to sacrifice the accuracy of one classifier
However, when we have unlabeled data, we might find that these two classifiers actually make different predictions on unlabeled data
This would be important for ensemble design
For example, given two pairs of classifiers,  SYMBOL  and  SYMBOL , if we know that all of them are with 100 SYMBOL  accuracy on labeled training data, then there will be no difference taking either the ensemble consisting of  SYMBOL  or the ensemble consisting of  SYMBOL ; however, if we find that  SYMBOL  and  SYMBOL  make the same predictions on unlabeled data, while  SYMBOL  and  SYMBOL  make different predictions on some unlabeled data, then we will know that the ensemble consisting of  SYMBOL  should be better
So, in contrast to previous ensemble methods which focus on achieving both high accuracy and high diversity using only the labeled data, the use of unlabeled data would open a promising direction for designing new ensemble methods
In this paper, we propose the {\udeed} ( Unlabeled Data to Enhance Ensemble Diversity ) approach
Experiments show that by using unlabeled data for diversity augmentation, {\udeed} achieves much better performance than its counterpart which does not consider the usefulness of unlabeled data
Moreover, {\udeed} also achieves highly comparable performance to other state-of-the-art semi-supervised ensemble methods
The rest of this paper is organized as follows
Section  briefly reviews related work on semi-supervised ensembles
Section  presents {\udeed}
Section  reports our experimental results
Finally, Section  concludes
### abstract ###
We propose a randomized algorithm for   training Support vector machines(SVMs) on large datasets
By using ideas from Random projections we show that  the combinatorial dimension of SVMs is  SYMBOL  with high probability
This estimate of combinatorial dimension is used  to derive an iterative algorithm, called RandSVM,  which at each step calls an existing solver to train SVMs on  a randomly chosen subset of size  SYMBOL
The algorithm has probabilistic guarantees and is  capable of training SVMs  with Kernels for both classification and regression problems
Experiments done on synthetic and real life data sets demonstrate that the algorithm scales up  existing SVM learners, without loss of accuracy \keywords{Support Vector Machines,  Randomized Algorithms, Random Projections} \subclass{68W20 90C25 90C06 90C90 }
### introduction ###
Consider a training data set  SYMBOL  where  SYMBOL  are data points and  SYMBOL  are labels
The problem of learning a linear classifier,  SYMBOL ,  where  SYMBOL  or a linear function  SYMBOL  when  SYMBOL  is a scalar  can be understood as estimating  SYMBOL  from  SYMBOL
Over the years Support Vector Machines(SVMs) have emerged as powerful tools for estimating such functions
In this paper we concentrate on developing  randomized algorithms for learning SVMs on large datasets
For a  detailed review of SVM classification and SVM regression please see  CITATION
To develop notation we briefly discuss the problem of training linear classifiers
The SVM formulation for linearly separable datasets is given by  CITATION    SYMBOL }  where  SYMBOL , is the euclidean norm of  SYMBOL
The formulation has very interesting geometric underpinnings  ~ CITATION
It can be understood as computing the distance between convex  hulls of the sets  SYMBOL  and  SYMBOL
For linearly non-separable datasets the following formulation \\     C-SVM-1:  \\  SYMBOL } which will be called  SYMBOL , again due to  CITATION , can be used
This  formulation do not have an elegant geometric interpretation like the separable  case,  but one can consider C-SVMs as computing the distance between two  reduced convex hulls ~ CITATION
Both the formulations are instances of  Abstract Optimization Problem(AOP) ~ CITATION
An AOP is defined as follows:  Every AOP has a  combinatorial dimension associated  with it; the combinatorial dimension captures the notion of number of free variables for that AOP
An AOP can be solved by a randomized algorithm by selecting subsets of size greater than the combinatorial dimension of the problem~ CITATION
We wish to exploit this property  of AOPs to design randomized algorithms for SVMs
The idea is to develop an iterative algorithm where in each step one needs  to solve a SVM formulation on a small subset of the training data
Crucial  to this idea is the size of the subset which is tied to the combinatorial  dimension of the SVM formulation
To this end note that at optimality  SYMBOL  is given by  SYMBOL } for both the separable and non-separable case
Using the  SYMBOL  variables one can define the set of Support vectors~(SVs),  SYMBOL } which defines  SYMBOL
The set  SYMBOL  may not be unique, though  SYMBOL  is
The combinatorial dimension of SVMs is given by the minimum number of SVs   required to define  SYMBOL
More formally  SYMBOL } where  SYMBOL  is the cardinality of the set  SYMBOL
The parameter  SYMBOL  does not change with number of examples  SYMBOL , and is often much less than  SYMBOL
Apriori the value of  SYMBOL  is not known, but for linearly separable classification problems the following holds:  SYMBOL
This follows from the observation that  it computes the distance between 2 non-overlapping convex hulls~ CITATION
When the problem is not linearly separable, the reduced convex hull interpretation leads to a very crude upper bound, which is much larger than  SYMBOL
The idea of iterating over randomly sampled subsets of size greater than   SYMBOL , for training SVMs was first explored by  ~ CITATION , and  the resulting algorithm was called RandSVM
The  RandSVM procedure iterates over subsets of size proportional to  SYMBOL  , as shown in Algorithm~
However as the authors noted that RandSVM is not practical because of the following reasons
For linear classifiers the sample size is too large in case of high dimensional data sets
For non-linear SVMs ~ CITATION   the dimension of feature space is usually unknown when using kernels
Even in this case one can obtain a very crude  upper-bound on  SYMBOL  by the reduced convex hull approach but  is not really useful as the number obtained is very large \end{algorithm}  This work overcomes the above problems using ideas from random projections~ CITATION  and randomized algorithms~ CITATION
As mentioned by the authors of RandSVM, the biggest bottleneck in their algorithm is the value of  SYMBOL  as it is too large
The main contribution of this work is, using ideas from random projections, the conjecture that if RandSVM is solved using  SYMBOL  equal to  SYMBOL , then the solution obtained is close to optimal with high probability(Theorem~, particularly for linearly separable and almost separable data sets
Almost separable data sets are those which become linearly separable when a small number of properly chosen data points are deleted from them
The second contribution is an algorithm which, using ideas from randomized algorithms for Linear Programming(LP), solves the SVM problem by using samples of size linear in  SYMBOL
This work also shows that the theory can be applied to non-linear kernels
The formulation naturally applies to regression problems
The paper is organized as follows: Section~ introduces the previous work, Section~ presents the improved algorithm for classification for almost linearly  separable data
Section~ presents the improved algorithm for the  SYMBOL tube regression formulation
We present our results  and conclusions in Section~ and ~
### abstract ###
The Minimum Description Length (MDL) principle selects the model that has the shortest code for data plus model
We show that for a countable class of models, MDL predictions are close to the true distribution in a strong sense
The result is completely general
No independence, ergodicity, stationarity, identifiability, or other assumption on the model class need to be made
More formally, we show that for any countable class of models, the distributions selected by MDL (or MAP) asymptotically predict (merge with) the true measure in the class in total variation distance
Implications for non- iid  \ domains like time-series forecasting, discriminative learning, and reinforcement learning are discussed
### introduction ###
The  minimum description length  (MDL) principle recommends to use, among competing models, the one that allows to compress the data+model most  CITATION
The better the compression, the more regularity has been detected, hence the better will predictions be
The MDL principle can be regarded as a formalization of Ockham's razor, which says to select the simplest model consistent with the data
We consider sequential prediction problems, i e \ having  observed sequence   SYMBOL ,  predict   SYMBOL , then observe  SYMBOL  for  SYMBOL
Classical prediction is concerned with  SYMBOL , multi-step lookahead with  SYMBOL , and total prediction with  SYMBOL
In this paper we consider the last, hardest case
An infamous problem in this category is the Black raven paradox  CITATION : Having observed  SYMBOL  black ravens, what is the likelihood that  all  ravens are black
A more computer science problem is (infinite horizon) reinforcement learning, where predicting the infinite future is necessary for evaluating a policy
See Section  for these and other applications
Let  SYMBOL  be a  countable class of models =\linebreak[1]theories=\linebreak[1]hypotheses=\linebreak[1]probabilities over sequences  SYMBOL , sorted w r t \ to their  complexity=codelength   SYMBOL  (say), containing the  unknown true sampling distribution   SYMBOL
Our main result will be for arbitrary measurable spaces  SYMBOL , but to keep things simple in the introduction, let us illustrate MDL for finite  SYMBOL
In this case, we define  SYMBOL  as the  SYMBOL -probability of data sequence  SYMBOL
It is possible to code  SYMBOL  in  SYMBOL  bits, eg \ by using Huffman coding
Since  SYMBOL  is sampled from  SYMBOL , this code is optimal (shortest among all prefix codes)
Since we do not know  SYMBOL , we could select the  SYMBOL  that leads to the shortest code on the observed data  SYMBOL
In order to be able to reconstruct  SYMBOL  from the code we need to know which  SYMBOL  has been chosen, so we also need to code  SYMBOL , which takes  SYMBOL  bits
Hence  SYMBOL  can be coded in  SYMBOL  bits
MDL selects as model the minimizer \MDL^x \;:=\; \arg\min_{Q\in\M}\{-Q(x)+K(Q)\}  Given  SYMBOL , the true predictive probability of  SYMBOL  is  SYMBOL
Since  SYMBOL  is unknown we use  SYMBOL  as a substitute
Our main concern is how close is the latter to the former
We can measure the distance between two predictive distributions by d_h(P,Q|x) \;=\; \sum_{z\in\X^h}\big|P(z|x)-Q(z|x)\big| for  SYMBOL  and  SYMBOL
It is easy to see that  SYMBOL  is monotone increasing and that  SYMBOL  is twice the total variation distance (tvd) defined in \req{tvd}
MDL is closely related to Bayesian prediction, so a comparison to existing results for Bayes is interesting
Bayesians use  SYMBOL  for prediction, where  SYMBOL  is the Bayesian mixture with prior weights  SYMBOL  and  SYMBOL
A natural choice is  SYMBOL
The following results can be shown {\sum_{\l=0}^\E[d_h(P,\MDL^x|x_{1:\l})] 21\,h\ \cdot\ 2^{K(P)},\sum_{\l=0}^\E[d_h(P,\Bayes|x_{1:\l})] h\ \cdot\
w_P^{-1},} {d_\infty(P,\MDL^x|x) 0 d_\infty(P,\Bayes|x)0 }  \;\;\left\{ {\mbox{almost surely} \mbox{for}\;\; \l(x)\ \to\ \infty} \right
where the expectation  SYMBOL  is w r t \  SYMBOL
The left statements for  SYMBOL  imply  SYMBOL  almost surely, including some form of convergence rate
For Bayes it has been proven in  CITATION ; for MDL the proof in  CITATION  can be adapted
As far as asymptotics is concerned, the right results  SYMBOL  are much stronger, and require more sophisticated proof techniques
For Bayes, the result follows from  CITATION
The proof for MDL is the primary novel contribution of this paper; more precisely for arbitrary measurable  SYMBOL  in total variation distance
Another general consistency result is presented in  CITATION
Consistency is shown (only) in probability and the predictive implications of the result are unclear
A stronger almost sure result is alluded to, but the given reference to  CITATION  contains only results for  iid  \ sequences which do not generalize to arbitrary classes
So existing results for discrete MDL are far less satisfactory than the elegant Bayesian prediction in tvd
The results above hold for completely arbitrary countable model classes  SYMBOL
No independence, ergodicity, stationarity, identifiability, or other assumption need to be made
The bulk of previous results for MDL are for continuous model classes  CITATION
Much has been shown for classes of independent identically distributed ( iid  ) random variables  CITATION
Many results naturally generalize to stationary-ergodic sequences like ( SYMBOL th-order) Markov
For instance, asymptotic consistency has been shown in  CITATION
There are many applications violating these assumptions, some of them are presented below and in Section
One can often hear the exaggerated claim that (e g \ unlike Bayes) MDL can be used even if the true distribution  SYMBOL  is not in  SYMBOL
Indeed, it can be used, but the question is wether this is any good
There are some results supporting this claim, eg \ if  SYMBOL  is in the closure of  SYMBOL , but similar results exist for Bayes
Essentially  SYMBOL  needs to be at least close to some  SYMBOL  for MDL to work, and there are interesting environments that are not even close to being stationary-ergodic or  iid 
Non- iid  \ data is pervasive  CITATION ; it includes all time-series prediction problems like weather forecasting and stock market prediction  CITATION
Indeed, these are also perfect examples of non-ergodic processes
Too much green house gases, a massive volcanic eruption, an asteroid impact, or another world war could change the climate/economy irreversibly
Life is also not ergodic; one inattentive second in a car can have irreversible consequences
Also stationarity is easily violated in multi-agent scenarios: An environment which itself contains a learning agent is non-stationary (during the relevant learning phase)
Extensive games and multi-agent reinforcement learning are classical examples  CITATION
Often it is assumed that the true distribution can be uniquely identified asymptotically
For non-ergodic environments, asymptotic distinguishability can depend on the realized observations, which prevent a prior reduction or partitioning of  SYMBOL
Even if principally possible, it can be practically burdensome to do so, eg \ in the presence of approximate symmetries
Indeed this problem is the primary reason for considering  predictive  MDL
MDL might never identify the true distribution, but our main result shows that the sequentially selected models become predictively indistinguishable
The countability of  SYMBOL  is the severest restriction of our result
Nevertheless the countable case is useful
A semi-parametric problem class  SYMBOL  with  SYMBOL  (say) can be reduced to a countable class  SYMBOL  for which our result holds, where  SYMBOL  is a Bayes or NML or other estimate of  SYMBOL   CITATION
Alternatively,  SYMBOL  could be reduced to a countable class by considering only computable parameters  SYMBOL
Essentially all interesting model classes contain such a countable topologically dense subset
Under certain circumstances MDL still works for the non-computable parameters  CITATION
Alternatively one may simply reject non-computable parameters on philosophical grounds  CITATION
Finally, the techniques for the countable case might aid proving general results for continuous  SYMBOL , possibly along the lines of  CITATION
The paper is organized as follows: In Section  we provide some insights how MDL and Bayes work in restricted settings, what breaks down for general countable  SYMBOL , and how to circumvent the problems
The formal development starts with Section , which introduces notation and our main result
The proof for finite  SYMBOL  is presented in Section  and for denumerable  SYMBOL  in Section
In Section  we show how the result can be applied to sequence prediction, classification and regression, discriminative learning, and reinforcement learning
Section  discusses some MDL variations
### abstract ###
We investigate the problem of learning a topic model -- the well-known Latent Dirichlet Allocation -- in a distributed manner, using a cluster of C processors and dividing the corpus to be learned equally among them
We propose a simple approximated method that can be tuned, trading speed for accuracy according to the task at hand
Our approach is asynchronous, and therefore suitable for clusters of heterogenous machines
### introduction ###
Very large datasets are becoming increasingly common -- from specific collections, such as Reuters and PubMed, to very broad and large ones, such as the images and metadata of sites like Flickr, scanned books of sites like Google Books and the whole internet content itself
Topic models, such as Latent Dirichlet Allocation (LDA), have proved to be a useful tool to model such collections, but suffer from scalability limitations
Even though there has been some recent advances in speeding up inference for such models, this still remains a fundamental open problem
### abstract ###
Minimizing the rank of a matrix subject to affine constraints is a fundamental problem with many important applications in machine learning and statistics
In this paper we propose a simple and fast algorithm  SYMBOL  (Singular Value Projection) for rank minimization with affine constraints ( SYMBOL ) and show that SVP recovers the minimum rank solution for affine constraints that satisfy the {restricted isometry property}
We show robustness of our method to noise with a strong geometric convergence rate even for noisy measurements
Our results improve upon a recent breakthrough by Recht, Fazel and Parillo  CITATION  and Lee and Bresler  CITATION  in three significant ways: 1) our method ( SYMBOL ) is significantly simpler to analyze and easier to implement, 2) we give recovery guarantees under strictly weaker isometry assumptions 3) we give geometric convergence guarantees for   SYMBOL  and, as demonstrated empirically,  SYMBOL  is significantly faster on real-world and synthetic problems
In addition, we address the practically important problem of low-rank matrix completion, which can be seen as a special case of  SYMBOL
However, the affine constraints defining the matrix-completion problem do not obey the {restricted isometry property} in general
We empirically demonstrate that our algorithm recovers low-rank {incoherent} matrices from an almost optimal number of uniformly sampled entries
We make partial progress towards proving exact recovery and provide some intuition for the performance of  SYMBOL  applied to matrix completion by showing a more restricted isometry property
Our algorithm outperforms existing methods, such as those of  CITATION , for  SYMBOL  and the matrix-completion problem by an order of magnitude and is also significantly more robust to noise
### introduction ###
In this paper we study the general affine rank minimization problem (ARMP), \renewcommand{\theequation}{ARMP}  SYMBOL } \renewcommand{\theequation}{\arabic{equation}} \addtocounter{equation}{-1} where  SYMBOL   is an affine transformation from  SYMBOL  to  SYMBOL
The general affine rank minimization problem is of considerable practical interest and many important machine learning problems such as matrix completion, low-dimensional metric embedding, low-rank kernel learning can be viewed as instances of the above problem
Unfortunately, ARMP is NP-hard in general and is also NP-hard to approximate ( CITATION )
Until recently, most known methods for  SYMBOL  were heuristic in nature with few known rigorous guarantees
The most commonly used heuristic for the problem is to assume a factorization of  SYMBOL  and optimize the resulting non-convex problem by alternating minimization  CITATION , alternative projections  CITATION  or alternating LMIs  CITATION
Another common approach is to relax the rank constraint to a convex function such as the trace-norm or the log determinant  CITATION ,  CITATION
However, most of these methods do not have any optimality guarantees
Recently, Meka et al CITATION  proposed online learning based methods for ARMP
However, their methods can only guarantee at best a logarithmic approximation for the minimum rank
In a recent breakthrough, Recht et al ~ CITATION  obtained the first nontrivial exact-recovery results for  SYMBOL  obtaining guaranteed rank minimization for affine transformations  SYMBOL  that satisfy a {restricted isometry property} ( SYMBOL )
Define the isometry constant of  SYMBOL ,  SYMBOL  to be the smallest number such that for all  SYMBOL  of rank at most  SYMBOL ,   SYMBOL }  Recht et al ~show that for affine constraints with bounded isometry constants (specifically,  SYMBOL ), finding the minimum trace-norm solution recovers the minimum rank solution
Their results were later extended to noisy measurements and isometry constants up to  SYMBOL  by Lee and Bresler  CITATION
However, even the best existing optimization algorithms for the trace-norm relaxation are relatively inefficient in practice and their results are hard to analyze
In another recent work, Lee and Bresler  CITATION  obtained exact-recovery guarantees for  SYMBOL  satisfying  SYMBOL  using a different approach
Lee and Bresler propose an algorithm (ADMiRA) motivated by the {orthogonal matching pursuit} line of work in compressed sensing, and show that for affine constraints with isometry constant  SYMBOL  their algorithm recovers the optimal solution
They also prove similar guarantees for noisy measurements and provide a geometric convergence rate for their algorithm
However, their method is not very efficient for large datasets and is hard to analyze
In this paper we propose a simple and fast algorithm  SYMBOL  (Singular Value Projection) based on the classical projected gradient algorithm
We present a simple analysis showing that  SYMBOL  recovers the minimum rank solution for affine constraints that satisfy  SYMBOL  even in the presence of noise and prove the following guarantees
Independent of our work, Goldfarb and Ma  CITATION  proposed an algorithm similar to our algorithm
However, their analysis and formulation is different from ours
In particular, their analysis builds on the analysis of Lee and Bresler and they require stronger isometry assumptions,  SYMBOL , than we do
In addition, we make partial progress on analyzing  SYMBOL  for the matrix completion problem and proving exact recovery
Our analysis of  SYMBOL  is motivated by the recent work in the field of compressed sensing by Blumensath and Davies  CITATION , Garg and Khandekar  CITATION
Our results improve the results of Recht et al ~and Lee and Bresler as follows
SYMBOL  is considerably simpler to analyze than the methods of Recht et al ~and Lee and Bresler
Further, we need weaker isometry assumptions on  SYMBOL : we only require  SYMBOL  as opposed to  SYMBOL  required by Recht et al ,  SYMBOL  required by Lee and Bresler  CITATION  and  SYMBOL  required by Lee and Bresler  CITATION
SYMBOL  has a strong geometric convergence rate and is faster than using the best trace-norm optimization algorithms and the methods of Lee and Bresler by an order of magnitude
Although restricted isometry property is natural in settings where the affine constraints contain information about all the entries of the unknown matrix, in several cases of considerable practical interest the affine constraints only contain {local information} and may not satisfy  SYMBOL  directly
One such important problem where  SYMBOL  does not hold directly is the low-rank matrix completion problem
In the matrix completion problem we are given the entries of an unknown low-rank matrix  SYMBOL  for ordered pairs  SYMBOL  and the goal is to complete the missing entries of  SYMBOL
A highly popular application of the matrix completion problem is in the field of collaborative filtering, where typically the task is to predict user ratings given past ratings of the users
Recently, a lot of attention has been given to the problem  due to the Netflix Challenge  CITATION
Other applications of matrix completion include triangulation from incomplete data, link prediction in social networks etc
Similar to  SYMBOL , the low-rank matrix completion is also NP-hard in general and most methods are heuristic in nature with no theoretical guarantees
The alternating least squares minimization heuristic and its variants  CITATION  perform the best in practice but are notoriously hard to analyze
Recently, Candes and Recht  CITATION , Candes and Tao  CITATION  and Keshavan et al ~ CITATION  obtained the first non-trivial results for low-rank matrix completion under a few additional assumptions
Broadly, these papers give exact-recovery guarantees when the optimal solution  SYMBOL  is  SYMBOL -{incoherent} (see Definition ), and the entries  SYMBOL  are chosen uniformly at random with  SYMBOL , where  SYMBOL  depends only on  SYMBOL
However, the algorithms of the above papers, even when using methods tailored specifically for matrix-completion such as those of Cai et al ~ CITATION , are quite expensive in practice and not very tolerant to noise
As low-rank matrix completion is a special case of  SYMBOL , we can naturally adapt our algorithm  SYMBOL  for matrix completion
We demonstrate empirically that for a suitable step-size,  SYMBOL  significantly outperforms the methods of  CITATION ,  CITATION ,  CITATION ,  CITATION  in accuracy, computational time and tolerance to noise
Furthermore, our experiments strongly suggest (see Figure~) that guarantees similar to those of  CITATION ,  CITATION  hold for  SYMBOL , achieving exact recovery for incoherent matrices from an almost optimal number of entries
Although we do not provide a rigorous proof of exact-recovery for  SYMBOL  applied to matrix completion, we make partial progress in this direction and give strong intuition for the performance of  SYMBOL
We prove that though the affine constraints defining the matrix-completion problems do not obey the restricted isometry property, they obey the restricted isometry property over incoherent matrices
This weaker  SYMBOL  condition along with a hypothesis bounding the incoherence of the iterates of  SYMBOL  imply exact-recovery of a low-rank incoherent matrix from an almost optimal number of entries
We also provide strong empirical evidence supporting our hypothesis bounding the incoherence of the iterates of  SYMBOL  (see Figure ) }  We first present our algorithm  SYMBOL  in Section~ and present its analysis for affine constraints satisfying  SYMBOL  in Section~
In Section~, we specialize our algorithm  SYMBOL  to the task of low-rank matrix completion and prove a more restricted isometry property for the matrix completion problem
In Section~, we give empirical results for  SYMBOL  applied to  SYMBOL  and matrix-completion on real-world and synthetic problems
### abstract ###
Sampling-based methods have previously been proposed for the problem of finding interesting associations in data, even for low-support items
While these methods do not guarantee precise results, they can be vastly more efficient than approaches that rely on exact counting
However, for many similarity measures no such methods have been known
In this paper we show how a wide variety of measures can be supported by a simple  biased\/  sampling method
The method also extends to find high-confidence association rules
We demonstrate theoretically that our method is superior to exact methods when the threshold for ``interesting similarity/confidence'' is above the average pairwise similarity/confidence, and the average support is not too low
Our method is particularly good when transactions contain many items
We confirm in experiments on standard association mining benchmarks that this gives a significant speedup on real data sets (sometimes much larger than the theoretical guarantees)
Reductions in computation time of over an order of magnitude, and significant savings in space, are observed
### introduction ###
A central task in data mining is finding associations in a binary relation
Typically, this is phrased in a ``market basket'' setup, where there is a sequence of baskets (from now on ``transactions''), each of which is a set of items
The goal is to find patterns such as ``customers who buy diapers are more likely to also buy beer''
There is no canonical way of defining whether an association is interesting --- indeed, this seems to depend on problem-specific factors not captured by the abstract formulation
As a result, a number of measures exist: In this paper we deal with some of the most common measures, including  Jaccard ~ CITATION ,  lift ~ CITATION ,  cosine , and  all\_confidence ~ CITATION
In addition, we are interested in high-confidence association rules, which are closely related to the  overlap coefficient\/  similarity measure
We refer to~ CITATION  for general background and discussion of similarity measures
In the discussion we limit ourselves to the problem of binary associations, i e , patterns involving pairs of items
There is a large literature considering the challenges of finding patterns involving larger item sets, taking into account the aspect of time, multiple-level rules, etc
While some of our results can be extended to cover larger item sets, we will for simplicity concentrate on the binary case
Previous methods rely on one of the following approaches:     Identifying item pairs  SYMBOL  that ``occur frequently together'' in the transactions --- in particular, this means counting the number of co-occurrences of each such pair ---  or   Computing a ``signature'' for each item such that the similarity of every pair of items can be estimated by (partially) comparing the item signatures
Our approach is different from both these approaches, and generally offers improved performance and/or flexibility
In some sense we go directly to the desired result, which is the set of pairs of items with similarity measure above some user-defined threshold  SYMBOL
Our method is  sampling\/  based, which means that the output may contain false positives, and there may be false negatives
However, these errors are rigorously understood, and can be reduced to any desired level, at some cost of efficiency --- our experimental results are for a false negative probability of less than 2\%
The method for doing sampling is the main novelty of this paper, and is radically different from previous approaches that involve sampling
The main focus in many previous association mining papers has been on  space usage\/  and the number of  passes\/  over the data set, since these have been recognized as main bottlenecks
We believe that time has come to also carefully consider  CPU time
A transaction with  SYMBOL  items contains  SYMBOL  item pairs, and if  SYMBOL  is not small the effort of considering all pairs is non-negligible compared to the cost of reading the item set
This is true in particular if data resides in RAM, or on a modern SSD that is able to deliver data at a rate of more than a gigabyte per second
One remedy that has been used (to reduce space, but also time) is to require  high support , i e , define ``occur frequently together'' such that most items can be thrown away initially, simply because they do not occur frequently enough (they are below the  support threshold\/ )
However, as observed in~ CITATION  this means that potentially interesting or useful associations (e g ~correlations between genes and rare diseases) are not reported
In this paper we consider the problem of finding associations  without\/  support pruning
Of course, support pruning can still be used to reduce the size of the data set before our algorithms are applied
In the following sections we first discuss the need for focusing on CPU time in data mining, and then elaborate on the relationship between our contribution and related works
### abstract ###
Suppose the signal  SYMBOL  is realized by driving a  SYMBOL -sparse signal  SYMBOL  through an arbitrary unknown stable discrete-linear time invariant system  SYMBOL , namely,  SYMBOL , where  SYMBOL  is the impulse response of the operator  SYMBOL
These types of processes arise naturally in Reflection Seismology
In this paper we are interested in several problems: (a) Blind-Deconvolution: Can we recover both the filter  SYMBOL  and the sparse signal  SYMBOL  from noisy measurements (b) Compressive Sensing: Is  SYMBOL  compressible in the conventional sense of compressed sensing
Namely, can  SYMBOL  be reconstructed from a sparse set of measurements
We develop novel  SYMBOL  minimization methods to solve both cases and establish sufficient conditions for exact recovery for the case when the unknown system  SYMBOL  is auto-regressive (i e all pole) of a known order
In the compressed sensing/sampling setting it turns out that both  SYMBOL  and  SYMBOL  can be reconstructed from  SYMBOL  measurements under certain technical conditions on the support structure of  SYMBOL
Our main idea is to pass  SYMBOL  through a linear time invariant system  SYMBOL  and collect  SYMBOL  sequential measurements
The filter  SYMBOL  is chosen suitably, namely, its associated Toeplitz matrix satisfies the RIP property
We develop a novel LP optimization algorithm and show that both the unknown filter  SYMBOL  and the sparse input  SYMBOL  can be reliably estimated
### introduction ###
In this paper we focus on blind de-convolution problems for filtered sparse processes
Specifically, a sparse input  SYMBOL  is filtered by an unknown infinite impulse response (IIR) discrete time stable linear filter  SYMBOL  and the resulting output  SYMBOL  SYMBOL y(t) = x(t) + n(t) SYMBOL t = 0,\,1,\,\ldots,N SYMBOL u(t) SYMBOL H SYMBOL x(t) SYMBOL u(t) SYMBOL H SYMBOL H SYMBOL H SYMBOL H SYMBOL z SYMBOL H SYMBOL \ell_1 SYMBOL H SYMBOL u SYMBOL H SYMBOL u SYMBOL x(t) SYMBOL x(t) SYMBOL u(t) SYMBOL H SYMBOL z SYMBOL O(k\log^3(n)) SYMBOL GH SYMBOL H SYMBOL Hu SYMBOL x SYMBOL 3 SYMBOL \alpha_1=0 9,\,\alpha_2=0 7 SYMBOL \alpha_3=0 2 SYMBOL x SYMBOL u(t)=x(t)-x(t-1) SYMBOL x SYMBOL H SYMBOL u SYMBOL x=Hu SYMBOL H SYMBOL x SYMBOL G SYMBOL g(t) SYMBOL  SYMBOL  SYMBOL g*h SYMBOL  SYMBOL  SYMBOL u = Gu SYMBOL G SYMBOL G SYMBOL u SYMBOL H SYMBOL H SYMBOL H SYMBOL u(t) SYMBOL u(t) SYMBOL u(t) SYMBOL \ell_1 SYMBOL 1\% SYMBOL 10\% SYMBOL \ell_1 SYMBOL u SYMBOL \ell_1 SYMBOL \ell_1 SYMBOL 1\% SYMBOL 10\% SYMBOL H SYMBOL u SYMBOL H SYMBOL H^{\perp} SYMBOL p SYMBOL g * h = h * g SYMBOL \ell_1 SYMBOL u SYMBOL p SYMBOL m SYMBOL O(m+p) SYMBOL O(mp) SYMBOL \ell_1$ minimization  algorithm and the main result of this paper (Theorem ) is stated in this section
The proof of Theorem  can be found in Section
To help the reader understand the main idea of the proof we first consider a very simple case and Section  provides the proof for the general case
Section  addresses the blind-deconvolution problem, which can be regarded as a noisy version of our problem
We use lasso to solve this problem and the detailed proof is provided in Section
In Section , we extend the our techniques to two related problem, namely, decoding of ARMA process and decoding of a non-causal AR process
Finally, simulation results are shown in Section
### abstract ###
We introduce the Reduced-Rank Hidden Markov Model (RR-HMM), a generalization of HMMs that can model smooth state evolution as in Linear Dynamical Systems (LDSs) as well as non-log-concave predictive distributions as in continuous-observation HMMs
RR-HMMs assume an  SYMBOL -dimensional latent state and  SYMBOL  discrete observations, with a transition matrix of rank  SYMBOL
This implies the dynamics evolve in a  SYMBOL -dimensional subspace, while the shape of the set of predictive distributions is determined by  SYMBOL
Latent state belief is represented with a  SYMBOL -dimensional state vector and inference is carried out entirely in  SYMBOL , making RR-HMMs as computationally efficient as  SYMBOL -state HMMs yet more expressive
To learn RR-HMMs, we relax the assumptions of a recently proposed spectral learning algorithm for HMMs~ CITATION  and apply it to learn  SYMBOL -dimensional observable representations of rank- SYMBOL  RR-HMMs
The algorithm is consistent and free of local optima, and we extend its performance guarantees to cover the RR-HMM case
We show how this algorithm can be used in conjunction with a kernel density estimator to efficiently model high-dimensional multivariate continuous data
We also relax the assumption that single observations are sufficient to disambiguate state, and extend the algorithm accordingly
Experiments on synthetic data and a toy video, as well as on a difficult robot vision modeling problem, yield accurate models that compare favorably with standard alternatives in simulation quality and prediction capability
### introduction ###
Models of stochastic discrete-time dynamical systems have important applications in a wide range of fields
Hidden Markov Models (HMMs)~ CITATION  and  Gaussian Linear Dynamical Systems (LDSs)~ CITATION  are two examples of  latent variable models  of dynamical systems, which  assume that sequential data points are noisy, incomplete observations of a latent state that evolves over time
HMMs model this latent state as a discrete variable, and represent belief as a discrete distribution over states
LDSs on the other hand model the latent state as a set of real-valued variables, are restricted to linear transition and observation functions,  and employ a Gaussian belief distribution
The distributional assumptions of HMMs and LDSs also result in important differences in the evolution of their belief over time
The discrete state of HMMs is good for modeling systems with mutually exclusive states that can have completely different observation signatures
The joint predictive distribution over observations is allowed to be non-log-concave when predicting or simulating the future, leading to what we call  competitive inhibition  between states (see Figure~ below for an example)
Competitive inhibition denotes the ability of a model's predictive distribution to place probability mass on observations while disallowing mixtures of those observations
Conversely, the Gaussian joint predictive distribution over observations in LDSs is log-concave, and thus does not exhibit competitive inhibition
However, LDSs naturally model  smooth state evolution , which  HMMs are particularly bad at
The dichotomy between the two models hinders our ability to compactly model systems that exhibit  both  competitive inhibition and smooth state evolution
We present the Reduced-Rank Hidden Markov Model (RR-HMM), a smoothly evolving dynamical model with the ability to represent nonconvex predictive distributions by relating discrete-state and continuous-state models
HMMs can approximate smooth state evolution by tiling the state space with a very large number of low-observation-variance discrete states with a specific transition structure
However, inference and learning in such a model is highly inefficient due to the large number of parameters, and due to the fact that existing HMM learning algorithms, such as Expectation Maximization (EM)~ CITATION , are prone to local minima
RR-HMMs allow us to reap many of the benefits of large-state-space HMMs without incurring the associated inefficiency during inference and learning
Indeed, we show that all inference operations in the RR-HMM can be carried out in the low-dimensional space where the dynamics evolve, decoupling their computational cost from the number of hidden states
This makes  rank - SYMBOL  RR-HMMs (with any number of states) as computationally efficient as  SYMBOL - state  HMMs, but much more expressive
Though the RR-HMM is in itself novel, its low-dimensional  SYMBOL  representation is related to existing models such as Predictive State Representations (PSRs)~ CITATION , Observable Operator Models (OOMs)~ CITATION , generalized HMMs~ CITATION , and weighted automata~ CITATION , as well as the the representation of LDSs learned using Subspace Identification~ CITATION
These and other related models and algorithms are discussed further in Section~
To learn RR-HMMs from data, we adapt a recently proposed spectral learning algorithm by Hsu, Kakade and Zhang~ CITATION  (henceforth referred to as HKZ) that learns  observable representations  of HMMs using matrix decomposition  and regression on empirically estimated observation probability matrices of past and future observations
An observable representation of an HMM allows us to model sequences with a series of operators without knowing the underlying stochastic transition and observation matrices
The HKZ algorithm is free of local optima and asymptotically unbiased, with a finite-sample bound on  SYMBOL  error in joint probability estimates from the resulting model
However, the original algorithm and its bounds assume (1) that the transition model is full-rank and (2) that single observations are informative about the entire latent state, i e \@   SYMBOL -step observability
We show how to generalize the HKZ bounds to the low-rank transition matrix case and derive tighter bounds that depend on  SYMBOL  instead of  SYMBOL , allowing us to learn rank- SYMBOL  RR-HMMs of arbitrarily large  SYMBOL  in  SYMBOL  time, where  SYMBOL  is the number of samples
We also describe and test a method for circumventing the  SYMBOL -step observability condition by combining observations to make them more informative
A version of this learning algorithm can learn general PSRs~ CITATION  though our error bounds don't yet generalize to this case
Experiments show that our learning algorithm can recover the underlying RR-HMM in a variety of synthetic domains
We also demonstrate that RR-HMMs are able to compactly model smooth evolution  and  competitive inhibition in a clock pendulum video, as well as in real-world mobile robot vision data captured in an office building
Robot vision data (and, in fact, most real-world multivariate time series data) exhibits smoothly evolving dynamics requiring multimodal predictive beliefs, for which RR-HMMs are particularly suited
We compare performance of RR-HMMs to LDSs and HMMs on simulation and prediction tasks
Proofs and details regarding examples are in the Appendix
### abstract ###
Assuming that the loss function is convex in the prediction, we construct a prediction strategy universal for the class of Markov prediction strategies, not necessarily continuous
Allowing randomization, we remove the requirement of convexity
### introduction ###
This paper belongs to the area of research known as universal prediction of individual sequences (see  CITATION  for a review): the predictor's goal is to compete with a wide benchmark class of prediction strategies
In the previous papers  CITATION  and  CITATION  we constructed prediction strategies competitive with the important classes of Markov and stationary, respectively, continuous prediction strategies
In this paper we consider competing against possibly discontinuous strategies
Our main results assert the existence of prediction strategies competitive with the Markov strategies
This paper's idea of transition from continuous to general benchmark classes was motivated by Skorokhod's topology for the space  SYMBOL  of ``c\`adl\`ag'' functions, most of which are discontinuous
Skorokhod's idea was to allow small deformations not only along the vertical axis but also along the horizontal axis when defining neighborhoods
Skorokhod's topology was metrized by Kolmogorov so that it became a separable space ( CITATION , Appendix III;  CITATION , p ~913), which allows us to apply one of the numerous algorithms for prediction with expert advice (Kalnishkan and Vyugin's Weak Aggregating Algorithm in this paper) to construct a universal algorithm
In Section  we give the main definitions and state our main results, Theorems  and ; their proofs are given in Sections  and , respectively
### abstract ###
We consider a problem of significant practical importance,  namely, the reconstruction of a low-rank data matrix from a small subset of its entries
This problem appears in many areas such as  collaborative filtering, computer vision and wireless sensor networks
In this paper, we focus on the matrix completion problem  in the case when the observed samples are corrupted by noise
We compare the performance of  three state-of-the-art matrix completion algorithms  (OptSpace, ADMiRA and FPCA) on a single simulation platform  and present numerical results
We show that in practice  these efficient algorithms can be used to reconstruct real data matrices, as well as randomly generated matrices, accurately
### introduction ###
We consider the problem of reconstructing an  SYMBOL   low rank matrix  SYMBOL  from a small set of observed entries possibly corrupted by noise
This problem is of considerable practical interest and has many applications
One example is collaborative filtering, where users submit rankings  for small subsets of, say, movies, and the goal is  to infer the preference of unrated movies for a recommendation system  CITATION
It is believed that the movie-rating matrix is approximately low-rank,  since only a few factors contribute to a user's preferences
Other examples of matrix completion include the problem of inferring  3-dimensional structure from motion  CITATION  and triangulation from incomplete  data of distances between wireless sensors  CITATION
### abstract ###
In this paper we adapt online estimation strategies to perform model-based clustering on large networks
Our work focuses on two algorithms, the first based on the SAEM algorithm, and the second on variational methods
These two strategies are compared with existing approaches on simulated and real data
We use the method to decipher the connexion structure of the political websphere during the US political campaign in 2008
We show that our online EM-based algorithms offer a good trade-off between precision and speed, when estimating parameters for mixture distributions in the context of random graphs
### introduction ###
Analyzing networks has become an essential part of a number of scientific fields
Examples include such widely differing phenomena as power grids, protein-protein interaction networks and friendship
In this work we focus on particular networks which are made of political Weblogs
With the impact of new social network websites like Myspace and Facebook, the web has an increasing influence on the political debate
As an example,  CITATION  showed that blogging played an important role in the political debate of the 2004 US Presidential Election
Although only a small minority of Americans actually used these Weblogs, their influence extended far beyond their readership, as a result of their interactions with national mainstream media
In this article we propose to uncover the connexion structure of the political websphere during the US political campaign in 2008
This data set consists of a one-day snapshot of over 130,520 links and 1870 manually classified websites (676 liberal, 1026 conservative and 168 independent) where nodes are connected if there exists a citation from one to another
Many strategies have been developed to study networks structure and topology
A distinction can be made between model-free [ CITATION ;  CITATION ] and model-based methods, with connexions between parametric and nonparametric models [ CITATION ]
Among model-based methods, model-based clustering has provided an efficient way to summarize complex networks structures
The basic idea of these strategies is to model the distribution of connections in the network, considering that nodes are spread among an unknown number of connectivity classes which are themselves unknown
This generalizes model-based clustering to network data, and various modeling strategies have been considered
CITATION  propose a mixture model on dyads that belong to some relational alphabet,  CITATION  propose a mixture on edges,  CITATION  consider continuous hidden variables and Airoldi et al ( CITATION ) consider both mixed membership and stochastic block structure
In this article our concern is not to assess nor to compare the appropriateness of these different models, but we focus on a computational issue that is shared by most of them
Indeed, even if the modeling strategies are diverse, EM like algorithms constitute a common core of the estimation strategy [ CITATION ;  CITATION ], and this algorithm is known to be slow to convergence and to be very sensitive to the size of the data set
This issue should be put into perspective with a new challenge that is inherent to the analysis of network data sets which is the development of optimization strategies with a reasonable speed of execution, and which can deal with networks composed of tens of thousands of nodes, if not more
To this extent, Bayesian strategies are limited, as they may not handle networks with more than a few hundred [ CITATION ;  CITATION ] or a few thousand [ CITATION ], and heuristic-based algorithms may not be satisfactory from the statistical point of view [ CITATION ]
Variational strategies have been proposed as well [ CITATION ;  CITATION ], but they are concerned by the same limitations as EM
Thus, the new question we assess in this work is ``how to perform efficient model-based clustering from a computational point of view on very large networks or on networks that grow over time
''  Online algorithms constitute an efficient alternative to classical batch algorithms when the data set grows over time
The application of such strategies to mixture models has been studied by many authors [ CITATION ;  CITATION ]
Typical clustering algorithms include the online  SYMBOL -means algorithm [ CITATION ]
More recently,  CITATION  modeled Internet traffic using a recursive EM algorithm for the estimation of Poisson mixture models
However, an additional difficulty of mixture models for random graphs is that the computation of  SYMBOL , the distribution of the hidden label variables  SYMBOL  conditionally on the observation  SYMBOL , cannot be factorized due to conditional dependency [ CITATION ]
In this work we consider two alternative strategies to deal with this issue
The first one is based on the Monte Carlo simulation of  SYMBOL , leading to a Stochastic version of the EM algorithm (Stochastic Approximation EM, SAEM) [ CITATION ]
The second one is the variational method proposed by  CITATION  which consists in a mean-field approximation of  SYMBOL
This strategy has also been proposed by  CITATION  and by  CITATION  in the Bayesian framework
In this article we begin by describing the blog database from the 2008 US presidential campaign
Then we present the MixNet model proposed by  CITATION , and we compare the model with its principal competitors in terms of modeling strategies
We use the  CITATION  data set for illustration
We derive the  online  framework to estimate the parameters of this mixture using SAEM or variational methods
Simulations are used to show that online methods are very effective in terms of computation time, parameter estimation and clustering efficiency
These simulations integrate both fixed-size and increasing size networks for which online methods have been designed
Finally, we uncover the connectivity structure of the 2008 US Presidential websphere using the proposed variational online algorithm of the MixNet model
### abstract ###
In this paper, spectrum access in cognitive radio networks is modeled as a repeated auction game subject to monitoring and entry costs
For secondary users, sensing costs are incurred as the result of primary users' activity
Furthermore, each secondary user pays the cost of transmissions upon successful bidding for a channel
Knowledge regarding other secondary users' activity is limited due to the distributed nature of the network
The resulting formulation is thus a dynamic game with incomplete information
In this paper, an efficient bidding learning algorithm is proposed based on the outcome of past transactions
As demonstrated through extensive simulations, the proposed distributed scheme outperforms a myopic one-stage algorithm, and can achieve a good balance between efficiency and fairness
### introduction ###
Recent studies have shown that despite claims of spectral scarcity, the actual licensed spectrum remains unoccupied for long periods of time~ CITATION
Thus, cognitive radio (CR) systems have been proposed~ CITATION  in order to efficiently exploit these spectral holes
CRs or secondary users (SUs) are wireless devices that can intelligently monitor and adapt to their environment, hence, they are able to share the spectrum with the licensed primary users (PUs), operating whenever the PUs are idle
Three key design challenges are active topics of research in cognitive radio networks, namely, distributed implementation, spectral efficiency, and the tradeoff between sensing and spectrum access
Previous studies have tackled various aspects of spectrum sensing and spectrum access
In  CITATION , the performance of spectrum sensing, in terms of throughput, is investigated when the SUs share their instantaneous knowledge of the channel
The work in  CITATION  studies the performance of different detectors for spectrum sensing, while in  CITATION  spatial diversity methods are proposed for improving the probability of detecting the PU by the SUs
Other aspects of spectrum sensing are discussed in  CITATION  and  CITATION
Furthermore, spectrum access has also received increased attention, eg ,  CITATION
In  CITATION , a dynamic programming approach is proposed to allow the SUs to maximize their channel access time while taking into account a penalty factor from any collision with the PU
The work in  CITATION  (and the references therein) establish that, in practice, the sensing time of CR networks is large and affects the access performance of the SUs
In  CITATION , the authors model the spectrum access problem as a non-cooperative game, and propose learning algorithms to find the correlated equilibria of the game
Non-cooperative solutions for dynamic spectrum access are also proposed in  CITATION  while taking into account changes in the SUs' environment such as the arrival of new PUs, among others
%In  CITATION ,  When multiple SUs compete for spectral opportunities, the issues of fairness and efficiency arise
On one hand, it is desirable for an SU to access a channel with high availability
On the other hand, the effective achievable rate of an SU decreases when contending with many SUs over the most available channel
Consequently, efficiency of spectrum utilization in the system reduces
Therefore, an SU should explore transmission opportunities in other channels if available and refrain from transmission in the same channel all the time
Intuitively, diversifying spectrum access in both frequency (exploring more channels) and time (refraining from continuous transmission attempts) would be beneficial to achieving fairness among multiple SUs, in that SUs experiencing poorer channel conditions are not starved in the long run
The objective of this paper is to design a mechanism that enables fair and efficient sharing of spectral resources among SUs
We model spectrum access in cognitive radio networks as a repeated auction game with entry and monitoring costs
Auctioning the spectral opportunities is carried out repeatedly
At the beginning of each period, each SU that wishes to participate in the spectrum access submits a bid to a coordinator based on its view of the channel and past auction history
Knowledge regarding other secondary users' activities is limited due to the distributed nature of the network
The resulting formulation is thus a dynamic game with incomplete information
The bidder with the highest bid gains spectrum access
Entry fees are charged for all bidders who participate in the auction irrespective of the outcome of the auction
An SU can also choose to stay out (SO) of the current round, in which case no entry fee is incurred
At the end of each auction period, information regarding bidding and allocation are made available to all SUs, and in turn a monitoring fee is incurred
To achieve efficient bidding, a learning algorithm is proposed based on the outcome of past transactions
Each SU decides on local actions with the objective of increasing its long-term cost effectiveness
As demonstrated through extensive simulations, the proposed distributed scheme outperforms a myopic one-stage algorithm where an SU always participates in the spectrum access game in both single channel and multi-channel networks
A comment is in order on the feasibility of such an auction-based approach to spectrum access in practice
Due to commercial and industrial exploitation and different stake holders' interests, the functional architectures and cognitive signaling schemes are currently under discussion within standardization forums, including IEEE SCC 41 and ETSI TC RRS (Reconfigurable Radio Systems)
Cognitive pilot channel (CPC) has gained attention as a potential enabler of data-aided mitigation techniques between secondary and primary communication systems as well as a  mechanism to support optimized radio resource and data management across heterogeneous networks
In CPC, a common control channel is used to provide the information corresponding to the operators, Radio Access Technology and frequencies allocated in a given area
We can thus leverage the intelligence of the CPC coordinator and the control channel to solicit bidding and broadcast the outcome of auctions
The main contributions of this paper are:   We have formulated the spectrum access problem in cognitive radio networks as a repeated auction game
A distributed learning algorithm is proposed for single-channel networks, and a non-regret learning algorithm is investigated for multi-channel networks
The rest of the paper is organized as follows
In Section~, the system model and terminology are introduced
Mechanism design of the repeated auction with learning is presented in Section~
Simulation results are given in Section~ followed by conclusions and a discussion of future work in Section~
### abstract ###
The learning of appropriate distance metrics is a critical problem in image classification and retrieval
In this work, we propose a boosting-based technique, termed \BoostMetric, for learning a Mahalanobis distance metric
One of the primary difficulties in learning such a metric is to ensure that the Mahalanobis matrix remains positive semidefinite
Semidefinite programming is sometimes used to enforce this constraint, but does not scale well
is instead based on a key observation that any positive semidefinite matrix can be decomposed into a linear positive combination of trace-one rank-one matrices
thus uses rank-one positive semidefinite matrices as weak learners within an efficient and scalable boosting-based learning process
The resulting method is easy to implement, does not require tuning, and can accommodate various types of constraints
Experiments on various datasets show that the proposed algorithm compares favorably to those state-of-the-art methods in terms of classification accuracy and running time
### introduction ###
It has been an extensively sought-after goal to learn an appropriate distance metric in image classification and retrieval problems using  simple and efficient  algorithms  CITATION
Such distance metrics are essential to the effectiveness of many critical algorithms such as  SYMBOL -nearest neighbor ( SYMBOL NN),  SYMBOL -means clustering, and kernel regression, for example
We show in this work how a Mahalanobis metric is learned from proximity comparisons among triples of training data
Mahalanobis distance, \aka~Gaussian quadratic distance, is parameterized by a positive semidefinite (\PSD) matrix
Therefore, typically methods for learning a Mahalanobis distance result in constrained semidefinite programs
We discuss the problem setting as well as the difficulties for learning such a matrix
If we let  SYMBOL  represent a set of points in  SYMBOL , the training data consist of a set of constraints upon the relative distances between these points,  SYMBOL , where  SYMBOL  measures the distance between  SYMBOL  and  SYMBOL
We are interested in the case that  SYMBOL  computes the Mahalanobis distance
The  Mahalanobis distance between two vectors takes the form:  SYMBOL  with  SYMBOL , a matrix
It is equivalent to learn a projection matrix  SYMBOL  and  SYMBOL
Constraints such as those above often arise when it is known that  SYMBOL  and  SYMBOL  belong to the same class of data points while  SYMBOL  belong to different classes
In some cases, these comparison constraints are much easier to obtain than either the class labels or distances between data elements
For example, in video content retrieval, faces extracted from successive frames at close locations can be safely assumed to belong to the same person, without requiring the individual to be identified
In web search, the results returned by a search engine are ranked according to the relevance, an ordering which allows a natural conversion into a set of constraints
The requirement of  SYMBOL  being has led to the development of a number of methods for learning a Mahalanobis distance which rely upon constrained semidefinite programing
This approach has a number of limitations, however, which we now discuss with reference to the problem of learning a matrix from a set of constraints upon pairwise-distance comparisons
Relevant work on this topic includes  CITATION  amongst others
Xing  CITATION  firstly proposed to learn a Mahalanobis metric for clustering using convex optimization
The inputs are two sets: a similarity set and  a dis-similarity set
The algorithm maximizes the distance between points in the dis-similarity set under the constraint that the distance between points in the similarity set is upper-bounded
Neighborhood component analysis (NCA)  CITATION  and large margin nearest neighbor (LMNN)  CITATION  learn a metric by maintaining consistency in data's neighborhood and keeping a large margin at the boundaries of different classes
It has been shown in  CITATION  that LMNN delivers the state-of-the-art performance among most distance metric learning algorithms
The work of LMNN   CITATION  and PSDBoost  CITATION  has directly inspired our work
Instead of using hinge loss in LMNN and PSDBoost, we use the exponential loss function in order to derive an AdaBoost-like optimization procedure
Hence, despite similar purposes, our algorithm differs essentially in the optimization
While the formulation of LMNN looks more similar to support vector machines (SVM's) and PSDBoost to LPBoost, our algorithm, termed \BoostMetric, largely draws upon AdaBoost  CITATION
In many cases, it is difficult to find a global optimum in the projection matrix  SYMBOL   CITATION
Reformulation-linearization is a typical technique in convex optimization to relax and convexify the problem  CITATION
In metric learning, much existing work instead learns  SYMBOL  for seeking a global optimum, \eg,  CITATION
The price is heavy computation and poor scalability: it is not trivial to preserve the semidefiniteness of  SYMBOL  during the course of learning
Standard approaches like interior point Newton methods require the Hessian, which usually requires  SYMBOL  resources (where  SYMBOL  is the input dimension)
It could be prohibitive for many real-world problems
Alternative projected (sub-)gradient is adopted in  CITATION
The disadvantages of this algorithm are: (1) not easy to implement; (2) many parameters involved; (3) slow convergence
PSDBoost  CITATION  converts the particular semidefinite program in metric learning into a sequence of linear programs (LP's)
At each iteration of PSDBoost, an LP needs to be solved as in LPBoost, which scales around  SYMBOL  with  SYMBOL  the number of iterations (and therefore variables)
As  SYMBOL  increases, the scale of the LP becomes larger
Another problem is that PSDBoost needs to store all the weak learners (the rank-one matrices) during the optimization
When the input dimension  SYMBOL  is large, the memory required is proportional to  SYMBOL , which can be prohibitively huge at a late iteration  SYMBOL
Our proposed algorithm solves both of these problems
Based on the observation from  CITATION  that any positive semidefinite matrix can be decomposed into a linear positive combination of trace-one rank-one matrices, we propose for learning a matrix
The weak learner of is a rank-one matrix as in PSDBoost
The proposed algorithm has the following desirable properties: (1) is efficient and scalable
Unlike most existing methods, no semidefinite programming is required
At each iteration, only the largest eigenvalue and its corresponding eigenvector are needed (2) can accommodate various types of constraints
We demonstrate learning a Mahalanobis metric by proximity comparison constraints (3) Like AdaBoost, does not have any parameter to tune
The user only needs to know when to stop
In contrast, both LMNN and PSDBoost have parameters to cross validate
Also like AdaBoost it is easy to implement
No sophisticated optimization techniques such as LP solvers are involved
Unlike PSDBoost, we do not need to store all the weak learners
The efficacy and efficiency of the proposed is demonstrated on various datasets
Throughout this paper,  a matrix is denoted by a bold upper-case letter ( SYMBOL ); a column vector is denoted by a bold lower-case letter ( SYMBOL )
The  SYMBOL th row of  SYMBOL  is denoted by  SYMBOL  and the  SYMBOL th column  SYMBOL
SYMBOL  is the trace of a symmetric matrix and  SYMBOL  calculates the inner product of two matrices
An element-wise inequality between two vectors like  SYMBOL  means  SYMBOL  for all  SYMBOL
We use  SYMBOL  to indicate that matrix  SYMBOL  is positive semidefinite
For a matrix  SYMBOL , the following statements are equivalent: (1)  SYMBOL  ( SYMBOL ); (2) All eigenvalues of  SYMBOL  are nonnegative ( SYMBOL ,  SYMBOL ); and (3)  SYMBOL ,  SYMBOL
### abstract ###
We examine the complexity of learning the distributions produced by finite-state quantum sources
We show how prior techniques for learning hidden Markov models can be adapted to the  quantum generator  model to find that the analogous state of affairs holds: information-theoretically, a polynomial number of samples suffice to approximately identify the distribution, but computationally, the problem is as hard as learning parities with noise, a notorious open question in computational learning theory
### introduction ###
In recent work, Wiesner and Crutchfield~ CITATION  introduced  Quantum Generators  as a formal model of simple quantum mechanical systems
In this model, a simple quantum mechanical system is observed repeatedly, yielding a classical stochastic process consisting of the sequence of discrete measurement outcomes, analogous to how an underlying Markov process yields a sequence of observations in a hidden Markov model
From this perspective, it is natural to wonder what can be learned about such a simple quantum mechanical system from the sequence of measurement outcomes
In this work, we consider the question of whether or not it is feasible to learn the distribution on measurement outcomes from a reasonable (polynomially  bounded) number of observations
We state two theorems on this subject: first, in Section~, we show that it is information-theoretically  possible to learn the distribution over measurements for binary processes in polynomially many observations, but we then show in Section~ that under a standard hardness assumption (Conjecture~, that it is computationally infeasible to learn parity functions in the presence of classification noise) that it is also computationally infeasible to learn the output distribution of a Quantum Generator (also for a binary alphabet)
### abstract ###
Most of the non-asymptotic theoretical work in regression is carried out for the square loss, where estimators can be obtained through closed-form expressions
In this paper, we use and extend  tools from the convex optimization literature, namely self-concordant functions, to provide simple extensions of theoretical results for the square loss to the logistic loss
We apply the extension techniques to logistic regression with regularization by the  SYMBOL -norm and regularization by the  SYMBOL -norm, showing that new results for binary classification through logistic regression can be easily derived from corresponding results for least-squares regression
### introduction ###
The theoretical analysis of statistical methods is usually greatly simplified when the estimators have   closed-form expressions
For methods based on the minimization of a certain functional, such as M-estimation methods~ CITATION , this is true when the function to minimize is quadratic, i e , in the context of regression, for the square loss
When such loss is used, asymptotic and non-asymptotic results may be derived with classical tools from probability theory (see, eg ,~ CITATION )
When the function which is minimized in M-estimation is not amenable to closed-form solutions, local approximations are then needed for obtaining and analyzing a solution of the optimization problem
In the asymptotic regime, this has led to interesting developments and extensions of results from the quadratic case, eg , consistency or asymptotic normality (see, eg ,~ CITATION )
However, the situation is different when one wishes to derive non-asymptotic results, i e , results where all constants of the problem are explicit
Indeed, in order to prove results as sharp as for the square loss, much notation and many assumptions have to be introduced regarding second and third derivatives; this makes the derived results much more complicated than the ones for closed-form estimators~ CITATION
A similar situation occurs in convex optimization, for the study of Newton's method for obtaining solutions of unconstrained optimization problems
It is known to be locally quadratically convergent for convex problems
However, its classical analysis requires cumbersome notations and assumptions regarding second and third-order derivatives~(see, eg ,~ CITATION )
This situation was greatly enhanced with the introduction of the notion of  self-concordant functions , i e , functions whose third derivatives are controlled by their second derivatives
With this tool, the analysis is much more transparent~ CITATION
While Newton's method is a commonly used algorithm  for logistic regression~(see, eg ,~ CITATION ), leading to iterative least-squares algorithms, we don't focus in the paper on the resolution of the optimization problems, but on the statistical analysis of the associated global minimizers
In this paper, we aim to borrow tools from convex optimization and self-concordance to analyze the statistical properties of logistic regression
Since the logistic loss is not itself a self-concordant function, we introduce in \mysec{self} a new type of functions with a different control of the third derivatives
For these functions, we prove  two types of results: first, we provide lower and upper Taylor expansions, i e , Taylor expansions which are globally upper-bounding or lower-bounding a given function
Second, we prove results on the behavior of Newton's method which are similar to the ones for self-concordant functions
We then apply them in Sections~,  and~ to the one-step  Newton iterate from the population solution of the corresponding problem (i e ,  SYMBOL  or  SYMBOL -regularized logistic regression)
This essentially shows that the analysis of logistic regression can be done  non-asymptotically  using the local quadratic approximation of the logistic loss,  without  complex additional assumptions
Since this approximation corresponds to a weighted least-squares problem, results from least-squares regression can thus be naturally extended
In order to consider such extensions and make sure that the new results closely match the corresponding ones for least-squares regression, we derive in Appendix~ new Bernstein-like concentration inequalities for quadratic forms of bounded random variables, obtained from general results on U-statistics~ CITATION
We first apply in \mysec{L2} the extension technique to regularization by the  SYMBOL -norm, where we consider two settings, a situation  with no assumptions regarding the conditional distribution of the observations, and another one where the model is assumed well-specified and we derive asymptotic expansions of the generalization performance with explicit bounds on remainder terms
In \mysec{L1}, we consider regularization by the  SYMBOL -norm and extend two known recent results for the square loss, one on model consistency~ CITATION  and one on prediction efficiency~ CITATION
The main contribution of this paper is to make these extensions as simple as possible, by allowing the use of non-asymptotic second-order Taylor expansions \paragraph{Notation }    For  SYMBOL  and  SYMBOL , we  denote by  SYMBOL  the  SYMBOL -norm of  SYMBOL , defined as  SYMBOL
We also denote by  SYMBOL  its  SYMBOL -norm
We   denote by  SYMBOL  and  SYMBOL  the largest and smallest eigenvalue of a symmetric matrix  SYMBOL
We use the notation  SYMBOL  (resp
SYMBOL ) for the positive semi-definiteness of the matrix  SYMBOL  (resp
SYMBOL )
For    SYMBOL ,  SYMBOL  denotes the sign of  SYMBOL , defined as  SYMBOL  if  SYMBOL ,  SYMBOL  if  SYMBOL , and  SYMBOL  if  SYMBOL
For a vector  SYMBOL ,  SYMBOL  denotes the   vector of signs of elements of  SYMBOL
Moreover, given a vector  SYMBOL  and a subset  SYMBOL  of  SYMBOL ,   SYMBOL  denotes the cardinal of the set  SYMBOL ,  SYMBOL  denotes the vector in  SYMBOL  of elements of  SYMBOL  indexed by  SYMBOL
Similarly, for a matrix  SYMBOL ,  SYMBOL   denotes the submatrix of   SYMBOL  composed of elements of  SYMBOL  whose rows are in  SYMBOL  and columns are in  SYMBOL
Finally, we let denote  SYMBOL  and  SYMBOL  general probability measures and expectations
### abstract ###
We study the problem of online regression
We do not make any assumptions about input vectors or outcomes
We prove a theoretical bound on the square loss of Ridge Regression
We also show that Bayesian Ridge Regression can be thought of as an online algorithm competing with all the Gaussian linear experts
We then consider the case of infinite-dimensional Hilbert spaces and prove relative loss bounds for the popular non-parametric kernelized Bayesian Ridge Regression and kernelized Ridge Regression
Our main theoretical guarantees have the form of equalities
### introduction ###
In the online prediction framework we are provided with some input at each step and try to predict an outcome using this input and information from previous steps  CITATION
In a simple case in statistics, it is assumed that each outcome is the value, corrupted by Gaussian noise, of a linear function of input
In competitive prediction the learner compares his loss at each step with the loss of any expert from a certain class of experts instead of making statistical assumptions about the data generating process
Experts may follow certain strategies
The learner wishes to predict almost as well as the best expert for  all  sequences
Our main result is Theorem~ in the next section, which compares the cumulative weighted square loss of Ridge Regression applied in the on-line mode with the regularized cumulative loss of the best linear predictor
The power of this result can be best appreciated by looking at the range of its implications, both known and new
For example, Corollary~ answers the question asked by several researchers, see  CITATION , whether Ridge Regression has a relative loss bound with the regret term of the order  SYMBOL  under the square loss function, where  SYMBOL  is the number of steps and the outcomes are assumed bounded; this corollary (as well as all other implications stated in Section~) is an explicit inequality rather than an asymptotic result
Theorem~ itself is much stronger, stating an equality rather than inequality and not assuming that the outcomes are bounded
Since it is an equality, it unites upper and lower bounds on the loss
It appears that all natural bounds on the square loss of Ridge Regression can be easily deduced from our theorem; we give some examples in the next section
Most of previous research in online prediction considers experts that disregard the presence of noise in observations
We consider experts predicting a distribution on the outcomes
We use Bayesian Ridge Regression and prove that it can predict as well as the best regularized expert; this is our Theorem~
The loss in this theoretical guarantee is the logarithmic loss
The algorithm that we apply was first used by  CITATION  and similar bounds to ours were obtained by  CITATION
Theorem~ is later used to deduce Theorem~
Ridge Regression predicts the mean of the Bayesian Ridge Regression predictive distribution, and the logarithmic loss of Bayesian Ridge Regression is close to scaled square loss of Ridge Regression
We extend our main result to the case of infinite dimensional Hilbert spaces of functions
The algorithm used becomes an analogue of non-parametric Bayesian methods
From Theorem~ and Theorem~ we deduce relative loss bounds on the logarithmic loss of kernelized Bayesian Ridge Regression and on the square loss of kernelized Ridge Regression in comparison with the loss of any function from a reproducing kernel Hilbert space
Both bounds have the form of equalities
There is a lot of research done to prove upper and lower relative loss bounds under different loss functions
If the outcomes are assumed to be bounded, the strongest known theoretical guarantees for square loss are given by  CITATION  and  CITATION  for the algorithm which we call VAW (Vovk-Azoury-Warmuth) following~ CITATION
%(this is not an apt name, since Ridge Regression is also a special case of the Aggregating Algorithm, corresponding to the logarithmic loss function and learning rate 1; and we will call this algorithm the Vovk-Azoury-Warmuth, or VAW, algorithm, following  CITATION )
In the case when the inputs and outcomes are not restricted in any way, like for our main guarantees, it is possible to prove certain loss bounds for the Gradient Descent; see  CITATION
In Section~ of this paper we present the online regression framework and the main theoretical guarantee on the square loss of Ridge Regression
Section~ describes what we call the Bayesian Algorithm
In Section~ we show that Bayesian Ridge Regression is competitive with the experts which take into account the presence of noise in observations
In Section~ we prove the main theorem
Section~ describes the case of infinite-dimensional Hilbert spaces
### abstract ###
We consider the problem of reconstructing a low rank  matrix from a small subset of its entries
In this paper,  we describe the implementation of an efficient algorithm proposed in  CITATION ,  based on singular value decomposition followed by local manifold optimization,  for solving the low-rank matrix completion problem
It has been shown that if the number of revealed entries is large enough,  the output of singular value decomposition gives a good estimate for the original matrix,  so that local optimization reconstructs the correct matrix with high probability
We present numerical results which show that  this algorithm can reconstruct the low rank matrix exactly  from a very small subset of its entries
We further study the robustness of the algorithm with respect to noise, and its performance on actual collaborative filtering datasets
### introduction ###
In this paper we consider the problem of reconstructing an  SYMBOL  low rank matrix  SYMBOL  from a small set of observed entries
This problem is of considerable practical interest and has many applications
One example is collaborative filtering, where users submit rankings for small subsets of, say, movies, and the goal is to infer the preference of unrated movies for a recommendation system  CITATION
It is believed that the movie-rating matrix is approximately low-rank, since only a few factors contribute to a users preferences
Other examples of matrix completion include the problem of inferring 3-dimensional structure from motion  CITATION  and triangulation from incomplete data of distances between wireless sensors, also known as the sensor localization problem  CITATION ,  CITATION
### abstract ###
We propose a novel non-parametric adaptive anomaly detection algorithm for high dimensional data based on score functions derived from nearest neighbor graphs on  SYMBOL -point nominal data
Anomalies are declared whenever the score of a test sample falls below  SYMBOL , which is supposed to be the desired false alarm level
The resulting anomaly detector is shown to be asymptotically optimal in that it is uniformly most powerful for the specified false alarm level,  SYMBOL , for the case when the anomaly density is a mixture of the nominal and a known density
Our algorithm is computationally efficient, being linear in dimension and quadratic in data size
It does not require choosing complicated tuning parameters or function approximation classes and it can adapt to local structure such as local change in dimensionality
We demonstrate the algorithm on both artificial and real data sets in high dimensional feature spaces
### introduction ###
Anomaly detection involves detecting statistically significant deviations of test data from nominal distribution
In typical applications the nominal distribution is unknown and generally cannot be reliably estimated from nominal training data due to a combination of factors such as limited data size and high dimensionality
We propose an adaptive non-parametric method for anomaly detection based on score functions that maps data samples to the interval  SYMBOL
Our score function is derived from a K-nearest neighbor graph (K-NNG) on  SYMBOL -point nominal data
Anomaly is declared whenever the score of a test sample falls below  SYMBOL  (the desired false alarm error)
The efficacy of our method rests upon its close connection to multivariate p-values
In statistical hypothesis testing, p-value is any transformation of the feature space to the interval  SYMBOL  that induces a uniform distribution on the nominal data
When test samples with p-values smaller than  SYMBOL  are declared as anomalies, false alarm error is less than  SYMBOL
We develop a novel notion of p-values based on measures of level sets of likelihood ratio functions
Our notion provides a characterization of the optimal anomaly detector, in that, it is uniformly most powerful for a specified false alarm level for the case when the anomaly density is a mixture of the nominal and a known density
We show that our score function is asymptotically consistent, namely, it converges to our multivariate p-value as data length approaches infinity
Anomaly detection has been extensively studied
It is also referred to as novelty detection  CITATION , outlier detection  CITATION , one-class classification  CITATION  and single-class classification  CITATION  in the literature
Approaches to anomaly detection can be grouped into several categories
In parametric approaches~ CITATION  the nominal densities are assumed to come from a parameterized family and generalized likelihood ratio tests are used for detecting deviations from nominal
It is difficult to use parametric approaches when the distribution is unknown and data is limited
A K-nearest neighbor (K-NN) anomaly detection approach is presented in  CITATION
There an anomaly is declared whenever the distance to the K-th nearest neighbor of the test sample falls outside a threshold
In comparison our anomaly detector utilizes the global information available from the entire K-NN graph to detect deviations from the nominal
In addition it has provable optimality properties
Learning theoretic approaches attempt to find decision regions, based on nominal data, that separate nominal instances from their outliers
These include one-class SVM of Sch SYMBOL lkopf et
al
CITATION  where the basic idea is to map the training data into the kernel space and to separate them from the origin with maximum margin
Other algorithms along this line of research include support vector data description  CITATION ,  linear programming approach  CITATION , and single class minimax probability machine  CITATION
While these approaches provide impressive computationally efficient solutions on real data, it is generally difficult to precisely relate tuning parameter choices to desired false alarm probability
Scott and Nowak  CITATION  derive decision regions based on minimum volume (MV) sets, which does provide Type I and Type II error control
They approximate (in appropriate function classes) level sets of the unknown nominal multivariate density from training samples
Related work by Hero  CITATION  based on geometric entropic minimization (GEM) detects outliers by comparing test samples to the most concentrated subset of points in the training sample
This most concentrated set is the  SYMBOL -point minimum spanning tree(MST) for  SYMBOL -point nominal data and converges asymptotically to the minimum entropy set (which is also the MV set)
Nevertheless, computing  SYMBOL -MST for  SYMBOL -point data is generally intractable
To overcome these computational limitations  CITATION  proposes heuristic greedy algorithms based on leave-one out K-NN graph, which while inspired by  SYMBOL -MST algorithm is no longer provably optimal
Our approach is related to these latter techniques, namely, MV sets of  CITATION  and GEM approach of  CITATION
We develop score functions on K-NNG which turn out to be the empirical estimates of the volume of the MV sets containing the test point
The volume, which is a real number, is a sufficient statistic for ensuring optimal guarantees
In this way we avoid explicit high-dimensional level set computation
Yet our algorithms lead to statistically optimal solutions with the ability to control false alarm and miss error probabilities
The main features of our anomaly detector are summarized (1) Like  CITATION  our algorithm scales linearly with dimension and quadratic with data size and can be applied to high dimensional feature spaces (2) Like  CITATION  our algorithm is provably optimal in that it is uniformly most powerful for the specified false alarm level,  SYMBOL , for the case that the anomaly density is a mixture of the nominal and any other density (not necessarily uniform) (3) We do not require assumptions of linearity, smoothness, continuity of the densities or the convexity of the level sets
Furthermore, our algorithm adapts to the inherent manifold structure or local dimensionality of the nominal density (4) Like  CITATION  and unlike other learning theoretic approaches such as  CITATION  we do not require choosing complex tuning parameters or function approximation classes
### abstract ###
Metric and kernel learning are important in several machine  learning applications
However, most existing metric learning algorithms are limited to learning metrics over low-dimensional data, while existing kernel learning algorithms are often limited to the transductive setting and do not  generalize to new data points
In this paper, we study metric learning as a problem of learning a linear transformation of the input data
We show that for high-dimensional data, a particular framework for learning a linear transformation of the data based on the LogDet divergence can be efficiently kernelized to learn a metric (or equivalently, a kernel function) over an arbitrarily high dimensional space
We further demonstrate that a wide class of convex loss functions for learning linear transformations can similarly be kernelized, thereby considerably expanding the potential applications of metric learning
We demonstrate our learning approach by applying it to large-scale real world problems in computer  vision and text mining
### introduction ###
One of the basic requirements of many machine learning algorithms (e g , semi-supervised clustering algorithms, nearest neighbor classification algorithms)  is the ability to compare two objects to compute a similarity or distance between them
In many cases, off-the-shelf distance or similarity functions such as the Euclidean distance or cosine similarity are used; for example, in text retrieval applications, the cosine similarity is a standard function to compare two text documents
However, such standard distance or similarity functions are not appropriate for all problems
Recently, there has been significant effort focused on learning how to compare data objects
One approach has been to learn a distance metric between objects given additional side information such as pairwise similarity and dissimilarity constraints over the data
One class of distance metrics that has shown excellent generalization properties is the  Mahalanobis distance  function~ CITATION
The Mahalanobis distance can be viewed as a method in which data is subject to a  linear transformation , and then distances in this transformed space are computed via the standard squared Euclidean distance
Despite their simplicity and generalization ability, Mahalanobis distances suffer from two major drawbacks: 1) the number of parameters grows quadratically with the dimensionality of the data, making it difficult to learn distance functions over high-dimensional data, 2) learning a linear transformation is inadequate for data sets with non-linear decision boundaries
To address the latter shortcoming,  kernel learning  algorithms typically attempt to learn a  kernel matrix over the data
Limitations of linear methods can be overcome by employing a non-linear input kernel, which effectively maps the data non-linearly to a high-dimensional feature space
However, many existing kernel learning methods are still limited in that the learned kernels do not generalize to new points~ CITATION
These methods are restricted to learning in the transductive  setting where all the data (labelled and unlabeled) is assumed to be given upfront
There has been some work on learning kernels that generalize to new points, most notably work on hyperkernels~ CITATION , but the resulting optimization problems are expensive and cannot be scaled to large or even medium-sized data sets
In this paper, we explore metric learning with linear transformations over arbitrarily high-dimensional spaces; as we will see, this is equivalent to learning a parameterized kernel function   SYMBOL  given an input kernel function  SYMBOL
In the first part of the paper, we focus on a particular loss function called the LogDet divergence, for learning the positive definite matrix  SYMBOL
This loss function is advantageous for several reasons: it is defined only over positive definite matrices, which makes the optimization simpler, as we will be able to effectively ignore the positive definiteness constraint on  SYMBOL
The loss function has precedence in optimization~ CITATION  and statistics~ CITATION
An important advantage of our method is that the proposed optimization algorithm is scalable to very large data sets of the order of millions of data objects
But perhaps most importantly, the loss function permits efficient kernelization, allowing the learning of a linear transformation in kernel space
As a result, unlike transductive kernel learning methods, our method easily handles out-of-sample extensions, i e , it can be applied to unseen data
Later in the paper, we extend our result on kernelization of the LogDet formulation to other convex loss functions for learning  SYMBOL ,  and give conditions for which we are able to compute and evaluate the learned kernel functions
Our result is akin to the representer theorem for reproducing kernel Hilbert spaces, where the optimal parameters can be expressed purely in terms of the training data
In our case, even though the matrix  SYMBOL  may be infinite-dimensional, it can be fully represented in terms of the constrained data points, making it possible to compute the learned kernel function value over arbitrary points
Finally, we apply our algorithm to a number of challenging learning problems, including ones from the domains of computer vision and text mining
Unlike existing  techniques, we can learn linear transformation-based distance   or kernel functions over these domains, and we show that the resulting functions lead to improvements over state-of-the-art techniques for a variety of problems
                                                                                                                                                                                                                                                                                                                   jmlr2e
sty                                                                                          0000644 0000000 0000000 00000031314 11272335103 011507  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   %   \typeout{Document Style `jmlr' -- January 2001 }   \RequirePackage{epsfig} \RequirePackage{amssymb} \RequirePackage{natbib} \RequirePackage{graphicx} \bibliographystyle{plainnat} \bibpunct{(}{)}{;}{a}{,}{,}   \renewcommand{\topfraction}{0 95}   % let figure take up nearly whole page \renewcommand{\textfraction}{0 05}  % let figure take up nearly whole page 25in    %   Note = 25in 0 07 true in -0 5in \addtolength{\headsep}{0 25in} 8 5 true in       % Height of text (including footnotes & figures) 6 0 true in        % Width of text line \widowpenalty=10000 \clubpenalty=10000 \@twosidetrue \@mparswitchtrue \def\ds@draft{5pt}    \def\@startsiction#1#2#3#4#5#6{\if@noskipsec \@tempskipa #4\@afterindenttrue \@tempskipa <\z@ \@tempskipa -\@tempskipa \@afterindentfalse\if@nobreak \everypar{}\addpenalty{\@secpenalty}\addvspace{\@tempskipa}\@ifstar {\@ssect{#3}{#4}{#5}{#6}}{\@dblarg{\@sict{#1}{#2}{#3}{#4}{#5}{#6}}}}  \def\@sict#1#2#3#4#5#6[#7]#8{#2>\c@secnumdepth \def\@svsec{}\refstepcounter{#1}\edef\@svsec{the#1\endcsname}\@tempskipa #5\@tempskipa>\z@ #6\@hangfrom{#3\relax\@svsec 0 1em} {\@M #8\par} #1mark\endcsname{#7}{toc}{#1}{#2>\c@secnumdepth \protect\numberline{the#1\endcsname}#7}\def\@svsechd{#6#3\@svsec #8#1mark{#7}{toc}{#1}{#2>\c@secnumdepth \protect\numberline{the#1\endcsname}#7}}\@xsect{#5}}  \def\@sect#1#2#3#4#5#6[#7]#8{#2>\c@secnumdepth \def\@svsec{} \refstepcounter{#1}\edef\@svsec{the#1\endcsname0 5em }\@tempskipa #5\@tempskipa>\z@  #6\@hangfrom{#3\relax\@svsec}{\@M #8\par} #1mark\endcsname{#7}{toc}{#1}{#2>\c@secnumdepth \protect\numberline{the#1\endcsname}#7}\def\@svsechd{#6#3\@svsec #8#1mark{#7}{toc}{#1}{#2>\c@secnumdepth \protect\numberline{the#1\endcsname}#7}}\@xsect{#5}}  \def{\arabic{section}} \def{\thesection \arabic{subsection}} \def
### abstract ###
There are at least two kinds of similarity
Relational similarity  is  correspondence between relations, in contrast with  attributional similarity ,  which is correspondence between attributes
When two words have a high  degree of attributional similarity, we call them  synonyms
When two  pairs   of words have a high degree of relational similarity, we say that their  relations are  analogous
For example, the word pair mason:stone is analogous  to the pair carpenter:wood
This paper introduces Latent Relational Analysis (LRA),  a method for measuring relational similarity
LRA has potential applications in many  areas, including information extraction, word sense disambiguation,   and information retrieval
Recently the Vector Space Model (VSM) of information  retrieval has been adapted to measuring relational similarity,  achieving a score of 47\% on a collection of 374 college-level multiple-choice  word analogy questions
In the VSM approach, the relation between a pair of words is  characterized by a vector of frequencies of predefined patterns in a large corpus
LRA extends the VSM approach in three ways: (1) the patterns are derived automatically  from the corpus, (2) the Singular Value Decomposition (SVD) is used to smooth the frequency  data, and (3) automatically generated synonyms are used to explore variations of the  word pairs
LRA achieves 56\% on the 374 analogy questions, statistically equivalent to the  average human score of 57\%
On the related problem of classifying semantic relations, LRA  achieves similar gains over the VSM
### introduction ###
There are at least two kinds of similarity
Attributional similarity  is correspondence between attributes and  relational similarity  is correspondence between relations  CITATION
When two words have a high degree of attributional  similarity, we call them  synonyms
When two word  pairs  have a high  degree of relational similarity, we say they are  analogous
Verbal analogies are often written in the form  A:B::C:D\/ ,  meaning  A is to B as C is to D ; for example,  traffic:street::water:riverbed
Traffic flows over a street;  water flows over a riverbed
A street carries traffic;  a riverbed carries water
There is a high degree of relational similarity between the word pair traffic:street and the word pair water:riverbed
In fact, this analogy is the basis of several mathematical theories of  traffic flow  CITATION
In Section~, we look more closely at the connections between attributional and relational similarity
In analogies such as mason:stone::carpenter:wood, it seems that  relational similarity can be reduced to attributional similarity,  since mason and carpenter are attributionally similar, as are stone  and wood
In general, this reduction fails
Consider the analogy traffic:street::water:riverbed
Traffic and water are not attributionally similar
Street and riverbed are only moderately attributionally similar
Many algorithms have been proposed for measuring the attributional  similarity between two words   CITATION
Measures of attributional similarity have been studied   extensively, due to their applications in problems such as recognizing synonyms  CITATION ,  information retrieval  CITATION , determining semantic orientation  CITATION ,  grading student essays  CITATION , measuring textual cohesion  CITATION , and word sense disambiguation  CITATION
On the other hand, since measures of relational  similarity are not as well developed as  measures of attributional similarity, the potential applications of  relational similarity are not as well known
Many problems that involve semantic relations would benefit from an algorithm for measuring relational similarity
We discuss related problems in natural language processing, information retrieval, and information extraction in more detail in Section~
This paper builds on the Vector Space Model (VSM) of information retrieval
Given a query, a search engine produces a ranked list of documents
The documents are ranked in order of decreasing attributional similarity between the query and each document
Almost all modern search engines measure attributional similarity using the VSM  CITATION  \namecite{turneylittman05} adapt the VSM approach to measuring relational similarity
They used a vector of frequencies of patterns in a corpus to represent the relation between a pair of words
Section~ presents the VSM approach to measuring similarity
In Section~, we present an algorithm for measuring  relational similarity, which we call Latent Relational Analysis (LRA)
The algorithm learns from a large corpus of unlabeled, unstructured  text, without supervision
LRA extends the VSM approach of  \namecite{turneylittman05} in three ways: (1) The connecting  patterns are derived automatically from the corpus, instead of using a fixed set of patterns (2) Singular Value Decomposition  (SVD) is used to smooth the frequency data (3) Given a word pair  such as traffic:street, LRA considers transformations of the word  pair, generated by replacing one of the words by synonyms, such as  traffic:road, traffic:highway
Section~ presents our experimental evaluation  of LRA with a collection of 374 multiple-choice word analogy questions  from the SAT college entrance exam
An example of a typical SAT question appears in Table~
In the educational testing literature, the first pair  (mason:stone) is called the  stem  of the analogy
The correct choice is called the  solution  and the incorrect choices are  distractors
We evaluate LRA by testing its ability to select the solution and avoid the distractors
The average performance of college-bound senior high school students  on verbal SAT questions corresponds to an accuracy of  about 57\%
LRA achieves an accuracy  of about 56\%
On these same questions, the VSM attained 47\% }  One application for relational similarity is classifying semantic  relations in noun-modifier pairs  CITATION
In Section~, we evaluate the performance of LRA  with a set of 600 noun-modifier pairs from \namecite{nastase03}
The problem is to classify a noun-modifier pair, such as ``laser printer'',  according to the semantic relation between the head noun (printer) and  the modifier (laser)
The 600 pairs have been manually labeled with 30  classes of semantic relations
For example, ``laser printer'' is classified  as  instrument ; the printer uses the laser as an instrument for printing
We approach the task of classifying semantic relations in noun-modifier  pairs as a supervised learning problem
The 600 pairs are divided into  training and testing sets and a testing pair is classified according  to the label of its single nearest neighbour in the training set
LRA  is used to measure distance (i e , similarity, nearness)
LRA achieves  an accuracy of 39 8\% on the 30-class problem and 58 0\% on the 5-class  problem
On the same 600 noun-modifier pairs, the VSM had accuracies of  27 8\% (30-class) and 45 7\% (5-class)  CITATION
We discuss the experimental results, limitations of LRA, and future work  in Section~ and we conclude in Section~
### abstract ###
The problem of joint universal source coding and modeling, addressed by Rissanen in the context of lossless codes, is generalized to fixed-rate lossy coding of continuous-alphabet memoryless sources
We show that, for bounded distortion measures, any compactly parametrized family of  iid 
real vector sources with absolutely continuous marginals (satisfying appropriate smoothness and Vapnik--Chervonenkis learnability conditions) admits a joint scheme for universal lossy block coding and parameter estimation, and give nonasymptotic estimates of convergence rates for distortion redundancies and variational distances between the active source and the estimated source
We also present explicit examples of parametric sources admitting such joint universal compression and modeling schemes
### introduction ###
In universal data compression, a single code achieves asymptotically optimal performance on all sources within a given family
Intuition suggests that a good universal coder should acquire an accurate model of the source statistics from a sufficiently long data sequence and incorporate this knowledge in its operation
For lossless codes, this intuition has been made rigorous by Rissanen  CITATION
Under his scheme, the data are encoded in a  two-stage  set-up, in which the binary representation of each source block consists of two parts: (1) a suitably quantized maximum-likelihood estimate of the source parameters, and (2) lossless encoding of the data matched to the acquired model; the redundancy of the resulting code converges to zero as  SYMBOL , where  SYMBOL  is the block length
In this paper, we extend Rissanen's idea to  lossy  block coding (vector quantization) of  iid 
sources with values in  SYMBOL  for some finite  SYMBOL
Specifically, let  SYMBOL  be an  iid 
source with the marginal distribution of  SYMBOL  belonging to some indexed class  SYMBOL  of absolutely continuous distributions on  SYMBOL , where  SYMBOL  is a bounded subset of  SYMBOL  for some  SYMBOL
For bounded distortion measures, our main result, Theorem~, states that if the class  SYMBOL  satisfies certain smoothness and learnability conditions, then there exists a sequence of finite-memory lossy block codes that achieves asymptotically optimal compression of each source in the class and permits asymptotically exact identification of the active source with respect to the  variational distance , defined as  SYMBOL , where the supremum is over all Borel subsets of  SYMBOL
The overhead rate and the distortion redundancy of the scheme converge to zero as  SYMBOL  and  SYMBOL , respectively, where  SYMBOL  is the block length, while the active source can be identified up to a variational ball of radius  SYMBOL  eventually almost surely
We also describe an extension of our scheme to unbounded distortion measures satisfying a certain moment condition, and present two examples of parametric families satisfying the regularity conditions of Theorem~
While most existing schemes for universal lossy coding rely on  implicit  identification of the active source (e g , through topological covering arguments  CITATION , Glivenko--Cantelli uniform laws of large numbers  CITATION , or nearest-neighbor code clustering  CITATION ), our code builds an  explicit model  of the mechanism responsible for generating the data and then selects an appropriate code for the data on the basis of the model
This ability to simultaneously model and compress the data may prove useful in such applications as  media forensics   CITATION , where the parameter  SYMBOL  could represent evidence of tampering, and the aim is to compress the data in such a way that the evidence can be later extracted with high fidelity from the compressed version
Another key feature of our approach is the use of Vapnik--Chervonenkis theory  CITATION  in order to connect universal encodability of a class of sources to the combinatorial ``richness" of a certain collection of decision regions associated with the sources
In a way, Vapnik--Chervonenkis estimates can be thought of as an (imperfect) analogue of the combinatorial method of types for finite alphabets  CITATION
### abstract ###
The versatility of exponential families, along with their attendant convexity properties, make them a popular and effective statistical model
A central issue is learning these models in high-dimensions, such as when there is some sparsity pattern of the optimal parameter
This work characterizes a certain strong convexity property of  general  exponential families, which allow their generalization ability to be quantified
In particular, we show how this property can be used to analyze generic exponential families under  SYMBOL  regularization
### introduction ###
Exponential models are perhaps the most versatile and pragmatic statistical model for a variety of reasons --- modelling flexibility (encompassing discrete variables, continuous variables, covariance matrices, time series, graphical models, etc); convexity properties allowing ease of optimization; and robust generalization ability
A principal issue for applicability to large scale problems is estimating these models when the ambient dimension of the parameters,  SYMBOL , is much larger than the sample size  SYMBOL  --- the `` SYMBOL '' regime
Much recent work has focused on this problem in the special case of linear regression in high dimensions, where it is assumed that the optimal parameter vector is sparse (e g CITATION )
This body of prior work focused on: sharply characterizing the convergence rates for the prediction loss; consistent model selection; and obtaining sparse models
As we tackle more challenging problems, there is a growing need for model selection in more general exponential families
Recent work here includes learning Gaussian graphs ( CITATION ) and Ising models ( CITATION )
Classical results established that consistent estimation in  general  exponential families is possible, in the asymptotic limit where the number of dimensions is held constant (though some work establishes rates under certain conditions as  SYMBOL  is allowed to grow slowly with  SYMBOL   CITATION )
However, in modern problems, we typically grow  SYMBOL  rapidly with  SYMBOL  (so even asymptotically we are often interested in the regime where  SYMBOL , as in the case of sparse estimation)
While we have a handle on this question for a variety of special cases, a pressing question here is understanding how fast  SYMBOL  can scale as a function of  SYMBOL  in  general  exponential families --- such an analysis must quantify the relevant aspects of the particular family at hand which govern their convergence rate
This is the focus of this work
We should emphasize that throughout this paper, while we are interested in  modelling  with an exponential family, we are agnostic about the true underlying distribution (e
g we do not necessarily assume that the data generating process is from an exponential family) \paragraph{Our Contributions and Related Work}  The key issue in analyzing the convergence rates of exponential families in terms of their prediction loss (which we take to be the log loss) is in characterizing the nature in which they are strictly convex --- roughly speaking, in the asymptotic regime where we have a large sample size  SYMBOL  (with  SYMBOL  kept fixed), we have a central limit theorem effect where the log loss of any exponential family approaches the log loss of a Gaussian, with a covariance matrix corresponding to the Fisher information matrix
Our first main contribution is quantifying the rate at which this  effect occurs in general exponential families
In particular, we show that every exponential family satisfies a certain rather natural growth rate condition on their standardized moments and standardized cumulants (recall that the  SYMBOL -th standardized moment is the  unitless  ratio of the  SYMBOL -th central moment to the  SYMBOL -th power of the standard deviation, which for  SYMBOL  is the skew and kurtosis)
This condition is rather mild, where these moments can grow as fast as  SYMBOL
Interestingly, similar conditions have been well studied for obtaining exponential tail bounds for the convergence of a random variable to its mean~ CITATION
We show that this growth rate characterizes the rate at which the prediction loss of the exponential family behaves as a strongly convex loss function
In particular, our analysis draws many parallels to that of the analysis of Newton's method, where there is a ``burn in'' phase in which a number of iterations must occur until the function behaves as a locally quadratic function --- in our statistical setting, we now require a (quantified) ``burn in'' sample size, where beyond this threshold sample size, the prediction loss inherits the desired strong convexity properties (i e it is locally quadratic)
Our second contribution is an analysis of  SYMBOL  regularization in generic families, in terms of both prediction loss and the sparsity level of the selected model
Under a particular sparse eigenvalue condition on the design matrix (the Restricted Eigenvalue (RE) condition in  CITATION ), we show how  SYMBOL  regularization in general exponential families enjoys a convergence rate of  SYMBOL  (where  SYMBOL  is the number of relevant features)
This RE condition is one of the least stringent conditions which permit  this optimal convergence rate for linear regression case (see  CITATION ) --- stronger mutual incoherence/irrepresentable conditions considered in  CITATION  also provide this rate
We show that an essentially identical convergence rate can be achieved for  general  exponential families --- our results are non-asymptotic and precisely relate  SYMBOL  and  SYMBOL
Our final contribution is one of  approximate  sparse model selection, i e where our goal is to obtain a sparse model with low prediction loss
A drawback of the RE condition in comparison to the mutual incoherence condition is that the latter permits perfect recovery of the true features (at the price of a more stringent condition)
However, for the case of the linear regression,  CITATION  show that, under a sparse eigenvalue or RE condition, the  SYMBOL  solution is actually sparse itself (with a multiplicative increase in the sparsity level, that depends on a certain condition number of the design matrix) -- so while the the  SYMBOL  solution may not precisely recover the true model, it still is sparse (with some multiplicative increase) and does recover those features with large true weights
For general exponential families, while we do not have a characterization of the sparsity level of the  SYMBOL -regularized solution (an interesting open question), we do however provide a simple two stage procedure (thresholding and refitting) which provides a sparse model, with support on no more than merely  SYMBOL  features and which has nearly as good performance (with a rather mild increase in the risk) --- this result is novel even for the square loss case
Hence, even under the rather mild RE condition, we can obtain both a favorable convergence rate and a  sparse model for generic families
      nips07submit_e
sty                                                                                  0000644 0000000 0000000 00000016414 11272723522 013176  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   %%%% NIPS Macros (LaTex)    \renewcommand{\topfraction}{0 95}   % let figure take up nearly whole page \renewcommand{\textfraction}{0 05}  % let figure take up nearly whole page   \setlength{\paperheight}{11in} \setlength{\paperwidth}{8 5in} 5in    %   Note = 5in 0 07 true in -0 625in \addtolength{\headsep}{0 25in} 9 0 true in       % Height of text (including footnotes & figures) 5 5 true in        % Width of text line \widowpenalty=10000 \clubpenalty=10000   \def\addcontentsline#1#2#3{}  \def\maketitle{ \def\thefootnote{\fnsymbol{footnote}} \def\@makefnmark{to 0pt{ SYMBOL \hss}} % for perfect author \long\def\@makefntext##1{1em to1 8em{ SYMBOL }##1} \@maketitle \@thanks \setcounter{footnote}{0} \let\maketitle\let\@maketitle\gdef\@thanks{}\gdef\@author{}\gdef\@title{}\let\thanks\relax}   \def\makeanontitle{ \def\thefootnote{\fnsymbol{footnote}} \def\@makefnmark{to 0pt{ SYMBOL \hss}} % for perfect author \long\def\@makefntext##1{1em to1 8em{ SYMBOL }##1} \@makeanontitle \@thanks \setcounter{footnote}{0} \let\makeanontitle\let\@makeanontitle\gdef\@thanks{}\gdef\@title{}\let\thanks\relax}    \def\@maketitle{\vbox{\hsize\linewidth0 1in {\LARGE\@title\par}  % 0 1in %  minus \def\And{\end{tabular}\hfil\linebreak[0]\hfil\linebreak[4]%  0 3in minus 0 1in}}  \def\@makeanontitle{\vbox{\hsize\linewidth0 1in {\LARGE\@title\par}  % 0 1in %  minus %  0 3in minus 0 1in}}  \renewenvironment{abstract}{\vskip 075in\centerline{\largeAbstract}1ex}  \def
### abstract ###
Ensemble methods, such as stacking, are designed to boost predictive accuracy by blending the predictions of multiple machine learning models
Recent work has shown that the use of meta-features, additional inputs describing each example in a dataset, can boost the performance of ensemble methods, but the greatest reported gains have come from nonlinear procedures requiring significant tuning and training time
Here, we present a linear technique, Feature-Weighted Linear Stacking (FWLS), that incorporates meta-features for improved accuracy while retaining the well-known virtues of linear regression regarding speed, stability, and interpretability
FWLS combines model predictions linearly using coefficients that are themselves linear functions of meta-features
This technique was a key facet of the solution of the second place team in the recently concluded Netflix Prize competition
Significant increases in accuracy over standard linear stacking are demonstrated on the Netflix Prize collaborative filtering dataset
### introduction ###
``Stacking'' is a technique in which the predictions of a collection of models are given as inputs to a second-level learning algorithm
This second-level algorithm is trained to combine the model predictions optimally to form a final set of predictions
Many machine learning practitioners have had success using stacking and related techniques to boost prediction accuracy beyond the level obtained by any of the individual models
In some contexts, stacking is also referred to as blending, and we will use the terms interchangeably here
Since its introduction  CITATION , modellers have employed stacking successfuly on a wide variety of problems, including chemometrics  CITATION , spam filtering  CITATION , and large collections of datasets drawn from the UCI Machine learning repository  CITATION
One prominent recent example of the power of model blending was the Netflix Prize collaborative filtering competition
The team  BellKor's Pragmatic Chaos  won the \$1 million prize using a blend of hundreds of different models  CITATION
Indeed, the winning solution was a blend at multiple levels, i e , a blend of blends
Intuition suggests that the reliability of a model may vary as a function of the conditions in which it is used
For instance, in a collaborative filtering context where we wish to predict the preferences of customers for various products, the amount of data collected may vary significantly depending on which customer or which product is under consideration
Model A may be more reliable than model B for users who have rated many products, but model B may outperform model A for users who have only rated a few products
In an attempt to capitalize on this intuition, many researchers have developed approaches that attempt to improve the accuracy of stacked regression by adapting the blending on the basis of side information
Such an additional source of information, like the number of products rated by a user or the number of days since a product was released, is often referred to as a ``meta-feature,'' and we will use that terminology here
Unsurprisingly, linear regression is the most common learning algorithm used in stacked regression
The many virtues of linear models are well known to modellers
The computational cost involved in fitting such models (via the solution of a linear system) is usually modest and always predictable
They typically require a minimum of tuning
The transparency of the functional form lends itself naturally to interpretation
At a minimum, linear models are often an obvious initial attempt against which the performance of more complex models is benchmarked
Unfortunately, linear models do not (at first glance) appear to be well suited to capitalize on meta-features
If we simply merge a list of meta-features with a list of models to form one overall list of independent variables to be linearly combined by a blending algorithm, then the resulting functional form does not appear to capture the intuition that the relative emphasis given the predictions of various models should depend on the meta-features, since the coefficient associated with each model is constant and unaffected by the values of the meta-features
Previous work has indeed suggested that nonlinear, iteratively trained models are needed to make good use of meta-features for blending
The winning Netflix Prize submission of  BellKor's Pragmatic Chaos  is a complex blend of many sub-blends, and many of the sub-blends use blending techniques which incorporate meta-features
The number of user and movie ratings, the number of items the user rated on a particular day, the date to be predicted, and various internal parameters extracted from some of the recommendation models were all used within the overall blend
In almost all cases, the algorithms used for the sub-blends incorporating meta-features were nonlinear and iterative, i e , either a neural network or a gradient-boosted decision tree
In  CITATION , a system called STREAM (Stacking Recommendation Engines with Additional Meta-Features) which blends recommendation models is presented
Eight meta-features are tested, but the results showed that most of the benefit came from using the number of user ratings and the number of item ratings, which were also two of the most commonly used meta-features by  BellKor's Pragmatic Chaos
Linear regression, model trees, and bagged model trees are used as blending algorithms with bagged model trees yielding the best results
Linear regression was the least successful of the approaches
Collaborative filtering is not the only application area where the use of meta-features or other dynamic approaches to model blending has been attempted
In a classification problem context  CITATION , Dzeroski and Zenko attempt to augment a linear regression stacking algorithm by meta-features such as the entropy of the predicted class probabilities, although they found that it yielded limited benefit on a suite of tasks from the UC Irvine machine learning repository
An approach which does not use meta-features per se but which does employ an adaptive approach to blending is described by Puuronen, Terziyan, and Tsymbal  CITATION
They present a blending algorithm based on weighted nearest neighbors which changes the weightings assigned to the models depending on estimates of the accuracies of the models within particular subareas of the input space
Thus, a survey of the pre-existing literature suggests that nonparametric or iterative nonlinear approaches are usually required in order to make good use of meta-features when blending
The method presented in this paper, however, can capitalize on meta-features while being fit via linear regression techniques
The method does not simply add meta-features as additional inputs to be regressed against
It parametrizes the coefficients associated with the models as linear functions of the meta-features
Thus, the technique has all the familiar speed, stability, and interpretability advantages associated with linear regression while still yielding a significant accuracy boost
The blending approach was an important part of the solution submitted by  The Ensemble , the team which finished in second place in the Netflix Prize competition
### abstract ###
The Lipschitz multi-armed bandit (MAB) problem generalizes the classical multi-armed bandit problem by assuming one is given side information consisting of a priori upper bounds on the difference in expected payoff between certain pairs of strategies
Classical results of Lai-Robbins~ CITATION  and Auer et al ~ CITATION  imply a logarithmic regret bound for the Lipschitz MAB problem on finite metric spaces
Recent results on continuum-armed bandit problems and their generalizations imply lower bounds of  SYMBOL , or stronger, for many infinite metric spaces such as the unit interval
Is this dichotomy universal
We prove that the answer is yes: for every metric space, the optimal regret of a Lipschitz MAB algorithm is either bounded above by any  SYMBOL , or bounded below by any  SYMBOL
Perhaps surprisingly, this dichotomy does not coincide with the distinction between finite and infinite metric spaces; instead it depends on whether the completion of the metric space is compact and countable
Our proof connects upper and lower bound techniques in online learning with classical topological notions  such as perfect sets and the Cantor-Bendixson theorem
We also consider the  full-feedback  (a k a ,  best-expert ) version of Lipschitz MAB problem, termed the  Lipschitz experts problem , and show that this problem exhibits a similar dichotomy
We proceed to give nearly matching upper and lower bounds on regret in the Lipschitz experts problem on uncountable metric spaces
These bounds are of the form  SYMBOL , where the exponent  SYMBOL  depends on the metric space
To characterize this dependence, we introduce a novel dimensionality notion tailored to the experts problem
Finally, we show that both Lipschitz bandits and Lipschitz experts problems become completely intractable (in the sense that no algorithm has regret  SYMBOL ) if and only if the completion of the metric space is non-compact
### introduction ###
Multi-armed bandit (henceforth, MAB) problems have been studied for more than fifty years as a clean abstract setting for analyzing the exploration-exploitation tradeoffs that are common in sequential decision making
In the  stochastic MAB problem , an algorithm must repeatedly choose from a fixed set of strategies (a k a ``arms"), each time receiving a random payoff whose distribution depends on the strategy selected
The performance of MAB algorithms is commonly evaluated in terms of  regret : the difference in expected payoff between the algorithm's choices and always playing one fixed strategy
In addition to their many applications --- which range from experimental design to online auctions and web advertising --- another appealing feature of multi-armed bandit algorithms is that they are surprisingly efficient in terms of the growth rate of regret: for finite-armed bandit problems, algorithms whose regret at time  SYMBOL  scales as  SYMBOL  have been known for more than two decades, beginning with the seminal work of Lai and Robbins~ CITATION  and extended in subsequent work such as~ CITATION
Many of the applications of MAB problems --- especially the computer science applications such as online auctions, web advertising, or adaptive routing --- require considering strategy sets which are very large or even infinite
For infinite strategy sets the  SYMBOL  bound does not apply, while for very large finite sets the  SYMBOL  notation masks a prohibitively large constant
Indeed, without making any assumptions about the strategies and their payoffs, bandit problems with large strategy sets allow for no non-trivial solutions --- any MAB algorithm performs as badly, on some inputs, as random guessing
This motivates the study of bandit problems in which the strategy set is large but one is given  side information  constraining the form of the payoffs
Such problems have  become the subject of quite intensive study in recent years, eg ~ CITATION
The  Lipschitz MAB problem  is a version of the stochastic MAB problem in which the side information consists of  a priori  upper bounds on the difference in expected payoff between certain pairs of strategies
This models situations where the decision maker has access to some similarity information about strategies which ensures that similar strategies obtain similar payoffs
Abstractly, the similarity information may be modeled as defining a  metric space  structure on the strategy set, and the side constraints imply that the expected payoff function  SYMBOL  is a Lipschitz function (with Lipschitz constant  SYMBOL ) on this metric space
%, with Lipschitz constant  SYMBOL
The Lipschitz MAB problem was introduced by Kleinberg et al ~ CITATION
Preceding work~ CITATION  has studied the problem  in a few specific metric spaces such as a one-dimensional real interval
The prior work considered regret  SYMBOL  as a function of time  SYMBOL , and focused on the asymptotic dependence of  SYMBOL  on, loosely speaking, the dimensionality of the metric space
Various upper and lower bounds of the form  SYMBOL  were proved, where the exponent  SYMBOL  depends on the metric space
In particular, if the metric space is the interval  SYMBOL  with the standard metric  SYMBOL , then there exists an algorithm with regret  SYMBOL , and this bound is tight up to polylog factors~ CITATION
More generally, for an arbitrary infinite metric space  SYMBOL  one can define an isometry invariant  SYMBOL  such that there exists an algorithm with regret  SYMBOL , which is tight up to polylog factors if  SYMBOL ; see~ CITATION
The following picture emerges
Although algorithms with regret  SYMBOL  are known for most metric spaces, existing work unfortunately provides no examples of infinite metric spaces admitting bandit algorithms satisfying the Lai-Robbins regret bound  SYMBOL , although this bound holds for all finite metrics
In fact, for most metric spaces that have been studied (such as the unit interval) this possibility is  excluded  by known lower bounds of the form  SYMBOL  where  SYMBOL  Therefore it is natural to ask,    Is    SYMBOL  regret the best possible for an infinite metric space
Alternatively, are there infinite metric spaces for which one can achieve regret  SYMBOL
Is there any metric space for which the best possible regret is  between   SYMBOL  and  SYMBOL
% for any metric space \xhdr{Our contributions } To make the above issue more concrete, let us put forward the following definition
We settle the questions listed above by proving the following dichotomy
It is worth mentioning that the regret bound  SYMBOL  is the best possible, even for two-armed bandit problems, by a lower bound of Lai and Robbins~ CITATION
Thus our upper bound for Lipschitz MAB problems in compact, countable metric spaces is nearly the best possible bound for such spaces, modulo the gap between `` SYMBOL " and `` SYMBOL "
Furthermore, we show that this gap is inevitable for infinite metric spaces:    We turn our attention to the  full-feedback  version of the Lipschitz MAB problem
For any MAB problem there exists a corresponding  full-feedback  problem in which after each round, the payoffs from all strategies are revealed
Such settings have been extensively studied in the online learning literature under the name  best experts problems ~ CITATION
In particular, for a finite set of strategies one can achieve a  constant  regret~ CITATION  when payoffs are  iid 
over time
In addition to the full feedback, one could also consider a version in which the payoffs are revealed for some but not all strategies
Specifically, we define the  double feedback , where in each round the algorithm selects two strategies: the ``bet" for which it receives the payoff, and the ``free peek"
After the round, the payoffs are revealed for both strategies
By abuse of notation, we will treat the bandit setting as a special case of the experts setting
The experts version of the Lipschitz MAB problem, called the  Lipschitz experts problem , is defined in the obvious way: a problem instance is specified by a triple  SYMBOL , where  SYMBOL  is a metric space and  SYMBOL  is a Borel probability measure on the set  SYMBOL  of payoff functions on  SYMBOL  (with the Borel  SYMBOL -algebra induced by the product topology on  SYMBOL ) such that the expected payoff function  SYMBOL  is a Lipschitz function on  SYMBOL
In each round an algorithm is presented with an  iid 
sample from  SYMBOL
The metric structure of  SYMBOL  is known to the algorithm, the measure  SYMBOL  is not
We show that the Lipschitz experts problem exhibits a dichotomy similar to the one in Theorem~
We formulate the upper bound for the double feedback, and the lower bound for the full feedback, thus avoiding the issue of what it means for an algorithm to receive feedback for infinitely many strategies
Theorems~ and~ assert a dichotomy between metric spaces on which the Lipschitz MAB/experts problem is very tractable, and those on which it is somewhat tractable
Let us consider the opposite end of the ``tractability spectrum" and ask for which metric spaces the problem becomes completely intractable
We obtain a precise characterization: the problem is completely intractable if and only if the metric space is not pre-compact
Moreover, our upper bound is for the bandit setting, whereas the lower bound is for full feedback
Consider the \FFproblem
In view of the  SYMBOL  lower bound from Theorems~, we are interested in matching upper bounds
Gupta et al ~ CITATION  observed that such bounds hold for every metric space  SYMBOL  of finite covering dimension: namely, the Lipschitz experts problem on  SYMBOL  is  SYMBOL -tractable (Their algorithm is a version of the ``naive algorithm'' from~ CITATION ) Therefore it is natural to ask whether there exist metric spaces for which the optimal regret in the Lipschitz experts problem is  between   SYMBOL  and  SYMBOL
We settle this question by proving a characterization with nearly matching upper and lower bounds in terms of a novel dimensionality notion tailored to the experts problem
The lower bound in Theorem~ holds for a restricted version of \FFproblem\ in which a problem instance  SYMBOL  satisfies a further property that each function  SYMBOL  is itself a Lipschitz function on  SYMBOL
We term this version the   (with full feedback)
In fact, for this version we obtain a matching upper bound \OMIT{ %%%%%% To this end, we consider ``very high-dimensional" metric spaces such as exponentially branching edge-weighted trees and the space of all probability distributions on  SYMBOL  under the Earthmover distance
We introduce a novel dimensionality notion which better captures the complexity of such spaces and characterizes the regret of the ``naive" experts algorithm from~ CITATION  (Interestingly, the \ULproblem{} allows for a very non-trivial improvement in the analysis ) } %%%%%%  \OMIT{ %%%%%%% For any metric space  SYMBOL , there exist an isometry-invariant parameters  SYMBOL  and  SYMBOL  such that the \FFproblem\ on  SYMBOL  is  SYMBOL -tractable for any  SYMBOL , and not  SYMBOL -tractable for any  SYMBOL
Depending on the metric space,  SYMBOL  can take any value in  SYMBOL
There exist metric spaces for which  SYMBOL  } %%%%%%%%%  \OMIT{For any metric space  SYMBOL , there exists an isometry invariant  SYMBOL  such that the full-feedback Lipschitz experts problem on  SYMBOL  is  SYMBOL -tractable for any  SYMBOL , and not  SYMBOL -tractable for any  SYMBOL  }   \OMIT{%%%%%  } %%%%%%%%%   \OMIT{%%%%%% We introduce several new techniques, the most important of which appear in the (joint) proof of the two main results -- Theorem~ and Theorem~ } %%%%%%%  \xhdr{Connection to point-set topology } The main technical contribution of this paper is an interplay of online learning and point-set topology, which requires novel algorithmic and lower-bounding techniques
In particular, the connection to topology is essential in the (joint) proof of the two main results (Theorem~ and Theorem~)
There, we identify a simple topological property ( well-orderability ) which entails the algorithmic result, and another topological property ( perfectness ) which entails the lower bound
Perfect spaces are a classical notion in point-set topology
Topological well-orderings are implicit in the work of Cantor~ CITATION , but the particular definition given here is new, to the best of our knowledge
The proof of Theorems~ and~ (for compact metric spaces) consists of three parts: the algorithmic result for a compact well-orderable metric space, the lower bound for a metric space with a perfect subspace, and the following lemma that ties together the two topological properties
Lemma~ follows from classical theorems of Cantor-Bendixson~ CITATION  and Mazurkiewicz-Sierpinski~ CITATION
We provide a proof in Appendix~ for the sake of making our exposition self-contained
To reduce the Lipschitz MAB problem to complete metric spaces we show that the problem is  SYMBOL -tractable on a given metric space if and only if it is  SYMBOL -tractable on the completion thereof
Same is true for the double-feedback Lipschitz experts problem, and the ``only if" direction holds for the \FFproblem
Then the main dichotomy results follow from the lower bound in Theorem~ \xhdr{Accessing the metric space } We define a bandit algorithm as a (possibly randomized) Borel measurable function that maps a history of past observations  SYMBOL  to a strategy  SYMBOL  to be played in the current period
An experts algorithm is similarly defined as a (possibly randomized) Borel measurable function mapping the observation history to a strategy  SYMBOL  to be played in the current period (Or, in the case of the double feedback model, a pair of strategies representing the ``bet'' and ``free peek'' ) The observation history is either a sequence of elements of  SYMBOL  in the full feedback model, or a sequence of quadruples  SYMBOL  in the double feedback model
These definitions abstract away a potentially thorny issue of representing and accessing an infinite metric space
For our algorithmic results, we handle this issue as follows: the metric space is accessed via well-defined calls to a suitable  oracle
Moreover, the main algorithmic result in Theorems~ and~ requires an oracle which represents the well-ordering
We also provide an extension in Section~: an  SYMBOL -tractability result for a wide family of metric spaces -- including, for example, compact metric spaces with a finite number of limit points -- for which a more intuitive oracle access suffices
These are the metric spaces with a finite  Cantor-Bendixson rank , a classic notion from point-set topology \xhdr{Related work and discussion } Algorithms for the stochastic MAB problem admit regret guarantees of the form  SYMBOL , which are of two types --  instance-specific  and  instance-independent  -- depending on whether the constant in  SYMBOL  is allowed to depend on the problem instance
For instance, {ucb1}~ CITATION  admits an instance-specific guarantee  SYMBOL , whereas the best-known instance-independent guarantee for this algorithm is only  SYMBOL , where  SYMBOL  is the number of arms
Accordingly, a lower bound for the instance-independent version has to show that for any algorithm and a given time  SYMBOL , there exists a problem instance whose regret is large at this time, whereas for the instance-specific version one needs a much more ambitious argument: for any algorithm there exists a problem instance whose regret is large  infinitely often
In this paper, we focus on instance-specific guarantees \OMIT{ %%%%%%%% Apart from the stochastic MAB problem considered in this paper, several other  formulations have been studied in the literature on multi-armed bandits, which spans Operations Research, Economics and Computer Science (see~ CITATION  for background) } %%%%%%%%%  Apart from the stochastic MAB problem considered in this paper, several other MAB formulations have been studied in the literature (see~ CITATION  for background)
Early work~ CITATION  has focused on Bayesian formulations in which Bayesian priors on payoffs are known, and goal is to maximize the payoff in expectation over these priors
In these formulations, an MAB instance is a  Markov Decision Process  (MDP) in which each arm is represented by a Markov Chain with rewards on states, and the transition happens whenever the arm is played
In the more ``difficult"  restless bandits   CITATION  formulations, the state also changes when the arm is passive, according to another transition matrix
In the theoretical computer science literature, recent work in this vein includes~ CITATION
Interestingly, these Bayesian formulations have an offline flavor: given the MDP, one needs to efficiently compute a (nearly) optimal mapping from states to actions
Contrasting the Bayesian formulations in which the probabilistic model is fully specified, the  adversarial MAB problem ~ CITATION  makes no stochastic assumptions whatsoever
Instead, it makes a very pessimistic assumption that payoffs are chosen by an adversary that has access to the algorithm's code but not to its random seed
As in the stochastic MAB problem, the goal is to minimize regret
For any fixed (finite) number of arms, the best possible regret in this setting is  SYMBOL ~ CITATION
For infinite strategy sets, one often considers the  linear MAB problem  in which strategies lie in a convex subset of  SYMBOL , and in each round the payoffs form a linear function~ CITATION  \OMIT{, or more generally, a convex function~ CITATION }  It is an open question whether the ideas from the Lipschitz MAB problem extend to the above formulations
The adversarial version of the Lipschitz MAB problem is well-defined, but to the best of our knowledge, the only known result is the ``naive" algorithm from~ CITATION
One could define the stochastic version of the linear MAB problem (in which the expected payoffs form a fixed time-invariant linear function), which can be viewed as a special case of the Lipschitz MAB problem
However, this view is not likely to be fruitful because in the Lipschitz MAB problem measuring a payoff of one arm is useless for estimating the payoffs of distant arms, whereas in prior work on the linear MAB problem inferences about distant arms are crucial
For Bayesian MAB problems with limited similarity information, it is not clear how to model this information, mainly because in the Bayesian setting similarity between arms is naturally represented via correlated priors rather than a metric space \OMIT{An  oblivious adversary  must fix all payoffs in advance before the first round; an  adaptive adversary  sees the choices made by the algorithm in all previous rounds }  \xhdr{Organization of the paper } Preliminaries are in Section~
We present a joint proof for the two main results (Theorems~ and~)
The lower bound is proved in Section~ and the algorithmic results are in Section~
Coupled with the topological equivalence (Lemma~), this gives the proof for compact metric spaces
A complementary  SYMBOL -intractability result for infinite metric spaces (Theorem~) is in Section~
The  SYMBOL -tractability result via simpler oracle access (for metric spaces of finite Cantor-Bendixson rank) is in Section~
The boundary-of-tractability result  (Theorems~) is in Section~
The \FFproblem\ in a (very) high dimension (including Theorems~ and~) is discussed in Sections~ and~
Some of the proofs are moved to appendices
In Appendix~ we reduce the problem to that on complete metric spaces
All KL-divergence arguments (which underlie our lower bounds) are gathered in Appendix~
We provide a self-contained proof of the topological lemma  (Lemma~) in Appendix~
### abstract ###
We consider computation of permanent of a positive  SYMBOL  non-negative matrix,  SYMBOL , or equivalently the problem of weighted counting of the perfect matchings over the complete bipartite graph  SYMBOL
The problem is known to be of likely exponential complexity
Stated as the partition function  SYMBOL  of a graphical model, the problem allows exact Loop Calculus representation [Chertkov, Chernyak '06] in terms of an interior minimum of the Bethe Free Energy functional over non-integer doubly stochastic matrix of marginal beliefs,  SYMBOL , also correspondent to a fixed point of the iterative message-passing algorithm of the Belief Propagation (BP) type
Our main result is an explicit expression of the exact partition function (permanent) in terms of the matrix of BP marginals,   SYMBOL , as  SYMBOL , where  SYMBOL  is the BP expression for the permanent stated explicitly in terms of  SYMBOL
We give two derivations of the formula, a direct one based on the Bethe Free Energy and an alternative one combining the Ihara graph- SYMBOL  function and the Loop Calculus approaches
Assuming that the matrix  SYMBOL  of the Belief Propagation marginals is calculated, we provide two lower bounds and one upper-bound to estimate the multiplicative term
Two complementary lower bounds are based on the Gurvits-van der Waerden theorem and on a relation between the modified permanent and determinant respectively
### introduction ###
The problem of calculating the permanent of a non-negative matrix arises in many contexts in statistics,  data analysis and physics
For example, it is intrinsic to the parameter learning of a flow used to follow particles in turbulence and to cross-correlate two subsequent images  CITATION
However, the problem is  SYMBOL -hard   CITATION ,  meaning that solving it in a time polynomial in the system size,  SYMBOL , is unlikely
Therefore, when size of the matrix is sufficiently large, one naturally looks for ways to approximate the permanent
A very significant breakthrough  was achieved with invention of a so-called Fully-Polynomial-Randomized Algorithmic Schemes (FPRAS) for the permanent problem  CITATION : the permanent is approximated in a polynomial time, with high probability and within an arbitrarily small relative error
However, the complexity of this FPRAS is  SYMBOL , making it impractical for the majority of realistic applications
This motivates the task of finding a lighter deterministic or probabilistic algorithm capable of evaluating the permanent more efficiently
This paper continues the thread of  CITATION  and  CITATION , where the Belief Propagation (BP) algorithm was suggested as an efficient heuristic of good (but not absolute) quality to approximate the permanent
The BP family of algorithms, originally introduced in the context of error-correction codes  CITATION  and artificial intelligence  CITATION , can generally be stated for any graphical model  CITATION
The exactness of the BP on any graph without loops  suggests that the algorithm can be an efficient heuristic for evaluating the partition function or for finding a Maximum Likelihood (ML) solution for the Graphical Model (GM) defined on sparse graphs
However, in the general loopy cases one would normally not expect BP to work well,  thus making the heuristic results of  CITATION  somehow surprising, even though not completely unexpected in view of existence of polynomially efficient algorithms for the ML version of the problem  CITATION , also realized in  CITATION  via an iterative BP algorithm
This raises the questions of understanding the performance of BP: what it does well and what it misses
It also motivates the challenge of improving the BP heuristics
An approach potentially capable of handling the question and the challenge was recently suggested in the general framework of GM
The Loop Series/Calculus (LS) of  CITATION  expresses the ratio between the Partition Function (PF) of a binary GM and its BP estimate in terms of a finite series, in which each term is associated with the so-called generalized loop (a subgraph with all vertices of degree larger than one) of the graph
Each term in the series,  as well as the BP estimate of the partition function, is expressed in terms of a doubly stochastic matrix of marginal probabilities,  SYMBOL , for matching pairs to contribute a perfect matching
This matrix  SYMBOL  describes a minimum of the so-called Bethe free energy,  and it can also be understood as a fixed point of an iterative BP algorithm
The first term in the resulting LS is equal to one
Accounting for all the loop-corrections, one recovers the exact expression for the PF
In other words,  the LS holds the key to understanding the gap between the approximate BP estimate for the PF and the exact result
In section  and section , we will give a technical introduction to the variational Bethe Free Energy (BFE) formulation of BP and a brief overview of the LS approach for the permanent problem respectively {Our results } In this paper, we develop an LS-based approach to describe the quality of the BP approximation for the permanent of a non-negative matrix (i) Our natural starting point is the analysis of the BP solution itself conducted in section
Evaluating the permanent of the non-negative matrix,  SYMBOL , dependent on the temperature parameter,  SYMBOL , we find that a non-integer BP solution is observed only at  SYMBOL , where  SYMBOL  is defined by \eq() (ii) At  SYMBOL , we derive an alternative representation for the LS in section
The entire LS is collapsed to a product of two terms: the first term is an easy-to-calculate function of  SYMBOL , and the second term is the permanent of the matrix,  SYMBOL  (The binary operator  SYMBOL  denotes the element-wise multiplication of matrices ) This is our main result stated in theorem , and the majority of the consecutive statements of our paper follows from it
We also present yet another, alternative, derivation of the theorem  using the multivariate Ihara-Bass formula for the graph zeta-function in subsection  (iii) Section  presents two easy-to-calculate lower bounds for the LS
The lower bound stated in the corollary  is based on the Gurvits-van der Waerden theorem applied to  SYMBOL
Interestingly enough this lower bound is invariant with respect to the BP transformation, i e it is exactly equivalent to the lower bound derived via application of the van der Waerden-Gurvits theorem to the original permanent
Another lower bound is stated in theorem
Note,  that as follows from an example discussed in the text, the two lower bounds are complementary: the latter is stronger at sufficiently small temperatures,  while the former dominates the large  SYMBOL  region (iv) Section  discusses an upper bound on the transformed permanent based on the application of the Godzil-Gutman formula and the Hadamard inequality
Possible future extensions of the approach are discussed in section
### abstract ###
% This paper describes a methodology for detecting anomalies from sequentially observed and potentially noisy data
The proposed approach consists of two main elements: (1)  filtering , or assigning a belief or likelihood to each successive measurement based upon our ability to predict it from previous noisy observations, and (2)  hedging , or flagging potential anomalies by comparing the current belief against a time-varying and data-adaptive threshold
The threshold is adjusted based on the available feedback from an end user
Our algorithms, which combine universal prediction with recent work on online convex programming, do not require computing posterior distributions given all current observations and involve simple primal-dual parameter updates
At the heart of the proposed approach lie exponential-family models which can be used in a wide variety of contexts and applications, and which yield methods that achieve sublinear per-round regret against both static and slowly varying product distributions with marginals drawn from the same exponential family
Moreover, the regret against static distributions coincides with the minimax value of the corresponding online strongly convex game
We also prove bounds on the number of mistakes made during the hedging step relative to the best offline choice of the threshold with access to all estimated beliefs and feedback signals
We validate the theory on synthetic data drawn from a time-varying distribution over binary vectors of high dimensionality, as well as on the Enron email dataset \\   {Keywords:} anomaly detection, exponential families, filtering, individual sequences, label-efficient prediction, minimax regret, online convex programming, prediction with limited feedback, sequential probability assignment, universal prediction
### introduction ###
\PARstart{I}{n this} paper, we explore the performance of online anomaly detection methods built on sequential probability assignment and dynamic thresholding based on limited feedback
We assume we sequentially monitor the state of some system of interest
At each time step, we observe a possibly  noise-corrupted  version  SYMBOL  of the current state  SYMBOL , and need to infer whether  SYMBOL  is  anomalous  relative to the actual sequence  SYMBOL  of the past states
This inference is encapsulated in a binary decision  SYMBOL , which can be either  SYMBOL  (non-anomalous or nominal behavior) or  SYMBOL  (anomalous behavior)
After announcing our decision, we may occasionally receive  feedback  on the ``true'' state of affairs and use it to adjust the future behavior of the decision-making mechanism
Our inference engine should make good use of this feedback, whenever it is available, to improve its future performance
One reasonable way to do it is as follows
Having observed  SYMBOL  (but not  SYMBOL ), we can use this observation to assign ``beliefs" or ``likelihoods" to the clean state  SYMBOL
Let us denote this likelihood assignment as  SYMBOL
Then, if we actually had access to the clean observation  SYMBOL , we could evaluate  SYMBOL  and declare an anomaly ( SYMBOL ) if  SYMBOL , where  SYMBOL  is some positive threshold; otherwise we would set  SYMBOL  (no anomaly at time  SYMBOL )
This approach is based on the intuitive idea that a new observation  SYMBOL  should be declared anomalous if it is very unlikely based on our past knowledge (namely,  SYMBOL )
In other words, observations are considered anomalous if they are in a portion of the observation domain which has very low likelihood according to the best probability model that can be assigned to them on the basis of previously seen observations (In fact, anomaly detection algorithms based on density level sets revolve around precisely this kind of reasoning ) The complication here, however, is that we do not actually observe  SYMBOL , but rather its noise-corrupted version  SYMBOL
Thus, we settle instead for an  estimate   SYMBOL  of  SYMBOL  based on  SYMBOL  and compare this estimate against  SYMBOL
If we receive feedback  SYMBOL  at time  SYMBOL  and it differs from our label  SYMBOL , then we adjust the threshold appropriately
### abstract ###
%   <- trailing '%' for backward compatibility of
sty file The Sample Compression Conjecture of Littlestone \& Warmuth has remained unsolved for over two decades
While maximum classes (concept classes meeting Sauer's Lemma with equality) can be compressed, the compression of general concept classes reduces to compressing maximal classes (classes that cannot be expanded without increasing VC-dimension)
Two promising ways forward are: embedding maximal classes into maximum classes with at most a polynomial increase to VC dimension, and compression via operating on geometric representations
This paper presents positive results on the latter approach and a first negative result on the former, through a systematic investigation of finite maximum classes
Simple arrangements of hyperplanes in Hyperbolic space are shown to represent maximum classes, generalizing the corresponding Euclidean result
We show that  sweeping a generic hyperplane across such arrangements forms an unlabeled compression scheme of size VC dimension and corresponds to a special case of peeling the one-inclusion graph, resolving a recent conjecture of Kuzmin \& Warmuth
A bijection between finite maximum classes and certain arrangements of Piecewise-Linear (PL) hyperplanes in either a ball or Euclidean space is established
Finally we show that  SYMBOL -maximum  classes corresponding to PL hyperplane arrangements in  SYMBOL  have cubical complexes homeomorphic to a  SYMBOL -ball, or equivalently complexes that are manifolds with boundary
A main result is that PL arrangements can be swept by a moving hyperplane to unlabeled  SYMBOL -compress  any  finite maximum class, forming a peeling scheme as conjectured by Kuzmin \& Warmuth
A corollary is that some  SYMBOL -maximal classes cannot be embedded into any maximum class of VC dimension  SYMBOL , for any constant  SYMBOL
The construction of the PL sweeping involves  Pachner moves  on the one-inclusion graph, corresponding to moves of a hyperplane across the intersection of  SYMBOL  other hyperplanes
This extends the well known Pachner moves for triangulations to cubical complexes
### introduction ###
\term{Maximum} concept classes have the largest cardinality possible for their given VC dimension
Such classes are of particular interest as their special recursive structure underlies all general sample compression schemes known to-date~ CITATION
It is this structure that admits many elegant geometric and algebraic topological representations upon which this paper focuses
CITATION  introduced the study of \term{sample compression schemes}, defined as a pair of mappings for given concept class  SYMBOL : a \term{compression function} mapping a  SYMBOL -labeled  SYMBOL -sample to a subsequence of labeled examples and a \term{reconstruction} \term{function} mapping the subsequence to a concept consistent with the entire  SYMBOL -sample
A compression scheme of bounded size---the maximum cardinality of the subsequence image---was shown to imply learnability
The converse---that classes of VC dimension  SYMBOL  admit compression schemes of size  SYMBOL ---has become one of the oldest unsolved problems actively pursued within learning theory~ CITATION
Interest in the  conjecture has been motivated by its interpretation as the converse to the existence of compression bounds for PAC learnable classes~ CITATION , the basis of practical machine learning methods on compression schemes~ CITATION , and the conjecture's connection to a deeper understanding of the combinatorial properties of concept classes~ CITATION
Recently~ CITATION  achieved compression of maximum classes without the use of labels
They also conjectured that their elegant Min-Peeling Algorithm constitutes such an unlabeled  SYMBOL -compression scheme for  SYMBOL -maximum classes
As discussed in our previous work~ CITATION , maximum classes can be  fruitfully viewed as \term{cubical complexes}
These are also topological spaces, with each cube equipped with a natural topology of open sets from its standard embedding into Euclidean space
We proved that  SYMBOL -maximum classes correspond to \term{ SYMBOL -contractible complexes}---topological spaces with an identity map homotopic to a constant map---extending the result that  SYMBOL -maximum classes have trees for one-inclusion graphs
Peeling can be viewed as a special form of contractibility for maximum classes
However, there are many  non-maximum contractible cubical complexes that cannot be peeled, which demonstrates that peelability reflects more detailed structure of maximum classes than given by contractibility alone
In this paper we approach peeling from the direction of simple hyperplane arrangement representations of maximum classes
CITATION  predicted that  SYMBOL -maximum classes corresponding to simple linear hyperplane arrangements could be unlabeled  SYMBOL -compressed by sweeping a generic hyperplane across the arrangement, and that concepts are min-peeled as their corresponding cell is swept away
We positively resolve the first part of the conjecture and show that sweeping such arrangements corresponds to a new form of \term{corner-peeling}, which we prove is distinct from min-peeling
While \term{min-peeling} removes minimum degree concepts from a one-inclusion graph, corner-peeling peels vertices that are contained in unique cubes of maximum dimension
We explore simple hyperplane arrangements in Hyperbolic geometry, which we show correspond to a set of maximum classes, properly containing those represented by simple linear Euclidean arrangements
These classes can again be corner-peeled by sweeping
Citing the proof of existence of maximum unlabeled compression schemes due to~ CITATION ,  CITATION  ask whether unlabeled compression schemes for infinite classes such as positive half spaces can be constructed explicitly
We present constructions for illustrative but simpler classes, suggesting that there are many interesting infinite maximum classes admitting explicit compression schemes, and under appropriate conditions, sweeping infinite Euclidean, Hyperbolic or PL arrangements corresponds to compression by  corner-peeling
Next we prove that all maximum classes in  SYMBOL  are represented as simple arrangements of Piecewise-Linear (PL) hyperplanes in the  SYMBOL -ball
This extends previous work by~ CITATION  on viewing simple PL hyperplane arrangements as maximum classes
The close relationship between such arrangements and their Hyperbolic versions suggests that they could be equivalent
Resolving the main problem left open in the preliminary version of this paper,~ CITATION , we show that sweeping of  SYMBOL -contractible PL arrangements does compress all finite  maximum classes by corner-peeling, completing~ CITATION
We show that a one-inclusion graph  SYMBOL  can be represented by a  SYMBOL -contractible PL hyperplane arrangement if and only if  SYMBOL  is a strongly contractible cubical complex
This motivates the nomenclature of  SYMBOL -contractible for the class of arrangements of PL hyperplanes
Note then that these one-inclusion graphs admit a corner-peeling scheme of the same  size  SYMBOL  as the largest dimension of a cube in  SYMBOL
Moreover if such a graph  SYMBOL  admits a corner-peeling scheme, then it is a contractible cubical complex
We give a simple example to show that there are one-inclusion graphs which admit corner-peeling schemes but are not strongly contractible and so are not represented by a  SYMBOL -contractible PL hyperplane arrangement
Compressing \term{maximal classes}---classes which cannot be grown without an increase to their VC dimension---is sufficient for compressing all classes, as embedded classes trivially inherit compression schemes of their super-classes
This reasoning motivates the attempt to embed  SYMBOL -maximal classes into  SYMBOL -maximum classes~ CITATION
We present non-embeddability results following from our earlier counter-examples to Kuzmin \& Warmuth's minimum  degree conjecture~ CITATION , and our new results on corner-peeling
We explore with examples, maximal classes that can be compressed but not peeled, and classes that are not strongly contractible but can be compressed
Finally, we investigate algebraic topological properties of maximum classes
Most notably we characterize  SYMBOL -maximum classes, corresponding to simple linear Euclidean arrangements, as cubical complexes homeomorphic to the  SYMBOL -ball
The result that such classes' boundaries are homeomorphic to the  SYMBOL -sphere begins the study of the boundaries of maximum classes, which are closely related to peeling
We conclude with several open problems
### abstract ###
% In conventional supervised pattern recognition tasks, model selection is typically accomplished by minimizing the classification error rate on a set of so-called development data, subject to ground-truth labeling by human experts or some other means
In the context of speech processing systems and other large-scale practical applications, however, such labeled development data are typically costly and difficult to obtain
This article proposes an alternative semi-supervised framework for likelihood-based model selection that leverages unlabeled data by using trained classifiers representing each model to automatically generate putative labels
The errors that result from this automatic labeling are shown to be amenable to results from robust statistics, which in turn provide for minimax-optimal censored likelihood ratio tests that recover the nonparametric sign test as a limiting case
This approach is then validated experimentally using a state-of-the-art automatic speech recognition system to select between candidate word pronunciations using unlabeled speech data that only potentially contain instances of the words under test
Results provide supporting evidence for the utility of this approach, and suggest that it may also find use in other applications of machine learning
### introduction ###
\IEEEPARstart{T}{his} article develops a simple and powerful likelihood-ratio framework that enables the use of  unlabeled  development data for model selection and system optimization in the context of large-scale speech processing
Within the speech engineering community,  acoustic  likelihoods have long played a prominent role both as a training criterion and an objective function to aid in system development
Log-likelihood ratios have in turn featured ever more prominently in areas such as speech, speaker, and language recognition; for instance, it is now common practice that ``target'' model likelihoods are compared to those of a universal ``background'' model as part of many large-scale speech processing systems~ CITATION
### abstract ###
We analyze the convergence behaviour of a recently proposed algorithm for regularized estimation called Dual Augmented Lagrangian (DAL)
Our analysis is based on a new interpretation of DAL as a proximal minimization algorithm
We theoretically show under some conditions that DAL converges super-linearly in a non-asymptotic and global sense
Due to a special modelling of sparse estimation problems in the context of machine learning, the assumptions we make are milder and more natural than those made in conventional analysis of augmented Lagrangian algorithms
In addition, the new interpretation enables us to generalize DAL to wide varieties of sparse estimation problems
We  experimentally confirm our analysis in  a large scale  SYMBOL -regularized logistic regression problem and   extensively compare the efficiency of DAL algorithm to previously  proposed algorithms on both synthetic and benchmark datasets
### introduction ###
Sparse estimation through convex regularization has become a common practice in many application areas including bioinformatics and natural language processing
However facing the rapid increase in the size of data-sets that we analyze everyday, clearly needed is the development of optimization algorithms that are tailored for machine learning applications
Regularization-based sparse estimation methods estimate unknown variables through the minimization of a loss term (or a data-fit term) plus a regularization term
In this paper, we focus on convex methods; i e , both the loss term and the regularization term are convex functions of unknown variables
Regularizers may be non-differentiable on some points; the non-differentiability can promote various types of sparsity on the solution
Although the problem is convex, there are three factors that challenge the straight-forward application of general tools for convex optimization~ CITATION  in  the context of machine learning
The first factor is the diversity of loss functions
Arguably the squared loss is most commonly used in the field of signal/image reconstruction, in which many algorithms for sparse estimation have been developed~ CITATION
However the variety of loss functions is much wider in machine learning, to name a few, logistic loss and other log-linear loss functions
Note that these functions are not necessarily strongly convex like the squared loss
See Table~ for a list of loss functions that we consider
The second factor is the nature of the data matrix, which we call the design matrix in this paper
For a regression problem, the design matrix is defined by stacking input vectors along rows
If the input vectors are numerical (e g , gene expression data), the design matrix is dense and has no structure
In addition, the characteristics of the matrix (e g , the condition number) is unknown until the data is provided
Therefore, we would like to minimize assumptions about the design matrix, such as, sparse, structured, or well conditioned
The third factor is the large number of unknown variables (or parameters) compared to observations
This is a situation regularized estimation methods are commonly applied
This factor may have been overlooked in the context of signal denoising, in which the number of observations and the number of parameters are equal
Various methods have been proposed for efficient sparse estimation (see  CITATION , and the references therein)
Many previous studies focus on the  non-differentiability  of the regularization term
In contrast, we focus on the  couplings  between variables (or non-separability) caused by the design matrix
In fact, if the optimization problem can be decomposed into smaller (e g , containing a single variable) problems, optimization is easy
Recently  CITATION  showed that the so called iterative shrinkage/thresholding (IST) method (see  CITATION ) can be seen  as an iterative  separable approximation  process
In this paper, we show that a recently proposed dual augmented Lagrangian (DAL) algorithm~ CITATION  can be considered as an  exact  (up to finite tolerance) version of the iterative approximation process discussed in  CITATION
Our formulation is based on the connection between the proximal minimization~ CITATION  and the augmented Lagrangian (AL) algorithm~ CITATION
The proximal minimization framework also allows us to rigorously study the convergence behaviour of DAL
We show that DAL converges super-linearly under some mild conditions,  which means that the number of iterations that we need to obtain an  SYMBOL -accurate solution grows no greater than logarithmically with  SYMBOL
Due to the generality of the framework, our analysis applies to a wide variety of practically important regularizers
Our analysis improves the classical result on the convergence of augmented Lagrangian algorithms in  CITATION  by taking special  structures of sparse estimation into account
In addition, we make no asymptotic arguments as in  CITATION  and  CITATION ; instead our convergence analysis is build on top of the recent result in   CITATION
Augmented Lagrangian formulations have also been considered in  CITATION  and  CITATION  for sparse signal reconstruction
What differentiates DAL approach of  CITATION  from those studied earlier is that the AL algorithm is applied to the dual problem (see \Secref{sec:dalreview}), which results in an inner minimization problem that can be solved efficiently exploiting the sparsity of intermediate solutions (see \Secref{sec:dall1})
Applying AL formulation to the dual problem also plays an important role in the convergence analysis because some loss functions (e g , logistic loss) are not strongly convex in the primal; see \Secref{sec:analysis}
Recently  CITATION  compared primal and dual augmented Lagrangian algorithms for  SYMBOL -problems and reported that the dual formulation was more efficient
See also  CITATION  for related discussions
This paper is organized as follows
In \Secref{sec:framework}, we  mathematically formulate the sparse estimation problem and we review DAL algorithm
We derive DAL algorithm from the proximal  minimization framework in  \Secref{sec:proximal_view}, and   discuss special instances of DAL algorithm are discussed in \Secref{sec:instances}
In \Secref{sec:analysis}, we theoretically analyze the convergence behaviour of DAL algorithm
We discuss previously proposed algorithms in \Secref{sec:algorithms} and contrast them with DAL
In \Secref{sec:results} we confirm our analysis in a simulated  SYMBOL -regularized logistic regression problem
Moreover, we extensively compare recently proposed algorithms for  SYMBOL -regularized logistic regression including DAL in   synthetic and benchmark datasets under a variety of conditions
Finally we conclude the paper in \Secref{sec:summary}
Most of the proofs are given in the appendix
### abstract ###
% Explaining adaptive behavior is a central problem in artificial intelligence research
Here we formalize adaptive agents as mixture distributions over sequences of inputs and outputs (I/O)
Each distribution of the mixture constitutes a `possible world', but the agent does not know which of the possible worlds it is actually facing
The problem is to adapt the I/O stream in a way that is compatible with the true world
A natural measure of adaptation can be obtained by the Kullback-Leibler (KL) divergence between the I/O distribution of the true world and the I/O distribution expected by the agent that is uncertain about possible worlds
In the case of pure input streams, the Bayesian mixture provides a well-known solution for this problem
We show, however, that in the case of I/O streams this solution breaks down, because outputs are issued by the agent itself and require a different probabilistic syntax as provided by intervention calculus
Based on this calculus, we obtain a Bayesian control rule that allows modeling adaptive behavior with mixture distributions over I/O streams
This rule might allow for a novel approach to adaptive control based on a minimum KL-principle
### introduction ###
The ability to adapt to unknown environments is often considered a hallmark of intelligence  CITATION
Agent and environment can be conceptualized as two systems that exchange symbols in every time step  CITATION : the symbol issued by the agent is an action, whereas the symbol issued by the environment is an observation
Thus, both agent and environment can be conceptualized as probability distributions over sequences of actions and observations (I/O streams)
If the environment is perfectly known then the I/O probability distribution of the agent can be tailored to suit this particular environment
However, if the environment is unknown, but known to belong to a set of possible environments, then the agent faces an adaptation problem
Consider, for example, a robot that has been endowed with a set of behavioral primitives and now faces the problem of how to act while being ignorant as to which is the correct primitive
Since we want to model both agent and environment as probability distributions over I/O sequences, a natural way to measure the degree of adaptation would be to measure the `distance' in probability space between the I/O distribution represented by the agent and the I/O distribution conditioned on the true environment
A suitable measure (in terms of its information-theoretic interpretation) is readily provided by the KL-divergence  CITATION
In the case of passive prediction, the adaptation problem has a well-known solution
The distribution that minimizes the KL-divergence is a Bayesian mixture distribution over all possible environments  CITATION
The aim of this paper is to extend this result for distributions over both inputs and outputs
The main result of this paper is that this extension is only possible if we consider the special syntax of actions in probability theory as it has been suggested by proponents of causal calculus  CITATION
### abstract ###
Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation
Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates
However, this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph
We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure
The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation
By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph, we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning
Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs, which are predictive of the pixel-pair connectivity
### introduction ###
Supervised learning has emerged as a serious contender in the field of image segmentation, ever since the creation of training sets of images with {}``ground truth'' segmentations provided by humans, such as the Berkeley Segmentation Dataset  CITATION
Supervised learning requires 1) a parametrized algorithm that map images to segmentations, 2) an objective function that quantifies the performance of a segmentation algorithm relative to ground truth, and 3) a means of searching the parameter space of the segmentation algorithm for an optimum of the objective function
In the supervised learning method presented here, the segmentation algorithm consists of a parametrized  classifier  that predicts the weights of a nearest neighbor affinity graph over image pixels, followed by a graph  partitioner  that thresholds the affinity graph and finds its connected components
Our objective function is the Rand index  CITATION , which has recently been proposed as a quantitative measure of segmentation performance  CITATION
We {}``soften'' the thresholding of the classifier output and adjust the parameters of the classifier by gradient learning based on the Rand index
Because maximin edges of the affinity graph play a key role in our learning method, we call it  maximin affinity learning of image segmentation , or MALIS
The minimax path and edge are standard concepts in graph theory, and maximin is the opposite-sign sibling of minimax
Hence our work can be viewed as a machine learning application of these graph theoretic concepts
MALIS focuses on improving classifier output at maximin edges, because classifying these edges incorrectly leads to genuine segmentation errors, the splitting or merging of segments
To the best of our knowledge, MALIS is the first supervised learning method that is based on optimizing a genuine measure of segmentation performance
The idea of training a classifier to predict the weights of an affinity graph is not novel
Affinity classifiers were previously trained to minimize the number of misclassified affinity edges  CITATION
This is not the same as optimizing segmentations produced by partitioning the affinity graph
There have been attempts to train affinity classifiers to produce good segmentations when partitioned by normalized cuts  CITATION
But these approaches do not optimize a genuine measure of segmentation performance such as the Rand index
The work of Bach and Jordan  CITATION  is the closest to our work
However, they only minimize an upper bound to a renormalized version of the Rand index
Both approaches require many approximations to make the learning tractable
In other related work, classifiers have been trained to optimize performance at detecting image pixels that belong to object boundaries  CITATION
Our classifier can also be viewed as a boundary detector, since a nearest neighbor affinity graph is essentially the same as a boundary map, up to a sign inversion
However, we combine our classifier with a graph partitioner to produce segmentations
The classifier parameters are not trained to optimize performance at boundary detection, but to optimize performance at segmentation as measured by the Rand index
There are also methods for supervised learning of image labeling using Markov or conditional random fields  CITATION
But image labeling is more similar to multi-class pixel classification rather than image segmentation, as the latter task may require distinguishing between multiple objects in a single image that all have the same label
In the cases where probabilistic random field models have been used for image parsing and segmentation, the models have either been simplistic for tractability reasons  CITATION  or have been trained piecemeal
For instance, Tu et al CITATION  separately train low-level discriminative modules based on a boosting classifier, and train high-level modules of their algorithm to model the joint distribution of the image and the labeling
These models have never been trained to minimize the Rand index
### abstract ###
%   <- trailing '%' for backward compatibility of
sty file Given a sample from a probability measure with support on a submanifold in Euclidean space one can construct a neighborhood graph which can be seen as an approximation of the submanifold
The graph Laplacian of such a graph is used in several machine learning methods like semi-supervised learning, dimensionality reduction and clustering
In this paper we determine the pointwise limit of three different graph Laplacians used in the literature as the sample size increases and the neighborhood size approaches zero
We show that for a uniform measure on the submanifold all graph Laplacians have the same limit up to constants
However in the case of a non-uniform measure on the submanifold only the so called random walk graph Laplacian converges to the weighted Laplace-Beltrami operator
### introduction ###
In recent years, methods based on graph Laplacians have become increasingly popular in machine learning
They have been used in semi-supervised learning  CITATION , spectral clustering  CITATION  and dimensionality reduction  CITATION
Their popularity is mainly due to the following properties of the Laplacian which will be discussed in more detail in a later section:   the Laplacian is the generator of the diffusion process (label propagation in semi-supervised learning),  the eigenvectors of the Laplacian have special geometric properties (motivation for spectral clustering),  the Laplacian induces an adaptive regularization functional, which adapts to the density and the geometric structure of the data (semi-supervised learning, classification)
If the data lies in  SYMBOL  the neighborhood graph built from the random sample can be seen as an approximation of the continuous structure
in particular,  if the data has support on a low-dimensional submanifold the neighborhood graph is a discrete approximation of the submanifold
In machine learning we are interested in the intrinsic properties and objects of this submanifold
The approximation of the Laplace-Beltrami operator via the graph Laplacian is a very important one since it has numerous applications as we will discuss later
Approximations of the Laplace-Beltrami operator or related objects have been studied for certain special deterministic graphs
The easiest case is a grid in  SYMBOL
In numerics it is standard to approximate the Laplacian with finite-differences schemes on the grid
These can be seen as a special instances of a graph Laplacian
There convergence for decreasing grid-size follows easily by an argument using Taylor expansions
Another more involved example is the work of  CITATION , where for a graph generated by an  SYMBOL -packing of a manifold, the equivalence of certain properties of random walks on the graph and Brownian motion on the manifold have been established
The connection between random walks and the graph Laplacian becomes obvious by noting that the graph Laplacian as well as the Laplace-Beltrami operator are the generators of the diffusion process on the graph and the manifold, respectively
In  CITATION  the convergence of a discrete approximation of the Laplace Beltrami operator for a triangulation of a 2D-surface in  SYMBOL  was shown
However,  it is unclear whether the approximation described there can be written as a graph Laplacian and whether this result can be generalized to higher dimensions
In the case where the graph is generated randomly, only first results have been proved so far
The first work on the large sample limit of graph Laplacians has been done by  CITATION
There the authors studied the convergence of the regularization functional induced by the graph Laplacian using the law of large numbers for  SYMBOL -statistics
In a second step taking the limit of the neighborhoodsize  SYMBOL , they got  SYMBOL  as the effective limit operator in  SYMBOL
Their result has recently been generalized to the submanifold case and uniform convergence over the space of H\"older-functions by  CITATION
In  CITATION , the neighborhoodsize  SYMBOL  was kept fixed while the large sample limit of the graph Laplacian was considered
In this setting, the authors showed strong convergence results of graph Laplacians to certain integral operators, which imply the convergence of the eigenvalues and eigenfunctions
Thereby showing the consistency of spectral clustering for a fixed neighborhood size
In contrast to the previous work  in this paper we will consider the large sample limit and the limit as the neighborhood size approaches zero simultaneously for a certain class of neighbhorhood graphs
The main emphasis lies on the case where the data generating measure has support on a submanifold of  SYMBOL
The bias term, that is the difference between the continuous counterpart of the graph Laplacian and the Laplacian itself has been studied first for compact submanifolds without boundary by  CITATION  and  CITATION  for the Gaussian kernel and a uniform data generating measure and was then generalized by  CITATION  to general isotropic weights and general probability measures
Additionally Lafon showed that the use of data-dependent weights for the graph allows to control the influence of the density
They all show that the bias term converges pointwise if the neighborhood size goes to zero
The convergence of the graph Laplacian towards these continuous averaging operators was left open
This part was first studied by  CITATION  and  CITATION
In  CITATION  the convergence was shown for the so called unnormalized graph Laplacian in the case of a uniform probability measure on a compact manifold without boundary and using the Gaussian kernel for the weights, whereas in  CITATION  the pointwise convergence was shown for the random walk graph Laplacian in the case of general probability measures on non-compact manifolds with boundary using general isotropic data-dependent weights
More recently  CITATION  have extended the pointwise convergence for the unnormalized graph Laplacian shown by  CITATION  to uniform convergence on compact submanifolds without boundary giving explicit rates
In  CITATION , see also  CITATION , the rate of convergence given by  CITATION  has been improved in the setting of the uniform measure
In this paper we will study the three most often used graph Laplacians in the machine learning literature and show their pointwise convergence in the general setting of  CITATION  and  CITATION , that is we will in particular consider the case where by using data-dependent weights for the graph we can control the influence of the density on the limit operator
In Section  we introduce the basic framework necessary to define graph Laplacians for general directed weighted graphs and then simplify the general case to undirected graphs
in particular,  we define the three graph Laplacians used in machine learning so far, which we call the normalized, the unnormalized and the random walk Laplacian
In Section  we introduce the neighborhood graphs studied in this paper, followed by an introduction to the so called weighted Laplace-Beltrami operator, which will turn out to be the limit operator in general
We also study properties of this limit operator and provide insights why and how this operator can be used for semi-supervised learning, clustering and regression
Then finally we present the main convergence result for all three graph Laplacians and give the conditions on the neighborhood size as a function of the sample size necessary for convergence
In Section  we illustrate the main result by studying the difference between the three graph Laplacians and the effects of different data-dependent weights on the limit operator
In Section  we prove the main result
We introduce a framework for studying non-compact manifolds with boundary and provide the necessary assumptions on the submanifold  SYMBOL , the data generating measure  SYMBOL  and the kernel  SYMBOL  used for defining the weights of the edges
We would like to note that the theorems given in Section  contain slightly stronger results than the ones presented in Section
The reader who is not familiar with differential geometry will find a brief introduction to the basic material used in this paper in Appendix
### abstract ###
A dictionary defines words in terms of other words
Definitions can tell you the meanings of words you don't know, but only if you know the meanings of the defining words
How many words do you need to know (and which ones) in order to be able to learn all the rest from definitions
We reduced dictionaries to their ``grounding kernels" (GKs), about 10\% of the dictionary, from which all the other words could be defined
The GK words turned out to have psycholinguistic correlates: they were learned at an earlier age and more concrete than the rest of the dictionary
But one can compress still more: the GK turns out to have internal structure, with a strongly connected ``kernel core" (KC) and a surrounding layer, from which a hierarchy of definitional distances can be derived, all the way out to the periphery of the full dictionary
These definitional distances, too, are correlated with psycholinguistic variables (age of acquisition, concreteness, imageability, oral and written frequency) and hence perhaps with the ``mental lexicon" in each of our heads
### introduction ###
A category is a  kind  of thing (object, event, action, trait or state)
To categorize is to do the right thing (eat, fight, flee, mate, etc ) with the right kind of thing
All species can acquire categories through trial and error  sensorimotor induction
We are the only species that can also acquire and transmit categories through  verbal instruction , by naming and defining them
The words in our dictionaries are almost all the names of categories, followed by their definitions
In principle, all categories can be acquired through verbal definition, but we cannot acquire all of them that way: we have to know the meanings of some of the defining words already, by some other means
This is the ``symbol grounding problem"  CITATION  and presumably that other means of acquiring categories is sensorimotor induction
But how many words -- and which ones -- need to be grounded directly through sensorimotor induction in order to allow all the rest to be acquired through verbal definition
We have been analyzing dictionaries in order to answer this question
By eliminating all the words that can be reached from other words through definition alone, we have been able to reduce the dictionary to its ``grounding kernel" (GK) -- a set of words (about  SYMBOL ) -- out of which all the rest of the words can be reached through definition alone  CITATION
The GK has some striking properties: The words in it are learned at a significantly younger age than the rest of the dictionary and are also more concrete  CITATION , but if the variance correlated with age is removed, the residual GK words are more abstract than the rest of the dictionary
What is the cause of this polarity shift
The GK is unique, and sufficient to ground all the rest of the dictionary, but it is not  minimal  -- it is not the smallest set of words from which all the rest can be reached via definition alone
That would be a ``minimum grounding set" (MGS), which is not in general unique; we have not yet been able to compute a MGS, because this problem (equivalent to finding a ``minimum cardinality feedback vertex set'' for a general graph) is NP-complete (i e too hard to compute in general)
We hope to be able to compute MGSs for our special cases, but meanwhile the GKs of our dictionaries -- Cambridge International Dictionary of English (CIDE)  CITATION  and Longman Dictionary of Contemporary English (LDOCE)  CITATION  -- already turn out to have more differentiated internal substructure which we begin analyzing further in this article
In particular two substructures play important roles: the GK itself and a strongly connected subset of the GK that we call the ``Kernel Core" (KC)
The GK words that are acquired earlier, and are more concrete than the rest of the dictionary, tend to be in the KC, whereas the GK words uncorrelated with age of acquisition tend to be in the outer layer surrounding the KC and are more abstract
These correlations between the KC and the rest of the GK, and between the GK and the rest of the dictionary as a whole, are binary (0/1), but one can make more graded comparisons by considering definitional chains of increasing lengths
We have accordingly extracted two hierarchies based on degrees of definitional distance, one based on the GK and one based on strongly connected components, to analyze how definitional distance correlates with age of acquisition, concreteness/abstractness and other psycholinguistic variables
### abstract ###
One of the most popular algorithms for clustering in Euclidean space is the  SYMBOL -means algorithm;  SYMBOL -means is difficult to analyze mathematically, and few theoretical guarantees are known about it, particularly when the data is  well-clustered
In this paper, we attempt to fill this gap in the literature by analyzing the behavior of  SYMBOL -means on well-clustered data
In particular, we study the case when each cluster is distributed as a different Gaussian -- or, in other words, when the input comes from a mixture of Gaussians
We analyze three aspects of the  SYMBOL -means algorithm under this assumption
First, we show that when the input comes from a mixture of two spherical Gaussians, a variant of the  SYMBOL -means algorithm successfully isolates the subspace containing the means of the mixture components
Second, we show an exact expression for the convergence of our variant of the  SYMBOL -means algorithm, when the input is a very large number of samples from a mixture of spherical Gaussians
Our analysis does not require any lower bound on the separation between the mixture components
Finally, we study the sample requirement of  SYMBOL -means; for a mixture of  SYMBOL  spherical Gaussians, we show an upper bound on the number of samples required by a variant of  SYMBOL -means to get close to the true solution
The sample requirement grows with increasing dimensionality of the data, and decreasing separation between the means of the Gaussians
To match our upper bound, we show an information-theoretic lower bound on any algorithm that learns mixtures of two spherical Gaussians; our lower bound indicates that in the case when the overlap between the probability masses of the two distributions is small, the sample requirement of  SYMBOL -means is  near-optimal
### introduction ###
One of the most popular algorithms for clustering in Euclidean space is the  SYMBOL -means algorithm~ CITATION ; this is a simple, local-search algorithm that iteratively refines a partition of the input points until convergence
Like many local-search algorithms,  SYMBOL -means is notoriously difficult to analyze, and few theoretical guarantees are known about it
There has been three lines of work on the  SYMBOL -means algorithm
A first line of questioning addresses the quality of the solution produced by  SYMBOL -means, in comparison to the globally optimal solution
While it has been well-known that for general inputs the quality of this solution can be arbitrarily bad, the conditions under which  SYMBOL -means yields a globally optimal solution on  well-clustered  data are not well-understood
A second line of work~ CITATION  examines the number of iterations required by  SYMBOL -means to converge ~ CITATION  shows that there exists a set of  SYMBOL  points on the plane, such that  SYMBOL -means takes as many as  SYMBOL  iterations to converge on these points
A smoothed analysis upper bound of  SYMBOL  iterations has been established by~ CITATION , but this bound is still much higher than what is observed in practice, where the number of iterations are frequently sublinear in  SYMBOL
Moreover, the smoothed analysis bound applies to small perturbations of arbitrary inputs, and the question of whether one can get faster convergence on well-clustered inputs, is still unresolved
A third question, considered in the statistics literature, is the statistical efficiency of  SYMBOL -means
Suppose the input is drawn from some simple distribution, for which  SYMBOL -means is statistically consistent; then, how many samples is required for  SYMBOL -means to converge
Are there other consistent procedures with a better sample requirement
In this paper, we study all three aspects of  SYMBOL -means, by studying the behavior of  SYMBOL -means on Gaussian clusters
Such data is frequently modelled as a mixture of Gaussians; a mixture is a collection of Gaussians  SYMBOL  and weights  SYMBOL , such that  SYMBOL
To sample from the mixture, we first pick  SYMBOL  with probability  SYMBOL  and then draw a random sample from  SYMBOL
Clustering such data then reduces to the problem of  learning a mixture ; here, we are given only the ability to sample from a mixture, and our goal is to learn the parameters of each Gaussian  SYMBOL , as well as determine which Gaussian each sample came from
Our results are as follows
First, we show that when the input comes from a mixture of two spherical Gaussians, a variant of the  SYMBOL -means algorithm successfully isolates the subspace containing the means of the Gaussians
Second, we show an exact expression for the convergence of a variant of the  SYMBOL -means algorithm, when the input is a large number of samples from a mixture of two spherical Gaussians
Our analysis shows that the convergence-rate is logarithmic in the dimension, and decreases with increasing separation between the mixture components
Finally, we address the sample requirement of  SYMBOL -means; for a mixture of  SYMBOL  spherical Gaussians, we show an upper bound on the number of samples required by a variant of  SYMBOL -means to get close to the true solution
The sample requirement grows with increasing dimensionality of the data, and decreasing separation between the means of the distributions
To match our upper bound, we show an information-theoretic lower bound on any algorithm that learns mixtures of two spherical Gaussians; our lower bound indicates that in the case when the overlap between the probability masses of the two distributions is small, the sample requirement of  SYMBOL -means is  near-optimal
Additionally, we make some partial progress towards analyzing  SYMBOL -means in the more general case -- we show that if our variant of  SYMBOL -means is run on a mixture of  SYMBOL  spherical Gaussians, then, it converges to a vector in the subspace containing the means of  SYMBOL
The key insight in our analysis is a novel potential function  SYMBOL , which is the minimum angle between the subspace of the means of  SYMBOL , and the normal to the hyperplane separator in  SYMBOL -means
We show that this angle decreases with iterations of our variant of  SYMBOL -means, and we can characterize convergence rates and sample requirements, by characterizing the rate of decrease of the potential
One of the most popular algorithms for clustering in Euclidean space is the  SYMBOL -means algorithm CITATION
SYMBOL -means is an iterative algorithm, which begins with an initial partition of the input points, and successively refines the partition until convergence
In this paper, we perform a probabilistic analysis of  SYMBOL -means, when applied to the problem of learning mixture models
A mixture model  SYMBOL  is a collection of distributions  SYMBOL  and weights  SYMBOL , such that  SYMBOL
A sample from a mixture  SYMBOL  is obtained by selecting  SYMBOL  with probability  SYMBOL , and then selecting a random sample from  SYMBOL
Given only the ability to sample from a mixture, the problem of learning a mixture is that of (a) determining the parameters of the distributions comprising the mixture and (b) classifying the samples, according to source distribution
Most previous work on  the analysis of  SYMBOL -means~ CITATION  studies the problem in a statistical setting, and shows  consistency guarantees, when the number of samples tend to infinity
The  SYMBOL -means algorithm is also closely related to the widely-used EM algorithm~ CITATION  for learning mixture models -- essentially, the main difference between  SYMBOL -means and EM being that EM allows a sample to fractionally belong to multiple clusters and  SYMBOL -means does not
Most previous work on analyzing EM view it as an optimization procedure over the likelihood surface, and study its convergence properties by analyzing the likelihood surface around the optimum~ CITATION
In this paper, we perform a probabilistic analysis of a variant of  SYMBOL -means, when the input is generated from a mixture of spherical Gaussians
Instead of analyzing the likelihood surface, we examine the geometry of the input, and use the structure in it to show that the algorithm makes progress towards the correct solution in each round with high probability
Previous probabilistic analysis of EM, due to~ CITATION , applies when the  input comes from a mixture of spherical Gaussians, separated, such that two samples from the same Gaussian are closer in space than two samples from different Gaussians
In contrast, our analysis is much finer, and while it still deals with mixtures of two or more spherical Gaussians, applies under any separation
Moreover, we quantify the number of samples required by  SYMBOL -means to work correctly \medskip{ Our Results } More specifically, our results are as follows
We perform a probabilistic analysis of a variant of  SYMBOL -means; our variant is essentially a symmetrized version of  SYMBOL -means, and it reduces to  SYMBOL -means when we have a very large number of samples from a mixture of two identical spherical Gaussians with equal weights
In the  SYMBOL -means algorithm, the separator between the two clusters is always a hyperplane, and we use the angle  SYMBOL   between the normal to this hyperplane and the mean of a mixture component  in round  SYMBOL , as a measure of the potential in each round
Note that  when  SYMBOL , we have arrived at the correct solution
First, in Section~, we consider the case when we have at our disposal a very large number of samples from a mixture of  SYMBOL  and  SYMBOL  with mixing weights  SYMBOL  respectively
We show an exact relationship between  SYMBOL  and  SYMBOL , for any value of  SYMBOL ,  SYMBOL ,  SYMBOL  and  SYMBOL
Using this relationship, we can approximate the rate of convergence of  SYMBOL -means, for different values of the separation, as well as different initialization procedures
Our guarantees illustrate that the progress of  SYMBOL -means is very fast -- namely, the square of the cosine of  SYMBOL  grows by at least a constant factor (for high separation) each round, when one is far from the actual solution, and slow when the actual solution is very close
Next, in Section~, we characterize the sample requirement for our variant of  SYMBOL -means to succeed, when the input is a mixture of two spherical Gaussians
For the case of two identical spherical Gaussians with equal mixing weight, our results imply that when the separation  SYMBOL , and when  SYMBOL  samples are used in each round, the  SYMBOL -means algorithm makes progress at roughly the same rate as in Section~
This agrees with the  SYMBOL  sample complexity lower bound~ CITATION  for learning a mixture of Gaussians on the line, as well as with experimental results of~ CITATION
When  SYMBOL , our variant of  SYMBOL -means makes progress in each round, when the number of samples is at least  SYMBOL
Then, in Section~, we provide an information-theoretic lower bound on the sample requirement of any algorithm for learning a mixture of two spherical Gaussians with standard deviation  SYMBOL  and equal weight
We show that when the separation  SYMBOL , any algorithm requires  SYMBOL  samples to converge to a vector within angle  SYMBOL  of the true solution, where  SYMBOL  is a constant
This indicates that  SYMBOL -means has near-optimal sample requirement when  SYMBOL
Finally, in Section~, we examine the performance of  SYMBOL -means when the input comes from a mixture of  SYMBOL  spherical Gaussians
We show that, in this case, the normal to the hyperplane separating the two clusters converges to a vector in the subspace containing the means of the mixture components
Again, we characterize exactly the rate of convergence, which looks very similar to the bounds in Section~ \medskip{ Related Work } The convergence-time of the  SYMBOL -means algorithm has been analyzed in the worst-case~ CITATION , and the smoothed analysis settings~ CITATION ; ~ CITATION  shows that the convergence-time of  SYMBOL -means may be  SYMBOL  even in the plane ~ CITATION  establishes a  SYMBOL  smoothed complexity bound ~ CITATION  analyzes the performance of  SYMBOL -means when the data obeys a clusterability condition; however, their clusterability condition is very different, and moreover, they examine conditions under which constant-factor approximations can be found
In statistics literature, the  SYMBOL -means algorithm has been shown to be consistent~ CITATION  ~ CITATION  shows that minimizing the  SYMBOL -means objective function (namely, the sum of the squares of the distances between each point and the center it is assigned to), is consistent, given sufficiently many samples
As optimizing the  SYMBOL -means objective is NP-Hard, one cannot hope to always get an exact solution
None of these two works quantify either the convergence rate or the exact sample requirement of  SYMBOL -means
There has been two lines of previous work on theoretical analysis of the EM algorithm~ CITATION , which is closely related to  SYMBOL -means
Essentially, for learning mixtures of identical Gaussians, the only difference between EM and  SYMBOL -means is that EM uses  partial assignments  or  soft clusterings , whereas  SYMBOL -means does not
First, ~ CITATION  views learning mixtures as an optimization problem, and EM as an optimization procedure over the likelihood surface
They analyze the structure of the likelihood surface around the optimum to conclude that EM has first-order convergence
An optimization procedure on a parameter  SYMBOL  is said to have first-order convergence, if,   SYMBOL  where  SYMBOL  is the estimate of  SYMBOL  at time step  SYMBOL  using  SYMBOL  samples,  SYMBOL  is the maximum likelihood estimator for  SYMBOL  using  SYMBOL  samples, and  SYMBOL  is some fixed constant between  SYMBOL  and  SYMBOL
In contrast, our analysis also applies when one is far from the optimum
The second line of work is a probabilistic analysis of EM due to~ CITATION ; they show a two-round variant of EM which converges to the correct partitioning of the samples, when the input is generated by a mixture of  SYMBOL  well-separated, spherical Gaussians
For their analysis to work,  they require the mixture components to be separated such that two samples from the same Gaussian are a little closer in space than two samples from different Gaussians
In contrast, our analysis applies when the separation is much smaller
The sample requirement of learning mixtures has been previously studied in the literature, but not in the context of  SYMBOL -means ~ CITATION  provides an algorithm that learns a mixture of two binary product distributions with uniform weights, when the separation  SYMBOL  between the mixture components is at least a constant, so long as  SYMBOL  samples are available (Notice that for such distributions, the directional standard deviation is at most  SYMBOL ) Their algorithm is similar to  SYMBOL -means in some respects, but different in that they use different sets of coordinates in each round, and this is  very crucial in their analysis
Additionally,~ CITATION  show a spectral algorithm which learns a mixture of  SYMBOL  binary product distributions, when the distributions have small overlap in probability mass, and the sample size is at least  SYMBOL
CITATION  shows that at least  SYMBOL  samples are required to learn a mixture of two Gaussians in one dimension
We note that although our lower bound of  SYMBOL  for  SYMBOL  seems to contradict the upper bound of~ CITATION , this is not actually the case
Our lower bound characterizes the number of samples required to find a vector at an angle  SYMBOL  with the vector joining the means
However, in order to classify a constant fraction of the points correctly, we only need to find a vector at an angle  SYMBOL  with the vector joining the means
Since the goal of~ CITATION  is to simply classify a constant fraction of the samples, their upper bound is less than  SYMBOL
In addition to theoretical analysis, there has been very interesting experimental work due to~ CITATION , which studies the sample requirement for EM on a mixture of  SYMBOL  spherical Gaussians
They conjecture that the problem of learning mixtures has three phases, depending on the number of samples : with less than about  SYMBOL  samples, learning mixtures is information-theoretically hard; with more than about  SYMBOL  samples, it is computationally easy, and in between, computationally hard, but easy in an information-theoretic sense
Finally, there has been a line of work which provides algorithms (different from EM or  SYMBOL -means) that are guaranteed to learn mixtures of Gaussians under certain separation conditions -- see, for example,~ CITATION
For mixtures of two Gaussians, our result is comparable to the best results for spherical Gaussians~ CITATION  in terms of separation requirement, and we have a smaller sample requirement
### abstract ###
% After building a classifier with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data
Thus, we get an answer to the question  what  is the most likely label of a given unseen data point
However, most methods will provide no answer  why  the model predicted the particular label for a single instance and what features were most influential for that particular instance
The only method that is currently able to provide such explanations are decision trees
This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of  any  classification method
### introduction ###
Automatic nonlinear classification is a common and powerful tool in data analysis
Machine learning research has created methods that are practically useful and that can classify unseen data after being trained on a limited training set of labeled examples
Nevertheless, most of the algorithms do not  explain  their decision
However in practical data analysis it is essential to obtain an instance based explanation, i e we would like to gain an understanding what input features made the nonlinear machine give its answer for each individual data point
Typically, explanations are provided jointly for all instances of the training set, for example feature selection methods  (including Automatic Relevance Determination) find out which inputs are salient for a good generalization  CITATION
While this can give a coarse impression about the global usefulness of each input dimension, it is still an ensemble view and does not provide an answer on an instance basis
In the neural network literature also solely an ensemble view was taken in algorithms like input pruning  CITATION
The only classification which does provide individual explanations are decision trees  CITATION
This paper proposes a simple framework that provides local explanation vectors applicable to  any  classification method in order to help understanding prediction results for single data instances
The local explanation yields the features being relevant for the prediction at the very points of interest in the data space and is able to spot local peculiarities which are neglected in the global view eg due to cancellation effects
The paper is organized as follows: We define local explanation vectors as class probability gradients in Section  and give an illustration for Gaussian Process Classification (GPC)
Some methods output a prediction without a direct probability interpretation
For these we propose in Section  a way to estimate local explanations
In Section  we will apply our methodology to learn distinguishing properties of Iris flowers by estimating explanation vectors for a k-NN classifier applied to the classic Iris data set
Section  will discuss how our approach applied to a SVM classifier allows us to explain how digits "two" are distinguished from digit "8" in the USPS data set
In Section  we discuss a more real-world application scenario where the proposed explanation capabilities prove useful in drug discovery: Human experts regularly decide how to modify existing lead compounds in order to obtain new compounds with improved properties
Models capable of explaining predictions can help in the process of choosing promising modifications
Our automatically generated explanations match with chemical domain knowledge about toxifying functional groups of the compounds in question
Section  contrasts our approach with related work and Section  discusses characteristic properties and limitations of our approach, before we conclude the paper in Section
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                iris_knn
### abstract ###
Despite the conventional wisdom that proactive security is superior to reactive security, we show that reactive security can be competitive with proactive security as long as the reactive defender learns from past attacks instead of myopically overreacting to the last attack
Our game-theoretic model follows common practice in the security literature by making worst-case assumptions about the attacker: we grant the attacker complete knowledge of the defender's strategy and do not require the attacker to act rationally
In this model, we bound the competitive ratio between a reactive defense algorithm (which is inspired by online learning theory) and the best fixed proactive defense
Additionally, we show that, unlike proactive defenses, this reactive strategy is robust to a lack of information about the attacker's incentives and knowledge
### introduction ###
Many enterprises employ a Chief Information Security Officer~(CISO) to manage the enterprise's information security risks
Typically, an enterprise has many more security vulnerabilities than it can realistically repair
Instead of declaring the enterprise ``insecure'' until every last vulnerability is plugged, CISOs typically perform a cost-benefit analysis to identify which risks to address, but what constitutes an effective CISO strategy
The conventional wisdom~ CITATION  is that CISOs ought to adopt a ``forward-looking'' proactive approach to mitigating security risk by examining the enterprise for vulnerabilities that might be exploited in the future
Advocates of proactive security often equate reactive security with myopic bug-chasing and consider it ineffective
We establish sufficient conditions for when reacting  strategically  to attacks is as effective in discouraging attackers
We study the efficacy of reactive strategies in an economic model of the CISO's security cost-benefit trade-offs
Unlike previously proposed economic models of security (see Section~), we do not assume the attacker acts according to a fixed probability distribution
Instead, we consider a game-theoretic model with a strategic attacker who responds to the defender's strategy
As is standard in the security literature, we make worst-case assumptions about the attacker
For example, we grant the attacker complete knowledge of the defender's strategy and do not require the attacker to act rationally
Further, we make conservative assumptions about the reactive defender's knowledge and do not assume the defender knows all the vulnerabilities in the system or the attacker's incentives
However, we do assume that the defender can observe the attacker's past actions, for example via an intrusion detection system or user metrics~ CITATION
In our model, we find that two properties are sufficient for a reactive strategy to perform as well as the best proactive strategies
First, no single attack is catastrophic, meaning the defender can survive a number of attacks
This is consistent with situations where intrusions (that, say, steal credit card numbers) are regrettable but not business-ending
Second, the defender's budget is \term{liquid}, meaning the defender can re-allocate resources without penalty
For example, a CISO can reassign members of the security team from managing firewall rules to improving database access controls at relatively low switching costs
Because our model abstracts many vulnerabilities into a single graph edge, we view the act of defense as increasing the attacker's \term{cost} for mounting an attack instead of preventing the attack (e g , by patching a single bug)
By making this assumption, we choose not to study the tactical patch-by-patch interaction of the attacker and defender
Instead, we model enterprise security at a more abstract level appropriate for the CISO
For example, the CISO might allocate a portion of his or her budget to engage a consultancy, such as WhiteHat or iSEC Partners, to find and fix cross-site scripting in a particular web application or to require that employees use SecurID tokens during authentication
We make the technical assumption that attacker costs are linearly dependent on defense investments locally
This assumption does not reflect patch-by-patch interaction, which would be better represented by a step function (with the step placed at the cost to deploy the patch)
Instead, this assumption reflects the CISO's higher-level viewpoint where the staircase of summed step functions fades into a slope
We evaluate the defender's strategy by measuring the attacker's cumulative return-on-investment, the \term{return-on-attack}~(ROA), which has been proposed previously~ CITATION
By studying this metric, we focus on defenders who seek to ``cut off the attacker's oxygen,'' that is to reduce the attacker's incentives for attacking the enterprise
We do not distinguish between ``successful'' and ``unsuccessful'' attacks
Instead, we compare the payoff the attacker receives from his or her nefarious deeds with the cost of performing said deeds
We imagine that sufficiently disincentivized attackers will seek alternatives, such as attacking a different organization or starting a legitimate business
In our main result, we show sufficient conditions for a learning-based reactive strategy to be competitive with the best fixed proactive defense in the sense that the competitive ratio between the reactive ROA and the proactive ROA is at most  SYMBOL , for all  SYMBOL , provided the game lasts sufficiently many rounds (at least  SYMBOL )
To prove our theorems, we draw on techniques from the online learning literature
We extend these techniques to the case where the learner does not know all the game matrix rows  a priori , letting us analyze situations where the defender does not know all the vulnerabilities in advance
Although our main results are in a graph-based model with a single attacker, our results generalize to a model based on Horn clauses with multiple attackers
Our results are also robust to switching from ROA to attacker profit and to allowing the proactive defender to revise the defense allocation a fixed number of times
Although myopic bug chasing is most likely an ineffective reactive strategy, we find that in some situations a  strategic  reactive strategy is as effective as the optimal fixed proactive defense
In fact, we find that the natural strategy of gradually reinforcing attacked edges by shifting budget from unattacked edges ``learns'' the attacker's incentives and constructs an effective defense
Such a strategic reactive strategy is both easier to implement than a proactive strategy---because it does not presume that the defender knows the attacker's intent and capabilities---and is less wasteful than a proactive strategy because the defender does not expend budget on attacks that do not actually occur
Based on our results, we encourage CISOs to  question the assumption that proactive risk management is inherently superior to reactive risk management \paragraph{Organization } Section~ formalizes our model
Section~ shows that perimeter defense and defense-in-depth arise naturally in our model
Section~ presents our main results bounding the competitive ratio of reactive versus proactive defense strategies
Section~ outlines scenarios in which reactive security out-performs proactive security
Section~ generalizes our results to Horn clauses and multiple attackers
Section~ relates related work
Section~ concludes }
### abstract ###
% The problem is sequence prediction in the following setting
A sequence  SYMBOL  of discrete-valued observations is generated  according to some unknown probabilistic law (measure)  SYMBOL
After observing each outcome,  it is required to give the conditional probabilities of the next observation
The measure   SYMBOL  belongs to an arbitrary but known class  SYMBOL   of stochastic process measures
We are interested in predictors  SYMBOL  whose conditional probabilities converge (in some sense) to the ``true''  SYMBOL -conditional probabilities if any  SYMBOL  is chosen to generate the sequence
The contribution of this work is in characterizing the families  SYMBOL  for which such predictors exist,  and in providing a specific and simple form in which to look for a solution
We show that if any predictor works, then  there exists a Bayesian predictor,  whose   prior is discrete, and which works too
We also find several sufficient and necessary conditions for the existence of a predictor, in terms of topological characterizations of the family  SYMBOL , as well as in terms of local behaviour of the measures in  SYMBOL ,  which in some cases lead to procedures for constructing such predictors
It should be  emphasized that the framework is completely general: the stochastic processes considered are not required to be   iid  , stationary, or to belong to any parametric or countable family
### introduction ###
Given a  sequence  SYMBOL  of observations  SYMBOL , where  SYMBOL  is a finite set, we  want to predict what are the probabilities of observing  SYMBOL  for each  SYMBOL , or, more generally, probabilities of observing different  SYMBOL , before  SYMBOL  is revealed, after which the process continues
It is assumed that the sequence is generated by some unknown stochastic process  SYMBOL , a probability measure on the space of one-way infinite sequences  SYMBOL
The goal is to have a predictor whose predicted probabilities converge (in a certain sense) to the correct ones (that is, to  SYMBOL -conditional probabilities)
In general this goal is impossible to achieve if  nothing is known about the measure  SYMBOL  generating the sequence
In other words, one cannot have a predictor whose error goes to zero for any measure  SYMBOL
The problem becomes tractable if we assume that the measure  SYMBOL  generating the data belongs to some known class  SYMBOL
The  questions addressed in this work are a part of the following general problem: given an arbitrary set   SYMBOL  of measures, how can we find  a predictor that performs well when the data is generated by any   SYMBOL , and whether it is possible to find such a predictor at all
An example of a generic  property  of a class  SYMBOL  that allows for construction of a predictor, is that  SYMBOL  is countable
Clearly, this condition is very strong
An example,  important from the applications point of view,  of a class  SYMBOL  of measures   for which  predictors are known,  is the class of all stationary measures
The general question, however, is very far from being answered
The contribution of this work to solving this question is, first, in that we  provide a specific form in which to look for a predictor
More precisely, we show that if a predictor that predicts every  SYMBOL  exists,  then such a predictor  can also be obtained as a weighted sum of  countably many elements of  SYMBOL
This result can also be viewed as a justification of the Bayesian approach to sequence prediction: if there exists  a predictor which predicts well every measure in the class, then there exists a Bayesian predictor (with a rather simple prior) that has this property too
In this respect it is important to note that the result obtained about such a  Bayesian predictor is pointwise (holds for every  SYMBOL  in  SYMBOL ), and stretches far beyond the set its prior is concentrated on
Next, we derive some characterizations of families  SYMBOL  for which a  predictor exist
We first analyze what is furnished by the notion of separability, when a suitable topology can be found: we find that  it is a sufficient but not always a necessary condition
We then derive some sufficient conditions for the existence of a predictor which are based on local (truncated to the first  SYMBOL  observation) behaviour of measures in the class  SYMBOL
Necessary conditions cannot be obtained in this way (as we demonstrate), but  sufficient conditions, along with rates  of convergence and construction of predictors, can be found
The {motivation} for studying predictors for arbitrary classes  SYMBOL  of processes is two-fold
First of all, prediction is a basic ingredient for  constructing intelligent systems
Indeed, in order to be able to find optimal behaviour in an unknown environment, an intelligent agent must be able, at the very least, to predict how the environment is going to behave (or, to be more precise, how relevant  parts of the environment are going to behave)
Since the response of the environment may in general depend on the actions of the agent, this response is necessarily non-stationary for explorative agents
Therefore, one cannot readily use prediction methods developed for stationary  environments, but rather has to find predictors for the classes of processes that can appear as a possible response of the environment
Apart from this, the problem of prediction itself has numerous applications in such diverse fields as data compression, market analysis,  bioinformatics, and many others
It seems clear that prediction methods constructed for one application cannot be expected to be optimal when applied to another
Therefore, an important question is how to develop specific prediction algorithms for each of the domains {Prior work}
As it was mentioned,  if the class  SYMBOL  of measures is countable (that is, if  SYMBOL  can be represented as  SYMBOL ), then  there exists a predictor which performs well for any  SYMBOL
Such a predictor can be obtained as a  Bayesian mixture   SYMBOL , where  SYMBOL  are summable positive real weights, and it has very strong predictive properties; in particular,   SYMBOL  predicts every  SYMBOL  in total variation distance, as follows from the result of   CITATION
Total variation distance measures the difference in (predicted and true) conditional probabilities of all future  events, that is, not only the probabilities of the next observations, but also of observations that are arbitrary far off in the future (see formal  definitions below)
In the context of sequence prediction the measure  SYMBOL   was first studied  by   CITATION
Since then, the idea of taking a convex combination of a finite or countable class of measures (or predictors) to obtain a predictor permeates most of the research on sequential prediction (see, for example,  CITATION ) and  more general learning problems~ CITATION
In practice it is clear that, on the one hand, countable models are not sufficient, since already the class  SYMBOL  of Bernoulli  iid 
processes, where  SYMBOL  is the probability of 0, is not countable
On the other hand, prediction in total variation can be too strong to require; predicting probabilities of the next observation may be sufficient, maybe even not  on every step but in the Cesaro sense
A key observation here is that a predictor  SYMBOL  may be a good predictor not only when the data is generated by one of the processes  SYMBOL ,  SYMBOL , but when it comes from a much larger class
Let us consider this point in more detail
Fix for simplicity  SYMBOL
The Laplace predictor  SYMBOL } predicts any Bernoulli  iid  ~process: although convergence in total variation distance of conditional probabilities does not hold, predicted probabilities of the next outcome converge to the correct ones
Moreover, generalizing the Laplace predictor,  a predictor   SYMBOL  can be constructed for  the class  SYMBOL  of all  SYMBOL -order Markov measures, for any given  SYMBOL
As was found by  CITATION , the combination  SYMBOL  is a good predictor not only for the set  SYMBOL  of all finite-memory processes, but also for any measure  SYMBOL  coming from a much larger class: that of all stationary measures on  SYMBOL
Here prediction is possible only in the Cesaro sense (more precisely,  SYMBOL  predicts every stationary process in expected time-average  Kullback-Leibler divergence, see definitions below)
The Laplace predictor itself can be obtained as a Bayes mixture over all Bernoulli  iid 
measures with uniform  prior on the parameter  SYMBOL  (the probability of 0)
However, as was observed in  CITATION  (and as is easy to see), the same (asymptotic) predictive properties are possessed by  a Bayes mixture with a countably supported prior which is dense in   SYMBOL  (e g taking  SYMBOL  where  SYMBOL  ranges over all Bernoulli  iid 
measures with rational probability of 0)
For a given  SYMBOL , the set of  SYMBOL -order Markov processes is parametrized by finitely many  SYMBOL -valued parameters
Taking a dense  subset of the values of these parameters, and a mixture of the corresponding measures, results in a predictor for the class of  SYMBOL -order Markov processes
Mixing over these (for all  SYMBOL ) yields, as in  CITATION , a predictor for the class of all  stationary processes
Thus, for the mentioned classes of processes, a predictor can be obtained as a Bayes mixture of  countably many measures in the class
An additional reason why this kind  of analysis is interesting is because of the difficulties arising in trying to construct  Bayesian predictors for classes of processes that can not be easily parametrized
Indeed, a natural way to obtain  a predictor for a class  SYMBOL  of stochastic processes is to take a Bayesian mixture of the class
To do this, one needs to define the structure of a probability space on  SYMBOL
If the class  SYMBOL  is well parametrized, as is the case with the set of all Bernoulli  iid 
process, then one can  integrate with respect to the parametrization
In general, when the problem lacks a natural parametrization, although one can define the structure of the probability  space on the set of (all) stochastic process measures in many different ways, the results one can obtain will then be with probability 1 with respect to the prior distribution (see, for example,  CITATION )
Pointwise consistency cannot be assured (see eg CITATION ) in this case, meaning that some  (well-defined) Bayesian predictors are not consistent on some (large) subset of  SYMBOL
Results with prior probability 1  can be hard to interpret if one is not sure that the structure  of the probability space defined on the set  SYMBOL  is indeed a natural one for the problem at hand (whereas if one does have a natural parametrization, then usually results for every value of the parameter can be obtained, as in the case with Bernoulli  iid 
processes mentioned above)
The results of the present work show that when a predictor exists it can indeed be given as  a Bayesian  predictor, which predicts  every (and not almost every) measure in the class, while its support is only a countable set
A related question is formulated as a question about two individual measures, rather than about a class of measures and a predictor
Namely, one can ask under which conditions one stochastic process  predicts another
In  CITATION  it was shown that  if one measure is absolutely continuous with respect to another, than  the latter predicts the former (the conditional probabilities converge in a very strong sense)
In  CITATION  a weaker form of convergence  of probabilities (in particular, convergence of expected average KL divergence) is obtained under  weaker assumptions {The results } First,  we show that if there is a predictor that performs well for every measure coming from a class  SYMBOL  of processes, then a predictor can also be obtained as a convex combination  SYMBOL  for some  SYMBOL  and some  SYMBOL ,  SYMBOL
This holds if the prediction quality is measured by either total variation distance, or expected average KL divergence:  one measure of performance that is very strong, the other rather weak
The analysis for the total variation case  relies on the fact that if  SYMBOL  predicts  SYMBOL  in total variation distance, then  SYMBOL  is absolutely continuous with respect to  SYMBOL , so that  SYMBOL  converges to a positive number with  SYMBOL -probability 1 and with a positive  SYMBOL -probability
However, if we settle for a weaker measure of performance, such as  expected average KL divergence, measures  SYMBOL  are typically singular with  respect to a predictor  SYMBOL
Nevertheless, since  SYMBOL  predicts  SYMBOL  we can show that   SYMBOL  decreases subexponentially with  SYMBOL  (with high probability or in expectation); then we can use this ratio as an analogue of the density for each time step  SYMBOL , and  find a convex combination of countably many measures from  SYMBOL  that has  desired predictive properties for each  SYMBOL
Combining these predictors for all  SYMBOL   results in a predictor that predicts every  SYMBOL  in average KL divergence
The proof techniques developed  have a potential to be used in solving other questions concerning sequence prediction, in particular, the general question of how to find a predictor for an arbitrary class  SYMBOL  of measures
We then  exhibit some sufficient conditions on the class  SYMBOL , under which a predictor for all measures in  SYMBOL  exists
It is important to note that none of these conditions relies on a parametrization of any kind
The conditions presented are of  two types: conditions on asymptotic behaviour of measures in  SYMBOL , and on their local (restricted to first  SYMBOL  observations) behaviour
Conditions of the first type concern separability of  SYMBOL  with respect to the total variation distance and the expected average KL divergence
We show that in the case of total variation separability is a necessary and sufficient condition for the existence of a predictor, whereas in the case of expected average KL divergence it is sufficient but is not necessary
The conditions of the second kind concern the ``capacity'' of the sets  SYMBOL ,  SYMBOL , where  SYMBOL  is the measure  SYMBOL  restricted to the first  SYMBOL  observations
Intuitively, if  SYMBOL  is small (in some sense), then prediction is possible
We measure the capacity of  SYMBOL  in two ways
The first way is  to find the maximum probability given to each sequence  SYMBOL  by some measure in the class, and then take a sum over  SYMBOL
Denoting the obtained  quantity   SYMBOL , one can show that  it grows polynomially in  SYMBOL  for  some important classes of processes, such as  iid 
or Markov processes
We show that, in general, if  SYMBOL  grows subexponentially then a predictor exists that predicts any measure in   SYMBOL  in expected average KL divergence
On the other hand, exponentially growing  SYMBOL  are not sufficient for prediction
A more refined way to measure the capacity of  SYMBOL  is using a concept of channel capacity from information  theory, which was developed for a closely related problem of finding optimal  codes for a class of sources
We extend corresponding results from information theory to show that sublinear growth of channel capacity  is sufficient for the existence of a predictor, in the sense of expected average divergence
Moreover, the obtained bounds on the divergence are optimal up to an additive logarithmic term
The rest of the paper is organized as follows
Section~  introduces the notation and definitions
In Section~ we show that if any predictor works than there is a Bayesian one that works,  while in Section~ we provide several characterizations of predictable classes of processes
Section~ is concerned with separability, while Section~ analyzes conditions based on local behaviour of measures
Finally, Section~ provides outlook and discussion
As running examples that illustrate the results of each section  we use countable classes of measures, the family of all Bernoulli  iid 
processes and that of  all stationary processes
### abstract ###
An approach to the classification problem of machine learning, based on building local classification rules, is developed
The local rules are considered as projections of the global classification rules to the event we want to classify
A massive global optimization  algorithm is used for optimization of quality criterion
The algorithm, which has polynomial complexity in typical case, is used to find all high--quality local rules
The other distinctive feature of the algorithm is the integration of attributes levels selection (for ordered attributes) with rules searching and original conflicting rules resolution strategy
The algorithm is practical; it was tested on a number of data sets from UCI repository, and a comparison with the other predicting techniques is presented
### introduction ###
Extraction of structural information from raw data is a problem which is of great interest for both fundamental and applied studies
This paper will focus on one  specific example of this problem --- classification
The goal is to predict a class of a particular event
This problem was approached from a number of  different disciplines, including Statistical Data Analysis  CITATION , Machine Learning  CITATION , Fuzzy Logic  CITATION , Operations Research  CITATION  and Data Mining  CITATION
As a result, a variety of learning techniques was developed
The result of learning can be represented  in a number of different forms
The form that we are interested in working with is a set of rules
It should be stressed that some other forms  (such as decision trees, fuzzy models and many others) are equivalent to a set of rules
A set of rules (or any other form to which  it is equivalent) is often a preferred form of knowledge representation because it allows for  a simple answer to the question, ``What was learned
'' This specific set of rules was learned from the data
For an algorithm, which produces only an answer, it is often impossible to understand what was really learned and why this specific answer was produced (The two mentioned knowledge representations differ as follows: in the case that the result is a rule, the  learned knowledge is represented in a language which is richer than one used to describe the dataset; in the case that the result is a value, the learned knowledge is represented in the same language  as the one used to describe the dataset  CITATION )  The model--based techniques,   such as developed in  CITATION ,  take training data as input and  produce a set of rules (or statements which  are equivalent to rules) which can classify any event
The lazy instance--based techniques, such as developed in  CITATION , return a result tailored to the specific event  we want to classify
With such techniques  the events similar to the given one are usually found first, then a prediction based on found instances is made
An interesting attempt to combine model based and lazy instance based learning  was presented in  CITATION
In  CITATION  a greedy lazy model--based approach for classification was developed in which the result was a rule tailored  to the specific observation
While such an approach gives a simple rule as an answer  (which is often much easier to understand than a complex rules set) and often works faster for classification of a single event, it--as every greedy algorithm--is not guaranteed to find  the best rule, because the algorithm may not reach the global maximum of the quality criterion and a sub--optimal rule may be returned
In the work  CITATION  an approach based on the brute force of rule--space scanning was developed
It was used for finding the ``nuggets'' of knowledge in the data (each nugget is a rule with a high degree of correctness)
In contrast with greedy type algorithms,   massive search algorithms are guaranteed to find the best rule(s)
In our early work  CITATION   we presented an approach which combined the  massive model--based rule search approach  with lazy instance--based learning
In that work we were also interested in ``nuggets'' of knowledge, but only those which were applicable for the instance we wanted to classify
The result was a set of rules which were applicable  for classification of the given event
One may think about these rules as  a projection of a global classification rules set to the given instance of the event
In the current paper this approach is taken to the next  level, and a practical algorithm, applicable to a variety of problems, is presented
A number of significant improvements have been made since that early version
The current algorithm includes  the following new features: 1
highly optimized rule--space scanning, which allows problems with significant number of attributes to be solved; 2
integration of levels selection procedure for ordered (continuous and literal) attributes with the  rule search algorithm; 3
information about  dependent attributes directly included into the  tree search algorithm thus significantly reducing  computational complexity; and  4
an original conflicting rules resolution strategy  which was especially built to work with automatically  generated rules
To create a practical algorithm, the three aspects --- logical, statistical and computational complexity need to be addressed
In section  we formulate the problem and discuss the logical formulas  which represent the rules we are interested in finding
In section  we discuss  the statistical quality criterion which can be used  for evaluation of rule quality and specify the  criteria which we use in this work
We also present a conflicting rules resolution strategy for automatically generated rules
At the end of section  a sketch of the algorithm is presented
In section  we discuss the selection  of attributes for analysis; it should be  stressed that some attributes as they are built in  section  are not independent, and this fact is known in advance
In section  we discuss  computational complexity issues; an approach which includes information about dependence of the attributes into the  algorithm is proposed
In section  we discuss error estimation
In section  we present the data analysis results  and compare our results with the results of C4 5R8  CITATION
In section  a discussion is presented
### abstract ###
Competitive on-line prediction (also known as universal prediction of individual sequences) is a strand of learning theory avoiding making any stochastic assumptions about the way the observations are generated
The predictor's goal is to compete with a benchmark class of prediction rules, which is often a proper Banach function space \ifFULLAlso popular are various discrete classes, such as the finite-state automata \blueendMetric entropy provides a unifying framework for competitive on-line prediction: the numerous known upper bounds on the metric entropy of various compact sets in function spaces readily imply bounds on the performance of on-line prediction strategies
This paper discusses strengths and limitations of the direct approach to competitive on-line prediction via metric entropy, including comparisons to other approaches
### introduction ###
A typical result of competitive on-line prediction says that, for a given benchmark class of prediction strategies, there is a prediction strategy that performs almost as well as the best prediction strategies in the benchmark class
For simplicity, in this paper the performance of a prediction strategy will be measured by the cumulative squared distance between its predictions and the true observations, assumed to be real (occasionally complex) numbers
Different methods of competitive on-line predictions (such as Gradient Descent, following the perturbed leader, strong and weak aggregating algorithms, defensive forecasting, etc )\ tend to have their narrow ``area of expertise'': each works well for benchmark classes of a specific ``size'' but is not readily applicable to classes of a different size
In this paper we will apply a simple general method based on metric entropy to benchmark classes of a wide range of sizes
Typically, this method does not give optimal results, but its results are often not much worse than those given by specialized methods, especially for benchmark classes that are not too massive
Since the method is almost universally applicable, it sheds new light on the known results
Another disadvantage of the metric entropy method is that it is not clear how to implement it efficiently, whereas many other methods are computationally very efficient
Therefore, the results obtained by this method are only a first step, and we should be looking for other prediction strategies, both computationally more efficient and having better performance guarantees
We start, in \S, by stating a simple asymptotic result about the existence of a universal prediction strategy for the class of continuous prediction rules
The performance of the universal strategy is in the long run as good as the performance of any continuous prediction rule, but we do not attempt to estimate the rate at which the former approaches the latter
This is the topic of the following section, \S, where we establish general results about performance guarantees based on metric entropy
For example, in the simplest case where the benchmark class  SYMBOL  is a compact set, the performance guarantees become weaker as the metric entropy of  SYMBOL  becomes larger
The core of the paper is organized according to the types of metric compacts pointed out by Kolmogorov and Tikhomirov in  CITATION  (\S3)
Type I compacts have metric entropy of order  SYMBOL ; this case corresponds to the finite-dimensional benchmark classes and is treated in \S
Type II, with the typical order  SYMBOL , contains various classes of analytic functions and is dealt with in \S
The key deals with perhaps the most important case of order  SYMBOL ; this includes, eg , Besov classes
The classes of type IV, considered in \S, have metric entropy that grows even faster
In \S\S-- the benchmark class is always given
In we ask the question of how prediction strategies competitive against various benchmark classes compare to each other
The previous section, \S, prepares the ground for this \ifFULLIn standard methods are used to deduce implications of the results of preceding sections for statistical learning theory \blueendThe concluding section, \S, lists several directions of further research
There is no real novelty in this paper; I just apply known results about metric entropy to competitive on-line prediction
I hope it will be useful as a survey
### abstract ###
Canonical correlation analysis is a technique to extract common features from a pair of multivariate data
In complex situations, however, it does not extract useful features because of its linearity
On the other hand, kernel method used in support vector machine is an efficient approach to improve such a linear method
In this paper, we investigate the effectiveness of applying kernel method to canonical correlation analysis \\ {Keyword:} multivariate analysis, multimodal data, kernel method, regularization
### introduction ###
This paper deals with the method to extract common features from multiple information sources
For instance, let us consider a task of learning in pattern recognition, in which an object is given by using an image and its name is given by a speech
For a newly given image, the system is required to answer its name by a speech, and for a newly given speech, the system is to answer the corresponding image
The task can be considered to be a regression problem from image to speech and vice versa
However, since the dimensionalities of images and speeches are generally very large, a regression analysis many not work effectively
In order to solve the problem, it is useful to map the inputs into low dimensional feature space and then to solve the regression problem
The canonical correlation analysis (CCA) has been used for such a purpose
CCA finds a linear transformation of a pair of multi-variates such that the correlation coefficient is maximized
From an information theoretical point of view, the transformation maximizes the mutual information between extracted features
However, if there is nonlinear relation between the  variates, CCA does not always extract useful features
On the other hand, the support vector machines (SVM) are attracted a lot of attention by its state-of-art performance in pattern recognition  CITATION  The kernel trick used in SVM is applicable not only for classification but also for other linear techniques, for example, kernel regression and kernel PCA CITATION    In this paper, we apply the kernel method to CCA
Since the kernel method is likely to overfit the data, we incorporate some regularization technique to avoid the overfitting
### abstract ###
We propose and analyze a new vantage point for the learning of mixtures of Gaussians: namely, the PAC-style model of learning probability distributions introduced by Kearns~et~al ~ CITATION
Here the task is to construct a hypothesis mixture of Gaussians that is statistically indistinguishable from the actual mixture generating the data; specifically, the KL~divergence should be at most  SYMBOL
In this scenario, we give a  SYMBOL  time algorithm that learns the class of mixtures of any constant number of axis-aligned Gaussians in  SYMBOL
Our algorithm makes  no  assumptions about the separation between the means of the Gaussians, nor does it have any dependence on the minimum mixing weight
This is in contrast to learning results known in the ``clustering'' model, where such assumptions are unavoidable
Our algorithm relies on the method of moments, and a subalgorithm developed in~ CITATION  for a discrete mixture-learning problem
### introduction ###
In~ CITATION  Kearns et al \ introduced an elegant and natural model of learning unknown probability distributions
In this framework we are given a class  SYMBOL  of probability distributions over  SYMBOL  and access to random data sampled from an unknown distribution  SYMBOL  that belongs to  SYMBOL  The goal is to output a hypothesis distribution  SYMBOL  which with high confidence is  SYMBOL -close to  SYMBOL  as measured by the the Kullback-Leibler (KL) divergence, a standard measure of the distance between probability distributions (see Section~ for details on this distance measure)
The learning algorithm should run in time  SYMBOL
This model is well-motivated by its close analogy to Valiant's classical Probably Approximately Correct (PAC) framework for learning Boolean functions~ CITATION
Several notable results, both positive and negative, have been obtained for learning in the Kearns et al \ framework of~ CITATION , see, eg ,  CITATION
Here we briefly survey some of the positive results that have been obtained for learning various types of  mixture distributions  (Recall that given distributions  SYMBOL  and mixing weights  SYMBOL  that sum to 1, a draw from the corresponding mixture distribution is obtained by first selecting  SYMBOL  with probability  SYMBOL  and then making a draw from  SYMBOL ) Kearns et al \ gave an efficient algorithm for learning certain mixtures of  Hamming balls ; these are product distributions over  SYMBOL  in which each coordinate mean is either  SYMBOL  or  SYMBOL  for some  SYMBOL  fixed over all mixture components
Subsequently Freund and Mansour~ CITATION  and independently Cryan et al ~ CITATION  gave efficient algorithms for learning a mixture of two arbitrary product distributions over  SYMBOL
Recently, Feldman et al ~ CITATION  gave a  SYMBOL -time algorithm that learns a mixture of any  SYMBOL  many arbitrary product distributions over the discrete domain  SYMBOL  for any  SYMBOL
### abstract ###
We introduce a simple framework for learning aggressive maneuvers in flight control of UAVs
Having inspired from biological environment, dynamic movement primitives are analyzed and extended using nonlinear contraction theory
Accordingly, primitives of an observed movement are stably combined and concatenated
We demonstrate our results experimentally on the Quanser Helicopter, in which we first imitate aggressive maneuvers  and then use them as primitives to achieve new maneuvers that can fly over an obstacle
### introduction ###
The role of UAVs (Unmanned Aerial Vehicles) has gained significant importance in the last decades
They have many advantages (agility, low surface area, ability to work in constrained or dangerous places) over their conventional precedents
In addition, current UAVs are more biologically-inspired in terms of shape and performance because of the improvements in electronics and propulsion
Unfortunately, we are still far away from using their capacity at the fullest
This  is mostly related with the weakness of current control algorithms against high-dimensional and   nonlinear environments
In this sense, generating aggressive maneuvers is interesting and hard to accomplish
In this paper, our approach to solve this issue is designed in view of the experiments on frogs and monkeys which suggest that we are faced with an inverse-kinematics algorithm that adapts to the environment and changes in a sequence of target points irrespective of the initial conditions
In theory, we analyzed dynamic movement primitives (DMPs) CITATION  and combined them using contraction theory
In experiments, obstacle avoidance DMP of a human-piloted flight data is segmented into parts and combined at different initial points to achieve maneuvers against different obstacles on different locations
Background of our work is briefly detailed below
### abstract ###
The cross-entropy method (CE) developed by R
Rubinstein is an elegant practical principle for simulating rare events
The method approximates the probability of the rare event by means of a family of probabilistic models
The method has been extended to optimization, by considering an optimal event as a rare event
CE works rather good when dealing with deterministic function optimization
Now, it appears that two conditions are needed for a good convergence of the method
First, it is necessary to have a family of models sufficiently flexible for discriminating the optimal events
Indirectly, it appears also that the function to be optimized should be deterministic
The purpose of this paper is to consider the case of partially discriminating model family, and of stochastic functions
It will be shown on simple examples that the CE could fail when relaxing these hypotheses
Alternative improvements of the CE method are investigated and compared on random examples in order to handle this issue
### introduction ###
The Cross-Entropy method has been developed by R
Rubinstein for the simulation of rare events CITATION
The algorithm iteratively builds a near-optimal importance sampling of the rare event, based on a family of parameterized sampling laws
The construction of the importance sampling is obtained by iteratively:   tossing samples,  selecting the samples which are approximating the rare events,  relearning the parameters of the sampling law by minimizing its Kulback-Leiber distance (cross-entropy) with the selection,  computing the importance weightings
By considering the optimal events related to an objective as rare events, the method has been extended to optimization problems \\[5pt] The cross-entropy method has been implemented successfully on many combinatorial problems
However, attempted proofs of the method make some assumptions as preliminary requests CITATION
First, the proof has been made in a deterministic context
Secondly, the closure of the simulation law family should contain the dirac on the optimum (or laws with support on the optimums) \\[5pt] The first condition cannot be fulfilled properly, in case of stochastic problem
The second condition is an obvious requirement
But there are some cases, where it is not possible to handle all the solutions precisely by the law family
Indeed, the solutions may not be countable practically; this is typically the case for some dynamic problems (for example, the strategy tree against a deterministic computer chess player)
Both difficulties are encountered in optimal planning with partial observation
The purpose of this paper is to point out on simple examples, that these hypotheses are necessary for the convergence of the classical CE method
The questions are:    Does the \emph{classical  CE algorithm solve stochastic problems properly } It appears that the quantile selection within the CE may not work properly, without a rather good estimation of the objective functional expectation
Nevertheless, smoother selection criteria seem to be a possible answer to these difficulties
Assume that the law family closure does not contain all the deterministic solutions
The CE algorithm will converge to a stochastic approximation of the optimal solution
Is this approximation the best possible within the law family
Our answer to this question is not absolutely negative
But it appears that some extensions of the CE, quite usually implemented, will fail on this question
This paper presents some counterexamples to these questions
In the case of stochastic optimization, tests are done on simple random examples in order to compare the convergence of various CE methods with the global optimum \\[5pt] Next section introduces shortly the principle of the CE method
Section~ will consider the case, where the optimal solution is not caught properly by the sampling family
A counterexample is proposed and studied
In section~, stochastic problems are considered
Two simple counterexamples are investigated, thus enlightening some typical convergence difficulties
Different evolutions of the cross-entropy are then compared to the basical method, by generating several random examples
In particular, a method with smooth sample selection is proposed as a possible alternative for the stochastic problems
Section~ concludes
### abstract ###
Much recent work in bioinformatics has focused on the inference of various types of biological networks, representing gene regulation, metabolic processes, protein-protein interactions, etc
A common setting involves inferring network edges in a supervised fashion from a set of high-confidence edges, possibly characterized by multiple, heterogeneous data sets (protein sequence, gene expression, etc )
Here, we distinguish between two modes of inference in this setting: direct inference based upon similarities between nodes joined by an edge, and indirect inference based upon similarities between one pair of nodes and another pair of nodes
We propose a supervised approach for the direct case by translating it into a distance metric learning problem
A relaxation of the resulting convex optimization problem leads to the support vector machine (SVM) algorithm with a particular kernel for pairs, which we call the  metric learning pairwise kernel
We demonstrate, using several real biological networks, that this direct approach often improves upon the state-of-the-art SVM for indirect inference with the tensor product pairwise kernel
### introduction ###
Increasingly, molecular and systems biology is concerned with describing various types of subcellular networks
These include protein-protein interaction networks, metabolic networks, gene regulatory and signaling pathways, and genetic interaction networks
While some of these networks can be partly deciphered by high-throughput experimental methods, fully constructing any such network requires lengthy biochemical validation
Therefore, the automatic prediction of edges from other available data, such as protein sequences, global network topology or gene expression profiles, is of importance, either to speed up the elucidation of important pathways or to complement high-throughput methods that are subject to high levels of noise  CITATION
Edges in a network can be inferred from relevant data in at least two complementary ways
For concreteness, consider a network of protein-protein interactions derived from some noisy, high-throughput technology
Our confidence in the correctness of a particular edge  SYMBOL --- SYMBOL  in this network increases if we observe, for example, that the two proteins  SYMBOL  and  SYMBOL  localize to the same cellular compartment or share similar evolutionary patterns  CITATION
Generally, in this type of  direct inference , two genes or proteins are predicted to interact if they bear some direct similarity  to each other  in the available data
An alternative mode of inference, which we call  indirect inference , relies upon similarities between pairs of genes or proteins
In the example above, our confidence in  SYMBOL --- SYMBOL  increases if we find some other, high-confidence edge  SYMBOL --- SYMBOL  such that the pair  SYMBOL  resembles  SYMBOL  in some meaningful fashion
Note that in this model, the two connected proteins  SYMBOL  and  SYMBOL  might not be similar to one another
For example, if the goal is to detect edges in a regulatory network by using time series expression data, one would expect the time series of the regulated protein to be delayed in time compared to that of the regulatory protein
Therefore, in this case, the learning phase would involve learning this feature from other pairs of regulatory/regulated proteins
The most common application of the indirect inference approach in the case of protein-protein interaction involves comparing the amino acid sequences of  SYMBOL  and  SYMBOL  versus  SYMBOL  and  SYMBOL  (e g ,  CITATION )
Indirect inference amounts to a straightforward application of the machine learning paradigm to the problem of edge inference: each edge is an example, and the task is to learn by example to discriminate between ``true'' and ``false'' edges
Not surprisingly, therefore, several machine learning algorithms have been applied to predict network edges from properties of protein pairs
For example, in the context of machine learning with support vector machines (SVM) and kernel methods, Ben-Hur and Noble  CITATION  describe how to map an embedding of individual proteins onto an embedding of pairs of proteins
The mapping defines two pairs of proteins as similar to each other when each protein in a pair is similar to one corresponding protein in the other pair
In practice, the mapping is defined by deriving a kernel function on pairs of proteins from a kernel function  SYMBOL  on individual proteins, obtained by a tensorization of the initial feature space
We therefore call this pairwise kernel, shown below, the  tensor product pairwise kernel  (TPPK):  SYMBOL }  Less attention has been paid to the use of machine learning approaches in the direct inference paradigm
Two exceptions are the works of Yamanishi  et al CITATION  and Vert  et al CITATION , who derive supervised machine learning algorithms to optimize the measure of similarity that underlies the direct approach by learning from examples of interacting and non-interacting pairs
Yamanishi  et al employ kernel canonical correlation analysis to embed the proteins into a feature space where distances are expected to correlate with the presence or absence of interactions between protein pairs
Vert  et al highlight the similarity of this approach with the problem of distance metric learning  CITATION , while proposing an algorithm for that purpose
Both of these direct inference approaches, however, suffer from two important drawbacks
First, they are based on the optimization of a proxy function that is slightly different from the objective of the embedding, namely, finding a distance metric such that interacting/non-interacting pairs fall above/below some threshold
Second, the methods of  CITATION  and  CITATION  are applicable only when the known part of the network used for training is defined by a subset of proteins in the network
In other words, in order to apply these methods, we must have a complete set of high-confidence edges for one set of proteins, from which we can infer edges in the rest of the network
This setting is unrealistic
In practice, our training data will generally consist of known positive and negative edges distributed throughout the target network
In this paper we propose a convex formulation for supervised learning in the direct inference paradigm that overcomes both of the limitations mentioned above
We show that a slight relaxation of this formulation bears surprising similarities with the supervised approach of  CITATION , in the sense that it amounts to defining a kernel between pairs of proteins from a kernel between individual proteins
We therefore call our method the  metric learning pairwise kernel  (MLPK)
An important property of this formulation as an SVM is the possibility to learn from several data types simultaneously by combining kernels, which is of particular importance in various bioinformatics applications  CITATION
We validate the MLPK approach on the task of reconstructing two yeast networks: the network of metabolic pathways and the co-complex network
In each case, the network is inferred from a variety of genomic and proteomic data, including protein amino acid sequences, gene expression levels over a large set of experiments, and protein cellular localization
We show that the MLPK approach nearly always provides better prediction performance than the state-of-the-art TPPK approach
### abstract ###
One property of networks that has received comparatively little attention is hierarchy, ie , the property of having vertices that cluster together in groups, which then join to form groups of groups, and so forth, up through all levels of organization in the network
Here, we give a precise definition of hierarchical structure, give a generic model for generating arbitrary hierarchical structure in a random graph, and describe a statistically principled way to learn the set of hierarchical features that most plausibly explain a particular real-world network
By applying this approach to two example networks, we demonstrate its advantages for the interpretation of network data, the annotation of graphs with edge, vertex and community properties, and the generation of generic null models for further hypothesis testing
### introduction ###
Networks or graphs provide a useful mathematical representation of a broad variety of complex systems, from the World Wide Web and the Internet to social, biochemical, and ecological systems
The last decade has seen a surge of interest across the sciences in the study of networks, including both empirical studies of particular networked systems and the development of new techniques and models for their analysis and interpretation~ CITATION
Within the mathematical sciences, researchers have focused on the statistical characterization of network structure, and, at times, on producing descriptive generative mechanisms of simple structures
This approach, in which scientists have focused on statistical summaries of network structure, such as path lengths~ CITATION , degree distributions~ CITATION , and correlation coefficients~ CITATION , stands in contrast with, for example, the work on networks in the social and biological sciences, where the focus is instead on the properties of individual vertices or groups
More recently, researchers in both areas have become more interested in the global organization of networks~ CITATION
One property of real-world networks that has received comparatively little attention is that of  hierarchy , i e , the observation that networks often have a fractal-like structure in which vertices cluster together into groups that then join to form groups of groups, and so forth, from the lowest levels of organization up to the level of the entire network
In this paper, we offer a precise definition of the notion of hierarchy in networks and give a generic model for generating networks with arbitrary hierarchical structure
We then describe an approach for learning such models from real network data, based on maximum likelihood methods and Markov chain Monte Carlo sampling
In addition to inferring global structure from graph data, our method allows the researcher to annotate a graph with community structure, edge strength, and vertex affiliation information
At its heart, our method works by sampling hierarchical structures with probability proportional to the likelihood with which they produce the input graph
This allows us to contemplate the ensemble of random graphs that are statistically similar to the original graph, and, through it, to measure various average network properties in manner reminiscent of Bayesian model averaging
In particular, we can   search for the maximum likelihood hierarchical model of a particular graph, which can then be used as a  null model  for further hypothesis testing,  derive a consensus hierarchical structure from the ensemble of sampled models, where hierarchical features are weighted by their likelihood, and  annotate an edge, or the absence of an edge, as ``surprising'' to the extent that it occurs with low probability in the ensemble
To our knowledge, this method is the only one that offers such information about a network
Moreover, this information can easily be represented in a human-readable format, providing a compact visualization of important organizational features of the network, which will be a useful tool for practitioners in generating new hypotheses about the organization of networks
### abstract ###
This paper addresses the problem of distributed learning under communication constraints, motivated by distributed signal processing in wireless sensor networks and data mining with distributed databases
After formalizing a general model for distributed learning, an algorithm for collaboratively training regularized kernel least-squares regression estimators is derived
Noting that the algorithm can be viewed as an application of successive orthogonal projection algorithms, its convergence properties are investigated and the statistical behavior of the estimator is discussed in a simplified theoretical setting
### introduction ###
In this paper, we address the problem of  distributed learning under communication constraints , motivated primarily by distributed signal processing in wireless sensor networks (WSNs) and data mining with distributed databases
WSNs  are  a fortiori  designed to make inferences from the environments they are sensing; however they are typically characterized by constraints on energy and bandwidth, which limit the sensors' ability to share data with each other or with a centralized fusion center
In data mining with distributed databases, multiple agents (e g , corporations) have access to possibly overlapping databases, and wish to collaborate to make optimal inferences; privacy or security concerns, however, may preclude them from fully sharing information
Nonparametric methods studied within machine learning have demonstrated widespread empirical success in many centralized (i e , communication  unconstrained ) signal processing applications
Thus, in both the aforementioned applications, a natural question arises: can the power of machine learning methods be tapped for nonparametric inference in distributed learning under communication constraints
In this paper, we address this question by formalizing a general model for distributed learning, and then deriving a distributed algorithm for collaborative training in regularized kernel least-squares regression
The algorithm can be viewed as an instantiation of successive orthogonal projection algorithms, and thus, insight into the statistical behavior of these algorithms can be gleaned from standard analyses in mathematical programming
### abstract ###
For   dimension reduction in  SYMBOL , the method of  Cauchy random projections  multiplies the original data matrix  SYMBOL  with a random matrix  SYMBOL  ( SYMBOL ) whose entries are  iid 
samples of the standard Cauchy  SYMBOL
Because of the impossibility results,  one can not hope to recover the pairwise  SYMBOL  distances in  SYMBOL  from  SYMBOL ,  using linear estimators without incurring large errors
However, nonlinear estimators are still useful for certain applications in data stream computation, information retrieval, learning, and data mining
We propose three types of nonlinear estimators: the bias-corrected sample median estimator, the bias-corrected geometric mean estimator, and the bias-corrected maximum likelihood estimator
The sample median estimator and the geometric mean estimator are asymptotically (as  SYMBOL ) equivalent but the latter is more accurate at small  SYMBOL
We derive explicit tail bounds for the geometric mean estimator and establish an analog of the Johnson-Lindenstrauss  (JL) lemma for dimension reduction in  SYMBOL , which is weaker than the classical JL lemma for dimension reduction in  SYMBOL
Asymptotically, both the sample median estimator and the geometric mean estimators are about  SYMBOL  efficient compared to the maximum likelihood estimator (MLE)
We analyze the moments of the MLE and propose approximating the distribution of the MLE by an  inverse Gaussian
### introduction ###
This paper focuses on dimension reduction in  SYMBOL ,  in particular, on the method based on  Cauchy random projections   CITATION , which is special case of  linear random projections
The idea of  linear random projections  is to multiply the original data matrix  SYMBOL  with a random projection matrix  SYMBOL , resulting in a projected matrix  SYMBOL
If  SYMBOL , then it should be much more efficient to compute certain summary statistics (e g , pairwise distances) from   SYMBOL  as opposed to  SYMBOL
Moreover,  SYMBOL  may be small  enough to reside in physical memory while  SYMBOL  is often too large to fit in the main memory
The choice of the random projection matrix  SYMBOL  depends on which norm we would like to work with
CITATION  proposed constructing  SYMBOL  from   iid 
samples of  SYMBOL -stable distributions, for dimension reduction in  SYMBOL  ( SYMBOL )
In the stable distribution family  CITATION , normal is 2-stable and Cauchy is 1-stable
Thus, we will call random projections for  SYMBOL  and  SYMBOL ,   normal random projections  and  Cauchy random projections , respectively
In  normal random projections   CITATION , we can estimate the original pairwise  SYMBOL  distances of  SYMBOL  directly using the corresponding  SYMBOL  distances of  SYMBOL  (up to a normalizing constant)
Furthermore, the Johnson-Lindenstrauss  (JL) lemma  CITATION  provides the performance guarantee
We will review  normal random projections  in more detail in Section
For  Cauchy random projections , we should not use the  SYMBOL  distance in  SYMBOL  to approximate the original  SYMBOL  distance in  SYMBOL , as the Cauchy distribution does not even have  a finite first moment
The impossibility results  CITATION  have proved that one can not hope to recover the  SYMBOL  distance using linear projections and linear estimators (e g , sample mean), without incurring large errors
Fortunately, the impossibility results do not rule out nonlinear estimators, which may be still useful in certain applications in data stream computation, information retrieval, learning, and data mining
CITATION  proposed using the sample median (instead of the sample mean) in  Cauchy random projections  and described its application in data stream computation
In this study, we provide three types of nonlinear estimators:  the bias-corrected sample median estimator, the bias-corrected geometric mean estimator, and the bias-corrected maximum likelihood estimator
The sample median estimator and the geometric mean estimator are asymptotically equivalent (i e , both are about  SYMBOL  efficient as the maximum likelihood estimator), but the latter is more accurate at small sample size  SYMBOL
Furthermore, we derive explicit tail bounds for the bias-corrected geometric mean estimator and establish an analog of the  JL Lemma for dimension reduction in  SYMBOL
This analog of the JL Lemma for  SYMBOL  is weaker than the classical JL Lemma for  SYMBOL , as the geometric mean estimator is a non-convex norm and hence is not a metric
Many efficient algorithms, such as some sub-linear time (using super-linear memory) nearest neighbor algorithms  CITATION , rely on the metric properties (e g , the triangle inequality)
Nevertheless, nonlinear estimators may be still useful in important scenarios
Estimating  SYMBOL  distances online  \\ The original data matrix  SYMBOL  requires  SYMBOL  storage space; and hence it is often too large for physical memory
The storage cost of all pairwise distances is  SYMBOL , which may be also too large for the  memory
For example, in information retrieval,  SYMBOL  could be the total number of  word types or documents at Web scale
To avoid page fault, it may be more efficient to estimate the distances on the fly from the  projected data matrix  SYMBOL  in the memory
Computing all pairwise  SYMBOL  distances  \\ In distance-based clustering and  classification applications, we need to compute all pairwise distances in  SYMBOL , at the cost of time  SYMBOL
Using  Cauchy random projections , the cost can be reduced to  SYMBOL
Because  SYMBOL , the savings could be enormous
Linear scan nearest neighbor searching \\ We can always search for the nearest neighbors by linear scans
When working with the projected data matrix  SYMBOL  (which is in the  memory), the cost of searching for the nearest neighbor for one data point is time  SYMBOL , which may be still significantly faster than the sub-linear algorithms working with the original data matrix  SYMBOL  (which is often on the disk)
We briefly comment on  coordinate sampling , another strategy for dimension reduction
Given a data matrix  SYMBOL , one can randomly sample  SYMBOL  columns from  SYMBOL  and estimate the summary statistics (including  SYMBOL  and  SYMBOL  distances)
Despite its simplicity, there are two major disadvantages in coordinate sampling
First, there is no performance guarantee
For  heavy-tailed data, we may have to choose  SYMBOL  very large in order to achieve sufficient accuracy
Second, large datasets are often highly sparse, for example,  text data  CITATION  and market-basket data  CITATION
CITATION  and   CITATION  provide an alternative coordinate sampling strategy, called  Conditional Random Sampling (CRS) , suitable for sparse data
For non-sparse data, however, methods based on  linear  random projections  are superior
The rest of the paper is organized as follows
Section  reviews  linear random projections
Section  summarizes the main results for three types of nonlinear estimators
Section  presents the sample median estimators
Section  concerns the geometric mean estimators
Section  is devoted to the maximum likelihood estimators
Section  concludes the paper
### abstract ###
In this paper we propose a method that learns to play Pac-Man
We define a set of high-level observation and action modules
Actions are temporally extended, and multiple action modules may be in effect concurrently
A decision of the agent is represented as a rule-based policy
For learning, we apply the cross-entropy method, a recent global optimization algorithm
The learned policies reached better score than the hand-crafted policy, and neared the score of average human players
We argue that learning is successful mainly because (i) the policy space includes the combination of individual actions and thus it is sufficiently rich, (ii) the search is biased towards low-complexity policies and low complexity solutions can be found quickly if they exist
Based on these principles, we formulate a new theoretical framework, which can be found in the Appendix as supporting material
### introduction ###
During the last two decades, reinforcement learning has reached a mature state, and has been laid on solid foundations
We have a large variety of algorithms, including value-function based, direct policy search and hybrid methods  CITATION
The basic properties of many such algorithms are relatively well understood (e g conditions for convergence, complexity, effect of various parameters etc ), although it is needless to say that there are still lots of important open questions
There are also plenty of test problems (like various maze-navigation tasks, pole-balancing, car on the hill etc ) on which the capabilities of RL algorithms have been demonstrated, and the number of successful large-scale RL applications is also growing steadily
However, there is still a sore need for more successful applications to validate the place of RL as a major branch of artificial intelligence
We think that games (including the diverse set of classical board games, card games, modern computer games etc ) are ideal test environments for reinforcement learning
Games are intended to be interesting and challenging for human intelligence and therefore, they are ideal means to explore what artificial intelligence is still missing
Furthermore, most games fit well into the RL paradigm: they are goal-oriented sequential decision problems, where each decision can have long-term effect
In many cases, hidden information, random events, unknown environment, known, or unknown players account for (part of) the difficulty of playing the game
Such circumstances are in the focus of the reinforcement learning idea
They are also attractive for testing new methods: the decision space is huge in most cases, so finding a good strategy is a challenging task
There is another great advantage of games as test problems: the rules of the games are fixed, so the danger of `tailoring the task to the algorithm' -- i e , to tweak the rules and/or the environment so that they meet the capabilities of the proposed RL algorithm -- is reduced, compared, eg , to various maze navigation tasks
RL has been tried in many classical games, including checkers  CITATION , backgammon  CITATION , and chess  CITATION
On the other hand, modern computer games got into the spotlight only recently, and there are not very many successful attempts to learn them with AI tools
Notable exceptions are, eg ,  role-playing game  Baldur's Gate   CITATION , real-time strategy game  Wargus   CITATION ), and possibly,  Tetris   CITATION
These games are also interesting from the point of view of RL, as they catch different aspects of human intelligence: instead of deep and wide logical deduction chains, most modern computer games need short-term strategies, but many observations have to be considered in parallel, and both the observation space and the action space can be huge
In this spirit, we decided to investigate the arcade game Pac-Man
The game is interesting on its own, as it is largely unsolved, but also imposes several important questions in RL, which we will overview in Section~
We will show that a hybrid approach is more successful than either tabula rasa learning or a hand-coded strategy alone
We will provide hand-coded high-level actions and observations, and the task of RL is to learn how to combine them into a good policy
We will apply rule-based policies because they are easy to interpret, and it is easy to include human domain-knowledge
For learning, we will apply the cross-entropy method, a recently developed general optimization algorithm
In the next section we overview the Pac-Man game and the related literature
We also investigate the emerging questions upon casting this game as a reinforcement learning task
In sections  and  we give a short description of rule-based policies and the cross-entropy optimization method, respectively
In section  we describe the details of the learning experiments, and in section  we present our results
Finally, in section  we summarize and discuss our approach with an emphasis on its implications for other RL problems
### abstract ###
Recent advances in machine learning make it possible to design efficient prediction algorithms for data sets with huge numbers of parameters
This paper describes a new technique for ``hedging'' the predictions output by many such algorithms, including support vector machines, kernel ridge regression, kernel nearest neighbours, and by many other state-of-the-art methods
The hedged predictions for the labels of new objects include quantitative measures of their own accuracy and reliability
These measures are provably valid under the assumption of randomness, traditional in machine learning: the objects and their labels are assumed to be generated independently from the same probability distribution
In particular, it becomes possible to control (up to statistical fluctuations) the number of erroneous predictions by selecting a suitable confidence level
Validity being achieved automatically, the remaining goal of hedged prediction is efficiency: taking full account of the new objects' features and other available information to produce as accurate predictions as possible
This can be done successfully using the powerful machinery of modern machine learning
### introduction ###
The two main varieties of the problem of prediction, classification and regression, are standard subjects in statistics and machine learning
The classical classification and regression techniques can deal successfully with conventional small-scale, low-dimensional data sets; however, attempts to apply these techniques to modern high-dimensional and high-throughput data sets encounter serious conceptual and computational difficulties
Several new techniques, first of all support vector machines  CITATION  and other kernel methods, have been developed in machine learning recently with the explicit goal of dealing with high-dimensional data sets with large numbers of objects
A typical drawback of the new techniques is the lack of useful measures of confidence in their predictions
For example, some of the tightest upper bounds of the popular PAC theory on the probability of error exceed~1 even for relatively clean data sets ( CITATION , p ~249)
This paper describes an efficient way to ``hedge'' the predictions produced by the new and traditional machine-learning methods, i e , to complement them with measures of their accuracy and reliability
Appropriately chosen, not only are these measures valid and informative, but they also take full account of the special features of the object to be predicted
We call our algorithms for producing hedged predictions ``conformal predictors''; they are formally introduced in Section
Their most important property is the automatic validity under the randomness assumption (to be discussed shortly)
Informally, validity means that conformal predictors never overrate the accuracy and reliability of their predictions
This property, stated in Sections  and , is formalized in terms of finite data sequences, without any recourse to asymptotics
The claim of validity of conformal predictors depends on an assumption that is shared by many other algorithms in machine learning, which we call the assumption of randomness: the objects and their labels are assumed to be generated independently from the same probability distribution
Admittedly, this is a strong assumption, and areas of machine learning are emerging that rely on other assumptions (such as the Markovian assumption of reinforcement learning; see, eg ,  CITATION ) or dispense with any stochastic assumptions altogether (competitive on-line learning; see, eg ,  CITATION )
It is, however, much weaker than assuming a parametric statistical model, sometimes complemented with a prior distribution on the parameter space, which is customary in the statistical theory of prediction
And taking into account the strength of the guarantees that can be proved under this assumption, it does not appear overly restrictive
So we know that conformal predictors tell the truth
Clearly, this is not enough: truth can be uninformative and so useless
We will refer to various measures of informativeness of conformal predictors as their ``efficiency''
As conformal predictors are provably valid, efficiency is the only thing we need to worry about when designing conformal predictors for solving specific problems
Virtually any classification or regression algorithm can be transformed into a conformal predictor, and so most of the arsenal of methods of modern machine learning can be brought to bear on the design of efficient conformal predictors
We start the main part of the paper, in Section , with the description of an idealized predictor based on Kolmogorov's algorithmic theory of randomness
This ``universal predictor'' produces the best possible hedged predictions but, unfortunately, is noncomputable
We can, however, set ourselves the task of approximating the universal predictor as well as possible
In Section  we formally introduce the notion of conformal predictors and state a simple result about their validity
In that section we also briefly describe results of computer experiments demonstrating the methodology of conformal prediction
In Section  we consider an example demonstrating how conformal predictors react to the violation of our model of the stochastic mechanism generating the data (within the framework of the randomness assumption)
If the model coincides with the actual stochastic mechanism, we can construct an optimal conformal predictor, which turns out to be almost as good as the Bayes-optimal confidence predictor (the formal definitions will be given later)
When the stochastic mechanism significantly deviates from the model, conformal predictions remain valid but their efficiency inevitably suffers
The Bayes-optimal predictor starts producing very misleading results which superficially look as good as when the model is correct
In Section  we describe the ``on-line'' setting of the problem of prediction, and in Section  contrast it with the more standard ``batch'' setting
The notion of validity introduced in Section  is applicable to both settings, but in the on-line setting it can be strengthened: we can now prove that the percentage of the erroneous predictions will be close, with high probability, to a chosen confidence level
For the batch setting, the stronger property of validity for conformal predictors remains an empirical fact
In Section  we also discuss limitations of the on-line setting and introduce new settings intermediate between on-line and batch
To a large degree, conformal predictors still enjoy the stronger property of validity for the intermediate settings
Section  is devoted to the discussion of the difference between two kinds of inference from empirical data, induction and transduction (emphasized by Vladimir Vapnik  CITATION )
Conformal predictors belong to transduction, but combining them with elements of induction can lead to a significant improvement in their computational efficiency (Section )
We show how some popular methods of machine learning can be used as underlying algorithms for hedged prediction
We do not give the full description of these methods and refer the reader to the existing readily accessible descriptions
This paper is, however, self-contained in the sense that we explain all features of the underlying algorithms that are used in hedging their predictions
We hope that the information we provide will enable the reader to apply our hedging techniques to their favourite machine-learning methods
### abstract ###
Symbolic dynamics has proven to be an invaluable tool in analyzing the mechanisms that lead to unpredictability and random behavior in nonlinear dynamical systems
Surprisingly, a discrete partition of continuous state space can produce a coarse-grained description of the behavior that accurately describes the invariant properties of an underlying chaotic attractor
In particular, measures of the rate of information production---the topological and metric entropy rates---can be estimated from the outputs of Markov or generating partitions
Here we develop Bayesian inference for  SYMBOL -th order Markov chains as a method to finding generating partitions and estimating entropy rates from finite samples of discretized data produced by coarse-grained dynamical systems
### introduction ###
Research on chaotic dynamical systems during the last forty years produced a new vision of the origins of randomness
It is now widely understood that observed randomness can be generated by low-dimensional deterministic systems that exhibit a chaotic attractor
Today, when confronted with what appears to be a high-dimensional stochastic process, one now asks whether or not the process is instead a hidden low-dimensional, but nonlinear dynamical system
This awareness, though, requires a new way of looking at apparently random data since chaotic dynamics are very sensitive to the measurement process~ CITATION , which is both a blessing and a curse, as it turns out
Symbolic dynamics, as one of a suite of tools in dynamical systems theory, in its most basic form addresses this issue by considering a coarse-grained view of a continuous dynamics ~  In this sense, any finite-precision instrument that measures a chaotic system induces a symbolic representation of the underlying continuous-valued behavior
To effectively model time series of discrete data from a continuous-state system two concerns must be addressed
First, we must consider the measurement instrument and the representation of the true dynamics which it provides
Second, we must consider the inference of models based on this data
The relation between these steps is more subtle than one might expect
As we will demonstrate, on the one hand, in the measurement of chaotic data, the instrument should be designed to maximize the entropy rate of the resulting data stream
This allows one to extract as much information from each measurement as possible
On the other hand, model inference strives to minimize the apparent randomness (entropy rate) over a class of alternative models
This reflects a search for determinism and structure in the data
Here we address the interplay between optimal instruments and optimal models by analyzing a relatively simple nonlinear system
We consider the design of binary-output instruments for chaotic maps with additive noise
We then use Bayesian inference of a  SYMBOL -th order Markov chain to model the resulting data stream
Our model system is a one-dimensional chaotic map with additive noise~ CITATION   SYMBOL } where  SYMBOL ,  SYMBOL , and  SYMBOL  is Gaussian random variable with mean zero and variance  SYMBOL
To start we consider the design of instruments in the zero-noise limit
This is the regime of most previous work in symbolic dynamics and provides a convenient frame of reference
The construction of a symbolic dynamics representation of a continuous-state system goes as follows  CITATION
We assume time is discrete and consider a map  SYMBOL  from the  state space   SYMBOL  to itself  SYMBOL
This space can partitioned into a finite set  SYMBOL  of nonoverlapping regions in many ways
The most powerful is called a  Markov partition  and must satisfy two conditions
First, the image of each region  SYMBOL  must be a union of intervals:  SYMBOL
Second, the map  SYMBOL , restricted to an interval, must be one-to-one and onto
If a Markov partition cannot be found for the system under consideration, the next best coarse-graining is called a  generating partition
For one dimensional maps, these are often easily found using the extrema of  SYMBOL ---its  critical points
The critical points in the map are used to divide the state space into intervals  SYMBOL  over which  SYMBOL  is monotone
Note that Markov partitions are generating, but the converse is not generally true
Given any partition  SYMBOL , then, a series of continuous-valued states  SYMBOL  can be projected onto its symbolic representation  SYMBOL
The latter is simply the associated sequence of partition-element indices
This is done by defining an operator  SYMBOL  that returns a unique symbol  SYMBOL  for each  SYMBOL  from an alphabet  SYMBOL  when  SYMBOL
The central result in symbolic dynamics establishes that, using a generating partition, increasingly long sequences of observed symbols identify smaller and smaller regions of the state space
Starting the system in such a region produces the associated measurement symbol sequence
In the limit of infinite symbol sequences, the result is a discrete-symbol representation of a continuous-state system---a representation that, as we will show, is often much easier to analyze
In this way a chosen partition creates a symbol sequence  SYMBOL  which describes the continuous dynamics as a sequence of symbols
The choice of partition then is equivalent to our instrument-design problem
The effectiveness of a partition (in the zero noise limit) can be quantified by estimating the entropy rate of the resulting symbolic sequence
To do this we consider length- SYMBOL   words   SYMBOL
The  block entropy  of length- SYMBOL  sequences obtained from partition  SYMBOL  is then  SYMBOL } where  SYMBOL  is the probability of observing the word  SYMBOL
From the block entropy the  entropy rate  can be estimated as the following limit  SYMBOL } In practice it is often more accurate to calculate the length- SYMBOL  estimate of the entropy rate using  SYMBOL }  Another key result in symbolic dynamics says that the entropy of the original continuous system is found using generating partitions  CITATION
In particular, the true entropy rate maximizes the estimated entropy rates:  SYMBOL } Thus, translated into a statement about experiment design, the results tell us to design an instrument so that it maximizes the observed entropy rate
This reflects the fact that we want each measurement to produce the most information possible
As a useful benchmark on this, useful only in the case when we know  SYMBOL ,  Piesin's Identity ~ CITATION  tells us that the value of  SYMBOL  is equal the sum of the positive Lyapunov characteristic exponents:  SYMBOL
For one-dimensional maps there is a single Lyapunov exponent which is numerically estimated from the map  SYMBOL  and observed trajectory  SYMBOL  using  SYMBOL }  Taken altogether, these results tell us how to design our instrument for effective observation of deterministic chaos
Notably, in the presence of noise no such theorems exist
However,  CITATION  demonstrated the methods developed above are robust in the presence of noise
In any case, we view the output of the instrument as a stochastic process
A sample realization  SYMBOL  of length  SYMBOL  with measurements taken from a finite alphabet is the basis for our inference problem:  SYMBOL
For our purposes here, the sample is generated by a partition of continuous-state sequences from iterations of a one-dimensional map and that states are on a chaotic attractor
This means, in particular, that the stochastic process is stationary
We assume, in addition, that the alphabet is binary  SYMBOL
### abstract ###
We develop a new collaborative filtering (CF) method that combines both previously known users' preferences, ie standard CF, as well as product/user attributes, ie classical function approximation, to predict a given user's interest in a particular product
Our method is a generalized low rank matrix completion problem, where we learn a function whose inputs are pairs of vectors -- the standard low rank matrix completion problem being a special case where the inputs to the function are the row and column indices of the matrix
We solve this generalized matrix completion problem using tensor product kernels for which we also formally generalize standard kernel properties
Benchmark experiments on movie ratings show the advantages of our generalized matrix completion method over the standard matrix completion one with no information about movies or people, as well as over standard multi-task or single task learning methods
### introduction ###
Collaborative Filtering (CF) refers to the task of predicting preferences of a given user based on their previously known preferences as well as the preferences of other users
In a book recommender system, for example, one would like to suggest new books to a customer based on what he and others have recently read or purchased
This can be formulated as the problem of filling a matrix with customers as rows, objects (e g , books) as columns, and missing entries corresponding to preferences that one would like to infer
In the simplest case, a preference could be a binary variable (thumbs up/down), or perhaps even a more quantitative assessment (scale of 1 to 5)
Standard CF assumes that nothing is known about the users or the objects apart from the preferences expressed so far
In such a setting the most common assumption is that preferences can be decomposed into a small number of factors, both for users and objects, resulting in the search for a low-rank matrix which approximates the partially observed matrix of preferences
This problem is usually a difficult non-convex problem for which only heuristic algorithms exist~ CITATION
Alternatively convex formulations have been obtained by relaxing the rank constraint by constraining the trace norm of the matrix~ CITATION
In many practical applications of CF, however, a description of the users and/or the objects through attributes (e g , gender, age) or measures of similarity is available
In that case it is tempting to take advantage of both known preferences and descriptions to model the preferences of users
An important benefit of such a framework over pure CF is that it potentially allows the prediction of preferences for new users and/or new objects
Seen as learning a preference function from examples, this problem can be solved by virtually any algorithm for supervised classification or regression taking as input a pair (user, object)
If we suppose for example that a positive definite kernel between pairs can be deduced from the description of the users and object, then learning algorithms like support vector machines or kernel ridge regression can be applied
These algorithms minimize an empirical risk over a ball of the reproducing kernel Hilbert space (RKHS) defined by the pairwise kernel
Both the rank constraint and the RKHS norm restriction act as regularization based on prior hypothesis about the nature of the preferences to be inferred
The rank constraint is based on the hypothesis that preferences can be modelled by a limited number or factors to describe users and objects
The RKHS norm constraint assumes that preferences vary smoothly between similar users and similar objects, where the similarity is assessed in terms of the kernel for pairs
The main contribution of this work is to propose a framework which combines both regularizations on the one hand, and which interpolates between the pure CF approach and the pure attribute-based approaches on the other hand
In particular, the framework encompasses low-rank matrix factorization for collaborative filtering, multi-task learning, and classical regression/classification over product spaces
We show on a benchmark experiment of movie recommendations that the resulting algorithm can lead to significant improvements over other state-of-the-art methods
### abstract ###
%   <- trailing '%' for backward compatibility of
sty file  We propose a method for improving approximate inference methods that corrects for the influence of loops in the graphical model
The method is applicable to arbitrary factor graphs, provided that the size of the Markov blankets is not too large
It is an alternative implementation of an idea introduced recently by  CITATION
In its simplest form, which amounts to the assumption that no loops are present, the method reduces to the minimal Cluster Variation Method approximation (which uses maximal factors as outer clusters)
On the other hand, using estimates of the effect of loops (obtained by some approximate inference algorithm) and applying the Loop Correcting (LC) method usually  gives significantly better results than applying the approximate inference algorithm directly without loop corrections
Indeed, we often observe that the loop corrected error is approximately the square of the error of the approximate inference method used to estimate the effect of loops
We compare  different variants of the Loop Correcting method with other approximate inference methods on a variety of graphical models, including ``real world''  networks, and conclude that the LC approach generally obtains the most accurate  results
### introduction ###
In recent years, much research has been done in the field of approximate inference on graphical models
One of the goals is to obtain accurate approximations of marginal probabilities of complex probability distributions defined over many variables, using limited computation time and memory
This research has led to a large number of approximate inference methods
Apart from sampling (``Monte Carlo'') methods, the most well-known methods and algorithms are variational approximations such as Mean Field (MF), which originates in statistical physics  CITATION ; Belief Propagation (BP), also known as the Sum-Product Algorithm and as Loopy Belief Propagation  CITATION , which is directly related to the Bethe approximation used in statistical physics  CITATION ; the Cluster Variation Method (CVM)  CITATION  and other region-based approximation methods  CITATION , which are related to the Kikuchi approximation  CITATION , a generalization of the Bethe approximation using larger clusters; Expectation Propagation (EP)  CITATION , which includes TreeEP  CITATION  as a special case
To calculate the results of CVM and other region based approximation methods, one can use the Generalized Belief Propagation (GBP) algorithm  CITATION  or double-loop algorithms that have guaranteed convergence  CITATION
It is well-known that Belief Propagation yields exact results if the graphical model is a tree, or, more generally, if each connected component is a tree
If the graphical model does contain loops, BP can still yield surprisingly accurate results using little computation time
However, if the influence of loops is large, the approximate marginals calculated by BP can have large errors and the quality of the BP results may not be satisfactory
One way to correct for the influence of short loops is to increase the cluster size of the approximation, using CVM (GBP) with clusters that subsume as many loops as possible
However, choosing a good set of clusters is highly nontrivial  CITATION , and in general this method will only work if the clusters do not have many intersections, or in other words, if the loops do not have many intersections
Another method that corrects for loops to a certain extent is TreeEP, which does exact inference on the base tree, a subgraph of the graphical model which has no loops, and approximates the other interactions
This corrects for the loops that consist of part of the base tree and exactly one additional factor and yields good results if the graphical model is dominated by the base tree, which is the case in very sparse models
However, loops that consist of two or more interactions that are not part of the base tree are approximated in a similar way as in BP
Hence, for  denser models, the improvement of TreeEP over BP usually diminishes
In this article we propose a method that takes into account  all  the loops in the graphical model in an approximate way and therefore obtains more accurate results in many cases
Our method is a variation on the theme introduced by  CITATION
The basic idea is to first estimate the cavity distributions of all variables and subsequently improve these estimates by cancelling out errors using certain consistency constraints
A cavity distribution of some variable is the probability distribution on its Markov blanket (all its neighbouring variables) of a modified graphical model, in which all factors involving that variable have been removed
The removal of the factors breaks all the loops in which that variable takes part
This allows an approximate inference algorithm to estimate the strength of these loops in terms of effective interactions or correlations between the variables of the Markov blanket
Then, the influence of the removed factors is taken into account, which yields accurate approximations to the probability distributions of the original graphical model
Even more accuracy is obtained by imposing certain consistency relations between the cavity distributions, which results in a cancellation of errors to some extent
This error cancellation is done by a message passing algorithm which can be interpreted as a generalization of BP in the pairwise case and of the minimal CVM approximation in general
Indeed, the assumption that no loops are present, or equivalently, that the cavity distributions factorize, yields the BP / minimal CVM results
On the other hand, using better estimates of the effective interactions in the cavity distributions yields accurate loop corrected results
Although the basic idea underlying our method is very similar to that described in  CITATION , the alternative implementation that we propose here offers two advantages
Most importantly, it is directly applicable to arbitrary factor graphs, whereas the original method has only been formulated for the rather special case of graphical models with binary variables and pairwise factors, which excludes eg \ many interesting Bayesian networks
Furthermore, our implementation appears to be more robust and also gives improved results for relatively strong interactions, as will be shown numerically
This article is organised as follows
First we explain the theory behind our proposed method and discuss the differences with the original method by  CITATION
Then we report extensive numerical experiments regarding the quality of the approximation and the computation time, where we compare with other approximate inference methods
Finally, we discuss the results and state conclusions
### abstract ###
Approximation of the optimal two-part MDL code for given data, through successive  monotonically length-decreasing two-part MDL codes, has the following properties: (i) computation of each step may take arbitrarily long; (ii) we may not know when we reach the optimum, or whether we will reach the optimum at all; (iii) the sequence of models generated may not monotonically improve the goodness of fit;  but (iv) the model associated with the optimum has (almost) the best goodness of fit
To express the practically interesting goodness of fit of individual models for individual data sets we have to rely on Kolmogorov complexity
### introduction ###
In machine learning pure applications of MDL are rare, partially because of the difficulties one encounters trying to define an adequate model code and data-to-model code, and partially because of the operational difficulties that are poorly understood
We analyze aspects of both the power and the perils of  MDL precisely and formally
Let us first resurrect a familiar problem from our childhood to illustrate some of the issues involved
The process of solving a jigsaw puzzle involves an  incremental reduction of entropy , and this serves to illustrate the analogous features of the learning problems which are the main issues of this work
Initially, when the pieces come out of the box they have a completely random ordering
Gradually we combine pieces, thus reducing the entropy and increasing the order until the puzzle is solved
In this last stage we have found a maximal ordering
Suppose that Alice and Bob both start to solve two versions of the same puzzle, but that they follow different strategies
Initially,  Alice sorts all pieces according to color, and Bob starts by sorting the pieces according to shape (For the sake of argument we assume that the puzzle has no recognizable edge pieces ) The crucial insight, shared by experienced puzzle aficionados, is that Alice's strategy is efficient whereas Bob's strategy is not and is in fact even worse than a random strategy
Alice's strategy is efficient, since the probability that pieces with about the same color match is much greater than the unconditional probability of a match
On the other hand the information about the shape of the pieces can only be used in a relatively late stage of the puzzle process
Bob's effort in the beginning is a waste of time, because he must reorder the pieces before he can proceed to solve the puzzle
This example shows that if the solution of a problem depends on finding a  maximal  reduction of entropy this does not mean that  every  reduction of entropy brings us closer to the solution
Consequently reduction of entropy is not in all cases a good strategy
### abstract ###
Kohonen self-organisation maps are a well know classification tool, commonly used  in a wide variety of problems, but with limited applications in time series  forecasting context
In this paper, we propose a forecasting method specifically  designed for multi-dimensional long-term trends prediction, with a double application  of the Kohonen algorithm
Practical applications of the method are also presented
### introduction ###
Time series forecasting is a problem encountered in many fields of applications,  as finance (returns, stock markets), hydrology (river floods), engineering (electrical  consumption), etc
Many methods designed for time series forecasting perform well  (depending on the complexity of the problem) on a rather short-term horizon but are rather poor on a longer-term one
This is due to the fact that these methods are  usually designed to optimize the performance at short term, their use at longer  term being not optimized
Furthermore, they generally carry out the prediction of a single value while the real problem sometimes requires predicting a vector of  future values in one step
For example, in the case of some a priori known periodicity,  it could be interesting to predict all values for a period as a whole
But forecasting  a vector requires either more complex models (with potential loss of performance for some of the vector components) or many distinct single value predicting models  (with potential loss of the correlation information between the various values)
Methods able to forecast a whole vector with the same precision for each of its  components are thus of great interest
While enlarging the prediction horizon is of course of primary interest for  practitioners, there is of course some limit to the accuracy that can be expected  for a long-term forecast
The limitation is due to the availability of the information  itself, and not to possible limitations of the forecasting methods
Indeed, there is no  doubt that, whatever forecasting method is used, predicting at long term (i e many time  steps in advance) is more difficult that predicting at short term, because of the missing  information in the unknown future time steps (those between the last known value and  the one to predict)
At some term, all prediction methods will thus fail
The purpose  of the method presented in this paper is not to enlarge the time horizon for which  accurate predictions could be expected, but rather to enlarge the horizon for which  we can have insights about the future evolution of the series
By insights, we mean  some information of interest to the practitioner, even if it does not mean accurate  predictions
For example, are there bounds on the future values
What can we  expect in average
Are confidence intervals on future values large or narrow
Predicting many steps in advance could be realized in a straightforward way, by subsampling the known sequence, then using any short-term prediction method
However, in this case, the loss of information (used for the forecast) is obviously even higher, due to the lower  resolution of the known sequence
Furthermore, such solution does not allow in a general  way to introduce a stochastic aspect to the method, which is a key issue in the proposed  method
Indeed, to get insights about the future evolution of a series through some  statistics (expected mean, variance, confidence intervals, quartiles, etc ), several predictions should be made in order to extract such statistics
The predictions should  differ; a stochastic prediction method is able to generate several forecasts by repeated  Monte-Carlo runs
In the method presented in this paper, the stochastic character of the  method results from the use of random draws on a probability law
Another attractive aspect of the method presented in this paper is that it can be used  to predict scalar values or vectors, with the same expected precision for each component  in the case of vector prediction
Having at disposal a time series of values  SYMBOL  with   SYMBOL , the prediction of a vector can be defined as follows :  SYMBOL } where  SYMBOL  is the size of the vector to be predicted,  SYMBOL  is the data generating process,   SYMBOL  is the number of past values that influence the future values and  SYMBOL   is a centred noise vector
The past values are gathered in a  SYMBOL -dimensional vector called  regressor
The knowledge of  SYMBOL  values of the time series (with  SYMBOL  and  SYMBOL ) means that  relation () is known for many ( SYMBOL ) time steps in the past
The  modeling problem then becomes to estimate a function  SYMBOL  that models correctly the time series for the whole set of past regressors
The idea of the method is to segment the space of  SYMBOL -dimensional regressors
This segmentation can be seen as a way to make possible a local modeling in each segment
This part of the method is achieved using the Self-Organizing Map (SOM)  CITATION
The prototypes obtained for each class model locally the regressors of the corresponding  class
Furthermore, in order to take into account temporal dependences in the series,  deformation regressors are built
Those vectors are constructed as the differences between  two consecutive regressors
The set of regressor deformations can also be segmented using  the SOM
Once those two spaces are segmented and their dependences characterized, simulations  can be performed
Using a kind of Monte-Carlo procedure to repeat the simulations, it is  then possible to estimate the distribution of these simulations and to forecast global trends of the time series at long term
Though we could have chosen some other classical vector quantization (VQ) method as only  the clustering property is of interest here, the choice of the SOM tool to perform  the segmentation  of the two spaces is justified by the fact that SOM are efficient  and fast compared to other VQ methods with a limited complexity  CITATION  and  that they provide an intuitive and helpful graphical representation
In the following of this paper, we first recall some basic concepts about the SOM  classification tool
Then we introduce the proposed forecasting method, the double  vector quantization, for scalar time series and then for vector ones
Next we present  some experimental results for both scalar and vector forecastings
A proof of the method  stability is given in appendix
### abstract ###
Because query execution is the most crucial part of Inductive Logic Programming (ILP) algorithms, a lot of effort is invested in developing faster execution mechanisms
These execution mechanisms typically have a low-level implementation, making them hard to debug
Moreover, other factors such as the complexity of the problems handled by ILP algorithms and size of the code base of ILP data mining systems make debugging at this level a very difficult job
In this work, we present the trace-based debugging approach currently used in the development of new execution mechanisms in hipP, the engine underlying the ACE Data Mining system
This debugger uses the delta debugging algorithm to automatically reduce the total time  needed to expose bugs in ILP execution, thus making manual debugging step much lighter
### introduction ###
Data mining  CITATION  is the process of finding patterns that describe a large set of data best
Inductive Logic Programming (ILP)   CITATION  is a multi-relational data mining approach, which uses the Logic Programming paradigm as its basis
ILP uses a generate-and-test approach, where in each iteration a large set of hypotheses (or `queries') has to be evaluated on the data (also called `examples')
Based on the results of this evaluation, the ILP  process selects the ``best'' hypotheses and refines them further
Due to the size of the data of the problems handled by ILP,  the underlying query evaluation engine (e g a Prolog system) is a crucial part of a real life ILP system
Hence, a lot of effort is invested in optimizing the engine to yield faster evaluation time through the use of new execution mechanisms, different internal data representations, etc
The development of new execution mechanisms for ILP happens mainly in the engine of the ILP system
These optimized execution strategies typically require a low level implementation to yield significant benefits
For example, the query pack~ CITATION  and adpack~ CITATION   execution mechanisms require the introduction of new dedicated WAM instructions, together with a set of new data structures which these instructions use and manipulate
Because of their low-level nature, finding bugs  in the implementation of these execution mechanisms is very hard
While tracing bugs in these low-level implementations  might still be feasible for small test programs, many  bugs  only appear during the execution of the ILP algorithm on real life data sets
Several factors make debugging in this situation difficult:    The size of the ILP system itself
Real life ILP systems group the implementation of many algorithms into one big system
These systems therefore often have a very large code base
For example, the ACE system~ CITATION  consists of over 150000 lines of code
In the case of the ACE system, the code base is very heterogeneous, where parts of code are written in different languages and others are generated automatically using preprocessors etc
This makes it in practice very hard to use standard tracing to detect  bugs
The complexity/size of the ILP problem
With large datasets,  it can take a very long time (hours, even days) before a specific bug occurs
When debugging, one typically performs multiple  runs with small modifications to pin-point the exact problem, and so long execution times make this approach infeasible
The high complexity of the hypothesis generation phase
While the evaluation of hypotheses is often the bottleneck, some algorithms  (such as rule learners) have a very expensive hypothesis generation  phase
This phase is independent from the execution of the queries itself, and as such has no influence on the exposure of the bug
For algorithms with a very complex hypothesis generation, it can take a  very long time for the bug in the execution mechanism to expose itself, even when the time spent on executing these queries is small
Non-determinacy of ILP algorithms
If an ILP algorithm makes  random decisions (typically in the hypothesis generation phase), the  exact point in time where the bug occurs changes from run to run
It is even possible that the bug does not occur at all in certain runs
In  CITATION , we proposed a trace-based approach for analyzing and debugging ILP data mining execution
This approach allowed easy and fast debugging of the underlying query execution engines,  independent of the ILP algorithm causing the bug to appear
In this work, we present an extension to this debugging approach, automating a large part of the debugging process
By applying the  delta debugging algorithm ~ CITATION  on ILP execution traces, we automatically generate minimal traces exposing a bug, thus greatly reducing the time and effort needed to track the bug down
This approach is currently used in the development of new execution mechanisms  in hipP~ CITATION , the engine underlying the ACE Data Mining system~ CITATION  \\  The organization of this paper is as follows: In Section~, we give a brief introduction to Inductive Logic Programming
Section~ discusses the collection of the run-time information necessary for our trace-based debugging approach
Section~ then discusses applying the delta debugging algorithm on these traces to allow fast and easy debugging
We briefly discuss the  implementation of our delta debugger in Section~
Finally, we conclude in Section~
### abstract ###
We bound the future loss when predicting any (computably) stochastic sequence online
Solomonoff finitely bounded the total deviation of his universal predictor  SYMBOL  from the true distribution  SYMBOL  by the algorithmic complexity of  SYMBOL
Here we assume that we are at a time  SYMBOL  and have already observed  SYMBOL
We bound the future prediction performance on  SYMBOL  by a new variant of algorithmic complexity of  SYMBOL  given  SYMBOL , plus the complexity of the randomness deficiency of  SYMBOL
The new complexity is monotone in its condition in the sense that this complexity can only decrease if the condition is prolonged
We also briefly discuss potential generalizations to Bayesian model classes and to classification problems
### introduction ###
We consider the problem of online=sequential predictions
We assume that the sequences  SYMBOL  are drawn from some ``true'' but unknown probability distribution  SYMBOL
Bayesians proceed by considering a class  SYMBOL  of models=hypotheses=distributions, sufficiently large such that  SYMBOL , and a prior over  SYMBOL
Solomonoff considered the truly large class that contains all computable probability distributions~ CITATION
He showed that his universal distribution  SYMBOL  converges rapidly to  SYMBOL ~ CITATION , i e \ predicts well in any environment as long as it is computable or can be modeled by a computable probability distribution (all physical theories are of this sort)
SYMBOL  is roughly  SYMBOL , where  SYMBOL  is the length of the shortest description of  SYMBOL , called the Kolmogorov complexity of  SYMBOL
Since  SYMBOL  and  SYMBOL  are incomputable, they have to be approximated in practice
See eg ~ CITATION  and references therein
The universality of  SYMBOL  also precludes useful statements about the prediction quality at particular time instances~ SYMBOL ~ CITATION , as opposed to simple classes like  iid  \ sequences (data) of size  SYMBOL , where accuracy is typically  SYMBOL
Luckily, bounds on the expected  total =cumulative loss (e g \ number of prediction errors) for  SYMBOL  can be derived~ CITATION , which is often sufficient in an online setting
The bounds are in terms of the (Kolmogorov) complexity of  SYMBOL
For instance, for deterministic  SYMBOL , the number of errors is (in a sense tightly) bounded by  SYMBOL  which measures in this case the information (in bits) in the observed infinite sequence~ SYMBOL
In this paper we assume we are at a time  SYMBOL  and have already observed  SYMBOL
Hence we are interested in the future prediction performance on  SYMBOL , since typically we don't care about past errors
If the total loss is finite, the future loss must necessarily be small for large  SYMBOL
In a sense the paper intends to quantify this apparent triviality
If the complexity of  SYMBOL  bounds the total loss, a natural guess is that something like the conditional complexity of  SYMBOL  given  SYMBOL  bounds the future loss (If  SYMBOL  contains a lot of (or even all) information about  SYMBOL , we should make fewer (no) errors anymore ) Indeed, we prove two bounds of this kind but with additional terms describing structural properties of  SYMBOL
These additional terms appear since the total loss is bounded only in expectation, and hence the future loss is small only for ``most''  SYMBOL
In the first bound (Theorem~), the additional term is the complexity of the length of  SYMBOL  (a kind of worst-case estimation)
The second bound (Theorem~) is finer: the additional term is the complexity of the randomness deficiency of  SYMBOL
The advantage is that the deficiency is small for ``typical''  SYMBOL  and bounded on average (in contrast to the length)
But in this case the conventional conditional complexity turned out to be unsuitable
So we introduce a new natural modification of conditional Kolmogorov complexity, which is monotone as a function of condition
Informally speaking, we require programs (=descriptions) to be consistent in the sense that if a program generates some  SYMBOL  given  SYMBOL , then it must generate the same  SYMBOL  given any prolongation of  SYMBOL
The new posterior bounds also significantly improve upon the previous total bounds
The paper is organized as follows
Some basic notation and definitions are given in Sections~ and~
In Section~ we prove and discuss the length-based bound Theorem~
In Section~ we show why a new definition of complexity is necessary and formulate the deficiency-based bound Theorem~
We discuss the definition and basic properties of the new complexity in Section~, and prove Theorem~ in Section~
We briefly discuss potential generalizations to general model classes  SYMBOL  and classification in the concluding Section~
### abstract ###
Given a finite set of words  SYMBOL  independently drawn according to a fixed unknown distribution law  SYMBOL  called a  stochastic language , an usual goal in Grammatical Inference is to infer an estimate of  SYMBOL  in some class of probabilistic models, such as  Probabilistic Automata  (PA)
Here, we study the class  SYMBOL  of  rational stochastic languages , which consists in stochastic languages that can be generated by  Multiplicity Automata  (MA) and which strictly includes the class of stochastic languages generated by PA
Rational stochastic languages have minimal normal representation which may be very concise, and whose parameters can be efficiently estimated from stochastic samples
We design an efficient inference algorithm DEES which aims at building a minimal normal representation of the target
Despite the fact that no recursively enumerable class of MA computes exactly  SYMBOL , we show that DEES strongly identifies  SYMBOL  in the limit
We study the intermediary MA output by DEES and show that they compute rational series which converge absolutely to one and which can be used to provide stochastic languages which closely estimate the target
### introduction ###
In probabilistic grammatical inference, it is supposed that data arise in the form of a finite set of words  SYMBOL , built on a predefinite alphabet  SYMBOL , and independently drawn according to a fixed unknown distribution law on  SYMBOL  called a  stochastic language
Then, an usual goal is to try to infer an estimate of this distribution law in some class of probabilistic models, such as  Probabilistic Automata  (PA), which have the same expressivity as Hidden Markov Models (HMM)
PA are identifiable in the limit~ CITATION
However, to our knowledge, there exists no efficient inference algorithm able to deal with the whole class of stochastic languages that can be generated from PA
Most of the previous works use restricted subclasses of PA such as Probabilistic Deterministic Automata (PDA)~ CITATION
In the other hand, Probabilistic Automata are particular cases of  Multiplicity Automata , and stochastic languages which can be generated by multiplicity automata are special cases of  rational languages  that we call  rational stochastic languages
MA have been used in grammatical inference in a variant of the exact learning model of Angluin  CITATION  but not in probabilistic grammatical inference
Let us design by  SYMBOL , the class of rational stochastic languages over the semiring  SYMBOL
When  SYMBOL  or  SYMBOL ,  SYMBOL  is exactly the class of stochastic languages generated by PA with parameters in  SYMBOL
But, when  SYMBOL  or  SYMBOL , we obtain strictly greater classes which provide several advantages and at least one drawback: elements of  SYMBOL  may have significantly smaller representation in  SYMBOL  which is clearly an advantage from a learning perspective; elements of  SYMBOL  have a minimal normal representation while such normal representations do not exist for PA; parameters of these minimal representations are directly related to probabilities of some natural events of the form  SYMBOL , which can be efficiently estimated from stochastic samples; lastly, when  SYMBOL  is a field, rational series over  SYMBOL  form a vector space and efficient linear algebra techniques can be used to deal with rational stochastic languages
However, the class  SYMBOL  presents a serious drawback : there exists no recursively enumerable subset of MA which exactly generates it~ CITATION
Moreover, this class of representations is unstable: arbitrarily close to an MA which generates a stochastic language, we may find MA whose associated rational series  SYMBOL  takes negative values and is not absolutely convergent: the global weight  SYMBOL  may be unbounded or not (absolutely) defined
However, we show that  SYMBOL  is strongly identifiable in the limit: we design an algorithm DEES such that, for any target  SYMBOL  and given access to an infinite sample  SYMBOL  drawn according to  SYMBOL , will converge in a finite but unbounded number of steps to a minimal normal representation of  SYMBOL
Moreover, DEES is efficient: it runs within polynomial time in the size of the input and it computes a minimal number of parameters with classical statistical rates of convergence
However, before converging to the target, DEES output MA which are close to the target but which do not compute stochastic languages
The question is: what kind of guarantees do we have on these intermediary hypotheses and how can we use them for a probabilistic inference purpose
We show that, since the algorithm aims at building a minimal normal representation of the target, the intermediary hypotheses  SYMBOL  output by DEES have a nice property: they absolutely converge to 1, i e SYMBOL  and  SYMBOL
As a consequence,  SYMBOL  is defined without ambiguity for any  SYMBOL , and it can be shown that  SYMBOL  tends to 0 as the learning proceeds
Given any such series  SYMBOL , we can efficiently compute a stochastic language  SYMBOL , which is not rational, but has the property that  SYMBOL  for any word  SYMBOL  such that  SYMBOL
Our conclusion is that, despite the fact that no recursively enumerable class of MA represents the class of rational stochastic languages, MA can be used efficiently to infer such stochastic languages
Classical notions on stochastic languages, rational series, and multiplicity automata are recalled in Section~
We study an example which shows that the representation of rational stochastic languages by MA with real parameters may be very concise
We introduce our inference algorithm DEES in Section~ and we show that  SYMBOL  is strongly indentifiable in the limit
We study the properties of the MA output by DEES in Section~ and we show that they define absolutely convergent rational series which can be used to compute stochastic languages which are estimates of the target
### abstract ###
Sequential decision theory formally solves the problem of rational agents in uncertain worlds if the true environmental prior probability distribution is known
Solomonoff's theory of universal induction formally solves the problem of sequence prediction for unknown prior distribution
We combine both ideas and get a parameter-free theory of universal Artificial Intelligence
We give strong arguments that the resulting AIXI model is the most intelligent unbiased agent possible
We outline how the AIXI model can formally solve a number of problem classes, including sequence prediction, strategic games, function minimization, reinforcement and supervised learning
The major drawback of the AIXI model is that it is uncomputable
To overcome this problem, we construct a modified algorithm AIXI SYMBOL  that is still effectively more intelligent than any other time  SYMBOL  and length  SYMBOL  bounded agent
The computation time of AIXI SYMBOL  is of the order  SYMBOL
The discussion includes formal definitions of intelligence order relations, the horizon problem and relations of the AIXI theory to other AI approaches
### introduction ###
This chapter article gives an introduction to a mathematical theory for intelligence
We present the AIXI model, a parameter-free optimal reinforcement learning agent embedded in an arbitrary unknown environment
The science of Artificial Intelligence (AI) may be defined as the construction of intelligent systems and their analysis
A natural definition of a  system  is anything that has an input and an output stream
Intelligence is more complicated
It can have many faces like creativity, solving problems, pattern recognition, classification, learning, induction, deduction, building analogies, optimization, surviving in an environment, language processing, knowledge and many more
A formal definition incorporating every aspect of intelligence, however, seems difficult
Most, if not all known facets of intelligence can be formulated as goal-driven or, more precisely, as maximizing some utility function
It is, therefore, sufficient to study goal-driven AI; eg \ the (biological) goal of animals and humans is to survive and spread
The goal of AI systems should be to be useful to humans
The problem is that, except for special cases, we know neither the utility function nor the environment in which the agent will operate in advance
The mathematical theory, coined AIXI, is supposed to solve these problems
Assume the availability of unlimited computational resources
The first important observation is that this does not make the AI problem trivial
Playing chess optimally or solving NP-complete problems become trivial, but driving a car or surviving in nature don't
This is because it is a challenge itself to well-define the latter problems, not to mention presenting an algorithm
In other words: The AI problem has not yet been well defined
One may view AIXI as a suggestion for such a mathematical definition of AI
AIXI is a universal theory of sequential decision making akin to Solomonoff's celebrated universal theory of induction
Solomonoff derived an optimal way of predicting future data, given previous perceptions, provided the data is sampled from a computable probability distribution
AIXI extends this approach to an optimal decision making agent embedded in an unknown environment
The  main idea  is to replace the unknown environmental distribution  SYMBOL  in the Bellman equations by a suitably generalized universal Solomonoff distribution  SYMBOL
The state space is the space of complete histories
AIXI is a universal theory without adjustable parameters, making no assumptions about the environment except that it is sampled from a computable distribution
From an algorithmic complexity perspective, the AIXI model generalizes optimal passive universal induction to the case of active agents
From a decision-theoretic perspective, AIXI is a suggestion of a new (implicit) ``learning'' algorithm, which may overcome all (except computational) problems of previous reinforcement learning algorithms
There are strong arguments that AIXI is the most intelligent unbiased agent possible
We outline for a number of problem classes, including sequence prediction, strategic games, function minimization, reinforcement and supervised learning, how the AIXI model can formally solve them
The major drawback of the AIXI model is that it is incomputable
To overcome this problem, we construct a modified algorithm AIXI SYMBOL  that is still effectively more intelligent than any other time  SYMBOL  and length  SYMBOL  bounded agent
The computation time of AIXI SYMBOL  is of the order  SYMBOL
Other discussed topics are a formal definition of an intelligence order relation, the horizon problem and relations of the AIXI theory to other AI approaches
The article is meant to be a gentle introduction to and discussion of the AIXI model
For a mathematically rigorous treatment, many subtleties, and proofs see the references to the author's works in the annotated bibliography section at the end of this chapterarticle\fi, and in particular the book  CITATION
This section also provides references to introductory textbooks and original publications on algorithmic information theory and sequential decision theory
presents the theory of sequential decisions in a very general form (called AI SYMBOL  model) in which actions and perceptions may depend on arbitrary past events
We clarify the connection to the Bellman equations and discuss minor parameters including (the size of) the I/O spaces and the lifetime of the agent and their universal choice which we have in mind
Optimality of AI SYMBOL  is obvious by construction
How and in which sense induction is possible at all has been subject to long philosophical controversies
Highlights are Epicurus' principle of multiple explanations, Occam's razor, and probability theory
Solomonoff elegantly unified all these aspects into one formal theory of inductive inference based on a universal probability distribution  SYMBOL , which is closely related to Kolmogorov complexity  SYMBOL , the length of the shortest program computing  SYMBOL
Rapid convergence of  SYMBOL  to the unknown true environmental distribution  SYMBOL  and tight loss bounds for arbitrary bounded loss functions and finite alphabet can be shown
Pareto optimality of  SYMBOL  in the sense that there is no other predictor that performs better or equal in all environments and strictly better in at least one can also be shown
In view of these results it is fair to say that the problem of sequence prediction possesses a universally optimal solution
In the active case, reinforcement learning algorithms are usually used if  SYMBOL  is unknown
They can succeed if the state space is either small or has effectively been made small by generalization techniques
The algorithms work only in restricted (e g \ Markovian) domains, have problems with optimally trading off exploration versus exploitation, have nonoptimal learning rate, are prone to diverge, or are otherwise ad hoc
The formal solution proposed here is to generalize Solomonoff's universal prior  SYMBOL  to include action conditions and replace  SYMBOL  by  SYMBOL  in the AI SYMBOL  model, resulting in the AI SYMBOL AIXI model, which we claim to be universally optimal
We investigate what we can expect from a universally optimal agent and clarify the meanings of  universal ,  optimal , etc
Other discussed topics are formal definitions of an intelligence order relation, the horizon problem, and Pareto optimality of AIXI
We show how a number of AI problem classes fit into the general AIXI model
They include sequence prediction, strategic games, function minimization, and supervised learning
We first formulate each problem class in its natural way (for known  SYMBOL ) and then construct a formulation within the AI SYMBOL  model and show their equivalence
We then consider the consequences of replacing  SYMBOL  by  SYMBOL
The main goal is to understand in which sense the problems are solved by AIXI
The major drawback of AIXI is that it is incomputable, or more precisely, only asymptotically computable, which makes an implementation impossible
To overcome this problem, we construct a modified model AIXI SYMBOL , which is still superior to any other time  SYMBOL  and length  SYMBOL  bounded algorithm
The computation time of AIXI SYMBOL  is of the order  SYMBOL
The solution requires an implementation of first-order logic, the definition of a universal Turing machine within it and a proof theory system
Finally we discuss and remark on some otherwise unmentioned topics of general interest
We remark on various topics, including concurrent actions and perceptions, the choice of the I/O spaces, treatment of encrypted information, and peculiarities of mortal embodies agents
We continue with an outlook on further research, including optimality, down-scaling, implementation, approximation, elegance, extra knowledge, and training of/for AIXI( SYMBOL )
We also include some (personal) remarks on non-computable physics, the number of wisdom  SYMBOL , and consciousness
An annotated bibliography concludes this chapter
An annotated bibliography and other references conclude this work
### abstract ###
We propose simple randomized strategies for sequential decision (or prediction) under imperfect monitoring, that is, when the decision maker (forecaster) does not have access to the past outcomes but rather to a feedback signal
The proposed strategies are consistent in the sense that they achieve, asymptotically, the best possible average reward among all fixed actions
It was Rustichini  CITATION  who first proved the existence of such consistent predictors
The forecasters presented here offer the first constructive proof of consistency
Moreover, the proposed algorithms are computationally efficient
We also establish upper bounds for the rates of convergence
In the case of deterministic feedback signals, these rates are optimal up to logarithmic terms
### introduction ###
In sequential decision problems a decision maker (or forecaster) tries to predict the outcome of a certain unknown process at each (discrete) time instance and  takes an action accordingly
Depending on the outcome of the predicted event and the action taken, the decision maker receives a reward
Very often, probabilistic modeling of the underlying process is difficult
For such situations the prediction problem can be formalized as a repeated game between the decision maker and the environment
This formulation goes back to the 1950's when Hannan~ CITATION  and Blackwell~ CITATION  showed that the decision maker has a randomized strategy that guarantees,  regardless of the outcome sequence, an average asymptotic reward as high as the maximal reward one could get by knowing the empirical distribution of the outcome sequence in advance
Such strategies are called  Hannan consistent
To prove this result, Hannan and Blackwell assumed that the decision maker has full access to the past outcomes
This case is termed the  full information  or the  perfect monitoring  case
However, in many important applications, the decision maker has limited information about the past elements of the sequence to be predicted
Various models of limited feedback have been considered in the literature
Perhaps the best known of them is the so-called  multi-armed bandit problem  in which the forecaster is only informed of its own reward but not the actual outcome; see Ba\~nos~ CITATION , Megiddo~ CITATION , Foster and Vohra~ CITATION , Auer, Cesa-Bianchi, Freund, and Schapire~ CITATION , Hart and Mas Colell~ CITATION
For example, it is shown in  CITATION  that Hannan consistency is achievable in this case as well
Sequential decision problems like the ones considered in this paper have been studied in different fields under various names such as repeated games, regret minimization, on-line learning, prediction of individual sequences, and sequential prediction
The vocabulary of different sub-communities differ
Ours is perhaps closest to that used by learning theorists
For a general introduction and survey of the sequential prediction problem we refer to Cesa-Bianchi and Lugosi  CITATION
In this paper we consider a general model in which the information available to the forecaster is a general given  (possibly randomized) function of the outcome and the decision of the forecaster
It is well understood under what conditions Hannan consistency is achievable in this setup, see Piccolboni and Schindelhauer  CITATION  and Cesa-Bianchi, Lugosi, and Stoltz  CITATION
Roughly speaking, this is possible whenever, after suitable transformations of the problem, the reward matrix can be expressed as a linear function of the matrix of (expected) feedback signals
However, this condition is not always satisfied and then the natural question is what the best achievable performance for the decision maker is
This question was answered by Rustichini  CITATION  who characterized the maximal achievable average reward that can be guaranteed asymptotically for all possible outcome sequences (in an almost sure sense)
However, Rustichini's proof of achievability is not constructive
It uses abstract  approachability  theorems due to Mertens, Sorin, and Zamir  CITATION  and it seems unlikely that his proof method can give rise to computationally efficient prediction algorithms, as noted in the conclusion of  CITATION
A simplified efficient approachability-based strategy in the special case where the feedback is a function of the action of nature alone was shown in Mannor and Shimkin  CITATION
In the general case, the simplified approachability-based strategy of  CITATION  falls short of the maximal achievable average reward characterized by Rustuchini  CITATION
The goal of this paper is to develop computationally efficient forecasters in the general prediction problem under imperfect monitoring that achieve the best possible asymptotic performance
We introduce several forecasting strategies that exploit some specific properties of the problem at hand
We separate four cases, according to whether the feedback signal only depends on the outcome or both on the outcome and the forecaster's action and whether the feedback signal is deterministic or not
We design different prediction algorithms for all four cases
As a by-product, we also obtain finite-horizon performance bounds with explicit guaranteed rates of convergence in terms of the number  SYMBOL  of rounds the prediction game is played
In the case of deterministic feedback signals these rates are optimal up to logarithmic factors
In the random feedback signal case we do not know if it is possible to construct forecasters with a significantly smaller regret
A motivating example for such a prediction problem arises naturally in multi-access channels that are prevalent in both wired and wireless networks
In such networks, the communication medium is shared between multiple decision makers
It is often technically difficult to synchronize between the decision makers
Channel sharing protocols, and, in particular, several variants of spread spectrum, allow multiple agents to use the same channel (or channels that may interfere with each other) simultaneously
More specifically, consider a wireless system where multiple agents can choose in which channel to transmit data at any given time
The quality of each channel may be different and interference from other users using this channel (or other ``close'' channels) may affect the base-station reception
The transmitting agent may choose which channel to use and how much power to spend on every transmission
The agent has a tradeoff between the amount of power wasted on transmission and the cost of having its message only partially received
The transmitting agent may not receive immediate feedback on how much data were received in the base station (even if feedback is received, it often happens on a much higher layer of the communication protocol)
Instead, the transmitting agent can monitor the transmissions of the other agents
However, since the transmitting agent is physically far from the base-station and the other agents, the information about the channels chosen by other agents and the amount of power they used is imperfect
This naturally abstracts to an online learning problem with imperfect monitoring
The paper is structured as follows
In the next section we formalize the prediction problem we investigate, introduce the  target quantity, that is, the best achievable reward, and the notion of regret
In Section  we describe some analytical properties of a key function  SYMBOL , defined in Section
This function represents the worst possible average reward for a given vector of observations and is needed in our analysis
In Section  we consider the simplest special case when the actions of the forecaster do not influence the feedback signal, which is, moreover, deterministic
This case is basically as easy as the full information case and we obtain a regret bound of the order of  SYMBOL  (with high probability) where  SYMBOL  is the number of rounds of the prediction game
In Section  we study random feedback signals but still with the restriction that it is only determined by the outcome
Here we are able to obtain a regret of the order of  SYMBOL
The most general case is dealt with in Section
The forecaster introduced there has a regret of the order of  SYMBOL
Finally, in Section  we show that this may be improved to  SYMBOL  in the case of deterministic feedback signals, which is known to be optimal (see  CITATION )
### abstract ###
This correspondence studies an estimator of the conditional  support of a distribution underlying a set of  iid 
observations
The relation with mutual information is shown via an extension of  Fano's theorem in combination with a generalization bound based on a compression argument
Extensions to estimating the conditional quantile interval, and  statistical guarantees on the minimal convex hull are given {Keywords}: -  Statistical Learning, Fano's inequality, Mutual Information, Support Vector Machines
### introduction ###
Given a set of paired observations   SYMBOL   which are  iid 
copies of a random vector  SYMBOL  possessing a fixed but unknown joint distribution  SYMBOL ,  this letter concerns the question which values the random variable  SYMBOL  can  possibly/likely take given a covariate  SYMBOL
This investigation on predictive tolerance intervals  is motivated as one is often interested in other characteristics of the joint distribution than the conditional expectation (regression): eg in econometrics one is often more interested in the volatility of a market than in its precise prediction
In environmental sciences  one is typically concerned with the extremal behavior  (i e the min or max value) of a magnitude, and its respective conditioning  on related environmental variables
The main contribution of this letter is the extension to Fano's classical inequality (see eg CITATION , p 38) which gives a lower-bound to the mutual information of two random variables
This classical result is extended towards a setting of learning theory where random variables have an arbitrary fixed distribution
The derivation yields a non-parametric estimator of the mutual information possessing  a probabilistic guarantee which is derived using a classical compression argument
The described relationship differs from other results relating  estimators and mutual information as eg using Fisher's information matrix  CITATION  or based on Gaussian assumptions as eg in  CITATION , as a distribution free context is adopted
As an aside,  (i) an estimator of the conditional support is derived  and is extended to the setting of conditional quantiles,  (ii) its theoretical properties are derived,  (iii) the relation to the method of the minimal convex hull is made explicit, and (iv) it is shown how the estimate can be computed efficiently by  solving a linear program
While studied in the literature eg on quantile regression   CITATION , we argue that this question can be approached   naturally from a setting of statistical learning theory, pattern recognition and Support Vector Machines (SVM), see  CITATION  for an overview
A main conceptual difference with the existing literature on classical regression and  other predictor methods is that no attempt is made whatsoever to reveal an underlying  conditional mean (as in regression), conditional quantile (as in quantile regression), or minimal risk point prediction of the dependent variable (as in pattern recognition)
Here we target instead (the change of) the rough contour of the conditional distribution
This implies that one becomes interested in  (i) to what extent the estimated conditional support of the tube is conservative  (i e does it overestimate the actual conditional support ), and  (ii) what is the probability of covering the actual conditional support (i e to what probability a new sample can occur outside the estimated interval) }   Section II proofs the main result, and explores the relation with the convex hull
From a practical perspective, Section III provides further insight in  how the optimal estimate can be found efficiently by solving a linear program
### abstract ###
This work is motivated by the necessity to automate the discovery of structure in vast and ever-growing collection of relational data commonly represented as graphs, for example genomic networks
A novel algorithm, dubbed  Graphitour , for structure induction by lossless graph compression is presented and illustrated by a clear and broadly known case of nested structure in a DNA molecule
This work extends to graphs some well established approaches to grammatical inference previously applied only to strings
The bottom-up graph compression problem is related to the maximum cardinality (non-bipartite)  maximum cardinality matching problem
The algorithm accepts a variety of graph types including directed graphs and graphs with labeled nodes and arcs
The resulting structure could be used for representation and classification of  graphs
### introduction ###
The explosive growth of relational data, for example data about genes, drug molecules and proteins, their functions and interactions, necessitates efficient mathematical algorithms and software tools to extract meaningful generalizations
There is a large body of literature on the subject coming from a variety of disciplines from Theoretical Computer Science to Computational Chemistry
However, one fundametal issue has so far remained unaddressed
Given a multi-level nested network of relations, such as a complex molecule, or a protein-protein interaction network, how can its structure be inferred from first principles
This paper is meant to fill this surprising gap in automated data processing
Let us illustrate the purpose of this method through the description of DNA molecular structure, the way most of us learned it from a textbook or in class
The DNA molecule is a double chain made of four kinds of nucleotides: A, T, G, C;   Each of these is composed of two parts: one part---backbone---is identical among all the nucleotides (neglecting the difference between ribose and 2'-deoxyribose), another---heterocyclic base---is nucleotide-specific;  The backbone consists of sugar and phosphate;  The heterocyclic bases (C,T-pyrimidines; A,G-purines) all contain a pyrimidine ring;   The components can be further reduced to individual atoms and covalent bonds
This way of description is not unique, and may be altered according to the desired level of detail, but crucially, it is a hieararchical description of the whole as a structure built from identifiable and repetitive subcomponents
The picture of this beautiful multi-level hierarchy has emerged after years of bio-chemical discovery by scientists who gradually applied their natural abstraction and generalization abilities
Hence, structural elements in this hierarchy also make functional sense from bio-chemical point of view }  The properties of hierarchical description are formally well-studied and applied in other scientific domains, such as linguistics and computer science
It is viewed as the result of a rule-driven generative process, which combines a finite set of undecomposable elements--- terminal symbols ---into novel complex objects--- non-terminal symbols , which can be combined in turn to produce the next level of description
The rules and symbols on which the process operates are determined by a  grammar  and the process itself is termed a  grammatical derivation
In the case of the DNA molecule above, the chemical elements correspond to terminal symbols
They are assembled into non-terminal symbols, i e compounds, according to some set of production rules defined by chemical properties
Now, imagine receiving an alternative description of the same object, stripped off of any domain knowledge and context, simply as an enormous list of objects and binary relations on objects, corresponding to thousands of atoms and covalent bonds
Such a list would remain completely incomprehensible to a human mind, along with any repetitive hierarchical structure present in it
Discovering a hierarchy of nested elements without any prior knowledge of a kind, size and frequency of these constitutes a formidable challenge
Remarkably, this is precisely the challenge which is undertaken by contemporary scientists trying to make sense of data, mounting up from small fragments, like protein interaction networks, regulatory and metabolic pathways, small molecule repositories, homology networks, etc
Our goal is to be able to approach such  tasks in an automated fashion
Figure~ illustrates the kind of induction we describe in this paper on a trivial example
We will use this as a running example throughout the paper, leaving more rigorous mathematical formulation out for the purpose of clarity and wider accessibility
To the left is a graph which contains repetitive structure
Let us imagine for a moment that the human researcher is not smart enough to comprehend a 6-node graph and find an explanatory layout
Thus, we would want to automatically translate such a graph into the graph grammar on the right
The graph grammar consist of two productions
The first expands a starting representation---a degenerate graph of a single node "S"---into a graph connecting two nodes of the same type "S1"
The second additionally defines a node "S1" as a fully connected triple }  Formal description of the relational data of such kind is known as graphs, while the hierarchical nested structures of such kind are described by graph grammars
It is outside the scope of this paper to survey a vast literature in the field of graph grammars; please refer to a book by G
Rozenberg~ CITATION  for extensive overview
It suffices to say that this field is mostly concerned with the transformation of the graphs, or parsing, i e explaining away a graph according to some known graph grammar, rather than with inducing such grammar from raw data
The closest work related to the ideas presented here is due to D
Cook, L
Holder and their colleagues (e g see~ CITATION  and several follow-up papers)
Their work however is not concerned with inducing a structure from given graph data
Rather, they induce a flat, context-free grammar, possibly with recursion, which is not only capable of, but is also bound to, generate objects not included in the original data
Thus, their approach defies the relation to compression exploited here
Moreover, the authors present the negative result of running their {subdue} algorithm on just the kind of biological data we successfully use in this paper
Another remotely similar work is by Stolke~ CITATION  in application to inducing hidden Markov models
There are many other works attempting to induce structure from relational data or compress graphs, but none seem to relate closely to the method considered here
Our method builds on the parallels between understanding and compression
Indeed, to understand some phenomenon from the raw data means to find some repetitive pattern and hierarchical structure, which in turn could be exploited to re-encode the data in a compact way
This work extends to graphs some well established approaches to grammatical inference previously applied only to strings
Two methods particularly worth mentioning in this context for grammar induction on sequences are  Sequitour ~ CITATION  and {adios}~ CITATION
We also take inspiration from a wealth  of sequence compression algorithms, often unknowingly run daily by all computer users in a form of archival software like  pkzip  in Unix  or  expand  for Mac OS X
%  winzip  for Windows
Let us briefly convey the intuition behind such algorithms, many of which are surveyed by Lehman and Shelat~ CITATION
Although quite different in detail, all algorithms share common principles and have very similar compression ratio and computational complexity bounds
First, one has to remember that all such compression/discovery algorithms are bound to be heuristics, since finding the best compression is related to the so-called Kolmogorov complexity and is provably hard~ CITATION
These heuristics are in turn related to the MDL (Minimum Description Length) principle, and work in the way described by Table~ }  Naturally, the difference is in how exactly statistics are used to pick which substring will be substituted by a new compound symbol
In some cases, a greedy strategy is used (see eg Apostolico \& Lonardi~ CITATION ), i e the substitution which will maximally reduce the size of the encoding at the current step is picked; in other cases, a simple first-come-first-served principle is used and any repetition is immediately eliminated (see eg Nevill-Manning \& Witten~ CITATION )
Extending these methods to a graph structure turns out to be non-trivial for several reasons
First, maintaining a lexicon of strings and looking up entries is quite different for graphs
Second, directly extending the greedy approach~ CITATION  fails due to inherent non-linear entity interactions in a graph
### abstract ###
Reinforcement learning means learning a policy---a mapping of observations into actions---based on feedback from the environment
The learning can be viewed as browsing a set of policies while evaluating them by trial through interaction with the environment
We present an application of gradient ascent algorithm for reinforcement learning to a complex domain of packet routing in network communication and compare the performance of this algorithm to other routing methods on a benchmark problem
### introduction ###
Successful telecommunication requires efficient resource allocation that can be achieved by developing adaptive control policies
Reinforcement learning ({rl})~ CITATION  presents a natural framework for the development of such policies by trial and error in the process of interaction with the environment
In this work we apply the {rl} algorithm to network routing
Effective network routing means selecting the optimal communication paths
It can be modeled as a multi-agent {rl} problem
In a sense, learning the optimal control for network routing could be thought of as learning in some traditional for {rl} episodic task, like maze searching or pole balancing, but repeating trials many times in parallel with interaction among trials
Under this interpretation, an individual router is an agent which makes its routing decisions according to an individual policy
The parameters of this policy are adjusted according to some measure of the global performance of the network, while control is determined by local observations
Nodes do not have any information regarding the topology of network or their position in it
The initialization of each node, as well as the learning algorithm it follows, are identical to that of every other node and independent of the structure of the network
There is no notion of orientation in space or other semantics of actions
Our approach allows us to update the local policies while avoiding the necessity for centralized control or global knowledge of the networks structure
The only global information required by the learning algorithm is the network utility expressed as a reward signal distributed once in an epoch and dependent on the average routing time
This learning multi-agent system is biologically plausible and could be thought of as neural network in which each neuron only performs simple computations based on locally available quantities~ CITATION
### abstract ###
In a sensor network, in practice, the communication among sensors is subject to:  The signal-to-noise ratio~(SNR) is usually a main factor in determining the probability of error (or of communication failure) in a link
These probabilities are then a proxy for  the SNR under which the links operate
The paper studies the problem of designing the topology, ie ,   assigning the probabilities of reliable communication among sensors (or of link failures) to maximize the rate of convergence of average consensus, when the link communication costs are taken into account, and there is an overall communication budget constraint
To consider this problem,  we address a number of preliminary issues:    With these results, we formulate topology design, subject to random link failures and to a communication cost constraint, as a constrained convex optimization problem to which we apply semidefinite programming techniques
We show by an extensive numerical study that the optimal design improves significantly the convergence speed of the consensus algorithm and can achieve the asymptotic performance of a non-random network at a fraction of the communication cost
### introduction ###
We consider the design of the optimal topology, i e , the communication configuration of a sensor network that maximizes  the convergence rate of average consensus
Average consensus is a distributed algorithm that has been considered by Tsitsiklis in his PhD thesis,  CITATION , see also~ CITATION ,  found application recently in several areas, and is the subject of active research, e
g,,  CITATION
This topology design for sensor networks  has not received much attention in the literature
References~ CITATION  and~ CITATION  consider  restrict it to classes of random graphs,  in particular, small-world topologies
The more general question of designing the topology that maximizes the convergence rate, under a constraint on the number of network links,  was considered in our previous work,  CITATION , where we reduced to average consensus the problem of distributed inference in sensor networks; see also~ CITATION
Realistic networks operate under stress:   We model such a non-deterministic network topology as a random field
Specifically, we assume the following:  Designing the network topology corresponds then to   The paper extends our preliminary  convergence results,  CITATION , on networks with random links
The recent paper~ CITATION  adopts a similar model and  analyzes convergence properties using ergodicity of stochastic matrices
Consensus with a randomized network also relates to gossip algorithms,  CITATION , where only a single pair of randomly selected sensors is allowed to communicate at each iteration, and the communication exchanged by the nodes is averaged
In our randomized consensus, we use multiple  randomly selected links at each iteration and, in contradistinction with~ CITATION , we design the optimal topology, i e , the optimal weight (not simple average) and the optimal probabilities of edge utilization, recognizing that communication entails costs, and that there is a communication cost constraint
Other recent work on evolving topologies includes~ CITATION  that considers continuous time consensus in networks with switching topologies and communication delays, and~ CITATION  that studies distributed consensus when the network is  a complete graph with identical link failure probabilities on all links
We outline the paper
Section~ summarizes spectral graph theory concepts like  the graph Laplacian~ SYMBOL  and the graph algebraic connectivity   SYMBOL
% of the  Laplacian~ SYMBOL
The Section formulates the problem of distributed average consensus with random link failures
Sections~ and  derive necessary and sufficient conditions  for convergence of the mean state, mss convergence, and a s ~convergence in terms of the average  SYMBOL  and in terms of  SYMBOL , where  SYMBOL
Section~ presents bounds on the mss convergence rate
Section~ addresses the topology design for random networks with communication cost constraints
We formulate a first version of the problem, the randomized distributed consensus with a communication cost constraint (RCCC), and then an alternate version, which we show is a convex constrained optimization problem,  to which we apply semidefinite programming~(SDP) techniques
Section~  studies the performance of the topologies found by solving numerically the SDP optimization
We show that these designs can improve significantly the convergence rate, for example, by a factor of~ SYMBOL , when compared to geometric networks (networks where sensors communicate with every other sensor within a fixed radius) and that they can achieve practically the (asymptotic) performance of a nonrandom network at a fraction, eg , 50~\%, of the communication cost per iteration
Section~ concludes the paper
### abstract ###
The on-line shortest path problem is considered under various models of partial monitoring
Given a weighted directed acyclic graph whose edge weights can change in an arbitrary (adversarial) way, a decision maker has to choose in each round of a game a path between two distinguished vertices such that the loss of the chosen path (defined as the sum of the weights of its composing edges) be as small as possible
In a setting generalizing the multi-armed bandit problem, after choosing a path, the decision maker learns only the weights of those edges that belong to the chosen path
For this problem, an algorithm is given whose average cumulative loss in  SYMBOL  rounds exceeds that of the best path, matched off-line to the entire sequence of the edge weights, by a quantity that is proportional to  SYMBOL  and depends only polynomially on the number of edges of the graph
The algorithm can be implemented with linear complexity in the number of rounds  SYMBOL  and in the number of edges
An extension to the so-called label efficient setting is also given, in which the decision maker is informed about the weights of the edges corresponding to the chosen path at a total of  SYMBOL  time instances
Another extension is shown where the decision maker competes against a time-varying path, a generalization of the problem of tracking the best expert
A version of the multi-armed bandit setting for shortest path is also discussed where the decision maker learns only the total weight of the chosen path but not the weights of the individual edges on the path
Applications to routing in packet switched networks along with simulation results are also presented
### introduction ###
In a sequential decision problem, a decision maker (or forecaster) performs a sequence of actions
After each action the decision maker suffers some loss, depending on the response (or state) of the environment, and its goal is to minimize its cumulative loss over a certain period of time
In the setting considered here, no probabilistic assumption is made on how the losses corresponding to different actions are generated
In particular, the losses may depend on the previous actions of the decision maker, whose goal is to perform well relative to a set of reference forecasters (the so-called ``experts'') for any possible behavior of the environment
More precisely, the aim of the decision maker is to achieve asymptotically the same average (per round) loss as the best expert
Research into this problem started in the 1950s (see, for example,  Blackwell  CITATION  and Hannan  CITATION  for some of the basic results) and gained new life in the 1990s following the work of Vovk  CITATION , Littlestone and Warmuth  CITATION , and Cesa-Bianchi  et al SYMBOL    CITATION
These results show that for any bounded loss function, if the decision maker has access to the past losses of all experts, then it is possible to construct on-line algorithms that perform, for any possible behavior of the environment, almost as well as the best of  SYMBOL  experts
More precisely, the per round cumulative loss of these algorithms is at most as large as that of the best expert plus a quantity proportional to  SYMBOL  for any bounded loss function, where  SYMBOL  is the number of rounds in the decision game
The logarithmic dependence on the number of experts makes it possible to obtain meaningful bounds even if the pool of experts is very large
In certain situations the decision maker has only limited knowledge about the losses of all possible actions
For example, it is often natural to assume that the decision maker gets to know only the loss corresponding to the action it has made, and has no information about the loss it would have suffered had it made a different decision
This setup is referred to as the  multi-armed bandit problem , and was considered, in the adversarial setting, by Auer  et al SYMBOL     CITATION  who gave an algorithm whose normalized regret (the difference of the algorithm's average loss  and that of the best expert) is upper bounded by a quantity  which is  proportional to  SYMBOL
Note that, compared to the  full information   case  described above where the losses of all possible actions are revealed to the decision maker, there is an extra  SYMBOL  factor  in the performance bound, which seriously limits the usefulness of the bound if the number of experts is large
Another interesting example for the limited information case is the so-called  label efficient decision problem  (see Helmbold and Panizza  CITATION ) in which it is too costly to observe the state of the environment, and so the decision maker can query the losses of all possible actions for only a limited number of times
A recent result of Cesa-Bianchi, Lugosi, and Stoltz  CITATION  shows that in this case, if the decision maker can query the losses  SYMBOL  times during a period of length  SYMBOL , then it can achieve  SYMBOL  average excess loss relative to the best expert
In many applications the set of experts has a certain structure that may be exploited to construct efficient on-line decision algorithms
The construction of such algorithms has been of great interest in computational learning theory
A partial list of works dealing with this problem includes Herbster and Warmuth~ CITATION , Vovk~ CITATION , Bousquet and Warmuth~ CITATION , Helmbold and Schapire~ CITATION , Takimoto and Warmuth~ CITATION ,  Kalai and Vempala~ CITATION , Gy\"orgy  at al SYMBOL  ~ CITATION
For a more complete survey, we refer to Cesa-Bianchi and Lugosi  CITATION
In this paper we study the on-line shortest path problem, a representative example of structured expert classes that has received attention in the literature for its many applications, including, among others, routing in communication networks; see, eg , Takimoto and Warmuth  CITATION ,  Awerbuch  et al \  CITATION , or Gy\"orgy and Ottucs\'ak  CITATION , and adaptive quantizer design in zero-delay lossy source coding; see, Gy\"orgy  et al SYMBOL  ~ CITATION
In this problem, a weighted directed (acyclic) graph is given whose edge weights can change in an arbitrary manner, and the decision maker has to pick in each round a path between two given vertices, such that the weight of this path (the sum of the weights of its composing edges) be as small as possible
Efficient solutions, with time and space complexity proportional to the number of edges rather than to the number of paths (the latter typically being exponential in the number of edges), have been given in the full information case, where in each round the weights of all the edges are revealed after a path has been chosen; see, for example, Mohri  CITATION , Takimoto and Warmuth  CITATION , Kalai and Vempala  CITATION , and Gy\"orgy  et al SYMBOL  ~ CITATION
In the bandit setting only the weights of the edges or just the sum of the weights of the edges composing the chosen path are revealed to the decision maker
If one applies the general bandit algorithm of Auer  et al  \  CITATION , the resulting bound will be too large to be of practical use because of its square-root-type dependence on the number  of paths  SYMBOL
On the other hand, using the special graph structure in the problem, Awerbuch and Kleinberg  CITATION  and McMahan and Blum  CITATION  managed to get rid of the exponential dependence on the number of edges in the performance bound
They achieved this by extending the exponentially weighted average predictor and the  follow-the-perturbed-leader algorithm of Hannan  CITATION  to the generalization of the multi-armed bandit setting for shortest paths, when only the sum of the weights of the edges is available for the algorithm
However, the dependence of the bounds obtained in  CITATION  and  CITATION  on the number of rounds  SYMBOL  is significantly worse than the  SYMBOL  bound of Auer  et al  \  CITATION
Awerbuch and Kleinberg  CITATION  consider the model of ``non-oblivious'' adversaries for shortest path (i e , the losses assigned to the edges can depend on the previous actions of the forecaster) and prove an  SYMBOL  bound for the expected per-round regret
McMahan and Blum  CITATION  give a simpler algorithm than in  CITATION  however obtain a bound of the order of  SYMBOL  for the expected regret
In this paper we provide an extension of the bandit algorithm of Auer  et al  \   CITATION  unifying the advantages of the above approaches, with a performance bound that is polynomial in the number of edges, and converges to zero at the right  SYMBOL  rate as the number of rounds increases
We achieve this bound in a model which assumes that the losses of all edges on the path chosen by the forecaster are available separately after making the decision
We also discuss the case (considered by  CITATION  and  CITATION ) in which only the total loss (i e , the sum of the losses on the chosen path) is known to the decision maker
We exhibit a simple algorithm which achieves an  SYMBOL  per-round regret  with high probability  against ``non-oblivious'' adversary
In this case it remains an open problem to find an algorithm whose cumulative loss is polynomial in the number of edges of the graph and decreases as  SYMBOL  with the number of rounds
In Section~ we formally  define the on-line shortest path problem, which is extended to the multi-armed bandit setting in Section~
Our new algorithm for the shortest path problem in the bandit setting is given in Section~ together with its performance analysis
The algorithm is extended to solve the shortest path problem in a combined label efficient multi-armed bandit setting in Section~
Another extension, when the algorithm competes against a time-varying path is studied in Section
An algorithm for the ``restricted'' multi-armed bandit setting (when only the sums of the losses of the edges are available) is given in Section~
Simulation results are presented in Section~
### abstract ###
Ordinal regression is an important type of learning, which has properties of both classification and regression
Here we describe a simple and effective approach to adapt a traditional neural network to  learn ordinal categories
Our approach is a generalization of the perceptron method for ordinal regression
On several benchmark datasets, our method (NNRank) outperforms a  neural network classification method
Compared with the ordinal regression methods  using Gaussian processes and support vector machines, NNRank achieves comparable performance
Moreover, NNRank has the advantages of traditional neural networks: learning in both online and batch modes, handling very large training datasets, and making rapid predictions
These features make NNRank a useful and complementary tool for large-scale data processing tasks such as information retrieval, web page ranking, collaborative filtering, and protein ranking in Bioinformatics \\
### introduction ###
Ordinal regression (or ranking learning) is an important supervised problem of  learning a ranking or ordering on instances, which has the property of both  classification and metric regression
The learning task of ordinal regression is to assign data points into a set of finite ordered categories
For example, a  teacher rates students' performance using A, B, C, D, and E  (A  SYMBOL  B  SYMBOL  C  SYMBOL  D  SYMBOL  E) (Chu \& Ghahramani, 2005a)
Ordinal regression is different from classification due to the order of categories
In contrast to metric regression, the response variables (categories) in  ordinal regression is discrete and finite
The research of ordinal regression dated back to the ordinal statistics methods in 1980s (McCullagh, 1980; McCullagh \& Nelder, 1983) and  machine learning research in 1990s (Caruana et al , 1996; Herbrich et al , 1998; Cohen et al , 1999)
It has attracted the considerable attention in recent years due to its potential applications in many data-intensive domains such as information retrieval (Herbrich et al , 1998), web page ranking (Joachims, 2002), collaborative filtering (Goldberg et al , 1992; Basilico \& Hofmann, 2004; Yu et al , 2006),  image retrieval (Wu et al , 2003), and protein ranking (Cheng \& Baldi, 2006) in  Bioinformatics
A number of machine learning methods have been developed or redesigned to address ordinal regression problem (Rajaram et al , 2003), including  perceptron (Crammer \& Singer, 2002) and its kernelized generalization (Basilico \& Hofmann, 2004), neural network with gradient descent (Caruana et al , 1996; Burges et al , 2005), Gaussian process (Chu \& Ghahramani, 2005b; Chu \& Ghahramani, 2005a; Schwaighofer et al , 2005), large margin classifier (or support vector machine) (Herbrich et al , 1999; Herbrich et al , 2000; Joachims, 2002; Shashua \& Levin, 2003; Chu \& Keerthi, 2005; Aiolli \& Sperduti, 2004; Chu \& Keerthi, 2007), k-partite classifier (Agarwal \& Roth, 2005), boosting algorithm (Freund et al , 2003; Dekel et al , 2002), constraint classification (Har-Peled et al , 2002),  regression trees (Kramer et al , 2001), Naive Bayes (Zhang et al , 2005), Bayesian hierarchical experts (Paquet et al , 2005), binary classification approach (Frank \& Hall, 2001; Li \& Lin, 2006) that decomposes the original ordinal regression problem into a set of binary classifications, and the optimization of nonsmooth cost functions (Burges et al , 2006)
Most of these methods can be roughly classified into two categories:  pairwise constraint approach (Herbrich et al , 2000; Joachims, 2002; Dekel et al , 2004; Burges et al , 2005) and  multi-threshold approach (Crammer \& Singer, 2002; Shashua \& Levin, 2003; Chu \& Ghahramani, 2005a)
The former is to convert the full ranking relation into pairwise order constraints
The latter  tries to learn multiple thresholds to divide data into ordinal categories
Multi-threshold approaches  also can be unified under the general, extended binary classification framework (Li \& Lin, 2006)
The ordinal regression methods have different advantages and disadvantages
Prank (Crammer \& Singer, 2002), a perceptron approach that generalizes the binary perceptron algorithm to the ordinal multi-class situation,  is a fast online algorithm
However, like a standard perceptron method, its accuracy suffers when dealing with non-linear data, while a quadratic kernel version of Prank  greatly relieves this problem
One class of accurate large-margin classifier approaches (Herbrich et al , 2000; Joachims, 2002) convert the ordinal relations into  SYMBOL  ( SYMBOL : the number of data points)  pairwise ranking constraints for the structural  risk minimization (Vapnik, 1995; Schoelkopf \& Smola, 2002)
Thus, it can not be applied to medium size datasets  ( SYMBOL  10,000 data points), without discarding some pairwise preference relations
It may also overfit noise due to incomparable pairs
The other class of powerful large-margin classifier  methods (Shashua \& Levin, 2003; Chu \& Keerthi, 2005) generalize the support vector formulation for ordinal regression by finding  SYMBOL  thresholds on the real line that divide   data into  SYMBOL  ordered categories
The size of this optimization problem is linear in the number of training examples
However, like support vector machine used for  classification, the prediction speed is slow when the solution is not sparse, which makes it not appropriate for time-critical tasks
Similarly, another state-of-the-art approach, Gaussian process method (Chu \& Ghahramani, 2005a),   also has the difficulty of handling large training datasets  and the problem of slow prediction speed in some situations
Here we describe a new neural network approach for ordinal regression that  has the advantages of  neural network learning: learning in both online and batch mode, training on very large dataset (Burges et al , 2005), handling non-linear data, good performance, and rapid prediction
Our method can  be considered a generalization of the perceptron     learning (Crammer \& Singer, 2002) into multi-layer perceptrons (neural network) for ordinal regression
Our method is also related to the classic generalized linear models (e g , cumulative logit model) for ordinal regression (McCullagh, 1980)
Unlike the neural network method (Burges et al , 2005) trained on pairs of   examples to learn pairwise order relations,  our method works on individual data points and uses multiple output nodes to estimate the probabilities of ordinal categories
Thus, our method falls into the category of multi-threshold approach
The learning of our method proceeds similarly as traditional neural networks using back-propagation (Rumelhart et al , 1986)
On the same benchmark datasets, our method yields the performance better than the standard classification  neural networks and comparable to the state-of-the-art methods using support vector machines and  Gaussian processes
In addition, our method can learn on very large datasets and make rapid predictions
### abstract ###
Consider the problem of joint parameter estimation and prediction in a Markov random field: ie , the model parameters are estimated on the basis of an initial set of data, and then the fitted model is used to perform prediction (e g , smoothing, denoising, interpolation) on a new noisy observation
Working under the restriction of limited computation, we analyze a joint method in which the  same convex variational relaxation  is used to construct an M-estimator for fitting parameters, and to perform approximate marginalization for the prediction step
The key result of this paper is that in the computation-limited setting, using an inconsistent parameter estimator (i e , an estimator that returns the ``wrong'' model even in the infinite data limit) can be provably beneficial, since the resulting errors can partially compensate for errors made by using an approximate prediction technique
En route to this result, we analyze the asymptotic properties of M-estimators based on convex variational relaxations, and establish a Lipschitz stability property that holds for a broad class of variational methods
We show that joint estimation/prediction based on the reweighted sum-product algorithm substantially outperforms a commonly used heuristic based on ordinary sum-product
### introduction ###
Graphical models such as Markov random fields (MRFs) are widely used in many application domains, including spatial statistics, statistical signal processing, and communication theory
A fundamental limitation to their practical use is the infeasibility of computing various statistical quantities (e g , marginals, data likelihoods etc ); such quantities are of interest both Bayesian and frequentist settings
Sampling-based methods, especially those of the Markov chain Monte Carlo (MCMC) variety~ CITATION , represent one approach to obtaining stochastic approximations to marginals and likelihoods
A disadvantage of sampling methods is their relatively high computational cost
For instance, in applications with severe limits on delay and computational overhead (e g , error-control coding, real-time tracking, video compression), MCMC methods are likely to be overly slow
It is thus of considerable interest for various application domains to consider less computationally intensive methods for generating approximations to marginals, log likelihoods, and other relevant statistical quantities
Variational methods are one class of techniques that can be used to generate deterministic approximations in Markov random fields (MRFs)
At the foundation of these methods is the fact that for a broad class of MRFs, the computation of the log likelihood and marginal probabilities can be reformulated as a convex optimization problem (see~ CITATION  for an overview)
Although this optimization problem is intractable to solve exactly for general MRFs, it suggests a principled route to obtaining approximations---namely, by relaxing the original optimization problem, and taking the optimal solutions to the relaxed problem as approximations to the exact values
In many cases, optimization of the relaxed problem can be carried out by ``message-passing'' algorithms, in which neighboring nodes in the Markov random field convey statistical information (e g , likelihoods) by passing functions or vectors (referred to as messages)
Estimating the parameters of a Markov random field from data poses another significant challenge
A direct approach---for instance, via (regularized) maximum likelihood estimation---entails evaluating the cumulant generating (or log partition) function, which is computationally intractable for general Markov random fields
One viable option is the pseudolikelihood method~ CITATION , which can be shown to produce consistent parameter estimates under suitable assumptions, though with an associated loss of statistical efficiency
Other researchers have studied algorithms for ML estimation based on stochastic approximation~ CITATION , which again are consistent under appropriate assumptions, but can be slow to converge
### abstract ###
This paper uncovers and explores the close relationship between Monte Carlo Optimization of a parametrized integral (MCO), Parametric machine-Learning (PL), and `blackbox' or `oracle'-based optimization (BO)
We make four contributions
First, we prove that MCO is mathematically identical to a broad class of PL problems
This identity potentially provides a new application domain for all broadly applicable PL techniques: MCO
Second, we introduce immediate sampling, a new version of the Probability Collectives (PC) algorithm for blackbox optimization
Immediate sampling transforms the original BO problem into an MCO problem
Accordingly, by combining these first two contributions, we can apply all PL techniques to BO
In our third contribution we validate this way of improving BO by demonstrating that cross-validation and bagging improve immediate sampling
Finally, conventional MC and MCO procedures ignore the relationship between the sample point locations and the associated values of the integrand; only the values of the integrand at those locations are considered
We demonstrate that one can exploit the sample location information using PL techniques, for example by forming a fit of the sample locations to the associated values of the integrand
This provides an additional way to apply PL techniques to improve MCO
### introduction ###
This paper uncovers and explores some aspects of the close relationship between Monte Carlo Optimization of a parametrized integral (MCO), Parametric machine Learning (PL), and `blackbox' or `oracle-based' optimization (BO)
We make four primary contributions
First, we establish a mathematical identity equating MCO with PL
This identity potentially provides a new application domain for all broadly-applicable PL techniques, viz , MCO
Our second contribution is the introduction of immediate sampling
This is a new version of the Probability Collectives (PC) approach to blackbox optimization
PC encompasses Estimation of Distribution Algorithms (EDAs) CITATION  and the Cross Entropy (CE) method~ CITATION  as special cases
However PC is broader and more fully motivated
This means it uncovers (and overcomes) formal shortcomings in those other approaches
In the immediate sampling version of PC the original BO problem is transformed into an MCO problem
In light of our first contribution, this means we can apply PL to immediate sampling
In this way  SYMBOL  PL techniques --- including cross-validation, bagging, boosting, active learning, stacking, and others --- can be applied to blackbox optimization
In our third contribution we experimentally explore the power of this identity between MCO and PL
In these experiments we demonstrate that cross-validation and bagging improve the performance of immediate sampling blackbox optimization
In particular, in these experiments we show that cross-validation can be used to adaptively set an `annealing schedule' for blackbox optimization using immediate sampling {\it{without any extra calls to the oracle}}
In some cases, we show that this adaptively formed annealing schedule results in better optimization performance than  any  exponential annealing schedule {}  Finally, conventional MC and MCO procedures ignore the relationship between the sample point locations and the associated values of the integrand (Only the values of the integrand at the sample locations are considered by such algorithms ) We end by exploring ways to use PL techniques to exploit the information in the sample locations, for instance, by Bayesian fitting of a surface from the sample locations to the associated values of the integrand
This constitutes yet another way of applying PL to MCO in general, and therefore to BO in particular
### abstract ###
The problem of joint universal source coding and modeling, treated in the context of lossless codes by Rissanen, was recently generalized to fixed-rate lossy coding of finitely parametrized continuous-alphabet  iid 
sources
We extend these results to variable-rate lossy block coding  of stationary ergodic sources and show that, for bounded metric distortion measures, any finitely parametrized family of stationary sources satisfying suitable mixing, smoothness and Vapnik--Chervonenkis learnability conditions admits universal schemes for joint lossy source coding and identification
We also give several explicit examples of parametric sources satisfying the regularity conditions
### introduction ###
A universal source coding scheme is one that performs asymptotically optimally for all sources within a given class
Intuition suggests that a good universal coder should acquire a probabilistic model of the source from a sufficiently long data sequence and operate based on this model
For lossless codes, this intuition has been made rigorous by Rissanen  CITATION : the data are encoded via a two-part code which comprises (1) a suitably quantized maximum-likelihood estimate of the source parameters, and (2) an encoding of the data with the code optimized for the acquired model
The redundancy of this scheme converges to zero as  SYMBOL , where  SYMBOL  is the block length and  SYMBOL  is the dimension of the parameter space
Recently we have extended Rissanen's ideas to  lossy  block coding  of finitely parametrized continuous-alphabet  iid 
sources with bounded parameter spaces  CITATION
We have shown that, under appropriate regularity conditions, there exist joint universal schemes for lossy coding and source identification whose distortion redundancy and source estimation fidelity both converge to zero as  SYMBOL  as the block length  SYMBOL  tends to infinity
The code operates by coding each block with the code matched to the parameters estimated from the preceding block
Moreover, the constant hidden in the  SYMBOL  notation increases with the ``richness" of the model class, as measured by the Vapnik--Chervonenkis (VC) dimension  CITATION  of a certain class of decision regions in the source alphabet
The main limitation of the results of  CITATION  is the  iid 
assumption, which excludes such practically relevant model classes as autoregressive sources or Markov and hidden Markov processes
Furthermore, the assumption of a bounded parameter space may not be always justified
In this paper we relax both of these assumptions
Because the parameter space is not bounded, we have to use variable-rate codes with countably infinite codebooks, whose performance is naturally quantified by Lagrangians  CITATION
We show that, under certain regularity conditions, there are universal schemes for joint lossy source coding and modeling such that, as the block length  SYMBOL  tends to infinity, both the Lagrangian redundancy relative to the best variable-rate code at each block length and the source estimation fidelity at the decoder converge to zero as  SYMBOL , where  SYMBOL  is the VC dimension of a certain class of decision regions induced by the collection of all  SYMBOL -dimensional marginals of the source process distributions
The key novel feature of our scheme is that, unlike most existing schemes for universal lossy coding, which rely on implicit identification of the active source, it learns an explicit probabilistic model
Moreover, our results clearly show that the ``price of universality" of a modeling-based compression scheme grows with the combinatorial richness of the underlying model class, as captured by the VC dimension sequence  SYMBOL
The richer the model class, the harder it is to learn, which in turn affects the compression performance because we use the source parameters learned from past data in deciding how to encode the current block
These insights may prove useful in such settings as digital forensics or adaptive control under communication constraints, where trade-offs between the quality of parameter estimation and compression performance are of central importance
### abstract ###
We introduce a framework for filtering features that employs the Hilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence between the features and the labels
The key idea is that good features should maximise such dependence
Feature selection for various supervised learning problems (including classification and regression) is unified under this framework, and the solutions  can be approximated using a backward-elimination algorithm
We demonstrate the usefulness of our method on both artificial and real world datasets
### introduction ###
In supervised learning problems, we are typically given  SYMBOL  data points  SYMBOL  and their labels  SYMBOL
The task is to find a functional dependence between  SYMBOL  and  SYMBOL ,  SYMBOL , subject to certain optimality conditions
Representative tasks include binary classification, multi-class classification, regression and ranking
We often want to reduce the dimension of the data (the number of features) before the actual learning  CITATION ; a larger number of features  can be associated with higher data collection cost, more difficulty in model interpretation,  higher computational cost for the classifier, and decreased generalisation ability
It is therefore important to select an informative feature subset
The problem of supervised feature selection can be cast as a combinatorial optimisation problem
We have a full set of features, denoted  SYMBOL  (whose elements correspond to the dimensions of the data)
We use these features to predict a particular outcome, for instance the presence of cancer: clearly, only a subset  SYMBOL  of features will be relevant
Suppose the relevance of  SYMBOL  to the outcome is quantified by  SYMBOL , and is computed by restricting the data to the dimensions in  SYMBOL
Feature selection can then be formulated as\\[-0 5cm] \\[-0 5cm] where  SYMBOL  computes the cardinality of a set and  SYMBOL  upper bounds the number of selected features
Two important aspects of problem () are the choice of the criterion  SYMBOL  and the selection algorithm \paragraph{Feature Selection Criterion } The choice of  SYMBOL  should respect the underlying supervised learning tasks --- estimate  dependence function  SYMBOL  from training data and guarantee  SYMBOL  predicts well on test data
Therefore, good criteria should satisfy two conditions:\\[-0 5cm]  While many feature selection criteria have been explored, few take these two conditions explicitly into account
Examples include the leave-one-out error bound of SVM  CITATION  and the mutual information  CITATION
Although the latter has good theoretical justification, it requires density estimation, which is problematic for high dimensional and continuous variables
We sidestep these problems by employing a mutual-information  like  quantity --- the Hilbert Schmidt Independence Criterion (HSIC)  CITATION
HSIC uses kernels for measuring dependence and does not require density estimation
HSIC also has good uniform convergence guarantees
As we show in section~, HSIC satisfies conditions  I  and  II , required for  SYMBOL  \paragraph{Feature Selection Algorithm } Finding a global optimum for \eq{eq:fs} is in general NP-hard  CITATION
Many algorithms transform \eq{eq:fs} into a continuous problem by introducing weights on the dimensions  CITATION
These methods perform well for linearly separable problems
For nonlinear problems, however, the optimisation usually becomes non-convex and a local optimum does not necessarily provide good features
Greedy approaches -- forward selection and backward elimination -- are often used to tackle problem () directly
Forward selection tries to increase  SYMBOL  as much as possible for each inclusion of features, and backward elimination tries to achieve this for each deletion of features~ CITATION
Although forward selection is computationally more efficient, backward elimination provides better features in general since the features are assessed within the context of all others \paragraph{BAHSIC } In principle, HSIC can be employed using either the forwards or backwards strategy, or a mix of strategies
However, in this paper, we will focus on a backward elimination algorithm
Our experiments show that backward elimination outperforms forward selection for HSIC
Backward elimination using HSIC (BAHSIC) is a filter method for feature selection
It selects features independent of a particular classifier
Such decoupling not only facilitates subsequent feature interpretation but also speeds up the computation over wrapper and embedded methods
Furthermore, BAHSIC is directly applicable to binary, multiclass, and regression problems
Most other feature selection methods are only formulated either for binary classification or regression
The multi-class extension of these methods is usually accomplished using a one-versus-the-rest strategy
Still fewer methods handle classification and regression cases at the same time
BAHSIC, on the other hand, accommodates all these cases in a principled way: by choosing different kernels, BAHSIC also subsumes many existing methods as special cases
The versatility of BAHSIC originates from the generality of HSIC
Therefore, we begin our exposition with an introduction of HSIC
### abstract ###
Max-product belief propagation is a local, iterative algorithm to find the mode/MAP estimate of a probability distribution
While it has been successfully employed in a wide variety of applications, there are relatively few theoretical guarantees of convergence and correctness for general loopy graphs that may have many short cycles
Of these, even fewer provide exact ``necessary and sufficient'' characterizations
In this paper we investigate the problem of using max-product to find the maximum weight matching in an arbitrary graph with edge weights
This is done by first constructing a probability distribution whose mode corresponds to the optimal matching, and then running max-product
Weighted matching can also be posed as an integer program, for which there is an LP relaxation
This relaxation is not always tight
In this paper we show that    If the LP relaxation is tight, then max-product always converges, and that too to the correct answer
If the LP relaxation is loose, then max-product does not converge
This provides an exact, data-dependent characterization of max-product performance, and a precise connection to LP relaxation, which is a well-studied optimization technique
Also, since LP relaxation is known to be tight for bipartite graphs, our results generalize other recent results on using max-product to find weighted matchings in bipartite graphs
### introduction ###
Message-passing algorithms, like Belief Propagation and its variants and generalizations, have been shown empirically to be very effective in solving many instances of hard/computationally intensive problems in a wide range of fields
These algorithms were originally designed for exact inference (i e calculation of marginals/max-marginals) in tree-structured probability distributions
Their application to general graphs involves replicating their iterative local update rules on the general graph
In this case however, there are no guarantees of either convergence or correctness in general
Understanding and characterizing the performance of message-passing algorithms in general graphs remains an active research area
CITATION  show correctness for graphs with at most one cycle
CITATION  show that for gaussian problems the sum-product algorithm finds the correct means upon convergence, but does not always find the correct variances
CITATION  show asymptotic correctness for random graphs associated with decoding
CITATION  shows that if max-product converges, then it is optimal in a relatively large ``local'' neighborhood
In this paper we consider the problem of using max-product to find the maximum weight matching in an arbitrary graph with arbitrary edge weights
This problem can be formulated as an integer program, which has a natural LP relaxation
In this paper we prove the following   If the LP relaxation is tight, then max-product always converges, and that too to the correct answer
If the LP relaxation is loose, then max-product does not converge
Bayati, Shah and Sharma  CITATION  were the first to investigate max-product for the weighted matching problem
They showed that if the graph is bipartite then max-product always converges to the correct answer
Recently, this result has been extended to  SYMBOL -matchings on bipartite graphs  CITATION
Since the LP relaxation is always tight for bipartite graphs, the first part of our results recover their results and can be viewed as the correct generalization to arbitrary graphs, since in this case the tightness is a function of structure as well as weights
We would like to point out three features of our work:   It provides a  necessary and sufficient  condition for convergnce of max-product in arbitrary problem instances
There are very few non-trivial classes of problems for which there is such a tight characterization of message-passing performance
The characterization is  data dependent : it is decided based not only on the graph structure but also on the weights of the particular instance
Tightness of LP relaxations is well-studied for broad classes of problems, making this chracterization promising in terms of both understanding and development of new algorithms
Relations, similarities and comparisons between max-product and linear programming have been used/mentioned by several authors  CITATION , and an exact characterization of this relationship in general remains an interesting endeavor
In particular, it would be interesting to investigate the implications of these results as regards elucidating the relationship between iterative decoding of channel codes and LP decoding  CITATION
### abstract ###
We consider the problem of minimal correction of the training set to make it consistent with monotonic constraints
This problem arises during analysis of data sets via techniques that require monotone data
We show that this problem is NP-hard in general and is equivalent to finding a maximal independent set in special orgraphs
Practically important cases of that problem considered in detail
These are the cases when a partial order given on the replies set is a total order or has a dimension 2
We show that the second case can be reduced to maximization of a quadratic convex function on a convex set
For this case we construct an approximate polynomial algorithm based on convex optimization
Keywords: machine learning, supervised learning, monotonic constraints
### introduction ###
Requirements to a classifying rule in supervised learning problems consist of two parts
The first part is induced by a set of precedents, called the training set
Each element in the training set is a pair of "object--reply" type
A classifying rule which is a mapping from objects set to the replies set should map objects from the training set pairs to the consistent replies
And the second part of requirements express our common knowledge of a classifying rule
One of the popular types of such requirements is the monotonicity which is considered in that paper
In some cases these two parts of requirements can not be satisfied both and then we have a problem of a minimal correction of the training set
Let us see what that problem is
Suppose the sets  SYMBOL  are given and on this sets we have partial orders  SYMBOL  consistently
We assume more that the partial order  SYMBOL  is a lattice
For any given mapping  SYMBOL  where  SYMBOL  we pose a problem of finding a function  SYMBOL  which is monotone due to partial orders  SYMBOL  and minimizes the following functional:  SYMBOL
Let us denote the set of monotonic functions from  SYMBOL  to  SYMBOL  by  SYMBOL
Then for a given mapping  SYMBOL  our task is the following:  SYMBOL   Every mapping  SYMBOL  which is monotone on the subset  SYMBOL  can be extended to the mapping monotone on the whole set  SYMBOL  because  SYMBOL  is a lattice
Actually on every finite subset of the lattice  SYMBOL  the operation  SYMBOL  is defined and the function  SYMBOL  is both monotone and satisfies  SYMBOL
From this we see that in the posed problem we can imply that  SYMBOL
From the above said we conclude more that this problem is equivalent to finding a maximal subset  SYMBOL  such that the function  SYMBOL  restricted on the subset  SYMBOL  is monotone
So let us consider the following generalization of our problem which we will call MaxCMS(Maximal Consistent with Monotonicity Set) {MaxCMS } The finite sets  SYMBOL  where  SYMBOL  are given; on each of them partial orders  SYMBOL  are defined consistently and the function  SYMBOL  is given
Then every element  SYMBOL  is assigned by a positive integer weight  SYMBOL
Our task is to find a maximal by weight subset  SYMBOL  such that the function  SYMBOL  restricted on  SYMBOL  is monotone i e SYMBOL {Definition 1 } The set  SYMBOL  is called acceptable iff the function  SYMBOL  restricted on  SYMBOL  is monotone {Definition 2 } A set which  is acceptable and maximal by weight is denoted by  SYMBOL (in some cases we use this notation to mean the weight of this set)
In the remainder of the paper we will consider that problem
### abstract ###
Observations consisting of measurements on relationships for pairs of objects arise in many settings, such as protein interaction and gene regulatory networks, collections of author-recipient email, and social networks
Analyzing such data with probabilisic models can be delicate because the simple exchangeability assumptions underlying many boilerplate models no longer hold
In this paper, we describe a latent variable model of such data called the  mixed membership stochastic blockmodel
This model extends blockmodels for relational data to ones which capture mixed membership latent relational structure, thus providing an object-specific low-dimensional representation
We develop a general variational inference algorithm for fast approximate posterior inference
We explore applications to social and protein interaction networks
Keywords:   Hierarchical Bayes, Latent Variables, Mean-Field Approximation, Statistical Network Analysis, Social Networks, Protein Interaction Networks
### introduction ###
Modeling relational information among objects, such as pairwise relations represented as graphs, is becoming an important problem in modern data analysis and machine learning
Many data sets contain interrelated observations
For example, scientific literature connects papers by citation, the Web connects pages by links, and protein-protein interaction data connects proteins by physical interaction records
In these settings, we often wish to infer hidden attributes of the objects from the observed measurements on pairwise properties
For example, we might want to compute a clustering of the web-pages, predict the functions of a protein, or assess the degree of relevance of a scientific abstract to a scholar's query
Unlike traditional attribute data collected over individual objects,  relational data  violate the classical independence or exchangeability assumptions that are typically made in machine learning and statistics
In fact, the observations are interdependent by their very nature, and this interdependence necessitates developing special-purpose statistical machinery for analysis
There is a history of research devoted to this end
One problem that has been heavily studied is that of  clustering  the objects to uncover a group structure based on the observed patterns of interactions
Standard model-based clustering methods, eg , mixture models, are not immediately applicable to relational data because they assume that the objects are conditionally independent given their cluster assignments
The latent stochastic blockmodel~ CITATION  represents an adaptation of mixture modeling to dyadic data
In that model, each object belongs to a cluster and the relationships between objects are governed by the corresponding pair of clusters
Via posterior inference on such a model one can identify latent roles that objects possibly play, which govern their relationships with each other
This model originates from the stochastic blockmodel, where the roles of objects are known in advance~ CITATION
A recent extension of this model relaxed the finite-cardinality assumption on the latent clusters, via a nonparametric hierarchical Bayesian formalism based on the Dirichlet process prior~ CITATION
The latent stochastic blockmodel suffers from a limitation that each object can only belong to one cluster, or in other words, play a single latent role
In real life, it is not uncommon to encounter more intriguing data on entities that are multi-facet
For example, when a protein or a social actor interacts with different partners, different functional or social contexts may apply and thus the protein or the actor may be acting according to different latent roles they can possible play
In this paper, we relax the assumption of single-latent-role for actors, and develop a  mixed membership model  for relational data
Mixed membership models, such as latent Dirichlet allocation~ CITATION , have emerged in recent years as a flexible modeling tool for data where the single cluster assumption is violated by the heterogeneity within of a data point
They have been successfully applied in many domains, such as document analysis~ CITATION , surveys~ CITATION , image processing~ CITATION , transcriptional regulation  CITATION , and population genetics~ CITATION
The mixed membership model associates each unit of observation with multiple clusters rather than a single cluster, via a membership probability-like vector
The concurrent membership of a data in different clusters can capture its different aspects, such as different underlying topics for words constituting each document
The mixed membership formalism is a particularly natural idea for relational data, where the objects can bear multiple latent roles or cluster-memberships that influence their relationships to others
As we will demonstrate, a mixed membership approach to relational data lets us describe the interaction between objects playing multiple roles
For example, some of a protein's interactions may be governed by one function; other interactions may be governed by another function
Existing mixed membership models are not appropriate for relational data because they assume that the data are conditionally independent given their latent membership vectors
In relational data, where each object is described by its relationships to others, we would like to assume that the ensemble of mixed membership vectors help govern the relationships of each object
The conditional independence assumptions of modern mixed membership models do not apply
In this paper, we develop mixed membership models for relational data, develop a fast variational inference algorithm for inference and estimation, and demonstrate the application of our technique to large scale protein interaction networks and social networks
Our model captures the multiple roles that objects exhibit in interaction with others, and the relationships between those roles in determining the observed interaction matrix
Mixed membership and the latent block structure can be reliably recovered from relational data (Section )
The application to a friendship network among students tests the model on a real data set where a well-defined latent block structure exists (Section )
The application to a protein interaction network tests to what extent our model can reduce the dimensionality of the data, while revealing substantive information about the functionality of proteins that can be used to inform subsequent analyses (Section )
### abstract ###
In the process of training Support Vector Machines~(SVMs) by decomposition methods, working set selection is an important technique, and some exciting schemes were employed into this field
To improve working set selection, we propose a new model for working set selection in sequential minimal optimization~(SMO) decomposition methods
In this model, it selects  SYMBOL  as % SYMBOL  as working set without reselection
Some properties are given by simple proof, and experiments demonstrate that the proposed method is in general faster than existing methods
### introduction ###
In the past few years, there has been huge of interest in Support Vector Machines~(SVMs)~ CITATION  because they have excellent generalization performance on a wide range of problems
The key work in training SVMs is to solve the follow quadratic optimization problem
where  SYMBOL  is the vector of all ones,  SYMBOL  is the upper bound of all variables, and  SYMBOL ,  SYMBOL  is the kernel function
Notable effects have been taken into training SVMs~ CITATION
Unlike most optimization methods which update the whole vector  SYMBOL  in each iteration, the decomposition method modifies only a subset of  SYMBOL  per iteration
In each iteration, the variable indices are split into a "working set":  SYMBOL  and its complement  SYMBOL
Then, the sub-problem with variables  SYMBOL , is solved, thereby, leaving the values of the remaining variables  SYMBOL  unchanged
This method leads to a small sub-problem to be minimized in each iteration
An extreme case is the Sequential Minimal Optimization~(SMO)~ CITATION , which restricts working set to have only two elements
Comparative tests against other algorithms, done by Platt~ CITATION , indicates that SMO is often much faster and has better scaling properties
Since only few components are updated per iteration, for difficult problems, the decomposition method suffers from slow convergence
Better method of working set selection can reduce the number of iterations and hence is an important research issue
Some methods were proposed to solve this problem and to reduce the time of training SVMs~ CITATION
In this paper, %we proposed  we propose a new model to select the working set
In this model, specially, it selects  SYMBOL  without reselection
In another word, once  SYMBOL  are selected, they will not be tested or selected during the following working set selection
Experiments demonstrate that the new model is in general faster than existing methods
This paper is organized as following
In section II, we give literature review, SMO decomposition method and existing working set selection are both discussed
A new method of working set selection is then presented in section III
In section IV, experiments with corresponding analysis are given
Finally, section V concludes this paper
### abstract ###
Conformal prediction uses past experience to determine precise levels of confidence in new predictions
Given an error probability  SYMBOL , together with  a method that makes a prediction  SYMBOL  of a label  SYMBOL ,  it produces a set of labels, typically containing  SYMBOL , that also contains  SYMBOL  with probability  SYMBOL
Conformal prediction can be applied to any method for producing  SYMBOL : a nearest-neighbor method, a support-vector machine, ridge regression, etc
Conformal prediction is designed for an on-line setting in which labels are predicted successively, each one being revealed before the next is predicted
The most novel and valuable feature of conformal prediction is that if the successive examples are sampled  independently from the same distribution, then the successive predictions will be right  SYMBOL  of the time, even though they are based on an accumulating dataset rather than on  independent datasets
In addition to the model under which successive examples are  sampled independently, other  on-line compression models can also use conformal prediction
The widely used Gaussian linear model is one of these
This tutorial presents a self-contained account of the theory of  conformal prediction and works through several numerical examples
A more comprehensive treatment of the topic is provided in   Algorithmic Learning in a Random World , by Vladimir Vovk, Alex Gammerman, and Glenn Shafer (Springer, 2005)
### introduction ###
How good is your prediction  SYMBOL
If you are predicting the label  SYMBOL  of a new object, how confident are you that  SYMBOL
If the label  SYMBOL  is a number, how close do you think it is to  SYMBOL
In machine learning, these questions are usually answered in a fairly rough way  from past experience
We expect new predictions to fare about as well as past predictions
Conformal prediction uses past experience to determine precise  levels of confidence in  predictions
Given a method for making a  prediction  SYMBOL , conformal prediction produces a   SYMBOL  prediction region ---a set   SYMBOL  that contains  SYMBOL  with probability at least  SYMBOL
Typically  SYMBOL  also contains the prediction  SYMBOL
We call  SYMBOL  the  point prediction , and we call  SYMBOL  the  region prediction
In the case of  regression, where  SYMBOL  is a number,  SYMBOL  is typically an interval  around  SYMBOL
In the case of classification, where  SYMBOL  has  a limited number of possible values,  SYMBOL  may consist of a few of these values or, in the ideal case, just one
Conformal prediction can be used with any method of point prediction for classification or regression, including support-vector  machines, decision trees, boosting, neural networks, and Bayesian prediction
Starting from the method for  point prediction, we construct a  nonconformity measure , which measures how unusual an example looks relative to previous examples, and the  conformal algorithm  turns this nonconformity measure into prediction regions
Given a nonconformity measure, the conformal algorithm produces a prediction region  SYMBOL  for every probability of error  SYMBOL
The region  SYMBOL  is a  SYMBOL - prediction  region ; it contains  SYMBOL  with probability at least  SYMBOL
The regions for different  SYMBOL  are nested:  when  SYMBOL , so that   SYMBOL  is a lower level of confidence than  SYMBOL , we have  SYMBOL
If  SYMBOL  contains only a single label (the ideal outcome in the  case of classification), we may ask how small  SYMBOL  can be made before we must enlarge  SYMBOL  by adding a second label; the corresponding value of  SYMBOL  is the confidence we assert in the predicted label
As we explain in~\S, the conformal algorithm  is designed for an on-line setting, in which we predict the labels of objects  successively, seeing each label after we have  predicted it and before we predict the next one
Our  prediction  SYMBOL  of the  SYMBOL th label  SYMBOL  may use observed features  SYMBOL  of the  SYMBOL th object and the preceding examples  SYMBOL
The size of the prediction region  SYMBOL  may also depend on these details
Readers most interested in implementing the conformal algorithm may wish to turn directly to  the elementary examples in  and~and then turn back to the earlier more general material as needed
As we explain in \S, the on-line picture leads to a new concept of validity for  prediction with confidence
Classically, a method for finding  SYMBOL  prediction regions was considered valid if it had a  SYMBOL  probability of containing  the label predicted, because by the law of the large numbers it would then be correct  SYMBOL  of the time when repeatedly applied to independent datasets
But in the on-line picture, we repeatedly apply a method not to independent datasets but to an accumulating dataset
After using  SYMBOL  and  SYMBOL  to predict  SYMBOL , we use   SYMBOL  and  SYMBOL  to predict  SYMBOL , and so on
For a  SYMBOL  on-line method to be valid,  SYMBOL  of these predictions must be correct
Under minimal assumptions, conformal prediction is valid in this new and powerful sense
One setting where conformal prediction is valid in the new on-line sense is the one in which the  examples  SYMBOL  are sampled independently from a constant  population---i e , from a fixed but unknown probability  distribution  SYMBOL
It is also valid under the slightly weaker assumption that the examples are probabilistically  exchangeable  (see \S) and under other on-line compression models, including the widely used Gaussian linear model (see \S)
The validity of conformal prediction under these models is  demonstrated in Appendix~
In addition to the validity of a method for producing  SYMBOL  prediction regions, we are also interested in its efficiency
It is efficient if the prediction region is usually  relatively small and therefore informative
In classification, we would like to see a 95\% prediction region  so small that it contains only the single predicted label  SYMBOL
In regression, we would like to see a very narrow interval around the predicted number  SYMBOL
The claim of 95\% confidence for a 95\% conformal prediction region is valid under exchangeability, no matter what the probability distribution  SYMBOL  the examples follow and no matter what nonconformity measure is used to construct the conformal prediction region
But the efficiency of conformal prediction  will depend on  SYMBOL  and the nonconformity measure
If we think we know  SYMBOL , we may choose a nonconformity measure that will be efficient if we are right
If we have prior probabilities for  SYMBOL ,  we may use these prior probabilities to construct a point predictor  SYMBOL  and a nonconformity measure
In the regression case, we might use as  SYMBOL  the mean of the posterior distribution for  SYMBOL  given the first  SYMBOL  examples and  SYMBOL ; in the classification case, we might use the label with the greatest  posterior probability
This strategy of first guaranteeing validity under a relatively weak assumption and then seeking efficiency under stronger assumptions conforms to advice long given by John Tukey and others  CITATION
Conformal prediction is studied in detail in  Algorithmic Learning in a Random World , by Vovk, Gammerman, and Shafer  CITATION
A recent exposition by Gammerman and Vovk  CITATION  emphasizes connections with the theory of randomness, Bayesian methods, and induction
In this article we emphasize  the on-line concept of validity, the meaning of exchangeability, and the generalization to other on-line compression models
We leave aside many important topics  that are treated in  Algorithmic Learning in a Random World , including extensions beyond the on-line picture
### abstract ###
Bounds on the risk play a crucial role in statistical learning theory
They usually involve as capacity measure of the model studied the VC dimension or one of its extensions
In classification, such ``VC dimensions'' exist for models taking values in  SYMBOL ,  SYMBOL  and  SYMBOL
We introduce the generalizations appropriate for the missing case, the one of models with values in  SYMBOL
This provides us with a new guaranteed risk for M-SVMs which appears superior to the existing one
### introduction ###
Vapnik's statistical learning theory~ CITATION  deals with three types of problems: pattern recognition, regression estimation and density estimation
However, the theory of bounds has primarily been developed for the computation of dichotomies only
Central in this theory is the notion of ``capacity'' of classes of functions
In the case of binary classifiers, the measure of this capacity is the famous Vapnik-Chervonenkis (VC) dimension
Extensions have also been proposed for real-valued bi-class models and multi-class models taking theirs values in the set of categories
Strangely enough, no generalized VC dimension was available so far for  SYMBOL -category classifiers taking their values in  SYMBOL
This was all the more unsatisfactory as many classifiers exhibit this property, such as the multi-layer perceptrons, or the multi-class support vector machines (M-SVMs)
In this paper, the scale-sensitive  SYMBOL -dimensions are introduced to fill this gap
A generalization of Sauer's lemma  CITATION  is given,  which relates the covering numbers appearing in the standard guaranteed risk for large margin multi-category discriminant models to one of these dimensions, the margin Natarajan dimension
This latter dimension is then bounded from above for the architecture shared by all the M-SVMs proposed so far
This provides us with a sharper bound on their sample complexity
The organization of the paper is as follows
Section~ introduces the basic bound on the risk of large margin multi-category discriminant models
In Section~, the scale-sensitive  SYMBOL -dimensions are defined, and the generalized Sauer lemma is formulated
The upper bound on the margin Natarajan dimension of the M-SVMs is then described in Section~
For lack of space, proofs are omitted
They can be found in  CITATION
### abstract ###
The goal of the present paper is to provide a systematic and comprehensive study of  rational stochastic languages  over a semiring  SYMBOL
A rational stochastic language is a probability distribution over a free monoid  SYMBOL  which is rational over  SYMBOL , that is which can be generated by a multiplicity automata with parameters in  SYMBOL
We study the relations between the classes of rational stochastic languages  SYMBOL
We define the notion of  residual  of a stochastic language and we use it to investigate properties of several subclasses of rational stochastic languages
Lastly, we study the representation of rational stochastic languages by means of multiplicity automata
### introduction ###
In probabilistic grammatical inference, data often arise in the form of a finite sequence of words  SYMBOL  over some predefined alphabet  SYMBOL
These words are assumed to be independently drawn according to a fixed but unknown probability distribution over  SYMBOL
Probability distributions over free monoids  SYMBOL  are called  stochastic languages
A usual goal in grammatical inference is to try to infer an approximation of this distribution in some class of probabilistic models, such as  probabilistic automata
A probabilistic automaton (PA) is composed of a  structure , which is a finite automaton (NFA), and  parameters  associated with states and transitions, which represent the probability for a state to be initial, terminal or the probability for a transition to be chosen
It can easily be shown that probabilistic automata have the same expressivity as Hidden Markov Models (HMM), which are heavily used in statistical inference~ CITATION
Given the structure  SYMBOL  of a probabilistic automaton and a sequence of words  SYMBOL , computing parameters for  SYMBOL  which maximize the likelihood of  SYMBOL  is NP-hard  CITATION
In practical cases however, algorithms based on the E M ( Expectation-Maximization ) method  CITATION  can be used to compute approximate values
On the other hand, inferring a probabilistic automaton (structure and parameters) from a sequence of words is a widely open field of research
Most results obtained so far only deal with restricted subclasses of PA, such as Probabilistic Deterministic Automata (PDA), i e probabilistic automata whose structure is deterministic (DFA) or Probabilistic Residual Automata (PRA), i e probabilistic automata whose structure is a residual finite state automaton (RFSA) CITATION
In other respects, it can be noticed that stochastic languages are particular cases of  formal power series  and that probabilistic automata are also particular cases of  multiplicity automata , notions which have been extensively studied in the field of formal language theory CITATION
Therefore, stochastic languages which can be generated by multiplicity automata are special cases of  rational languages
We call them  rational stochastic languages
The goal of the present paper is to provide a systematic and comprehensive study of  rational stochastic languages  so as to bring out properties that could be useful for a grammatical inference purpose
Indeed, considering the objects to infer as special cases of rational languages makes it possible to use the powerful theoretical tools that have been developed in that field and hence, give answers to many questions that naturally arise when working with them: is it possible to decide within polynomial time whether two probabilistic automata generate the same stochastic language
does allowing negative coefficients in probabilistic automata extend the class of generated stochastic languages
can a rational stochastic language which takes all its values in  SYMBOL  always be generated by a multiplicity automata with coefficients in  SYMBOL
and so forth
Also, studying  rational stochastic languages  for themselves, considered as objects of language theory, helps to bring out notions and properties which are important in a grammatical inference pespective: for example, we show that the notion of residual language (or derivative), so important for grammatical inference~ CITATION , has a natural counterpart for stochastic languages~ CITATION , which can be used to express many properties of classes of stochastic languages
Formal power series  take their values in a semiring  SYMBOL : let us denote by  SYMBOL  the set of all formal power series
Here, we only consider semirings  SYMBOL ,  SYMBOL ,  SYMBOL  and  SYMBOL
For any such semiring  SYMBOL , we define the set  SYMBOL  of rational stochastic languages as the set of stochastic languages over  SYMBOL  which are rational languages over  SYMBOL
For any two distinct semirings  SYMBOL  and  SYMBOL , the corresponding sets of rational stochastic languages are distinct
We show that  SYMBOL  is a Fatou extension of  SYMBOL  for stochastic languages, which means that any rational stochastic language over  SYMBOL  which takes its values in  SYMBOL  is also rational over  SYMBOL
However,  SYMBOL  is not a Fatou extension of  SYMBOL  for stochastic languages: there exists a rational stochastic language over  SYMBOL  which takes its values in  SYMBOL  and which is not rational over  SYMBOL
For any stochastic language  SYMBOL  over  SYMBOL  and any word  SYMBOL  such that  SYMBOL , let us define the residual language  SYMBOL  of  SYMBOL  with respect to  SYMBOL  by  SYMBOL : residual languages clearly are stochastic languages
We show that the residual languages of a rational stochastic language  SYMBOL  over  SYMBOL  are also rational over  SYMBOL
The residual subsemimodule  SYMBOL  of  SYMBOL  spanned by the residual languages of any stochastic language  SYMBOL  may be used to express the rationality of  SYMBOL :  SYMBOL  is rational iff  SYMBOL  is included in a finitely generated subsemimodule of  SYMBOL
But when  SYMBOL  is positive, i e SYMBOL  or  SYMBOL , it may happen that  SYMBOL  itself is not finitely generated
We study the properties of two subclasses of  SYMBOL : the set  SYMBOL  composed of rational stochastic languages over  SYMBOL  whose residual subsemimodule is finitely generated and the set  SYMBOL  composed of rational stochastic languages over  SYMBOL  which have finitely many residual languages
We show that for any of these two classes,  SYMBOL  is a Fatou extension of  SYMBOL : any stochastic language of  SYMBOL  (resp
of  SYMBOL ) which takes its values in  SYMBOL  is an element of  SYMBOL  (resp
of  SYMBOL )
We also show that for any element  SYMBOL  of  SYMBOL , there exists a unique minimal subset of residual languages of  SYMBOL  which generates  SYMBOL
Then, we study the representation of rational stochastic languages by means of multiplicity automata
We first show that the set of multiplicity automata with parameters in  SYMBOL  which generate stochastic languages is not recursive
Moreover, it contains no recursively enumerable subset capable to generate the whole set of rational stochastic languages over  SYMBOL
A stochastic language  SYMBOL  is a formal series which has two properties: (i)  SYMBOL  for any word  SYMBOL , (ii)  SYMBOL
We show that the undecidability comes from the first requirement, since the second one can be decided within polynomial time
We show that the set of stochastic languages which can be generated by probabilistic automata with parameters in  SYMBOL  (resp
SYMBOL ) exactly coincides with  SYMBOL  (resp
SYMBOL )
A probabilistic automaton  SYMBOL  is called a Probabilistic Residual Automaton (PRA) if the stochastic languages associated with its states are residual languages of the stochastic languages  SYMBOL  generated by  SYMBOL
We show that the set of stochastic languages that can be generated by probabilistic residual automata with parameters in  SYMBOL  (resp
SYMBOL ) exactly coincides with  SYMBOL  (resp
SYMBOL )
We do not know whether the class of PRA is decidable
However, we describe two decidable subclasses of PRA capable of generating  SYMBOL  when  SYMBOL  or  SYMBOL : the class of  SYMBOL -reduced PRA and the class of prefixial PRA
The first one provides minimal representation in the class of PRA but we show that the membership problem is PSPACE-complete
The second one produces more cumbersome representation but the membership problem is polynomial
Finally, we show that the set of stochastic languages that can be generated by probabilistic deterministic automata with parameters in  SYMBOL  (resp
SYMBOL ) exactly coincides with  SYMBOL , which is also equal to  SYMBOL  (resp
SYMBOL , which is also equal to  SYMBOL )
We recall some properties on rational series, stochastic languages and multiplicity automata in Section~
We define and study rational stochastic languages in Section~
The relations between the classes of rational stochastic languages are studied in Subsection~
Properties of the residual languages of rational stochastic languages are studied in Subsection~
A characterisation of rational stochastic languages in terms of stable subsemimodule is given in Subsection~
Classes  SYMBOL  and  SYMBOL  are defined and studied in Subsection~
The representation of rational stochastic languages by means of multiplicity automata is given in Section~
### abstract ###
In this paper, we study the application of sparse principal component analysis (PCA) to clustering and feature selection problems
Sparse PCA seeks sparse factors, or linear combinations of the data variables, explaining a maximum amount of variance in the data while having only a limited number of nonzero coefficients
PCA is often used as a simple clustering technique and sparse factors allow us here to interpret the clusters in terms of a reduced set of variables
We begin with a brief introduction and motivation on sparse PCA and detail our implementation of the algorithm in d'Aspremont et al (2005)
We then apply these results to some classic clustering and feature selection problems arising in biology
### introduction ###
This paper focuses on applications of sparse principal component analysis to clustering and feature selection problems, with a particular focus on gene expression data analysis
Sparse methods have had a significant impact in many areas of statistics, in particular regression and classification (see  CITATION ,  CITATION  and  CITATION  among others)
As in these areas, our motivation for developing sparse multivariate visualization tools is the potential of these methods for yielding statistical results that are both more interpretable and more robust than classical analyses, while giving up little statistical efficiency
Principal component analysis (PCA) is a classic tool for analyzing large scale multivariate data
It seeks linear combinations of the data variables (often called factors or principal components) that capture a maximum amount of variance
Numerically, PCA only amounts to computing a few leading eigenvectors of the data's covariance matrix, so it can be applied to very large scale data sets
One of the key shortcomings of PCA however is that these factors are linear combinations of  all  variables; that is, all factor coefficients (or loadings) are non-zero
This means that while PCA facilitates model interpretation and visualization by concentrating the information in a few key factors, the factors themselves are still constructed using  all  observed variables
In many applications of PCA, the coordinate axes have a direct physical interpretation; in finance or biology for example, each axis might correspond to a specific financial asset or gene
In such cases, having only a few nonzero coefficients in the principal components would greatly improve the relevance and interpretability of the factors
In sparse PCA, we seek a trade-off between the two goals of  expressive power  (explaining most of the variance or information in the data) and  interpretability  (making sure that the factors involve only a few coordinate axes or variables)
When PCA is used as a clustering tool, sparse factors will allow us to identify the clusters with the action of only a few variables
Earlier methods to produce sparse factors include Cadima and Jolliffe  CITATION  where the loadings with smallest absolute value are thresholded to zero and nonconvex algorithms called SCoTLASS by  CITATION , SLRA  CITATION  and SPCA by  CITATION
This last method works by writing PCA as a regression-type optimization problem and applies LASSO  CITATION , a penalization technique based on the  SYMBOL  norm
Very recently,  CITATION  and  CITATION  also proposed a greedy approach which seeks globally optimal solutions on small problems and uses a greedy method to approximate the solution of larger ones
In what follows, we give a brief introduction to the relaxation of this problem in  CITATION  and describe how this smooth optimization algorithm was implemented
The most expensive numerical step in this algorithm is the computation of the gradient as a matrix exponential and our key numerical contribution here is to show that using only a partial eigenvalue decomposition of the current iterate can produce a sufficiently precise gradient approximation while drastically improving computational efficiency
We then show on classic gene expression data sets that using sparse PCA as a simple clustering tool isolates very relevant genes compared to other techniques such as recursive feature elimination or ranking
The paper is organized as follows
In Section , we begin with a brief introduction and motivation on sparse PCA and detail our implementation of the algorithm in a numerical toolbox called DSPCA, which is available for download on the authors' websites
In Section , we describe the application of sparse PCA to clustering and feature selection on gene expression data
### abstract ###
% We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse
Our approach is to solve a maximum likelihood problem with an added  SYMBOL -norm penalty term
The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes
We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case
Our first algorithm uses block coordinate descent, and can be interpreted as recursive  SYMBOL -norm penalized regression
Our second algorithm, based on Nesterov's first order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods
Using a log determinant relaxation of the log partition function ( CITATION ), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case
We test our algorithms on synthetic data, as well as on gene expression and senate voting records data
### introduction ###
% Put the title of the first chapter on this line Undirected graphical models offer a way to describe and explain the relationships among a set of variables, a central element of multivariate data analysis
The principle of parsimony dictates that we should select the simplest graphical model that adequately explains the data
In this paper weconsider practical ways of implementing the following approach to finding such a model:  given a set of data, we solve a maximum likelihood problem with an added  SYMBOL -norm penalty to make the resulting graph as sparse as possible
Many authors have studied a variety of related ideas
In the Gaussian case, model selection involves finding the pattern of zeros in the inverse covariance matrix, since these zeros correspond to conditional independencies among the variables
Traditionally, a greedy forward-backward search algorithm is used to determine the zero pattern  CITATION
However, this is computationally infeasible for data with even a moderate number of variables
CITATION  introduce a gradient descent algorithm in which they account for the sparsity of the inverse covariance matrix by defining a loss function that is the negative of the log likelihood function
Recently,  CITATION  considered penalized maximum likelihood estimation, and  CITATION  proposed a set of large scale methods for problems where a sparsity pattern for the inverse covariance is given and one must estimate the nonzero elements of the matrix
Another way to estimate the graphical model is to find the set of neighbors of each node in the graph by regressing that variable against the remaining variables
In this vein,  CITATION  employ a stochastic algorithm to manage tens of thousands of variables
There has also been a great deal of interest in using  SYMBOL -norm penalties in statistical applications
CITATION  apply an  SYMBOL  norm penalty to sparse principle component analysis
Directly related to our problem is the use of the Lasso of  CITATION  to obtain a very short list of neighbors for each node in the graph
CITATION  study this approach in detail, and show that the resulting estimator is consistent, even for high-dimensional graphs
The problem formulation for Gaussian data, therefore, is simple
The difficulty lies in its computation
Although the problem is convex, it is non-smooth and has an unbounded constraint set
As we shall see, the resulting complexity for existing interior point methods is  SYMBOL , where  SYMBOL  is the number of variables in the distribution
In addition, interior point methods require that at each step we compute and store a Hessian of size  SYMBOL
The memory requirements and complexity are thus prohibitive for  SYMBOL  higher than the tens
Specialized algorithms are needed to handle larger problems
The remainder of the paper is organized as follows
We begin by considering Gaussian data
In Section  we set up the problem, derive its dual, discuss properties of the solution and how heavily to weight the  SYMBOL -norm penalty in our problem
In Section  we present a provably convergent block coordinate descent algorithm that can be interpreted as recursive  SYMBOL -norm penalized regression
In Section  we present a second, alternative algorithm based on Nesterov's recent work on non-smooth optimization, and give a rigorous complexity analysis with better dependence on problem size than interior point methods
In Section  we show that the algorithms we developed for the Gaussian case can also be used to solve an approximate sparse maximum likelihood problem for multivariate binary data, using a log determinant relaxation for the log partition function given by  CITATION
In Section , we test our methods on synthetic as well as gene expression and senate voting records data
### abstract ###
Given a sample covariance matrix, we examine the problem of maximizing the variance explained by a linear combination of the input variables while constraining the number of nonzero coefficients in this combination
This is known as sparse principal component analysis and has a wide array of applications in machine learning and engineering
We formulate a new semidefinite relaxation to this problem and derive a greedy algorithm that computes a  full set  of good solutions for all target numbers of non zero coefficients, with total complexity  SYMBOL , where  SYMBOL  is the number of variables
We then use the same relaxation to derive sufficient conditions for global optimality of a solution, which can be tested in  SYMBOL  per pattern
We discuss applications in subset selection and sparse recovery and show on artificial examples and biological data that our algorithm does provide globally optimal solutions in many cases
### introduction ###
Principal component analysis (PCA) is a classic tool for data analysis, visualization or compression and has a wide range of applications throughout science and engineering
Starting from a multivariate data set, PCA finds linear combinations of the variables called  principal components , corresponding to orthogonal directions maximizing variance in the data
Numerically, a full PCA involves a singular value decomposition of the data matrix
One of the key shortcomings of PCA is that the factors are linear combinations of  all  original variables; that is, most of factor coefficients (or loadings) are non-zero
This means that while PCA facilitates model interpretation and visualization by concentrating the information in a few factors, the factors themselves are still constructed using all variables, hence are often hard to interpret
In many applications, the coordinate axes involved in the factors have a direct physical interpretation
In financial or  biological applications, each axis might correspond to a specific asset or gene
In problems such as these, it is natural to seek a trade-off between the two goals of  statistical fidelity  (explaining most of the variance in the data) and  interpretability  (making sure that the factors involve only a few coordinate axes)
Solutions that have only a few nonzero coefficients in the principal components are usually easier to interpret
Moreover, in some applications, nonzero coefficients have a direct cost (\eg, transaction costs in finance) hence there may be a direct trade-off between statistical fidelity and practicality
Our aim here is to efficiently derive  sparse principal components , i
e, a set of sparse vectors that explain a maximum amount of  variance
Our belief is that in many applications, the decrease  in statistical fidelity required to obtain sparse factors is  small and relatively benign
In what follows, we will focus on the problem of finding sparse factors which explain a maximum amount of variance, which can be written:  \max_{ \| z \|  1 } z^T z - \Card(z) in the variable  SYMBOL , where  SYMBOL  is the (symmetric positive semi-definite) sample covariance matrix,  SYMBOL  is a parameter controlling sparsity, and  SYMBOL  denotes the cardinal (or  SYMBOL  norm) of  SYMBOL , i e the number of non zero coefficients of  SYMBOL
While PCA is numerically easy, each factor requires computing a leading eigenvector, which can be done in  SYMBOL , sparse PCA is a hard combinatorial problem
In fact,  CITATION  show that the subset selection problem for ordinary least squares, which is NP-hard~ CITATION , can be reduced to a sparse generalized eigenvalue problem, of which sparse PCA is a particular intance
Sometimes ad hoc ``rotation'' techniques are used to post-process the results from PCA and find interpretable directions underlying a particular subspace (see  CITATION )
Another simple solution is to  threshold  the loadings with small absolute value to zero  CITATION
A more systematic approach to the problem arose in recent years, with various researchers proposing nonconvex algorithms  (e g , SCoTLASS by  CITATION , SLRA by  CITATION  or D C based methods  CITATION  which find modified principal components  with zero loadings
The SPCA algorithm, which is based on the representation of PCA as a regression-type optimization problem~ CITATION , allows the application of the LASSO  CITATION , a penalization technique based on the  SYMBOL  norm
With the exception of simple thresholding, all the algorithms above require solving non convex problems
Recently also,  CITATION  derived an  SYMBOL  based semidefinite relaxation for the sparse PCA problem () with a complexity of  SYMBOL  for a given  SYMBOL
Finally,  CITATION  used greedy search and branch-and-bound methods to solve small instances of problem () exactly and get good solutions for larger ones
Each step of this greedy algorithm has complexity  SYMBOL , leading to a total complexity of  SYMBOL  for a full set of solutions
Our contribution here is twofold
We first derive a greedy algorithm for computing a  full set  of good solutions (one for each target sparsity between 1 and  SYMBOL ) at a total numerical cost of  SYMBOL  based on the convexity of the of the largest eigenvalue of a symmetric matrix
We then derive  tractable  sufficient conditions for a vector  SYMBOL  to be a  global  optimum of ()
This means in practice that, given a vector  SYMBOL  with support  SYMBOL , we can test if  SYMBOL  is a globally optimal solution to problem () by performing a few binary search iterations to solve a one dimensional convex minimization problem
In fact, we can take any sparsity pattern candidate from any algorithm and test its optimality
This paper builds on the earlier conference version~ CITATION , providing new and simpler conditions for optimality and describing applications to subset selection and sparse recovery
While there is certainly a case to be made for  SYMBOL  penalized maximum eigenvalues (\`a la  CITATION ), we strictly focus here on the  SYMBOL  formulation
However, it was shown recently (see  CITATION ,  CITATION  or  CITATION  among others) that there is in fact a deep connection between  SYMBOL  constrained extremal eigenvalues and LASSO type variable selection algorithms
Sufficient conditions based on sparse eigenvalues (also called restricted isometry constants in  CITATION ) guarantee consistent variable selection (in the LASSO case) or sparse recovery (in the decoding problem)
The results we derive here produce upper bounds on sparse extremal eigenvalues and can thus be used to prove consistency in LASSO estimation, prove perfect recovery in sparse recovery problems, or prove that a particular solution of the subset selection problem is optimal
Of course, our conditions are only sufficient, not necessary (which would contradict the NP-Hardness of subset selection) and the duality bounds we produce on sparse extremal eigenvalues cannot always be tight, but we observe that the duality gap is often small
The paper is organized as follows
We begin by formulating the sparse PCA problem in Section
In Section , we write an efficient algorithm for computing a full set of candidate solutions to problem () with total complexity  SYMBOL
In \mysec{semidefinite} we then formulate a convex relaxation for the sparse PCA problem, which we use in Section  to derive tractable sufficient conditions for the global optimality of a particular sparsity pattern
In Section  we detail applications to subset selection, sparse recovery and variable selection
Finally, in Section , we test the numerical performance of these results
### abstract ###
We consider an agent interacting with an unmodeled environment
At each time, the agent makes an observation, takes an action, and incurs a cost
Its actions can influence future observations and costs
The goal is to minimize the long-term average cost
We propose a novel algorithm, known as the active LZ algorithm, for optimal control based on ideas from the Lempel-Ziv scheme for universal data compression and prediction
We establish that, under the active LZ algorithm, if there exists an integer  SYMBOL  such that the future is conditionally independent of the past given a window of  SYMBOL  consecutive actions and observations, then the average cost converges to the optimum
Experimental results involving the game of Rock-Paper-Scissors illustrate merits of the algorithm
### introduction ###
\IEEEPARstart{C}{onsider} an agent that, at each integer time  SYMBOL , makes an observation  SYMBOL  from a finite observation space  SYMBOL , and takes an action  SYMBOL  selected from a finite action space  SYMBOL
The agent incurs a bounded cost  SYMBOL
The goal is to minimize the long-term average cost  SYMBOL  Here, the expectation is over the randomness in the  SYMBOL  process, and, at each time  SYMBOL , the action  SYMBOL  is selected as a function of the prior observations  SYMBOL  and the prior actions  SYMBOL
We will propose a general action-selection strategy called the  active LZ algorithm
In addition to the new strategy, a primary contribution of this paper is a theoretical guarantee that this strategy attains optimal average cost under weak assumptions about the environment
The main assumption is that there exists an integer  SYMBOL  such that the future is conditionally independent of the past given a window of  SYMBOL  consecutive actions and observations
In other words,  SYMBOL } where  SYMBOL  is a transition kernel and  SYMBOL  is the  SYMBOL -algebra generated by  SYMBOL
We are particularly interested in situations where neither  SYMBOL  nor even  SYMBOL  are known to the agent
That is, where there is a finite but unknown dependence on history
Consider the following examples, which fall into the above formalism
The optimization problem is to find a sequence of functions  SYMBOL , where each function  SYMBOL  specifies an encoder at time  SYMBOL , so as to minimize the long-term average distortion  SYMBOL  Assume that the source is Markov of order  SYMBOL , but that both the transition probabilities for the source and the order  SYMBOL  are unknown
Setting  SYMBOL , define the observation at time  SYMBOL  to be the vector  SYMBOL  and the action at time  SYMBOL  to be  SYMBOL
Then, optimal coding problem at hand falls within our framework (cf
CITATION  and references therein) \end{example}  With knowledge of the kernel  SYMBOL  (or even just the order of the kernel,  SYMBOL ), solving for the average cost optimal policy in either of the examples above via dynamic programming methods is relatively straightforward
This paper develops an algorithm that,  without knowledge of the kernel or its order , achieves average cost optimality
The active LZ algorithm we develop consists of two broad components
The first is an efficient data structure, a context tree on the joint process  SYMBOL , to store information relevant to predicting the observation at time  SYMBOL ,  SYMBOL , given the history available up to time  SYMBOL  and the action selected at time  SYMBOL ,  SYMBOL
Our prediction methodology borrows heavily from the Lempel-Ziv algorithm for data compression  CITATION
The second component of our algorithm is a dynamic programming scheme that, given the probabilistic model determined by the context tree, selects actions so as to minimize costs over a suitably long horizon
Absent knowledge of the order of the kernel,  SYMBOL , the two tasks above---building a context tree in order to estimate the kernel, and selecting actions that minimize long-term costs---must be done continually in tandem which creates an important tension between `exploration' and `exploitation'
In particular, on the one hand, the algorithm must select actions in a manner that builds an accurate context tree
On the other hand, the desire to minimize costs naturally restricts this selection
By carefully balancing these two tensions our algorithm achieves an average cost equal to that of an optimal policy with full knowledge of the kernel  SYMBOL
Related problems have been considered in the literature
Kearns and Singh  CITATION  present an algorithm for reinforcement learning in a Markov decision process
This algorithm can be applied in our context when  SYMBOL  is known, and asymptotic optimality is guaranteed
More recently, Even-Dar et al \  CITATION  present an algorithm for optimal control of partially observable Markov decision processes, a more general setting than what we consider here, and are able to establish theoretical bounds on convergence time
The algorithm there, however, seems difficult and unrealistic to implement in contrast with what we present here
Further, it relies on knowledge of a constant related to the amount of time a `homing' policy requires to achieve equilibrium
This constant may be challenging to estimate
Work by de Farias and Megiddo  CITATION  considers an optimal control framework where the dynamics of the environment are not known and one wishes to select the best of a finite set of `experts'
In contrast, our problem can be thought of as competing with the set of all possible strategies
The prediction problem for loss functions with memory and a Markov-modulated source considered by  Merhav et al \  CITATION  is essentially a Markov decision problem as the authors point out; again, in this case, knowing the structure of the loss function implicitly gives the order of the underlying Markov process
The active LZ algorithm is inspired by the Lempel-Ziv algorithm
This algorithm has been extended to address many problems, such as prediction  CITATION  and filtering  CITATION
In almost all cases, however, future observations are not influenced by actions taken by the algorithm
This is in contrast to the active LZ algorithm, which proactively anticipates the effect of actions on future observations
An exception is the work of Vitter and Krishnan  CITATION , which considers cache pre-fetching and can be viewed as a special case of our formulation
The Lempel-Ziv algorithm and its extensions revolve around a context tree data structure that is constructed as observations are made
This data structure is simple and elegant from an implementational point of view
The use of this data structure in reinforcement learning represents a departure from representations of state and belief state commonly used in the reinforcement learning literature
Such data structures have proved useful in representing experience in algorithms for engineering applications ranging from compression to prediction to denoising
Understanding whether and how some of this value can be extended to reinforcement learning is the motivation for this paper
The remainder of this paper is organized as follows
In Section~, we formulate our problem precisely
In Section~, we present our algorithm and provide computational results in the context of the rock-paper-scissors example
Our main result, as stated in Theorem~ in Section~, is that the algorithm is asymptotically optimal
Section~ concludes
### abstract ###
We consider the least-square regression problem with regularization by a block  SYMBOL -norm, ie , a sum of  Euclidean norms over spaces of dimensions larger than one
This problem, referred to as the group Lasso, extends the usual regularization by the  SYMBOL -norm where all spaces have dimension one, where it is commonly referred to as the Lasso
In this paper, we study the asymptotic model consistency of the group Lasso
We derive necessary and sufficient conditions for the consistency of group Lasso under practical assumptions, such as model misspecification
When the linear predictors and  Euclidean norms are replaced by functions and reproducing kernel Hilbert norms, the problem is usually referred to as multiple kernel learning and is commonly used for learning from heterogeneous data sources and for non linear variable selection
Using tools from functional analysis, and in particular covariance operators,  we extend the consistency results to this infinite dimensional case and also propose an adaptive scheme to obtain a consistent model estimate, even when the necessary  condition required for the non adaptive scheme is not satisfied
### introduction ###
Regularization has emerged as a dominant theme in machine  learning and  statistics
It provides an intuitive and principled tool for learning from high-dimensional data
Regularization by squared Euclidean norms or squared Hilbertian norms has been thoroughly studied in various settings, from approximation theory to statistics, leading to efficient practical algorithms based on linear algebra and very general theoretical consistency results~ CITATION
In recent years, regularization by non Hilbertian norms  has generated considerable interest in linear supervised learning, where the goal is to predict a response as a linear function of  covariates;  in particular, regularization by the  SYMBOL -norm (equal to the sum of absolute values), a method commonly referred to as the  Lasso ~ CITATION , allows to perform variable selection
However,  regularization by non Hilbertian norms cannot be solved empirically by simple linear algebra and instead leads to general convex optimization problems and much of the early effort has been dedicated to algorithms to solve the optimization problem efficiently
In particular, the  Lars  algorithm of~ CITATION  allows to find the entire regularization path (i e , the set of solutions for all values of the regularization parameters) at the cost of a single matrix inversion
As the consequence of the optimality conditions,  regularization by the  SYMBOL -norm  leads to  sparse  solutions, i e , loading vectors with many zeros
Recent works  CITATION  have looked precisely at the model consistency of the Lasso, i e , if we know that the data were generated from a sparse loading vector, does the Lasso actually recover it when the number of observed data points grows
In the case of a fixed number of covariates, the Lasso does recover the sparsity pattern if and only if a certain simple condition on the generating covariance matrices is verified~ CITATION
In particular, in low correlation settings, the Lasso is indeed consistent
However, in presence of strong correlations, the Lasso cannot be consistent, shedding light on potential problems of such procedures for variable selection
Adaptive versions where data-dependent weights are added to the  SYMBOL -norm  then allow to keep the consistency in all situations~ CITATION
A related Lasso-type procedure is the  group Lasso , where the covariates are assumed to be clustered in groups, and instead of summing the absolute values of each individual loading, the sum of Euclidean norms of the loadings in each group is used
Intuitively, this should drive all the weights in one group to zero  together , and thus lead to group selection~ CITATION
In \mysec{grouplasso}, we extend the consistency results of the Lasso to the group Lasso, showing that similar correlation conditions are necessary and sufficient conditions for consistency
The passage from groups of size one to groups of larger sizes leads however to a slightly weaker result as we can not get a single necessary and sufficient condition (in \mysec{refined}, we show that the stronger result similar to the Lasso is not true as soon as one group has dimension larger than one)
Also, in our proofs, we relax the  assumptions usually made for such consistency results, i e , that the model is completely well-specified (conditional expectation of the response which is linear in the covariates and constant conditional variance)
In the context of  misspecification , which is a common situation when applying methods such as the ones presented in this paper, we simply prove convergence to the best linear predictor (which is assumed to be sparse), both in terms of loading vectors and sparsity patterns
The group Lasso essentially replaces groups of size one by groups of size larger than one
It is natural in this context to allow the size of each group to grow unbounded, i e , to replace the sum of Euclidean norms by a sum  of appropriate Hilbertian norms
When the Hilbert spaces are reproducing kernel Hilbert spaces (RKHS), this procedure turns out to be equivalent to learn the best convex combination  of a set of basis kernels, where each kernel corresponds to one  Hilbertian norm used for regularization~ CITATION
This framework, referred to as  multiple kernel learning ~ CITATION , has applications in kernel selection, data fusion from heterogeneous data sources and non linear variable selection~ CITATION
In this latter case,  multiple kernel learning can exactly be seen as variable selection in a  generalized additive model ~ CITATION
We extend  the consistency results of the group Lasso to this non parametric  case, by using covariance operators and appropriate notions of functional analysis
These notions allow to carry out the analysis entirely in  ``primal/input''  space, while the algorithm has to work in  ``dual/feature''   space to avoid infinite dimensional optimization
Throughout the paper, we will always go back and forth between primal and dual formulations, primal formulation for analysis and dual formulation for algorithms
The paper is organized as follows: in \mysec{grouplasso}, we present the consistency results for the group Lasso, while in \mysec{mklsec}, we extend these to Hilbert spaces
Finally, we present the adaptive schemes in \mysec{adaptive} and illustrate our set of results with simulations on synthetic examples in \mysec{simulations}
### abstract ###
We show how rate-distortion theory provides a mechanism for automated theory building by naturally distinguishing between regularity and randomness
We start from the simple principle that model variables should, as much as possible, render the future and past conditionally independent
From this, we construct an objective function for model making whose extrema embody the trade-off between a model's structural complexity and its predictive power
The solutions correspond to a hierarchy of models that, at each level of complexity, achieve optimal predictive power at minimal cost
In the limit of maximal prediction the resulting optimal model identifies a process's intrinsic organization by extracting the underlying causal states
In this limit, the model's complexity is given by the statistical complexity, which is known to be minimal for achieving maximum prediction
Examples show how theory building can profit from analyzing a process's  causal compressibility , which is reflected in the optimal models' rate-distortion curve---the process's characteristic for optimally balancing structure and noise at different levels of representation
### introduction ###
Progress in science is often driven by the discovery of novel patterns
Historically, physics has relied on the creative mind of the theorist to  articulate mathematical models that capture nature's regularities in physical  principles and laws
But the last decade has witnessed a new era in collecting  truly vast data sets
Examples include contemporary experiments in particle  physics  CITATION  and astronomy  CITATION , but range to genomics, automated language translation  CITATION , and web social organization  CITATION
In all these, the volume of data far exceeds  what any human can analyze directly by hand
This presents a new challenge---automated pattern discovery and model building
A principled understanding of model making is critical to provide theoretical guidance for developing automated procedures
In this Letter, we show how basic  information-theoretic optimality criteria provide a method for automatically constructing a hierarchy of models that achieve different degrees of abstraction
Importantly, we show that in appropriate limits the method recovers a process's causal organization
Without this connection, it would be only another approach to statistical inference, with its own ad hoc assumptions about the character of natural pattern
Our starting point is the observation that natural systems store, process, and produce information---they compute intrinsically  CITATION
Theory building, then, faces the challenge of extracting from that information the structures underling its generation
Any physical theory delineates mechanism from  randomness by identifying what part of an observed phenomenon is due to  the underlying process's structure and what is irrelevant
Irrelevant parts  are considered noise and typically modeled probabilistically
Successful  theory building therefore depends centrally on deciding what is structure and what is noise; often, an implicit distinction
What constitutes a good theory, though
Which information is relevant
One can answer this question for time series prediction: Information about  the future of the time series is relevant
Beyond forecasting, though, models are often put to the test by assessing how well they predict new data and, hence, it is of general importance that a model capture information which aids prediction
Typically, there are many models that explain a given data set, and between two models that are equally predictive, one favors the simpler, smaller, less structurally complex model  CITATION
However, a more complex model can achieve smaller prediction error than a less complex model
The trade-off between model complexity and prediction error is tantamount to finding a distinction between causal structure and noise
The trade-off between assigning a causal mechanism to the occurrence of an event or explaining the event as being merely random has a long history, but  how one implements the trade-off is still a very active topic
Nonlinear time series analysis  CITATION , to take one example, attempts to account for long-range correlations produced by nonlinear dynamical systems---correlations not adequately modeled by assumptions such as linearity and independent, identically distributed ( iid  ) data
Success in this endeavor requires directly addressing the notion of structure and pattern  CITATION
Examination of the essential goals of prediction led to a principled definition of structure that captures a dynamical system's causal organization in part by discovering the underlying  causal states   CITATION
In  computational mechanics  a process  SYMBOL  is viewed as a communication channel  CITATION : it transmits information from the  past   SYMBOL  to the  future   SYMBOL  by storing it in the present
For the purpose of forecasting the future two different pasts, say  SYMBOL  and  SYMBOL , are equivalent if they result in the same prediction  CITATION
In general this prediction is probabilistic, given by the conditional future distribution  SYMBOL
The resulting equivalence relation  SYMBOL  groups all histories that give rise to the same conditional future distribution:  SYMBOL }    The resulting partition of the space  SYMBOL  of pasts defines the  process's  causal states   SYMBOL
The causal states constitute a model that is maximally predictive by means of capturing all the information that the past of a time series contains about the future
As a result, knowing the causal state renders past and future conditionally independent, a property we call  causal shielding , because the causal states have the Markovian property that they  shield  past and future  CITATION :  SYMBOL } where  SYMBOL
This is related to the fact that the causal-state partition is optimally predictive
To see this, note that Eq () implies  SYMBOL
Furthermore, note that, by definition, for  any  partition  SYMBOL  of  SYMBOL  with states  SYMBOL , when the past is known, then the future distribution is not altered by the history-space partitioning:   SYMBOL }  This implies for the causal states that  SYMBOL  and thus  SYMBOL
Therefore, causal shielding is equivalent to the fact  CITATION  that the causal states capture  all  of the information  SYMBOL  that is shared between past and future:  SYMBOL ,  the process's  excess entropy   SYMBOL  or  predictive information    CITATION
The causal states are  unique and minimal sufficient statistics  for time series prediction, capturing all of a process's predictive information at maximum efficiency  CITATION
The causal-state partition has the smallest  statistical complexity ,  SYMBOL , compared to all other  equally predictive partitions  SYMBOL
SYMBOL  measures the minimal amount of information that must be stored in order to communicate all of the excess entropy from the past to the future
Briefly stated, the causal states serve as the basis against which alternative models should be compared
### abstract ###
Supervised learning deals with the inference of a distribution over an output or label space  SYMBOL  conditioned on points in an observation space  SYMBOL , given a training dataset  SYMBOL  of pairs in  SYMBOL
However, in a lot of applications of interest, acquisition of large amounts of observations is easy, while the process of generating labels is time-consuming or costly
One way to deal with this problem is  active  learning, where points to be labelled are selected with the aim of creating a model with better performance than that of an model trained on an equal number of randomly sampled points
In this paper, we instead propose to deal with the labelling cost directly: The learning goal is defined as the minimisation of a cost which is a function of the expected model performance and the total cost of the labels used
This allows the development of general strategies and specific algorithms for  Though the main focus of the paper is optimal stopping, we also aim to provide the background for further developments and discussion in the related field of active learning
### introduction ###
Much of classical machine learning deals with the case where we wish to learn a target concept in the form of a function  SYMBOL , when all we have is a finite set of examples  SYMBOL
However, in many practical settings, it turns out that for each example  SYMBOL  in the set only the observations  SYMBOL  are available, while the availability of observations  SYMBOL  is restricted in the sense that either  In this paper we deal with the second case, where we can actually obtain labels for any  SYMBOL , but doing so incurs a cost
Active learning algorithms (i e CITATION ) deal indirectly with this by selecting examples which are expected to increase accuracy the most
However, the basic question of whether new examples should be queried at all is seldom addressed
This paper deals with the labelling cost explicitly
We introduce a cost function that represents the trade-off between final performance (in terms of generalisation error) and querying costs (in terms of the number of labels queried)
This is used in two ways
Firstly, as the basis for creating cost-dependent stopping rules
Secondly, as the basis of a comparison metric for learning algorithms and associated stopping algorithms
To expound further, we decide when to stop by estimating the expected performance gain from querying additional examples and comparing it with the cost of acquiring more labels
One of the main contributions is the development of methods for achieving this in a Bayesian framework
While due to the nature of the problem there is potential for misspecification, we nevertheless show experimentally that the stopping times we obtain are close to the optimal stopping times
We also use the trade-off in order to address the lack of a principled method for comparing different active learning algorithms under conditions similar to real-world usage
For such a comparison a method for choosing stopping times independently of the test set is needed
Combining stopping rules with active learning algorithms allows us to objectively compare active learning algorithms for a range of different labelling costs
The paper is organised as follows
Section~ introduces the proposed cost function for when labels are costly, while Section~ discusses related work
Section~ derives a Bayesian stopping method that utilises the proposed cost function
Some experimental results illustrating the proposed evaluation methodology and demonstrating the use of the introduced stopping method are presented in Section~
The proposed methods are not flawless, however
For example, the algorithm-independent stopping rule requires the use of  iid 
examples, which may interfere with its coupling to an active learning algorithm
We conclude with a discussion on the applicability, merits and deficiencies of the proposed approach to optimal stopping and of principled testing for active learning
### abstract ###
The method of defensive forecasting is applied to the problem of prediction with expert advice for binary outcomes
It turns out that defensive forecasting is not only competitive with the Aggregating Algorithm but also handles the case of ``second-guessing'' experts, whose advice depends on the learner's prediction; this paper assumes that the dependence on the learner's prediction is continuous
### introduction ###
There are many known techniques in competitive on-line prediction, such as following the perturbed leader (see, eg ,  CITATION ), Bayes-type aggregation (see, eg ,  CITATION ) and the closely related potential methods, gradient descent (see, eg ,  CITATION ) and closely related exponentiated gradient descent  CITATION , and the recently developed technique of defensive forecasting (see, eg ,  CITATION )
Defensive forecasting combines the ideas of game-theoretic probability (see, eg ,  CITATION ) with Levin and G\'acs's ideas of neutral measure  CITATION  and Foster and Vohra's ideas of universal calibration  CITATION
See  CITATION  for a general review of competitive on-line prediction
This paper applies the technique of defensive forecasting to prediction with expert advice in the simple case of binary outcomes The learner's goal in prediction with expert advice is to compete with free agents, called experts, who are allowed to choose any predictions at each step
We will be interested in performance guarantees of the type  SYMBOL } where  SYMBOL  is the number of experts,  SYMBOL  is a constant depending on  SYMBOL ,  SYMBOL  is the learner's cumulative loss over the first  SYMBOL  steps, and  SYMBOL  is the  SYMBOL th expert's cumulative loss over the first  SYMBOL  steps (see \S\S-- for precise definitions)
It has been shown by Watkins ( CITATION , Theorem 8) that the Aggregating Algorithm (implementing Bayes-type aggregation for general loss functions  CITATION , the AA for short) delivers the optimal value of the constant  SYMBOL  in () whenever the goal () can be achieved (Watkins's result was based on earlier results by Haussler, Kivinen, and Warmuth  CITATION , Theorem 3 1, and Vovk  CITATION , Theorem 1, establishing the optimality of the AA for a large number of experts ) Theorem  of this paper asserts that, perhaps surprisingly, defensive forecasting also achieves the same performance guarantee
Whether the goal () is achievable depends on the loss function used for evaluating the learner's and experts' performance
The necessary and sufficient condition is that the loss function should ``perfectly mixable'' (see for a definition)
For simplicity, we first consider two specific, perhaps most important, examples of perfectly mixable loss functions: the quadratic loss function in and the log loss function in \S
Those two sections are self-contained in that they do not require familiarity with the AA
In the last section, \S, we establish the general result, for arbitrary perfectly mixable loss functions
In an appendix we state Watkins's theorem in the form needed in this paper
It is interesting that the technique of defensive forecasting is also applicable to experts who are allowed to ``second-guess'' the learner: their recommendations can depend (in a continuous manner in this paper) on the learner's prediction
It is not clear that second-guessing experts can be handled at all by the AA
A result similar to this paper's results is proved by Stoltz and Lugosi in  CITATION , Theorem 14 (a more detailed comparison will be given in  CITATION )
Second-guessing experts are useful in game theory (where competing with second-guessing experts is known as prediction with a small internal regret)
For a more down-to-earth example of a useful second-guessing expert, remember that humans tend to give too categorical (i e , close to 0 or 1) predictions; therefore, a useful second-guessing expert for a human learner would transform his/her predictions to less categorical ones (according to the learner's expected calibration curve  CITATION )
### abstract ###
We introduce an approach to inferring the causal architecture of stochastic dynamical systems that extends rate distortion theory to use causal shielding---a natural principle of learning
We study two distinct cases of causal inference: optimal causal filtering and optimal causal estimation
Filtering corresponds to the ideal case in which the probability distribution of measurement sequences is known, giving a principled method to approximate a system's causal structure at a desired level of representation
We show that, in the limit in which a model complexity constraint is relaxed, filtering finds the exact causal architecture of a stochastic dynamical system, known as the  causal-state partition
From this, one can estimate the amount of historical information the process stores
More generally, causal filtering finds a graded model-complexity hierarchy of approximations to the causal architecture
Abrupt changes in the hierarchy, as a function of approximation, capture distinct scales of structural organization
For nonideal cases with finite data, we show how the correct number of underlying causal states can be found by optimal causal estimation
A previously derived model complexity control term allows us to correct for the effect of statistical fluctuations in probability estimates and thereby avoid over-fitting
### introduction ###
Time series modeling has a long and important history in science and engineering
Advances in dynamical systems over the last half century led to new methods that attempt to account for the inherent nonlinearity in many natural phenomena  CITATION
As a result, it is now well known that nonlinear systems produce highly correlated time series that are not adequately modeled under the typical statistical assumptions of linearity, independence, and identical distributions
One consequence, exploited in novel state-space reconstruction methods  CITATION , is that discovering the hidden structure of such processes is key to successful modeling and prediction  CITATION
In an attempt to unify the alternative nonlinear modeling approaches, computational mechanics  CITATION  introduced a minimal representation---the \eM---for stochastic dynamical systems that is an optimal predictor and from which many system properties can be directly calculated
Building on the notion of state introduced in Ref
CITATION , a system's effective states are those variables that  causally shield  a system's past from its future---capturing, in the present, information from the past that predicts the future
Following these lines, here we investigate the problem of learning predictive models of time series with particular attention paid to discovering hidden variables
We do this by using the information bottleneck method (IB)  CITATION  together with a complexity control method discussed by Ref
CITATION , which is necessary for learning from finite data
Ref
CITATION  lays out the relationship between computational mechanics and the information bottleneck method
Here, we make the mathematical connection for times series, introducing a new method
We adapt IB to time series prediction, resulting in a method we call  optimal causal filtering  (OCF)
Since OCF, in effect, extends rate-distortion theory  CITATION  to use causal shielding, in general it achieves an optimal balance between model complexity and approximation accuracy
The implications of these trade-offs for automated theory building are discussed in Ref
CITATION
We show that in the important limit in which prediction is paramount and model complexity is not restricted, OCF reconstructs the underlying process's causal architecture, as previously defined within the framework of computational mechanics  CITATION
This shows that, in effect, OCF captures a source's hidden variables and organization
The result gives structural meaning to the inferred models
For example, one can calculate fundamental invariants---such as, symmetries, entropy rate, and stored information---of the original system
To handle finite-data fluctuations, OCF is extended to  optimal causal estimation  (OCE)
When probabilities are estimated from finite data, errors due to statistical fluctuations in probability estimates must be taken into account in order to avoid over-fitting
We demonstrate how OCF and OCI work on a number of example stochastic processes with known, nontrivial correlational structure
### abstract ###
Solomonoff's central result on induction is that the prediction of a universal semimeasure  SYMBOL  converges rapidly and with probability 1 to the true sequence generating predictor  SYMBOL , if the latter is computable
Hence,  SYMBOL  is eligible as a universal sequence predictor in case of unknown  SYMBOL
Despite some nearby results and proofs in the literature, the stronger result of convergence for all (Martin-L{\"o}f) random sequences remained open
Such a convergence result would be particularly interesting and natural, since randomness can be defined in terms of  SYMBOL  itself
We show that there are universal semimeasures  SYMBOL  which do not converge to  SYMBOL  on all  SYMBOL -random sequences, ie \ we give a partial negative answer to the open problem
We also provide a positive answer for some non-universal semimeasures
We define the incomputable measure  SYMBOL  as a mixture over all computable measures and the enumerable semimeasure  SYMBOL  as a mixture over all enumerable nearly-measures
We show that  SYMBOL  converges to  SYMBOL  and  SYMBOL  to  SYMBOL  on all random sequences
The Hellinger distance measuring closeness of two distributions plays a central role
### introduction ###
A sequence prediction task is defined as to predict the next symbol  SYMBOL  from an observed sequence  SYMBOL
The key concept to attack general prediction problems is Occam's razor, and to a less extent Epicurus' principle of multiple explanations
The former/latter may be interpreted as to keep the simplest/all theories consistent with the observations  SYMBOL  and to use these theories to predict  SYMBOL
Solomonoff  CITATION  formalized and combined both principles in his universal a priori semimeasure  SYMBOL  which assigns high/low probability to simple/complex environments  SYMBOL , hence implementing Occam and Epicurus
Formally it can be represented as a mixture of all enumerable semimeasures
An abstract characterization of  SYMBOL  by Levin  CITATION  is that  SYMBOL  is a universal enumerable semimeasure in the sense that it multiplicatively dominates all enumerable semimeasures
Solomonoff's  CITATION  central result is that if the probability  SYMBOL  of observing  SYMBOL  at time  SYMBOL , given past observations  SYMBOL  is a computable function, then the universal predictor  SYMBOL  converges (rapidly )  with  SYMBOL -probability 1  (w p 1) for  SYMBOL  to the optimal/true/informed predictor  SYMBOL , hence  SYMBOL  represents a universal predictor in case of unknown ``true'' distribution  SYMBOL
Convergence of  SYMBOL  to  SYMBOL  w p 1 tells us that  SYMBOL  is close to  SYMBOL  for sufficiently large  SYMBOL  for almost all sequences  SYMBOL
It says nothing about whether convergence is true for any  particular  sequence (of measure 0)
Martin-L{\"o}f (M L ) randomness is the standard notion for randomness of individual sequences  CITATION
A M L -random sequence passes  all  thinkable effective randomness tests, eg \ the law of large numbers, the law of the iterated logarithm, etc
In particular, the set of all  SYMBOL -random sequences has  SYMBOL -measure 1
It is natural to ask whether  SYMBOL  converges to  SYMBOL  (in difference or ratio) individually for all M L -random sequences
Clearly, Solomonoff's result shows that convergence may at most fail for a set of sequences with  SYMBOL -measure zero
A convergence result for M L -random sequences would be particularly interesting and natural in this context, since M L -randomness can be defined in terms of  SYMBOL  itself  CITATION
Despite several attempts to solve this problem  CITATION , it remained open  CITATION
In this paper we construct an M L -random sequence and show the existence of a universal semimeasure which does not converge on this sequence, hence answering the open question negatively for some  SYMBOL
It remains open whether there exist (other) universal semimeasures, probably with particularly interesting additional structure and properties, for which M L -convergence holds
The main positive contribution of this work is the construction of a non-universal enumerable semimeasure  SYMBOL  which M L -converges to  SYMBOL  as desired
As an intermediate step we consider the incomputable measure  SYMBOL , defined as a mixture over all computable measures
We show M L -convergence of predictor  SYMBOL  to  SYMBOL  and of  SYMBOL  to  SYMBOL
The Hellinger distance measuring closeness of two predictive distributions plays a central role in this work
The paper is organized as follows: In Section~ we give basic notation and results (for strings, numbers, sets, functions, asymptotics, computability concepts, prefix Kolmogorov complexity), and define and discuss the concepts of (universal) (enumerable) (semi)measures
Section~ summarizes Solomonoff's and G\'acs' results on predictive convergence of  SYMBOL  to  SYMBOL  with probability 1
Both results can be derived from a bound on the expected Hellinger sum
We present an improved bound on the expected exponentiated Hellinger sum, which implies very strong assertions on the convergence rate
In Section~ we investigate whether convergence for all Martin-L{\"o}f random sequences hold
We construct a  SYMBOL -M L -random sequence on which some universal semimeasures  SYMBOL  do not converge to  SYMBOL
We give a non-constructive and a constructive proof of different virtue
In Section~ we present our main positive result
We derive a finite bound on the Hellinger sum between  SYMBOL  and  SYMBOL , which is exponential in the randomness deficiency of the sequence and double exponential in the complexity of  SYMBOL
This implies that the predictor  SYMBOL  M L -converges to  SYMBOL
Finally, in Section~ we show that  SYMBOL  is non-universal and asymptotically M L -converges to  SYMBOL , and summarize the computability, measure, and dominance properties of  SYMBOL ,  SYMBOL ,  SYMBOL , and  SYMBOL
Section~ contains discussion and outlook
### abstract ###
The purpose of this note is to show how the method of maximum entropy in the mean (MEM) may be used to improve parametric estimation when the measurements are corrupted by large level of noise
The method is developed in the context on a concrete example: that of estimation of the parameter in an exponential distribution
We compare the performance of our method with the bayesian and maximum likelihood approaches
### introduction ###
Suppose that you want to measure the half-life of a decaying nucleus or the life-time of some elementary particle, or some other random variable modeled by an exponential distribution describing, say a decay time or the life time of a process
Assume as well that the noise in the measurement process can be modeled by a centered gaussian random variable whose variance may be of the same order of magnitude as that of the decay rate to be measured
To make things worse, assume that you can only collect very few measurements
That is if  SYMBOL  denotes the realized value of the variable, one can only measure  SYMBOL , for  SYMBOL , where  SYMBOL  is a small mumbler, say  SYMBOL  or  SYMBOL  and  SYMBOL  denotes the additive measurement noise
In other words, assume that you know that the sample comes from a specific parametric distribution but is contaminated by additive noise
What to do
One possible approach is to apply small sample statistical estimation procedures
But these are designed for problems where the variability is due only to the random nature of the quantity measured,and there is no other noise in the measurement  Still another possibility, the one we that to explore here, is to apply a maxentropic filtering method,  to estimate both the unknown variable and the noise level
For this we recast the problem as a typical inverse problem consisting of solving for  SYMBOL  in  SYMBOL }   where  SYMBOL  is a convex set in  SYMBOL ,  SYMBOL  and for some  SYMBOL  and  SYMBOL , and  SYMBOL  is an  SYMBOL -matrix which depends on how we rephrase the our problem
We could, for example, consider the following problem: Find  SYMBOL  such that   SYMBOL }  In our case  SYMBOL , and we set  SYMBOL  Or we could consider a collection of  SYMBOL  such problems, one for every measurement, and then proceed to carry on the estimation
Once we have solved the generic problem (), the variations on the theme are easy to write down
What is important to keep in mind here, is that the output of the method is a filtered estimator  SYMBOL  of  SYMBOL  which itself is an estimator of the unknown parameter
The novelty then is to filter out the noise in ()
The method of maximum entropy in the mean is rather well suited for solving problems like (1)
See Navaza (1986) for an early development and Dacunha-Castele and Camboa (1990) for full mathematical treatment
Below we shall briefly review what the method is about and then apply it to  obtain an estimator  SYMBOL  from ()
In section 3  obtain the maxentropic estimator and in section 4 we examine some of its properties, in particular we examine what the results would be if either the noise level were small or the number of measurements were large
We devote section 4 to some simulations in which the method is compared with a bayesian and a maximum likelihood approaches
### abstract ###
The Bayesian framework is a well-studied and successful framework for inductive reasoning, which includes hypothesis testing and confirmation, parameter estimation, sequence prediction, classification, and regression
But standard statistical guidelines for choosing the model class and prior are not always available or can fail, in particular in complex situations
Solomonoff completed the Bayesian framework by providing a rigorous, unique, formal, and universal choice for the model class and the prior
I discuss in breadth how and in which sense universal (non- iid  )\ sequence prediction solves various (philosophical) problems of traditional Bayesian sequence prediction
I show that Solomonoff's model possesses many desirable properties: Strong total and future bounds, and weak instantaneous bounds, and in contrast to most classical continuous prior densities has no zero p(oste)rior problem, ie \ can confirm universal hypotheses, is reparametrization and regrouping invariant, and avoids the old-evidence and updating problem
It even performs well (actually better) in non-computable environments \ifjournal
### introduction ###
Given the weather in the past, what is the probability of rain tomorrow
What is the correct answer in an IQ test asking to continue the sequence 1,4,9,16,
Given historic stock-charts, can one predict the quotes of tomorrow
Assuming the sun rose 5000 years every day, how likely is doomsday (that the sun does not rise) tomorrow
These are instances of the important problem of induction or time-series forecasting or sequence prediction
Finding prediction rules for every particular (new) problem is possible but cumbersome and prone to disagreement or contradiction
What is desirable is a formal general theory for prediction
The Bayesian framework is the most consistent and successful framework developed thus far  CITATION
A Bayesian considers a set of environments\eqbr=hypotheses\eqbr=models  SYMBOL  which includes the true data generating probability distribution  SYMBOL
From one's prior belief  SYMBOL  in environment  SYMBOL  and the observed data sequence  SYMBOL , Bayes' rule yields one's posterior confidence in  SYMBOL
In a prequential  CITATION  or transductive  CITATION  setting, one directly determines the predictive probability of the next symbol  SYMBOL  without the intermediate step of identifying a (true or good or causal or useful) model
With the exception of Section , this paper concentrates on  prediction  rather than model identification
The ultimate goal is to make ``good'' predictions in the sense of maximizing one's profit or minimizing one's loss
Note that classification and regression can be regarded as special sequence prediction problems, where the sequence  SYMBOL  of  SYMBOL -pairs is given and the class label or function value  SYMBOL  shall be predicted
The Bayesian framework leaves open how to choose the model class  SYMBOL  and prior  SYMBOL
General guidelines are that  SYMBOL  should be small but large enough to contain the true environment  SYMBOL , and  SYMBOL  should reflect one's prior (subjective) belief in  SYMBOL  or should be non-informative or neutral or objective if no prior knowledge is available
But these are informal and ambiguous considerations outside the formal Bayesian framework
Solomonoff's  CITATION  rigorous, essentially unique, formal, and universal solution to this problem is to consider a single large universal class  SYMBOL  suitable for  all  induction problems
The corresponding universal prior  SYMBOL  is biased towards simple environments in such a way that it dominates (=superior to) all other priors
This leads to an a priori probability  SYMBOL  which is equivalent to the probability that a universal Turing machine with random input tape outputs  SYMBOL , and the shortest program computing  SYMBOL  produces the most likely continuation (prediction) of  SYMBOL
Many interesting, important, and deep results have been proven for Solomonoff's universal distribution  SYMBOL   CITATION
The motivation and goal of this paper is % to provide a broad discussion of how and in which sense universal sequence prediction solves all kinds of (philosophical) problems of Bayesian sequence prediction, and to % present some recent results
% Many arguments and ideas could be further developed
I hope that the exposition stimulates such a future, more detailed, investigation
In Section , I review the excellent predictive and decision-theoretic performance results of Bayesian sequence prediction for generic (non- iid  )\ countable and continuous model classes
Section  critically reviews the classical principles (indifference, symmetry, minimax) for obtaining objective priors, introduces the universal prior inspired by Occam's razor and quantified in terms of Kolmogorov complexity
In Section  (for  iid  \  SYMBOL ) and Section  (for universal  SYMBOL ) I show various desirable properties of the universal prior and class (non-zero p(oste)rior, confirmation of universal hypotheses, reparametrization and regrouping invariance, no old-evidence and updating problem) in contrast to (most) classical continuous prior densities
I also complement the general total bounds of Section  with some universal and some  iid 
-specific instantaneous and future bounds
Finally, I show that the universal mixture performs better than classical continuous mixtures, even in uncomputable environments
Section  contains critique, summary, and conclusions
The reparametrization and regrouping invariance, the (weak) instantaneous bounds, the good performance of  SYMBOL  in non-computable environments, and most of the discussion (zero prior and universal hypotheses, old evidence) are new or new in the light of universal sequence prediction
Technical and mathematical non-trivial new results are the Hellinger-like loss bound \req{lbnd} and the instantaneous bounds \req{iIIDbnd} and \req{iMbnd}
### abstract ###
In many real world applications, data cannot be accurately represented by vectors
In those situations, one possible solution is to rely on dissimilarity measures that enable sensible comparison between observations
Kohonen's Self-Organizing Map (SOM) has been adapted to data described only through their dissimilarity matrix
This algorithm provides both non linear projection and clustering of non vector data
Unfortunately, the algorithm suffers from a high cost that makes it quite difficult to use with voluminous data sets
In this paper, we propose a new algorithm that provides an important reduction of the theoretical cost of the dissimilarity SOM without changing its outcome (the results are exactly the same as the ones obtained with the original algorithm)
Moreover, we introduce implementation methods that result in very short running times
Improvements deduced from the theoretical cost model are validated on simulated and real world data (a word list clustering problem)
We also demonstrate that the proposed implementation methods reduce by a factor up to 3 the running time of the fast algorithm over a standard implementation
### introduction ###
The vast majority of currently available data analysis methods are based on a vector model in which observations are described with a fixed number of real values, i e , by vectors from a fixed and finite dimensional vector space
Unfortunately, many real world data depart strongly from this model
It is quite common for instance to have variable size data
They are natural for example in online handwriting recognition  CITATION  where the representation of a character drawn by the user can vary in length because of the drawing conditions
Other data, such as texts for instance, are strongly non numerical and have a complex internal structure: they are very difficult to represent accurately in a vector space
While a lot of work has been done to adapt classical data analysis methods to structured data such as tree and graph  CITATION  for neural based unsupervised processing of structured data and also  CITATION }, as well as to data with varying size, there is still a strong need for efficient and flexible data analysis methods that can be applied to any type of data
A way to design such methods is to rely on one to one comparison between observations
It is in general possible to define a similarity or a dissimilarity measure between arbitrary data, as long as comparing them is meaningful
In general, data analysis algorithms based solely on (dis)similarities between observations are more complex than their vector counterparts, but they are universal and can therefore be applied to any kind of data
Moreover, they allow one to rely on specific (dis)similarities constructed by experts rather than on a vector representation of the data that induces in general unwanted distortion in the observations
Many algorithms have been adapted to use solely dissimilarities between data
In the clustering field, the k-means algorithm  CITATION  has been adapted to dissimilarity data under the name of Partitioning Around Medoids  CITATION
More recently, approaches based on deterministic annealing have been used to propose another class of extensions of the k-means principle  CITATION
Following the path taken for the k-means, several adaptation of Kohonen's Self-Organizing Map  CITATION  to dissimilarity data have been proposed
CITATION  proposed a probabilistic formulation of the SOM that can be used directly for dissimilarity data
Deterministic annealing schemes have been also used for the SOM  CITATION
In the present paper, we focus on an adaptation proposed in  CITATION , where it was applied successfully to a protein sequence clustering and visualization problem, as well as to string clustering problems
This generalization is called the Dissimilarity SOM (DSOM, also known as the median SOM), and can be considered as a SOM formulation of the PAM method
Variants of the DSOM were applied to temperature time series  CITATION , spectrometric data  CITATION  and web usage data  CITATION
A major drawback of the DSOM is that its running time can be very high, especially when compared to the standard vector SOM
It is well known that the SOM algorithm behaves linearly with the number of input data  CITATION
On the contrary, the DSOM behaves quadratically with this number (see Section )
We propose in this paper several modifications of the basic algorithm that allow a much faster implementation
The quadratic nature of the algorithm cannot be avoided, essentially because dissimilarity data are intrinsically described by a quadratic number of one to one dissimilarities
Nevertheless, the standard DSOM algorithm cost is proportional to  SYMBOL , where  SYMBOL  is the number of observations and  SYMBOL  the number of clusters that the algorithm has to produce, whereas our modifications lead to a cost proportional to  SYMBOL
Moreover, a specific implementation strategy reduces the actual computation burden even more
An important property of all our modifications is that the obtained algorithm produces  exactly  the same results as the standard DSOM algorithm
The paper is organized as follows
In section  we recall the SOM adaptation to dissimilarity data and obtain the theoretical cost of the DSOM
In section , we describe our proposed new algorithm as well as the implementation techniques that decrease its running time in practice
Finally we evaluate the algorithm in section
This evaluation validates the theoretical cost model and shows that the implementation methods reduce the running time
The evaluation is conducted on simulated data and on real world data (a word list clustering problem)
### abstract ###
In data analysis new forms of complex data have to be considered like for example (symbolic data, functional data, web data, trees, SQL query and multimedia data,

)
In this context classical data analysis for knowledge discovery based on calculating the center of gravity can not be used because input are not  SYMBOL  vectors
In this paper, we present an application on real world symbolic data using the self-organizing map
To this end, %%@ we propose an extension of the self-organizing map that can handle symbolic data \\  keywords:  Classification, Self organizing map, symbolic data, dissimilarity
### introduction ###
The self-organizing map(SOM) introduced by Kohonen  CITATION  is an unsupervised neural network method which has both clustering and visualization %%@ properties
It can be considered as an algorithm that maps a high dimensional data space,  SYMBOL , to a lower dimension, generally 2, and which %%@ is called a map
This projection enables the input data to be partitioned into "similar" clusters while preserving their topology
Its most similar %%@ predecessors are the k-means algorithm  CITATION  and the dynamic clustering method  CITATION , which operate as a SOM without topology preservation %%@ and therefore without easy visualization
In data analysis, new forms of complex data have to be considered, most notably symbolic data (data with an internal structure such as interval %%@ data, distributions, functional data, etc ) and semi-structured data (trees, XML documents, SQL queries, etc )
In this context, classical data %%@ analysis based on calculating the center of gravity can not be used because input are not  SYMBOL  vectors
In order to solve this problem, %%@ several methods can be considered depending on the type of data (for example projection operators %%@ for functional data  CITATION )
However, those methods are not fully general and an adaptation of every data analysis algorithm to the resulting %%@ data is needed
The Kohonen's SOM is based on the center of gravity notion and unfortunately, this concept is not applicable to many kinds of complex data
In this paper we propose an adaptation of the SOM to dissimilarity data as an alternative solution
Our goal is to modify the SOM algorithm to allow its implementation on dissimilarity measures rather than on raw data
To this end, we take one's inspiration from the work of Kohonen  CITATION
To apply the method, only the definition of a dissimilarity for each type of data is necessary and so complex data can be processed
### abstract ###
The large number of spectral variables in most data sets encountered in spectral chemometrics often renders the prediction of a dependent variable uneasy
The number of variables hopefully can be reduced, by using either projection techniques or selection methods; the latter allow for the interpretation of the selected variables
Since the optimal approach of testing all possible subsets of variables with the prediction model is intractable, an incremental selection approach using a nonparametric statistics is a good option, as it avoids the computationally intensive use of the model itself
It has two drawbacks however: the number of groups of variables to test is still huge, and colinearities can make the results unstable
To overcome these limitations, this paper presents a method to select groups of spectral variables
It consists in a forward-backward procedure applied to the coefficients of a B-Spline representation of the spectra
The criterion used in the forward-backward procedure is the mutual information, allowing to find nonlinear dependencies between variables, on the contrary of the generally used correlation
The spline representation is used to get interpretability of the results, as groups of consecutive spectral variables will be selected
The experiments conducted on NIR spectra from fescue grass and diesel fuels show that the method provides clearly identified groups of selected variables, making interpretation easy, while keeping a low computational load
The prediction performances obtained using the selected coefficients are higher than those obtained by the same method applied directly to the original variables and similar to those obtained using traditional models, although using significantly less spectral variables
### introduction ###
Prediction problems are often encountered in analytical spectral chemometrics
They require estimating the unknown value of a dependent variable from, for example, a near-infrared spectrum
Such problems may be encountered in the food  CITATION , pharmaceutical  CITATION  and textile  CITATION  industry, to cite only a few
Viewed from a statistical or data analysis perspective, the main difficulty in such problem is to cope with the colinearity between spectral variables: not only consecutive variables in a spectrum are highly correlated by nature, but in addition real applications usually concern databases with a low number of known spectra, and a high number of spectral variables
Any method built on the original spectral variables is thus ill-posed, making feature (spectral variable) selection and/or projection necessary
Selection and projection methods differ by several aspects
Projection methods are more general by essence, as selection may be regarded as projection with many zero weights
However, projection methods usually build factors (latent variables) that are combinations of a large number of original features
Even if their prediction properties are good, they usually suffer from the fact that the latent variables are hardly interpretable in terms of original features (wavelengths in the case of infrared spectra)
On the contrary, selection methods are based on the principle of choosing a small number of variables among the original ones, leading to easy interpretation
Of course, the challenge with selection methods is to obtain prediction performances of the same level as projection ones
In this work, we are interested in variable selection methods providing interpretability
However, if the whole procedure consisting in selecting the features and building a prediction model on them is kept linear, it will certainly lead to poorer performances than the traditional and widely used PLS (Partial Least Squares), as the latter consists in a projection and a prediction
It is thus investigated how nonlinear models may be used, both for selecting the features and performing the prediction
Nonlinear models could be used in a wrapper approach  CITATION , in which their estimated generalization performances is used as a relevance criterion for a group of variables
This however, is very demanding in terms of computational load because resampling techniques must be used to estimate accurately the predicted error of the model, in addition to the fact that one model must be learned for each considered feature set
This paper thus focuses on the so-called filter approach: the features are selected prior the use of any prediction model
Among filter methods, the correlation is the standard criterion to be used for selecting features in a linear way: features with maximal correlation with the dependent (output) variable, and possibly with minimal information between them to avoid redundancy, are selected
Mutual information (see eg CITATION ) extends the correlation to the measure of nonlinear dependencies, while correlation is strictly limited to linear ones
As an example, the correlation between a centered antisymmetric variable and its second power is zero, despite the fact they obviously depend one from another (though in a nonlinear way)
The mutual information avoids this drawback, providing a more general and less restricted way to measure dependencies between variables
The mutual information (MI) has already been used to select variables from near-infrared spectra  CITATION
Despite it provides a promising way to extend state-of-the-art spectral analysis to nonlinear methodologies, the direct selection of variables by MI suffers from some drawbacks
First, the MI estimation becomes difficult as the number of selected variables grows
Indeed in a forward procedure the estimation is faced to the curse of dimensionality, making the estimation of the MI with the last selected feature much more difficult than with the first selected one
Second, the low number of spectra usually available for learning makes the results of the selection highly dependent on the data set: a small change in the data can lead to different selected variable sets, resulting in difficult interpretation
Finally, even though the estimation of the mutual information is less demanding in terms of computation time than the construction of a nonlinear model, the large number of initial variables results in high computation times for the selection
In this paper, we propose to first reduce the number of variables through a projection of the spectral features before the selection by mutual information
To maintain the interpretability despite the use of a projection, the latter is achieved by ensuring that each coordinate in the projection corresponds to a restricted set of initial features with consecutive wavelengths
The general methodology proposed in  CITATION  is followed: spectra are projected on a functional basis
More precisely, as in eg CITATION , a projection on a basis of B-splines is chosen, rather than wavelets for example; indeed B-splines have the advantage that they span a restricted interval of wavelengths, and that the intervals are roughly of the same length over the whole range
As a consequence, each coefficient depends on the value of the corresponding spectrum on a limited wavelength interval
The complete procedure then consists in replacing the spectra by their B-spline coefficients, in selecting relevant coefficients by measuring their mutual information with the output variable, and by predicting the latter using Radial-Basis Function networks (any other nonlinear model could be used)
All three steps are nonlinear, giving to the procedure the necessary flexibility to reach high performances both in prediction and in interpretation
Design parameters that are unavoidable in a nonlinear context, such as the number of B-splines to be used in the projection, are set automatically (without the necessity of a user's choice) using a cross-validation method
This paper shows that the prediction results obtained by this procedure are comparable than those obtained through conventional linear techniques such as PLS
In addition interpretability is added, as the number of wavelengths selected by the procedure remains low, making it possible to identify which wavelengths are responsible for the phenomenon to predict
Moreover, B-spline compression allows us both to reduce the feature selection running time and to increase the quality of the prediction results compared to the same nonlinear procedure applied directly to the original spectral variables
Section  of this paper reminds how spectra can be projected on a basis of B-splines, details how the number of B-splines can be set automatically and analyzes the computational complexity of the procedure
Section  presents the mutual information criterion and its use in a forward-backward procedure
It also investigates the computational complexity of the forward-backward method
Section  shows examples of the application of the proposed method on two data sets
The first one consists of NIR spectra obtained from fescue grass; the aim is to predict the nitrogen content of the plant
The second one is a database of spectra from fuel samples for which the goal is to predict the Cetane Number of the fuel
### abstract ###
Combining the mutual information criterion with a forward feature selection strategy offers a good trade-off between optimality of the selected feature subset and computation time
However, it requires to set the parameter(s) of the mutual information estimator and to determine when to halt the forward procedure
These two choices are difficult to make because, as the dimensionality of the subset increases, the estimation of the mutual information becomes less and less reliable
This paper proposes to use resampling methods, a K-fold cross-validation and the permutation test, to address both issues
The resampling methods bring information about the variance of the estimator, information which can then be used to automatically set the parameter and to calculate a threshold to stop the forward procedure
The procedure is illustrated on a synthetic dataset as well as on real-world examples
### introduction ###
Feature selection consists in choosing, among a set of input features, or variables, the subset of features that has maximum prediction power for the output
More formally, let us consider  SYMBOL  a random input vector and  SYMBOL  a continuous random output variable that has to be predicted from  SYMBOL
The task of feature selection consists in finding the features  SYMBOL  that are most relevant to predict the value of  SYMBOL   CITATION
Selecting features is important in practice, especially when distance-based methods like k-nearest neighbors (k-NN), Radial Basis Function Networks (RBFN) and Support Vector Machines (SVM) (depending on the kernel) are considered
These methods are indeed    quite sensitive to irrelevant inputs: their performances tend to decrease when useless variables are added to the data
When the data are high-dimensional (i e the initial number of variables is large)  the exhaustive search of an optimal feature set is of course intractable
In such cases, furthermore, most methods that `work backwards' by eliminating useless features perform badly
The backward elimination procedure for instance, or pruning methods for the MultiLayer Perceptron  CITATION , SVM-based feature selection  CITATION , or weighting methods like the Generalized Relevance Learning Vector Quantization algorithm  CITATION  require building a model with all initial features
With high-dimensional data,  this will often lead to large computation times, overfitting, convergence problems, and, more generally, issues related to the curse of dimensionality
These approaches are furthermore bound to a specific prediction model
By contrast, a forward feature selection procedure can be applied using any model and begins with small feature subsets
Such procedure is furthermore simple and often efficient
Nevertheless, when data are high-dimensional, it becomes difficult to perform the forward search using the prediction model directly
This is because, for every candidate feature subset, a prediction model must be fit, involving resampling techniques and grid searching for optimal structural parameters
A cheaper alternative is to estimate the relevance of each candidate subset with a statistical or information-theoretic measure, without using the prediction model itself
The combined use of a forward feature search and an information-theoretic-based relevance criterion  is generally considered to be a good option, when nonlinear effects prevent from using the correlation coefficient  CITATION
In this context, the mutual information estimated using a nearest neighbour-based approach has been shown to be effective  CITATION
Nevertheless, this approach, just like most feature selection methodologies, faces two difficulties
The first one, which is generic for all feature selection methods, lies in the optimal choice of the number of features to select
Most of the time, the number of features to select is chosen a priori or so as to maximize the relevance criterion
The former approach leaves no room for optimization, while the latter may be very sensitive  to the estimation of the relevance criterion
The second difficulty concerns the choice of parameter(s) in the estimation of the relevance criterion
Indeed, most of these criteria, except maybe for the correlation coefficient, have at least one structural parameter, like a number of units or a kernel width in a prediction model, a number of neighbours or a number of bins in a nonparametric relevance estimator, etc
Often, the result of the selection highly depends on the value of that (those) parameter(s)
The aim of this paper is to provide an automatic procedure to choose the two above-mentioned important parameters, i e the number of features to select in the forward search and the structural parameter(s) in the relevance criterion estimation
This procedure will be detailed in a situation where the mutual information is used as relevance criterion, and is estimated through nearest neighbours
Resampling methods will be used to obtain this automatic choice
Those methods increase the computational cost of the forward search, but provide meaningful information about the quality of the estimations and the setting of parameters: it will be shown that a permutation test can be used to automatically stop the forward procedure, and that a combination of permutation and K-fold resampling allows choosing the optimal number of neighbors in the estimation of the mutual information
The remaining of this paper is organized as follows
Section  introduces the mutual information, the permutation test and the K-fold resampling, and briefly reviews how they can be used together
Section  illustrates the challenges in choosing the number of neighbours in the mutual information estimation and the number of features to select in a forward search
Section  then presents the proposed approach
The performances of the method on real-world data are reported in Section
### abstract ###
% We show that the Brier game of prediction is mixable and find the optimal learning rate and substitution function for it
The resulting prediction algorithm is applied to predict results of football and tennis matches
The theoretical performance guarantee turns out to be rather tight on these data sets, especially in the case of the more extensive tennis data
### introduction ###
The paradigm of prediction with expert advice was introduced in the late 1980s (see, eg ,  CITATION ,  CITATION ,  CITATION ) and has been applied to various loss functions; see  CITATION  for a recent book-length review
An especially important class of loss functions is that of ``mixable'' ones, for which the learner's loss can be made as small as the best expert's loss plus a constant (depending on the number of experts)
It is known  CITATION  that the optimal additive constant is attained by the ``strong aggregating algorithm'' proposed in  CITATION  (we use the adjective ``strong'' to distinguish it from the ``weak aggregating algorithm'' of  CITATION )
There are several important loss functions that have been shown to be mixable and for which the optimal additive constant has been found
The prime examples in the case of binary observations are the log loss function and the square loss function
The log loss function, whose mixability is obvious, has been explored extensively, along with its important generalizations, the Kullback--Leibler divergence and Cover's loss function
In this paper we concentrate on the square loss function
In the binary case, its mixability was demonstrated in  CITATION
There are two natural directions in which this result could be generalized:  [Regression:] observations are real numbers (square-loss regression is a standard problem in statistics) [Classification:] observations take values in a finite set (this leads to the ``Brier game'', to be defined below, a standard way of measuring the quality of predictions in meteorology and other applied fields: see, eg ,  CITATION )
The mixability of the square loss function in the case of observations belonging to a bounded interval of real numbers was demonstrated in  CITATION ; Haussler et al 's algorithm was simplified in  CITATION
Surprisingly, the case of square-loss non-binary classification has never been analysed in the framework of prediction with expert advice
The purpose of this paper is to fill this gap
Its short conference version  CITATION  appeared in the ICML 2008 proceedings
### abstract ###
One of the most utilized data mining tasks is the search for association rules
Association rules represent %probabilistically significant relationships between items in transactions
We extend the concept of association rule to represent a much broader class of associations, which we refer to as  entity-relationship rules
Semantically, entity-relationship rules express associations between properties of related objects
Syntactically, these rules are based on a broad subclass of safe domain relational calculus queries
We propose a new definition of support and confidence for entity-relationship rules and for the frequency of entity-relationship queries
We prove that the definition of frequency satisfies standard probability axioms and the Apriori property
### introduction ###
One of the goals of data mining is to discover interesting relationships from data
Association rules express relationships that hold with sufficient frequency but not always
For example, it may be the case that not all managers earn over \ SYMBOL pq  SYMBOL p SYMBOL q SYMBOL q SYMBOL p SYMBOL p SYMBOL q SYMBOL p SYMBOL q SYMBOL pq SYMBOL p q SYMBOL fr(pq)$
Our definition of frequency for ER queries generalizes previous work on defining association rules in a multi-relational setting
CITATION  discusses extending itemset rules with negations and motivates the usefulness of this extension
The query extension approach of the system  CITATION  presents a special class of entity-relationship rules that allows conjunctions of nonnegated statements and existential quantification
Our concept  of ER rules %allows features in addition negations, universal quantification, nested quantifiers, and nested Boolean combinations
Thus one contribution of this paper is an extended rule format
A characteristic that distinguishes our approach from previous work is that previous approaches assume a given target table that defines a base set of tuples for evaluating the support of a query
In contrast, we start with a query and define a natural base set of tuples for evaluating the support of the query
We can think of this approach as dynamically generating entity sets for a given query rather than evaluating queries with respect to a fixed entity set
Thus the second main contribution of this paper is a new definition of support  for rules in our extended format
The paper is organized as follows
First we review basic relational database concepts such as the relational schema and the domain relational calculus
Then we introduce the concept of an entity query and define the frequency of a query in this class of queries
This definition provides the basis for the notion of an entity-relationship rule and for defining the support of an entity-relationship rule
We compare entity-relationship queries to frequent itemsets and to the rule language of the system
The final section establishes sevveral important formal properties of query frequencies as we define them and shows that they satisfy the Apriori property, that is, the frequency of a conjunction is no greater than the frequency of its conjuncts
### abstract ###
We address the problem of autonomously learning controllers for vision-capable mobile robots
We extend McCallum's (1995) Nearest-Sequence Memory algorithm to allow for general metrics over state-action trajectories
We demonstrate the feasibility of our approach by successfully running our algorithm on a real mobile robot
The algorithm is novel and unique in that it (a) explores the environment and learns directly on a mobile robot without using a hand-made computer model as an intermediate step, (b) does not require manual discretization of the sensor input space, (c) works in piecewise continuous perceptual spaces, and (d) copes with partial observability
Together this allows learning from much less experience compared to previous methods
### introduction ###
The realization of fully autonomous robots will require algorithms that can learn from direct experience obtained from visual input
Vision systems provide a rich source of information, but, the piecewise-continuous (PWC) structure of the perceptual space (e g video images) implied by typical mobile robot environments is not compatible with most current, on-line reinforcement learning approaches
These environments are characterized by regions of smooth continuity separated by discontinuities that represent the boundaries of physical objects or the sudden appearance or disappearance of objects in the visual field
There are two broad approaches that are used to adapt existing algorithms to real world environments: (1) discretizing the state space with fixed~ CITATION  or adaptive~ CITATION  grids, and (2) using a function approximator such as a neural-network~ CITATION , radial basis functions (RBFs)~ CITATION , CMAC~ CITATION , or instance-based memory~ CITATION
Fixed discrete grids introduce artificial discontinuities, while adaptive ones scale exponentially with state space dimensionality
Neural networks implement relatively smooth global functions that are not capable of approximating discontinuities, and RBFs and CMACs, like fixed grid methods, require knowledge of the appropriate local scale
Instance-based methods use a  neighborhood  of explicitly stored experiences to generalize to new experiences
These methods are more suitable for our purposes because they implement local models that in principle can approximate PWC functions, but typically fall short because, by using a fixed neighborhood radius, they assume a uniform sampling density on the state space
A fixed radius prevents the approximator from clearly identifying discontinuities because points on both sides of the discontinuity can be averaged together, thereby blurring its location
If instead we use a fixed number  SYMBOL  of neighbors (in effect using a variable radius) the approximator has arbitrary resolution near important state space boundaries where it is most needed to accurately model the local dynamics
To use such an approach,  an appropriate metric is needed to determine which stored instances provide the most relevant information for deciding what to do in a given situation~ CITATION
Apart from the PWC structure of the perceptual space, a robot learning algorithm must also cope with the fact that instantaneous sensory readings alone rarely provide sufficient information for the robot to determine where it is (localization problem) and what action it is best to take
Some form of short-term memory is needed to integrate successive inputs and identify the underlying environment states that are otherwise only  partially observable
In this paper, we present an algorithm called Piecewise Continuous Nearest Sequence Memory (PC-NSM) that extends McCallum's instance-based algorithm for discrete, partially observable state spaces, Nearest Sequence Memory (NSM;~ CITATION ), to the more general PWC case
Like NSM, PC-NSM stores all the data it collects from the environment, but uses a continuous metric on the history that allows it to be used in real robot environments without prior discretization of the perceptual space
An important priority in this work is minimizing the amount of  a priori  knowledge about the structure of the environment that is available to the learner
Typically, artificial learning is conducted in simulation, and then the resulting policy is transfered to the real robot
Building an accurate model of a real environment is human-resource intensive and only really achievable when simple  sensors are used (unlike full-scale vision), while overly simplified models make policy transfer difficult~ CITATION
For this reason, we stipulate that the robot must learn directly from the real world
Furthermore, since gathering data in the real world is costly, the algorithm should be capable of efficient autonomous exploration in the robot perceptual state space without knowing the amount of exploration required in different parts of the state space (as is normally the case in even the most advanced approaches to exploration in discrete~ CITATION , and even in metric~ CITATION  state spaces)
The next section introduces PC-NSM, section~ presents our experiments in robot navigation, and section~ discusses our results and future directions for our research
### abstract ###
Regularization by the sum of singular values, also referred to as the   trace norm , is a popular technique for estimating  low rank rectangular matrices
In this paper, we extend some of the consistency results of the Lasso to provide necessary and sufficient conditions for rank consistency of trace norm minimization with the square loss
We also  provide an adaptive version that is rank consistent even when the necessary condition for the non adaptive version is not fulfilled
### introduction ###
In recent years, regularization by various non Euclidean  norms has seen considerable interest
In particular, in the context of linear supervised learning, norms such as the  SYMBOL -norm may induce sparse loading vectors, i e , loading vectors with low cardinality or  SYMBOL -norm
Such regularization schemes, also known as the Lasso~ CITATION  for least-square regression, come with efficient path following algorithms~ CITATION
Moreover, recent work has studied conditions under which such procedures consistently estimate the sparsity pattern of the loading vector~ CITATION
When learning on rectangular matrices, the rank is a natural extension of the cardinality, and the sum of singular values, also known as the trace norm or the nuclear norm, is the natural extension of the  SYMBOL -norm; indeed, as the  SYMBOL -norm is the convex envelope of the  SYMBOL -norm on the unit ball (i e , the largest lower bounding convex function)~ CITATION , the trace norm is the convex envelope of the rank over the unit ball of the spectral norm~ CITATION
In practice, it leads to low rank solutions~ CITATION  and has seen recent increased interest in the context of collaborative filtering~ CITATION , multi-task learning~ CITATION  or classification with multiple classes~ CITATION
In this paper, we consider the rank consistency of trace norm regularization with the square loss, i e , if the data were actually generated by a low-rank matrix, will the matrix and its rank be consistently estimated
In \mysec{consistency}, we provide necessary and sufficient conditions for the rank consistency that are extensions of corresponding results for the Lasso~ CITATION   and the group Lasso~ CITATION
We do so under two sets of sampling assumptions detailed in \mysec{assumptions}: a full  iid  assumption and a non  iid  assumption which is natural in the context of collaborative filtering
As for the Lasso and the group Lasso, the necessary condition implies that such procedures do not always estimate the rank correctly; following the adaptive version of the Lasso and group Lasso~ CITATION , we design an adaptive version to achieve  SYMBOL -consistency and rank consistency, with no consistency conditions
Finally,  in \mysec{algorithms}, we present a smoothing approach to convex optimization with the trace norm, while  in \mysec{simulations}, we show simulations on toy examples to illustrate the consistency results
### abstract ###
This paper describes an efficient reduction of the learning problem of ranking to binary classification
The reduction guarantees an average pairwise misranking regret of at most that of the binary classifier regret, improving a recent result of Balcan et al which only guarantees a factor of  SYMBOL
Moreover, our reduction applies to a broader class of ranking loss functions, admits a simpler proof, and the expected running time complexity of our algorithm in terms of number of calls to a classifier or preference function is improved from  SYMBOL  to  SYMBOL
In addition, when the top  SYMBOL  ranked elements only are required ( SYMBOL ), as in many applications in information extraction or search engines, the time complexity of our algorithm can be further reduced to  SYMBOL
Our reduction and algorithm are thus practical for realistic applications where the number of points to rank exceeds several thousands
Much of our results also extend beyond the bipartite case previously studied
Our rediction is a randomized one
To complement our result, we  also derive lower bounds on any deterministic reduction from  binary (preference) classification to ranking, implying that our use of a randomized reduction is essentially necessary for the guarantees we provide
### introduction ###
The learning problem of ranking arises in many modern applications, including the design of search engines, information extraction, and movie recommendation systems
In these applications, the ordering of the documents or movies returned is a critical aspect of the system
The problem has been formulated within two distinct settings
In the  score-based setting , the learning algorithm receives a labeled sample of pairwise preferences and returns a  scoring function   SYMBOL  which induces a linear ordering of the points in the set  SYMBOL
Test points are simply ranked according to the values of  SYMBOL  for those points
Several ranking algorithms, including RankBoost  CITATION , SVM-type ranking  CITATION , and other algorithms such as PRank  CITATION , were designed for this setting
Generalization bounds have been given in this setting for the pairwise misranking error  CITATION , including margin-based bounds  CITATION
Stability-based generalization bounds have also been given in this setting for wide classes of ranking algorithms both in the case of bipartite ranking  CITATION  and the general case  CITATION
A somewhat different two-stage scenario was considered in other publications starting with Cohen, Schapire, and Singer  CITATION , and later Balcan et al CITATION , which we will refer to as the  preference-based setting
In the first stage of that setting, a  preference function   SYMBOL  is learned, where values of  SYMBOL  closer to one indicate that  SYMBOL  is ranked above  SYMBOL  and values closer to zero the opposite
SYMBOL  is typically assumed to be the output of a classification algorithm trained on a sample of labeled pairs, and can be for example a convex combination of simpler preference functions as in  CITATION
A crucial difference with the score-based setting is that, in general, the preference function  SYMBOL  does not induce a linear ordering
The order it induces may be non-transitive, thus we may have for example  SYMBOL  for three distinct points  SYMBOL ,  SYMBOL , and  SYMBOL
To rank a test subset  SYMBOL , in the second stage, the algorithm orders the points in  SYMBOL  by making use of the preference function  SYMBOL  learned in the first stage
This paper deals with the preference-based ranking setting just described
The advantage of this setting is that the learning algorithm is not required to return a linear ordering of all points in  SYMBOL , which is impossible to achieve faultlessly in accordance with a true pairwise preference labeling that is non-transitive
This is more likely to be achievable exactly or with a better approximation when the algorithm is requested instead, as in this setting, to supply a linear ordering, only for a limited subset  SYMBOL
When the preference function is learned by a binary classification algorithm, the preference-based setting can be viewed as a reduction of the ranking problem to a classification one
The second stage specifies how the ranking is obtained using the preference function
Cohen, Schapire, and Singer  CITATION  showed that in the second stage of the preference-based setting, the general problem of finding a linear ordering with as few pairwise misrankings as possible with respect to the preference function  SYMBOL  is NP-complete
The authors presented a greedy algorithm based on the tournament  degree  for each element  SYMBOL  defined as the difference between the number of elements  SYMBOL  is preferred to versus the number of those preferred to  SYMBOL
The bound proven by these authors, formulated in terms of the pairwise disagreement loss  SYMBOL  with respect to the preference function  SYMBOL , can be written as  SYMBOL , where  SYMBOL  is the loss achieved by the permutation  SYMBOL  returned by their algorithm and  SYMBOL  the one achieved by the optimal permutation  SYMBOL  with respect to the preference function  SYMBOL
This bound was given for the general case of ranking, but in the particular case of bipartite ranking (which we define below), a random ordering can achieve a pairwise disagreement loss of  SYMBOL  and thus the bound is not informative
More recently, Balcan et al  CITATION  studied the bipartite ranking problem and showed that sorting the elements of  SYMBOL  according to the same tournament degree used by  CITATION  guarantees a pairwise misranking regret of at most  SYMBOL  using a binary classifier with regret  SYMBOL
However, due to the quadratic nature of the definition of the tournament degree, their algorithm requires  SYMBOL  calls to the preference function  SYMBOL , where  SYMBOL  is the number of objects to rank
We describe an efficient algorithm for the second stage of preference-based setting and thus for reducing the learning problem of ranking to binary classification
We improve on the recent result of Balcan et al CITATION , by guaranteeing an average pairwise misranking regret of at most  SYMBOL  using a binary classifier with regret  SYMBOL
In other words, we improve their constant from  SYMBOL  to  SYMBOL
Our reduction applies (with different constants) to a broader class of ranking loss functions, admits a simpler proof, and the expected running time complexity of our algorithm in terms of number of calls to a classifier or preference function is improved from  SYMBOL  to  SYMBOL
Furthermore, when the top  SYMBOL  ranked elements only are required ( SYMBOL ), as in many applications in information extraction or search engines, the time complexity of our algorithm can be further reduced to  SYMBOL
Our reduction and algorithm are thus practical for realistic applications where the number of points to rank exceeds several thousands
Much of our results also extend beyond the bipartite case previously studied by  CITATION  to the general case of ranking
A by-product of our proofs is also a bound on the pairwise disagreement loss with respect to the preference function  SYMBOL  that we will compare to the result given by Cohen, Schapire, and Singer  CITATION
The algorithm used by Balcan et al CITATION  to produce a ranking based on the preference function is known as sort-by-degree and has been recently used in the context of minimizing the feedback arcset in tournaments  CITATION
Here, we use a different algorithm, QuickSort, which has also been recently used for minimizing the feedback arcset in tournaments  CITATION
The techniques presented make use of the earlier work by Ailon et al on combinatorial optimization problems over rankings and clustering  CITATION
The remainder of the paper is structured as follows
In Section~, we introduce the definitions and notation used in future sections and introduce a family of general loss functions that can be used to measure the quality of a ranking hypothesis
Section~ describes a simple and efficient algorithm for reducing ranking to binary classification, proves several bounds guaranteeing the quality of the ranking produced by the algorithm, and shows the running-time complexity of our algorithm to be very efficient
In Section~ we discuss the relationship of the algorithm and its proof with previous related work in combinatorial optimization
In Section~ we derive a lower bound of factor  SYMBOL  on any deterministic reduction from  binary (preference) classification to ranking, implying that our use of a randomized reduction is essentially necessary for the improved guarantees we provide
### abstract ###
In recent years, spectral clustering has become one of the most popular modern clustering algorithms
It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm
On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does
The goal of this tutorial is to give some intuition on those questions
We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches
Advantages and disadvantages of the different spectral clustering algorithms are discussed
### introduction ###
Clustering is one of the most widely used techniques for exploratory data analysis, with applications ranging from statistics, computer science, biology to social sciences or psychology
In virtually every scientific field dealing with empirical data, people attempt to get a first impression on their data by trying to identify groups of ``similar behavior'' in their data
In this article we would like to introduce the reader to the family of spectral clustering algorithms
Compared to the ``traditional algorithms'' such as  SYMBOL -means or single linkage, spectral clustering has many fundamental advantages
Results obtained by spectral clustering often outperform the traditional approaches, spectral clustering is very simple to implement and can be solved efficiently by standard linear algebra methods \\  This tutorial is set up as a self-contained introduction to spectral clustering
We derive spectral clustering from scratch and present different points of view to why spectral clustering works
Apart from basic linear algebra, no particular mathematical background is required by the reader
However, we do not attempt to give a concise review of the whole literature on spectral clustering, which is impossible due to the overwhelming amount of literature on this subject
The first two sections are devoted to a step-by-step introduction to the mathematical objects used by spectral clustering: similarity graphs in Section , and graph Laplacians in Section
The spectral clustering algorithms themselves will be presented in Section
The next three sections are then devoted to explaining why those algorithms work
Each section corresponds to one explanation: Section  describes a graph partitioning approach, Section  a random walk perspective, and Section  a perturbation theory approach
In Section  we will study some practical issues related to spectral clustering, and discuss various extensions and literature related to spectral clustering in Section
### abstract ###
Building rules on top of ontologies is the ultimate goal of the logical layer of the Semantic Web
To this aim an ad-hoc mark-up language for this layer is currently under discussion
It is intended to follow the tradition of hybrid knowledge representation and reasoning systems such as  SYMBOL -log that integrates the description logic  SYMBOL  and the function-free Horn clausal language \textsc{Datalog}
In this paper we consider the problem of automating the acquisition of these rules for the Semantic Web
We propose a general framework for rule induction that adopts the methodological apparatus of Inductive Logic Programming and relies on the expressive and deductive power of  SYMBOL -log
The framework is valid whatever the scope of induction (description vs prediction) is
Yet, for illustrative purposes, we also discuss an instantiation of the framework which aims at description and turns out to be useful in Ontology Refinement
### introduction ###
During the last decade increasing attention has been paid on  ontologies  and their role in Knowledge Engineering  CITATION
In the philosophical sense, we may refer to an ontology as a particular system of categories accounting for a certain vision of the world
As such, this system does not depend on a particular language: Aristotle's ontology is always the same, independently of the language used to describe it
On the other hand, in its most prevalent use in Artificial Intelligence, an ontology refers to an engineering artifact (more precisely, produced according to the principles of  Ontological Engineering   CITATION ), constituted by a specific vocabulary used to describe a certain reality, plus a set of explicit assumptions regarding the intended meaning of the vocabulary words
This set of assumptions has usually the form of a first-order logical theory, where vocabulary words appear as unary or binary predicate names, respectively called concepts and relations
In the simplest case, an ontology describes a hierarchy of concepts related by subsumption relationships; in more sophisticated cases, suitable axioms are added in order to express other relationships between concepts and to constrain their intended interpretation
The two readings of ontology described above are indeed related each other, but in order to solve the terminological impasse the word conceptualization is used to refer to the philosophical reading as appear in the following definition, based on  CITATION :  An ontology is a formal explicit specification of a shared conceptualization for a domain of interest
Among the other things, this definition emphasizes the fact that an ontology has to be specified in a language that comes with a formal semantics
Only by using such a formal approach ontologies provide the machine interpretable meaning of concepts and relations that is expected when using an ontology-based approach
Among the formalisms proposed by Ontological Engineering, the most currently used are  Description Logics  (DLs)  CITATION
Note that DLs are decidable fragments of First Order Logic (FOL) that are incomparable with Horn Clausal Logic (HCL) as regards the expressive power  CITATION  and the semantics  CITATION  } Ontology Engineering, notably its DL-based approach, is playing a relevant role in the definition of the  Semantic Web
The Semantic Web is the vision of the World Wide Web enriched by machine-processable information which supports the user in his tasks  CITATION
The architecture of the Semantic Web is shown in Figure
It consists of several layers, each of which is equipped with an ad-hoc mark-up language
In particular, the design of the mark-up language for the  ontological layer , OWL}, has been based on the very expressive DL  SYMBOL   CITATION
Whereas OWL is already undergoing the standardization process at W3C, the debate around a unified language for  rules  is still ongoing
Proposals like SWRL} extend OWL with constructs inspired to Horn clauses in order to meet the primary requirement of the  logical layer : 'to build rules on top of ontologies'
SWRL is intended to bridge the notorious gaps between DLs and HCL in a way that is similar in the spirit to hybridization in Knowledge Representation and Reasoning (KR\&R) systems such as  SYMBOL -log  CITATION
Generally speaking,  hybrid systems  are KR\&R systems which are constituted by two or more subsystems dealing with distinct portions of a single knowledge base by performing specific reasoning procedures  CITATION
The motivation for investigating and developing such systems is to improve on two basic features of KR\&R formalisms, namely  representational adequacy  and  deductive power , by preserving the other crucial feature, i e decidability
In particular, combining DLs with HCL can easily yield to undecidability if the interface between them is not reduced  CITATION
The hybrid system  SYMBOL -log integrates  SYMBOL   CITATION  and \textsc{Datalog}  CITATION  by using  SYMBOL  concept assertions essentially as type constraints on variables
It has been very recently mentioned as the blueprint for  well-founded  Semantic Web rule mark-up languages because its underlying form of integration (called  safe ) assures semantic and computational advantages that SWRL - though more expressive than  SYMBOL -log - currently can not assure  CITATION
Defining rules (including the ones for the Semantic Web) has been usually considered as a demanding task from the viewpoint of Knowledge Engineering
It is often supported by Machine Learning algorithms that can vary in the approaches
The approach known under the name of Inductive Logic Programming (ILP) seems to be promising for the case at hand due to the common roots with Logic Programming  CITATION
ILP has been historically concerned with rule induction from examples and background knowledge within the representation framework of HCL and with the aim of prediction  CITATION
More recently ILP has moved towards either different FOL fragments (e g , DLs) or new learning goals (e g , description)
In this paper we resort to the methodological apparatus of ILP to define a  general  framework for learning rules on top of ontologies for the Semantic Web within the KR\&R framework of  SYMBOL -log
The framework proposed is general in the sense that it is valid whatever the scope of induction (description vs prediction) is
For the sake of illustration we concentrate on an instantiation of the framework for the case of description
The paper is organized as follows
Section  introduces the basic notions of  SYMBOL -log
Section  defines the framework for learning rules in  SYMBOL -log
Section  illustrates an instantiation of the framework
Section  concludes the paper with final remarks
clarifies the links between OWL and DLs
### abstract ###
Higher-order tensor decompositions are analogous to the familiar Singular Value Decomposition (SVD), but they transcend the limitations of matrices (second-order tensors)
SVD is a powerful tool that has achieved impressive results in information retrieval, collaborative filtering, computational linguistics, computational vision, and other fields
However, SVD is limited to two-dimensional arrays of data (two modes), and many potential applications have three or more modes, which require higher-order tensor decompositions
This paper evaluates four algorithms for higher-order tensor decomposition: Higher-Order Singular Value Decomposition (HO\nobreakdash-SVD), Higher-Order Orthogonal Iteration (HOOI), Slice Projection (SP), and Multislice Projection (MP)
We measure the time (elapsed run time), space (RAM and disk space requirements), and fit (tensor reconstruction accuracy) of the four algorithms, under a variety of conditions
We find that standard implementations of HO\nobreakdash-SVD and HOOI do not scale up to larger tensors, due to increasing RAM requirements
We recommend HOOI for tensors that are small enough for the available RAM and MP for larger tensors
### introduction ###
Singular Value Decomposition (SVD) is growing increasingly popular as a tool for the analysis of two-dimensional arrays of data, due to its success in a wide variety of applications, such as information retrieval  CITATION , collaborative filtering  CITATION , computational linguistics  CITATION , computational vision  CITATION , and genomics  CITATION
SVD is limited to two-dimensional arrays (matrices or second-order tensors), but many applications require higher-dimensional arrays, known as higher-order tensors
There are several higher-order tensor decompositions, analogous to SVD, that are able to capture higher-order structure that cannot be modeled with two dimensions (two modes)
Higher-order generalizations of SVD include Higher-Order Singular Value Decomposition (HO\nobreakdash-SVD)  CITATION , Tucker decomposition  CITATION , and PARAFAC (parallel factor analysis)  CITATION , which is also known as CANDECOMP (canonical decomposition)  CITATION
Higher-order tensors quickly become unwieldy
The number of elements in a matrix increases quadratically, as the product of the number of rows and columns, but the number of elements in a third-order tensor increases cubically, as a product of the number of rows, columns, and tubes
Thus there is a need for tensor decomposition algorithms that can handle large tensors
In this paper, we evaluate four algorithms for higher-order tensor decomposition: Higher-Order Singular Value Decomposition (HO\nobreakdash-SVD)  CITATION , Higher-Order Orthogonal Iteration (HOOI)  CITATION , Slice Projection (SP)  CITATION , and Multislice Projection (MP) (introduced here)
Our main concern is the ability of the four algorithms to scale up to large tensors
In Section~, we motivate this work by listing some of the applications for higher-order tensors
In any field where SVD has been useful, there is likely to be a third or fourth mode that has been ignored, because SVD only handles two modes
The tensor notation we use in this paper is presented in Section~
We follow the notational conventions of \newcite{kolda2006moh}
Section~ presents the four algorithms, HO\nobreakdash-SVD, HOOI, SP, and MP
For HO\nobreakdash-SVD and HOOI, we used the implementations given in the MATLAB Tensor Toolbox  CITATION
For SP and MP, we created our own MATLAB implementations
Our implementation of MP for third-order tensors is given in the Appendix
Section~ presents our empirical evaluation of the four tensor decomposition algorithms
In the experiments, we measure the time (elapsed run time), space (RAM and disk space requirements), and fit (tensor reconstruction accuracy) of the four algorithms, under a variety of conditions
The first group of experiments looks at how the algorithms scale as the input tensors grow increasingly larger
We test the algorithms with random sparse third-order tensors as input
HO\nobreakdash-SVD and HOOI exceed the available RAM when given larger tensors as input, but SP and MP are able to process large tensors with low RAM usage and good speed
HOOI provides the best fit, followed by MP, then SP, and lastly HO\nobreakdash-SVD
The second group of experiments examines the sensitivity of the fit to the balance in the ratios of the core sizes (defined in Section~)
The algorithms are tested with random sparse third-order tensors as input
In general, the fit of the four algorithms follows the same pattern as in the first group of experiments (HOOI gives the best fit, then MP, SP, and HO\nobreakdash-SVD), but we observe that SP is particularly sensitive to unbalanced ratios of the core sizes
The third group explores the fit with varying ratios between the size of the input tensor and the size of the core tensor
For this group, we move from third-order tensors to fourth-order tensors
The algorithms are tested with random fourth-order tensors, with the input tensor size fixed while the core sizes vary
The fit of the algorithms follows the same pattern as in the previous two groups of experiments, in spite of the move to fourth-order tensors
The final group measures the performance with a real (nonrandom) tensor that was generated for a task in computational linguistics
The fit follows the same pattern as in the previous three groups of experiments
Furthermore, the differences in fit are reflected in the performance on the given task
This experiment validates the use of random tensors in the previous three groups of experiments
We conclude in Section~
There are tradeoffs in time, space, and fit for the four algorithms, such that there is no absolute winner among the four algorithms
The choice will depend on the time, space, and fit requirements of the given application
If good fit is the primary concern, we recommend HOOI for smaller tensors that can fit in the available RAM, and MP for larger tensors
### abstract ###
%\baselineskip=18pt Recent spectral clustering methods are a propular and powerful technique for data clustering
These methods need to solve the eigenproblem whose computational complexity is  SYMBOL , where  SYMBOL  is the number of data samples
In this paper, a non-eigenproblem based clustering method is proposed to deal with the clustering problem
Its performance is comparable to the spectral clustering algorithms but it is more efficient with computational complexity  SYMBOL
We show that with a transitive distance and an observed property, called K-means duality, our algorithm can be used to handle data sets with complex cluster shapes, multi-scale clusters, and noise
Moreover, no parameters except the number of clusters need to be set in our algorithm
### introduction ###
Data clustering is an important technique in many applications such as data mining, image processing, pattern recognition, and computer vision
Much effort has been devoted to this research~ CITATION ,  CITATION ,  CITATION ,  CITATION ,  CITATION ,  CITATION ,  CITATION ,  CITATION
A basic principle (assumption) that guides the design of a clustering algorithm is:    Consistency :  Data within the same cluster are closed to  each other, while data belonging to different clusters are relatively far away
According to this principle, the hierarchy approach  CITATION  begins with a trivial clustering scheme where every sample is a cluster, and then iteratively finds the closest (most similar) pairs of clusters and merges them into larger clusters
This technique totally depends on local structure of data, without optimizing a global function
An easily observed disadvantage of this approach is that it often fails when a data set consists of multi-scale clusters  CITATION
Besides the above consistency assumption, methods like the K-means and EM also assume that a data set has some kind of underlying structures (hyperellipsoid-shaped or Gaussian distribution) and thus any two clusters can be separated by hyperplanes
In this case, the commonly-used Euclidean distance is suitable for the clustering purpose
With the introduction of kernels, many recent methods like spectral clustering  CITATION ,  CITATION  consider that clusters in a data set may have more complex shapes other than compact sample clouds
In this general case, kernel-based techniques are used to achieve a reasonable distance measure among the samples
In  CITATION , the eigenvectors of the distance matrix play a key role in clustering
To overcome the problems such as multi-scale clusters in  CITATION , Zelnik-manor and Perona proposed self-tuning spectral clustering, in which the local scale of the data and the structure of the eigenvectors of the distance matrix are considered~ CITATION
Impressive results have been demonstrated by spectral clustering and it is regarded as the most promising clustering technique  CITATION
However, most of the current kernel related clustering methods, including spectral clustering that is unified to the kernel K-means framework in  CITATION , need to solve the eigenproblem, suffering from high computational cost when the data set is large
In this paper, we tackle the clustering problem where the clusters can be of complex shapes
By using a transitive distance measure and an observed property, called K-means duality, we show that if the consistency condition is satisfied, the clusters of arbitrary shapes can be mapped to a new space where the clusters are more compact and easier to be clustered by the K-means algorithm
With comparable performance to the spectral algorithms, our algorithm does not need to solve the eigenproblem and is more efficient with computational complexity  SYMBOL  than the spectral algorithms whose complexities are  SYMBOL , where  SYMBOL  is the number of samples in a data set
The rest of this paper is structured as follows
In Section~, we discuss the transitive distance measure through a graph model of a data set
In Section~, the duality of the K-means algorithm is proposed and its application to our clustering algorithm is explained
Section~ describes our algorithm and presents a scheme to reduce the computational complexity
Section~ shows experimental results on some synthetic data sets and benchmark data sets, together with comparisons to the K-means algorithm and the spectral algorithms in  CITATION  and  CITATION
The conclusions are given in Section~
### abstract ###
For a classification problem described by the joint density  SYMBOL , models of  SYMBOL  (the ``Bayesian similarity measure'') have been shown to be an optimal similarity measure for nearest neighbor classification
This paper analyzes demonstrates several additional properties of that conditional distribution
The paper first shows that we can reconstruct, up to class labels, the class  posterior distribution  SYMBOL  given  SYMBOL , gives a procedure for recovering the class labels, and gives an asymptotically Bayes-optimal classification procedure
It also shows, given such an optimal similarity measure, how to construct a classifier that outperforms the nearest neighbor classifier and achieves Bayes-optimal classification rates
The paper then analyzes Bayesian similarity in a framework where a classifier faces a number of related classification tasks (multitask learning) and illustrates that reconstruction of the class posterior distribution is not possible in general
Finally, the paper identifies a distinct class of classification problems using  SYMBOL  and shows that using  SYMBOL  to solve those problems is the Bayes optimal solution
### introduction ###
Statistical models of similarity have become increasingly important in recent work on information retrieval  CITATION , case-based reasoning  CITATION , pattern recognition CITATION , and computer vision  CITATION
Of particular interest is Bayesian similarity, a discriminatively trained model of  SYMBOL , which we will abbreviate as  SYMBOL
These models have been demonstrated to work well in a number of pattern recognition and visual object recognition problems  CITATION
It is easy to see that nearest neighbor classification using  SYMBOL  minimizes the risk that the class labels for  SYMBOL  and  SYMBOL  differ and therefore is optimal for 1-nearest neighbor classification  CITATION
However, beyond that observation, there have been several kinds of analysis of Bayesian similarity
The first, presented by Mahamud  CITATION  is an analysis considering a single instance of a classification problem, determined by a joint distribution  SYMBOL  of class labels  SYMBOL  and feature vectors  SYMBOL
The authors also argue for the existence of useful invariance properties of Bayesian similarity functions when those functions have a specific form  CITATION
The second is an analysis based on a hierarchical Bayesian framework presented by Breuel  CITATION , which effectively considers Bayesian similarity in the context of a distribution of related classification tasks
This paper analyzes the relationship between Bayesian similarity  SYMBOL  and the class posterior distribution  SYMBOL   in both the non-hierarchical and hierarchical cases and uses those results to construct an asymptotically Bayes-optimal classification procedure using Bayesian similarity
It also presents a new statistical model for the kinds of discrimination tasks described in  CITATION  and  demonstrates that Bayesian similarity is the Bayes-optimal solution for those tasks
The implications of these results for applications of Bayesian similarity will be discussed at the end
### abstract ###
Learning machines that have  hierarchical structures or hidden variables  are singular statistical models because they are nonidentifiable and  their Fisher information matrices are singular
In singular statistical models, neither  does the Bayes  a posteriori  distribution converge to the normal distribution nor does the maximum likelihood estimator satisfy asymptotic normality
This is the main reason that it has been difficult to  predict their generalization performance from trained states
In this paper, we study four errors,  (1) the Bayes generalization error, (2) the Bayes training error, (3) the Gibbs generalization error, and (4) the Gibbs training error, and prove that there are universal mathematical relations among  these errors
The formulas proved in this paper are equations of states in statistical estimation because they hold for any true distribution, any parametric model, and any  a priori  distribution
Also we show that the Bayes and Gibbs generalization errors can be  estimated by Bayes and Gibbs training errors, and we propose  widely applicable information criteria that can be applied to both regular and singular statistical models
### introduction ###
Recently, many learning machines are being used in information processing systems
For  example, layered neural networks, normal mixtures, binomial mixtures, Bayes networks, Boltzmann machines, reduced rank regressions, hidden Markov models, and stochastic context-free grammars  are being employed in pattern recognition, time series  prediction, robotic control, human modeling,  and biostatistics
Although their generalization performances determine the accuracy of the information systems,  it has been difficult to estimate generalization  errors based on training errors, because such  learning machines are singular statistical models
A parametric model is called regular if the mapping from the parameter to the  probability distribution is one-to-one and if its Fisher information matrix is always positive definite
If a statistical model is regular, then  the Bayes  a posteriori  distribution converges to the normal distribution,  and the maximum likelihood estimator satisfies  asymptotic normality
Based on such properties,  the relation between the generalization error and the training error was clarified, on which some information criteria  were proposed
On the other hand, if the mapping from the  parameter to the probability distribution is not one-to-one or if the Fisher information matrix is  singular, then the parametric model is called singular
In general, if a learning machine has hierarchical structure or hidden variables, then it is singular
Therefore, almost all learning machines are singular
For singular learning machines, the log likelihood  function can not be approximated by any quadratic form of the parameter, with the result that the conventional relationship between generalization errors and  training errors does not hold either for the maximum likelihood method  CITATION   CITATION  CITATION  or  Bayes estimation  CITATION
Singularities strongly affect generalization performances  CITATION  and learning dynamics  CITATION
Therefore, in order to establish the mathematical foundation of singular learning theory, it is necessary  to construct the formulas which hold even in singular learning machines
Recently, we proved  CITATION  CITATION  that the  generalization error in Bayes estimation is asymptotically equal to  SYMBOL , where  SYMBOL  is the rational number  determined by the zeta function of a learning machine and  SYMBOL  is the number of training samples
In regular statistical models,  SYMBOL ,  where  SYMBOL  is the dimension of the parameter space, whereas in singular statistical models,  SYMBOL   depends strongly on the learning machine, the true distribution, and the  a priori  probability distribution
In practical applications, the true distribution is often unknown, hence it has been difficult to estimate the generalization error from the training error
To estimate the generalization error when we do not have any information about the true distribution, we need a general formula which holds independently of singularities
In this paper, we study four errors,  (1) the Bayes generalization error  SYMBOL , (2) the Bayes training error  SYMBOL , (3) the Gibbs generalization error  SYMBOL , and (4) the Gibbs training error  SYMBOL , and prove the formulas  SYMBOL *} where  SYMBOL  denotes the expectation value and   SYMBOL  is the inverse temperature  of the  a posteriori  distribution
These equations assert that the increased error from training to  generalization is in proportion to  the difference between the Bayes and Gibbs training errors
It should be emphasized that these formulas hold for any true distribution, any learning machine,  any  a priori  probability distribution, and any singularities, therefore they reflect the universal laws of statistical estimation
Also,  based on the formula, we propose widely applicable information  criteria (WAIC) which can be applied to both regular and singular learning machines
In other words, we can apply WAIC without  any knowledge about the true distribution
This paper consists of six parts
In Section 2, we  describe the main results of this paper
In Section 3,  we propose widely applicable information criteria  and show how to apply them to statistical estimation
In Section 4, we prove the main results in the mathematically rigorous way
In Sections 5 and 6, we discuss and conclude of this paper
The proofs of lemmas are quite technical hence they are presented in Appendix
### abstract ###
Markov random fields are used to model high dimensional distributions in a number of applied areas
Much recent interest has been devoted to the reconstruction of the dependency structure from independent samples from the Markov random fields
We analyze a simple algorithm for reconstructing the underlying graph defining a Markov random field on  SYMBOL  nodes and maximum degree  SYMBOL  given observations
We show that under mild non-degeneracy conditions it reconstructs the generating graph with high probability using  SYMBOL  samples where  SYMBOL  depend on the local interactions
For most local interaction  SYMBOL  are of order  SYMBOL
Our results are optimal as a function of  SYMBOL  up to a multiplicative constant depending on  SYMBOL  and the strength of the local interactions
Our results seem to be the first results for general models that guarantee that  the  generating model is reconstructed
Furthermore, we provide explicit  SYMBOL  running time bound
In cases where the measure on the graph has correlation decay, the running time is  SYMBOL  for all fixed  SYMBOL
We also discuss the effect of observing noisy samples and show that as long as the noise level is low, our algorithm is effective
On the other hand, we construct an example where large noise implies non-identifiability even for generic noise and interactions
Finally, we briefly show that in some simple cases, models with hidden nodes can also be recovered
### introduction ###
In this paper we consider the problem of reconstructing the graph structure of a Markov random field from independent and identically distributed samples
Markov random fields (MRF) provide a very general framework for defining high dimensional distributions and the reconstruction of the MRF from observations has attracted much recent interest, in particular in biology, see eg ~ CITATION  and a list of related references~ CITATION
### abstract ###
We consider the problem of choosing a density estimate from a set of distributions~ SYMBOL , minimizing the  SYMBOL -distance to an unknown distribution ( CITATION )
Devroye and Lugosi~ CITATION  analyze two algorithms for the problem: Scheff\'e tournament winner and minimum distance estimate
The Scheff\'e tournament estimate requires fewer computations than the minimum distance estimate, but has strictly weaker guarantees than the latter
We focus on the computational aspect of density estimation
We present two algorithms, both with the same guarantee as the minimum distance estimate
The first one, a modification of the minimum distance estimate, uses the same number (quadratic in  SYMBOL ) of computations as the Scheff\'e tournament
The second one, called ``efficient minimum loss-weight estimate,'' uses only a linear number of computations, assuming that  SYMBOL  is preprocessed
We also give examples showing that the guarantees of the algorithms cannot be improved and explore randomized algorithms for density estimation
### introduction ###
We study the following density estimation problem considered in~ CITATION
There is an unknown distribution  SYMBOL  and we are given  SYMBOL  (not necessarily independent) samples which define empirical distribution  SYMBOL
Given a finite class  SYMBOL  of distributions, our objective is to output  SYMBOL  such that the error  SYMBOL  is minimized
The use of the  SYMBOL -norm is well justified by it has many useful properties, for example, scale invariance and the fact that approximate identification of a distribution in the  SYMBOL -norm gives an estimate for the probability of every event
The following two parameters influence the error of a possible estimate: the distance of  SYMBOL  from  SYMBOL  and the empirical error
The first parameter is required since we have no control over  SYMBOL , and hence we cannot select a distribution which is better than the ``optimal'' distribution in  SYMBOL , that is, the one closest to  SYMBOL  in  SYMBOL -norm
It is not obvious how to define the second parameter---the error of  SYMBOL  with respect to  SYMBOL
We follow the definition of~ CITATION , which is inspired by~ CITATION  (see Section~ for a precise definition)
Devroye and Lugosi~ CITATION  analyze two algorithms in this setting: Scheff\'e tournament winner and minimum distance estimate
The minimum distance estimate, defined by Yatracos~ CITATION , is a special case of the minimum distance principle, formalized by Wolfowitz in~ CITATION
The minimum distance estimate is a helpful tool, for example, it was used by~ CITATION  to obtain estimates for the smoothing factor for kernel density estimates and also by~ CITATION  for hypothesis testing
The Scheff\'e tournament winner algorithm requires fewer computations than the minimum distance estimate, but it has strictly weaker guarantees (in terms of the two parameters mentioned above) than the latter
Our main contribution are two procedures for selecting an estimate from  SYMBOL , both of which have the same guarantees as the minimum distance estimate, but are computationally more efficient
The first has a quadratic (in  SYMBOL ) cost, matching the cost of the Scheff\'e tournament winner algorithm
The second one is even faster, using  linearly  many (in  SYMBOL ) computations (after preprocessing  SYMBOL )
Now we outline the rest of the paper
In Section~ we give the required definitions and introduce the notion of a test-function (a variant of Scheff\'e set)
Then, in Section~, we restate the previous density estimation algorithms (Scheff\'e tournament winner and the minimum distance estimate) using test-functions
Next, in Section~, we present our algorithms
The first one is a modification of the minimum-distance estimate with improved (quadratic in  SYMBOL ) computational cost
The second one, which we call ``efficient minimum loss-weight estimate,'' has only  linear  computational cost after preprocessing  SYMBOL
In Section~ we explore randomized density estimation algorithms
In the final Section~, we give examples showing tightness of the theorems stated in the previous sections
Throughout this paper we focus on the case when  SYMBOL  is finite, in order to compare the computational costs of our estimates to previous ones
However our results generalize in a straightforward way to infinite classes as well if we ignore computational complexity
### abstract ###
A method of  topological grammars  is proposed for multidimensional data approximation
For data with complex topology we define a  principal cubic  complex  of low dimension and given complexity that gives the best approximation for the dataset
This complex is a generalization of linear and non-linear principal manifolds and includes them as particular cases
The problem of optimal principal complex construction is transformed into a series of minimization problems for quadratic functionals
These quadratic functionals have a physically transparent interpretation in terms of elastic energy
For the energy computation, the whole complex is represented as a system of nodes and springs
Topologically, the principal complex is a product of one-dimensional continuums (represented by graphs), and the grammars describe how these continuums transform during the process of optimal complex construction
This factorization of the whole process onto one-dimensional transformations using minimization of quadratic energy functionals allow us to construct efficient algorithms
### introduction ###
In this paper, we discuss a classical problem: how to approximate a finite set  SYMBOL  in  SYMBOL  for relatively large  SYMBOL  by a finite subset of a regular low-dimensional object in  SYMBOL
In application, this finite set is a dataset, and this problem arises in many areas: from data visualization to fluid dynamics
The first hypothesis we have to check is: whether the dataset  SYMBOL  is situated near a low--dimensional affine manifold (plane) in  SYMBOL
If we look for a point, straight line, plane,


that minimizes the average squared distance to the datapoints, we immediately come to the Principal Component Analysis (PCA)
PCA is one of the most seminal inventions in data analysis
Now it is textbook material
Nonlinear generalization of PCA is a great challenge, and many attempts have been made to answer it
Two of them are especially important for our consideration: Kohonen's Self-Organizing Maps (SOM) and principal manifolds
With the  SOM  algorithm  CITATION  we take a finite metric space  SYMBOL  with metric  SYMBOL  and try to map it into  SYMBOL  with (a) the best preservation of initial structure in the image of  SYMBOL  and (b) the best approximation of the dataset  SYMBOL
The  SOM algorithm has several setup variables to regulate the compromise between these goals
We start from some initial approximation of the map,  SYMBOL
On each ( SYMBOL -th) step of the algorithm we have a datapoint  SYMBOL  and a current approximation  SYMBOL
For these  SYMBOL  and  SYMBOL  we define an ``owner" of  SYMBOL  in  SYMBOL :  SYMBOL
The next approximation,  SYMBOL , is  SYMBOL } Here  SYMBOL  is a step size,  SYMBOL  is a monotonically decreasing cutting function
There are many ways to combine steps () in the whole algorithm
The idea of SOM is very flexible and seminal, has plenty of applications and generalizations, but, strictly speaking, we don't know what we are looking for: we have the algorithm, but no independent definition: SOM is a result of the algorithm work
The attempts to define SOM as solution of a minimization problem for some energy functional were not very successful  CITATION
For a known probability distribution,  principal manifolds  were introduced as lines or surfaces passing through ``the middle'' of the data distribution  CITATION
This intuitive vision was transformed into the mathematical notion of  self-consistency : every point  SYMBOL  of the principal manifold  SYMBOL  is a conditional expectation of all points  SYMBOL  that are projected into  SYMBOL
Neither manifold, nor projection should be linear: just a differentiable projection  SYMBOL  of the data space (usually it is  SYMBOL  or a domain in  SYMBOL ) onto the manifold  SYMBOL  with the self-consistency requirement for conditional expectations:  SYMBOL  For a finite dataset  SYMBOL , only one or zero datapoints are typically projected into a point of the principal manifold
In order to avoid overfitting, we have to introduce smoothers that become an essential part of the principal manifold construction algorithms
SOMs give the most popular approximations for principal manifolds: we can take for  SYMBOL  a fragment of a regular  SYMBOL -dimensional grid and consider the resulting SOM as the approximation to the  SYMBOL -dimensional principal manifold (see, for example,  CITATION )
Several original algorithms for construction of principal curves  CITATION  and surfaces for finite datasets were developed during last decade, as well as many applications of this idea
In 1996, in a discussion about SOM at the 5th Russian National Seminar in Neuroinformatics, a method of multidimensional data approximation based on elastic energy minimization was  proposed (see  CITATION  and the bibliography there)
This method is based on the analogy between the principal manifold and the elastic membrane (and plate)
Following the metaphor of elasticity, we introduce two quadratic smoothness penalty terms
This allows one to apply  standard minimization of quadratic functionals (i e , solving a system of linear algebraic equations with a sparse matrix)
